{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Quantization.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbdq0N7yLVIl"
      },
      "source": [
        "#imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision.models as models\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDkf-_XXLW0v",
        "outputId": "9989fe03-d8d2-40f1-e379-c6849dea2793"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9tXXPFALVIl"
      },
      "source": [
        "#read files\n",
        "def unpickle(file):\n",
        "    \n",
        "    with open(file, 'rb') as fo:\n",
        "        dictionary = pickle.load(fo, encoding='bytes')\n",
        "    return dictionary"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL0OLsnaLVIl"
      },
      "source": [
        "#data processing\n",
        "def reshape_images(data_dict):\n",
        "    reshaped = data_dict.numpy().reshape(len(data_dict), 1024, 3, order = 'F').reshape(len(data_dict), 32,32,3)\n",
        "    reshaped_processed = torch.from_numpy(reshaped).float().permute(0, 3, 1, 2)\n",
        "    return reshaped_processed"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GFPamvCLVIm"
      },
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGqiFrInLVIm"
      },
      "source": [
        "#data settings\n",
        "subset = False #for local running\n",
        "DATA_LOCAL = False\n",
        "BATCH_SIZE = 16\n",
        "#mean and std of cifar100 dataset\n",
        "CIFAR100_TRAIN_MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
        "CIFAR100_TRAIN_STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
        "ENABLE_VAL = False #we do not have validation set then\n",
        "#model settings\n",
        "USE_TENSORBOARD = False\n",
        "if USE_TENSORBOARD:\n",
        "    foo = SummaryWriter()\n",
        "use_gpu = True\n",
        "\n",
        "#lr scheduler\n",
        "BASE_LR = 0.001\n",
        "EPOCH_DECAY = 4\n",
        "DECAY_WEIGHT = 0.5\n",
        "\n",
        "DEVICE = 'cpu'\n",
        "if use_gpu and torch.cuda.is_available():\n",
        "    DEVICE = 'cuda'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXe1LxyFLVIm"
      },
      "source": [
        "## Load Data and Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNAIiG6tLVIm"
      },
      "source": [
        "if DATA_LOCAL:\n",
        "    test_dict = unpickle('../cifar-100-python/test')\n",
        "    train_dict = unpickle('../cifar-100-python/train')\n",
        "    meta = unpickle('../cifar-100-python/meta')\n",
        "    label_names = meta[b'fine_label_names']\n",
        "    #load to local\n",
        "    train_data = torch.from_numpy(train_dict[b'data'])\n",
        "    train_y = torch.tensor(train_dict[b'fine_labels'])\n",
        "    test_data = torch.from_numpy(test_dict[b'data'])\n",
        "    test_y = torch.tensor(test_dict[b'fine_labels'])\n",
        "    \n",
        "    def see_plot(phase, sample_id, test_y = test_y, label_names = label_names, test_data = test_data, train_y = train_y, train_data = train_data):\n",
        "    \n",
        "      if phase == 'train':\n",
        "          data = train_data\n",
        "          y = train_y\n",
        "      elif phase == 'test':\n",
        "          data = test_data\n",
        "          y = test_y\n",
        "      assert sample_id < len(data)\n",
        "      plt.imshow(data[sample_id].numpy().reshape(-1,3, order = 'F').reshape(32,32,3))\n",
        "      labeli = y[sample_id].item()\n",
        "      plt.title('label: ' + label_names[labeli].decode(\"utf-8\") + ', label id: ' + str(labeli))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fITfAvHdLVIm"
      },
      "source": [
        "if DATA_LOCAL:\n",
        "    # see pictures by sample id\n",
        "    see_plot('train', 16)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzkWaOhTLVIn"
      },
      "source": [
        "def get_training_dataloader(mean, std, batch_size=16, num_workers=2, shuffle=True, large_subset = False):\n",
        "    \"\"\" return training dataloader\n",
        "    Args:\n",
        "        mean: mean of cifar100 training dataset\n",
        "        std: std of cifar100 training dataset\n",
        "        path: path to cifar100 training python dataset\n",
        "        batch_size: dataloader batchsize\n",
        "        num_workers: dataloader num_works\n",
        "        shuffle: whether to shuffle\n",
        "    Returns: train_data_loader:torch dataloader object\n",
        "    \"\"\"\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        #transforms.ToPILImage(),\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "    ])\n",
        "\n",
        "    cifar100_training = torchvision.datasets.CIFAR100(root='cifar-100-python', train=True, download=True, transform=transform_train)\n",
        "    if subset:\n",
        "        cifar100_training = torch.utils.data.Subset(cifar100_training, [i for i in range(100)])\n",
        "    elif large_subset:\n",
        "        cifar100_training = torch.utils.data.Subset(cifar100_training, list(range(0, len(cifar100_training), 10)))\n",
        "\n",
        "    cifar100_training_loader = DataLoader(\n",
        "        cifar100_training, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n",
        "\n",
        "    return cifar100_training_loader"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_-3P9TwLVIn"
      },
      "source": [
        "def get_test_dataloader(mean, std, batch_size=16, num_workers=2, shuffle=True):\n",
        "    \"\"\" return training dataloader\n",
        "    Args:\n",
        "        mean: mean of cifar100 test dataset\n",
        "        std: std of cifar100 test dataset\n",
        "        path: path to cifar100 test python dataset\n",
        "        batch_size: dataloader batchsize\n",
        "        num_workers: dataloader num_works\n",
        "        shuffle: whether to shuffle\n",
        "    Returns: cifar100_test_loader:torch dataloader object\n",
        "    \"\"\"\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "    ])\n",
        "\n",
        "    cifar100_test = torchvision.datasets.CIFAR100(root='cifar-100-python', train=False, download=True, transform=transform_test)\n",
        "    if subset:\n",
        "        cifar100_test = torch.utils.data.Subset(cifar100_test, [i for i in range(100)])\n",
        "    cifar100_test_loader = DataLoader(\n",
        "        cifar100_test, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n",
        "\n",
        "    return cifar100_test_loader"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doCD-3QhLVIn",
        "outputId": "a62498fc-2acd-4a97-9aff-5c176a560173"
      },
      "source": [
        "CIFAR100_TRAIN_MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
        "CIFAR100_TRAIN_STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
        "cifar100_test_loader = get_test_dataloader(\n",
        "    CIFAR100_TRAIN_MEAN,\n",
        "    CIFAR100_TRAIN_STD,\n",
        "    num_workers = 4,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = False\n",
        ")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEGPXHtwLVIn",
        "outputId": "65140bae-f0cd-4234-df1a-8c975b3ac9cf"
      },
      "source": [
        "cifar100_training_loader = get_training_dataloader(\n",
        "    CIFAR100_TRAIN_MEAN,\n",
        "    CIFAR100_TRAIN_STD,\n",
        "    num_workers = 4,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True\n",
        ")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyGiVH5IU7SV",
        "outputId": "753e6fb4-3e41-4210-cbae-42a959f707b0"
      },
      "source": [
        "cifar100_training_loader_subset = get_training_dataloader(\n",
        "    CIFAR100_TRAIN_MEAN,\n",
        "    CIFAR100_TRAIN_STD,\n",
        "    num_workers = 4,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = False,\n",
        "    large_subset = True\n",
        ")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrR6Ao7sLVIn"
      },
      "source": [
        "dset_loaders = {'train': cifar100_training_loader, \n",
        "                'train_large_subset': cifar100_training_loader_subset, \n",
        "                'test': cifar100_test_loader}\n",
        "dset_sizes = {'train': len(cifar100_training_loader.dataset), \n",
        "              'train_large_subset': len(cifar100_training_loader_subset.dataset), \n",
        "              'test': len(cifar100_test_loader.dataset)}"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqObOH8WLVIn"
      },
      "source": [
        "## Load Model and Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9eseX6yLVIn"
      },
      "source": [
        "#train model\n",
        "def train_model(model, criterion, optimizer, lr_scheduler, num_epochs=5):\n",
        "    \n",
        "    model.to(DEVICE)\n",
        "    since = time.time()\n",
        "\n",
        "    best_model = model\n",
        "    best_acc = 0.0\n",
        "    if ENABLE_VAL:\n",
        "        phases = ['train', 'val']\n",
        "    else:\n",
        "        phases = ['train']\n",
        "        \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in phases:\n",
        "            if phase == 'train':\n",
        "                mode='train'\n",
        "                optimizer = lr_scheduler(optimizer, epoch)\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()\n",
        "                mode='val'\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for index, (inputs, labels) in enumerate(dset_loaders[phase]):\n",
        "                \n",
        "                inputs, labels = inputs.float().to(DEVICE), labels.long().to(DEVICE)\n",
        "\n",
        "                # Set gradient to zero to delete history of computations in previous epoch. Track operations so that differentiation can be done automatically.\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs.data, 1)\n",
        "                \n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    loss = Variable(loss, requires_grad = True)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    \n",
        "                running_loss += loss.item()\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "                if index % 500 == 0 and index > 0:\n",
        "                    print('{}/{} with loss {:.4f}'.format(index, dset_sizes['train']/16, running_loss/index))\n",
        "                \n",
        "            epoch_loss = running_loss / dset_sizes[phase]\n",
        "            epoch_acc = running_corrects.item() / float(dset_sizes[phase])\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val':\n",
        "                if USE_TENSORBOARD:\n",
        "                    foo.add_scalar('epoch_loss',epoch_loss,epoch)\n",
        "                    foo.add_scalar('epoch_acc',epoch_acc,epoch)\n",
        "                if epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model = copy.deepcopy(model)\n",
        "                    pickle.dump(best_model, open('best_model.pkl', 'wb'))\n",
        "                    print('new best accuracy = ',best_acc)\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    print('returning and looping back')\n",
        "    if USE_TENSORBOARD:\n",
        "        foo.close()\n",
        "    return best_model\n",
        "\n",
        "# This function changes the learning rate over the training model.\n",
        "def exp_lr_scheduler(optimizer, epoch, init_lr=BASE_LR, lr_decay_epoch=EPOCH_DECAY):\n",
        "    \"\"\"Decay learning rate by a factor of DECAY_WEIGHT every lr_decay_epoch epochs.\"\"\"\n",
        "    lr = init_lr * (DECAY_WEIGHT**(epoch // lr_decay_epoch))\n",
        "\n",
        "    if epoch % lr_decay_epoch == 0:\n",
        "        print('LR is set to {}'.format(lr))\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "#test model\n",
        "def test_model(model, data = 'test'):\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    \n",
        "    running_loss = 0\n",
        "    running_corrects = 0\n",
        "    with torch.no_grad():\n",
        "      for batch_index, (inputs, labels) in enumerate(dset_loaders[data]):\n",
        "          inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "          outputs = model(inputs)\n",
        "          _, preds = torch.max(outputs.data, 1)\n",
        "          corrects = torch.sum(preds == labels.data) \n",
        "          loss = criterion(outputs, labels)\n",
        "          running_loss += loss\n",
        "          running_corrects += corrects\n",
        "          del inputs\n",
        "          del labels\n",
        "          del outputs\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "    accuracy = (running_corrects / float(dset_sizes['test'])).item()\n",
        "    loss = (running_loss / dset_sizes['test']).item()\n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                'test', loss, accuracy))\n",
        "    return loss, accuracy"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-aNKs-VLVIn"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "cfg = {\n",
        "    'A' : [64,     'M', 128,      'M', 256, 256,           'M', 512, 512,           'M', 512, 512,           'M'],\n",
        "    'B' : [64, 64, 'M', 128, 128, 'M', 256, 256,           'M', 512, 512,           'M', 512, 512,           'M'],\n",
        "    'D' : [64, 64, 'M', 128, 128, 'M', 256, 256, 256,      'M', 512, 512, 512,      'M', 512, 512, 512,      'M'],\n",
        "    'E' : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
        "}\n",
        "\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, features, num_class=100):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.features(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.classifier(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "\n",
        "    input_channel = 3\n",
        "    for l in cfg:\n",
        "        if l == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            continue\n",
        "\n",
        "        layers += [nn.Conv2d(input_channel, l, kernel_size=3, padding=1)]\n",
        "\n",
        "        if batch_norm:\n",
        "            layers += [nn.BatchNorm2d(l)]\n",
        "\n",
        "        layers += [nn.ReLU(inplace=True)]\n",
        "        input_channel = l\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def vgg11_bn():\n",
        "    return VGG(make_layers(cfg['A'], batch_norm=True))\n",
        "\n",
        "def vgg13_bn():\n",
        "    return VGG(make_layers(cfg['B'], batch_norm=True))\n",
        "\n",
        "def vgg16_bn():\n",
        "    return VGG(make_layers(cfg['D'], batch_norm=True))\n",
        "\n",
        "def vgg19_bn():\n",
        "    return VGG(make_layers(cfg['E'], batch_norm=True))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC5eAMvYLVIn"
      },
      "source": [
        "def load_vgg(path):\n",
        "    model = vgg16_bn()\n",
        "    weights = torch.load(path, map_location=DEVICE)\n",
        "    model.load_state_dict(weights)\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od8kKoigLVIn"
      },
      "source": [
        "#vgg16 = load_vgg('../vgg16-197-best.pth')\n",
        "vgg16 = load_vgg('./drive/MyDrive/vgg16-197-best.pth')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AGXh8UqLVIn"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(vgg16.parameters(), lr=0.001)\n",
        "#train_model(vgg16, criterion, optimizer, exp_lr_scheduler, num_epochs = 3);"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a66C8znnLVIn",
        "outputId": "efc74f47-731a-4b44-8610-3b91d46cac87"
      },
      "source": [
        "start = time.time()\n",
        "loss, accuracy = test_model(vgg16)\n",
        "end = time.time()\n",
        "print(loss, accuracy)\n",
        "print('time seconds:', end - start)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Loss: 0.1027 Acc: 0.7201\n",
            "0.10269515216350555 0.7200999855995178\n",
            "time seconds: 136.56451988220215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3R_6hh6LVIn"
      },
      "source": [
        "#visualize tensorboard -- a little buggy...\n",
        "if USE_TENSORBOARD:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvE0OaypLVIn"
      },
      "source": [
        "## Quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFcL3iEDLVIn"
      },
      "source": [
        "def print_size_of_model(model, label=\"\"):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    size=os.path.getsize(\"temp.p\")\n",
        "    print(\"model: \",label,' \\t','Size (KB):', size/1e3)\n",
        "    os.remove('temp.p')\n",
        "    return size"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAjPxo6oLVIn"
      },
      "source": [
        "### Quant Dynamics with no retrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEyFaf11LVIn",
        "outputId": "a1c3ab16-1092-4992-b9cc-616a5453e34d"
      },
      "source": [
        "DEVICE = 'cpu'\n",
        "vgg16_quant1 = torch.quantization.quantize_dynamic(\n",
        "    vgg16.to(DEVICE),  # the original model\n",
        "    {torch.nn.Linear},  # a set of layers to dynamically quantize\n",
        "    dtype=torch.qint8)  # the target dtype for quantized weights\n",
        "start = time.time()\n",
        "loss, accuracy = test_model(vgg16_quant1)\n",
        "end = time.time()\n",
        "print(loss, accuracy)\n",
        "print('time seconds:', end - start)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Loss: 0.1027 Acc: 0.7201\n",
            "0.1027042344212532 0.7200999855995178\n",
            "time seconds: 127.8513925075531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TE61B1wLVIn",
        "outputId": "fee51076-4da4-427a-bdbe-c0adc85b75f8"
      },
      "source": [
        "# compare the sizes\n",
        "f=print_size_of_model(vgg16,\"baseline\")\n",
        "q=print_size_of_model(vgg16_quant1,\"dynamic quantization\")\n",
        "print(\"{0:.2f} times smaller\".format(f/q))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model:  baseline  \t Size (KB): 136126.773\n",
            "model:  dynamic quantization  \t Size (KB): 78277.298\n",
            "1.74 times smaller\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bf06HFZLVIo"
      },
      "source": [
        "### Quant Static with no retrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30Lc6xioLVIo"
      },
      "source": [
        "my_qconfig = torch.quantization.QConfig(activation=torch.quantization.MinMaxObserver.with_args(dtype=torch.quint8), \n",
        "                                        weight=torch.quantization.default_observer.with_args(dtype=torch.qint8))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aovIk9j3LVIo",
        "outputId": "e3f788a9-2e96-4264-95a5-5b58ac1b35e4"
      },
      "source": [
        "vgg16_quant2 = copy.deepcopy(vgg16)\n",
        "#add layers\n",
        "#set_parameter_requires_grad(vgg16_quant2, feature_extracting = True)\n",
        "vgg16_quant2.features = nn.Sequential(torch.quantization.QuantStub(), vgg16_quant2.features)\n",
        "vgg16_quant2.classifier = nn.Sequential(vgg16_quant2.classifier, torch.quantization.DeQuantStub())\n",
        "#set configs\n",
        "#vgg16_quant2.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "vgg16_quant2.qconfig = my_qconfig\n",
        "vgg16_quant2 = torch.quantization.fuse_modules(vgg16_quant2, [['features.1.0', 'features.1.1', 'features.1.2'],\n",
        "                                                             ['features.1.3', 'features.1.4', 'features.1.5'],\n",
        "                                                             ['features.1.7', 'features.1.8', 'features.1.9'],\n",
        "                                                             ['features.1.10', 'features.1.11', 'features.1.12'],\n",
        "                                                             ['features.1.14', 'features.1.15', 'features.1.16'],\n",
        "                                                             ['features.1.17', 'features.1.18', 'features.1.19'],\n",
        "                                                             ['features.1.20', 'features.1.21', 'features.1.22'],\n",
        "                                                             ['features.1.24', 'features.1.25', 'features.1.26'],\n",
        "                                                             ['features.1.27', 'features.1.28', 'features.1.29'],\n",
        "                                                             ['features.1.30', 'features.1.31', 'features.1.32'],\n",
        "                                                             ['features.1.34', 'features.1.35', 'features.1.36'],\n",
        "                                                             ['features.1.37', 'features.1.38', 'features.1.39'],\n",
        "                                                             ['features.1.40', 'features.1.41', 'features.1.42']])\n",
        "vgg16_quant2 = torch.quantization.prepare(vgg16_quant2)\n",
        "loss, accuracy = test_model(vgg16_quant2, data = 'train_large_subset')\n",
        "print(loss, accuracy)\n",
        "vgg16_quant2 = torch.quantization.convert(vgg16_quant2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Loss: 0.0003 Acc: 0.4991\n",
            "0.00025286932941526175 0.499099999666214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/quantization/observer.py:121: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk0t0mlhLVIo",
        "outputId": "4ed9b25c-39ee-41f4-c758-a82d3a00a1e0"
      },
      "source": [
        "start = time.time()\n",
        "loss, accuracy = test_model(vgg16_quant2)\n",
        "end = time.time()\n",
        "print(loss, accuracy)\n",
        "print('time seconds:', end - start)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Loss: 0.1029 Acc: 0.7181\n",
            "0.10290030390024185 0.7181000113487244\n",
            "time seconds: 63.51117753982544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le0u4YLGLVIo",
        "outputId": "126e658d-075e-48e7-8877-76650cfe6899"
      },
      "source": [
        "# compare the sizes\n",
        "f=print_size_of_model(vgg16,\"baseline\")\n",
        "q=print_size_of_model(vgg16_quant2,\"static quantization\")\n",
        "print(\"{0:.2f} times smaller\".format(f/q))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model:  baseline  \t Size (KB): 136126.773\n",
            "model:  static quantization  \t Size (KB): 34067.257\n",
            "4.00 times smaller\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szZ1liJZLVIo"
      },
      "source": [
        "### Quant Static with Retrain -- BUGGY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5HibH0JLVIo",
        "outputId": "3530c627-4e0c-4b8e-8f97-cf32b3f9e8d9"
      },
      "source": [
        "vgg16_quant3 = copy.deepcopy(vgg16)\n",
        "#add layers\n",
        "vgg16_quant3.features = nn.Sequential(torch.quantization.QuantStub(), vgg16_quant3.features)\n",
        "vgg16_quant3.classifier = nn.Sequential(vgg16_quant3.classifier, torch.quantization.DeQuantStub())\n",
        "#set configs\n",
        "vgg16_quant3.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "vgg16_quant3 = torch.quantization.prepare_qat(vgg16_quant3)\n",
        "#retrain\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vgg16_quant3.parameters(), lr=0.001)\n",
        "train_model(vgg16_quant3, criterion, optimizer, exp_lr_scheduler, num_epochs = 1);\n",
        "vgg16_quant3.eval()\n",
        "vgg16_quant3 = torch.quantization.convert(vgg16_quant3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/0\n",
            "----------\n",
            "LR is set to 0.001\n",
            "train Loss: 0.1743 Acc: 0.4400\n",
            "Training complete in 0m 52s\n",
            "Best val Acc: 0.000000\n",
            "returning and looping back\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbg-xC7nLVIo",
        "outputId": "2c5358bb-8342-4993-dfef-1024b1bcaec7"
      },
      "source": [
        "loss, accuracy = test_model(vgg16_quant3)\n",
        "print(loss, accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Loss: 0.0485 Acc: 0.0200\n",
            "0.048465121537446976 0.019999999552965164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4nH7QVcLVIo",
        "outputId": "69d7ebc6-0772-4a71-8ccb-b156771c7d6e"
      },
      "source": [
        "# compare the sizes\n",
        "f=print_size_of_model(vgg16,\"baseline\")\n",
        "q=print_size_of_model(vgg16_quant3,\"static quantization with retrain\")\n",
        "print(\"{0:.2f} times smaller\".format(f/q))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model:  baseline  \t Size (KB): 538686.817\n",
            "model:  static quantization with retrain  \t Size (KB): 134857.157\n",
            "3.99 times smaller\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXiKbe_HLVIo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}