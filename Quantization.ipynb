{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Quantization.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d19fd17a04b4728bb2b2195c58b327f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_82fc5752759f443fa6bca30c329425a6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d760e44eb6f43d99bd41926620c7a8a",
              "IPY_MODEL_45842d4ff78145ed98f8279516a9a9d1"
            ]
          }
        },
        "82fc5752759f443fa6bca30c329425a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d760e44eb6f43d99bd41926620c7a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_964b997747da408695955d0ab0703841",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_343a233f8ef8401da2eb98f879c2ed81"
          }
        },
        "45842d4ff78145ed98f8279516a9a9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cad94dcee1904a6c8441a380429eace7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:08&lt;00:00, 20930432.57it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_629498ba1aea4dada359a892d9aedf13"
          }
        },
        "964b997747da408695955d0ab0703841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "343a233f8ef8401da2eb98f879c2ed81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cad94dcee1904a6c8441a380429eace7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "629498ba1aea4dada359a892d9aedf13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbdq0N7yLVIl"
      },
      "source": [
        "#imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision.models as models\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDkf-_XXLW0v",
        "outputId": "dc698015-5941-4ac4-b97c-3c0df021d573"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9tXXPFALVIl"
      },
      "source": [
        "#read files\n",
        "def unpickle(file):\n",
        "    \n",
        "    with open(file, 'rb') as fo:\n",
        "        dictionary = pickle.load(fo, encoding='bytes')\n",
        "    return dictionary"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL0OLsnaLVIl"
      },
      "source": [
        "#data processing\n",
        "def reshape_images(data_dict):\n",
        "    reshaped = data_dict.numpy().reshape(len(data_dict), 1024, 3, order = 'F').reshape(len(data_dict), 32,32,3)\n",
        "    reshaped_processed = torch.from_numpy(reshaped).float().permute(0, 3, 1, 2)\n",
        "    return reshaped_processed"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GFPamvCLVIm"
      },
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGqiFrInLVIm"
      },
      "source": [
        "#data settings\n",
        "subset = False #for local running\n",
        "DATA_LOCAL = False\n",
        "BATCH_SIZE = 16\n",
        "#mean and std of cifar100 dataset\n",
        "CIFAR100_TRAIN_MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
        "CIFAR100_TRAIN_STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
        "ENABLE_VAL = False #we do not have validation set then\n",
        "#model settings\n",
        "USE_TENSORBOARD = False\n",
        "if USE_TENSORBOARD:\n",
        "    foo = SummaryWriter()\n",
        "use_gpu = True\n",
        "\n",
        "#lr scheduler\n",
        "BASE_LR = 0.001\n",
        "EPOCH_DECAY = 4\n",
        "DECAY_WEIGHT = 0.5\n",
        "\n",
        "DEVICE = 'cpu'\n",
        "if use_gpu and torch.cuda.is_available():\n",
        "    DEVICE = 'cuda'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXe1LxyFLVIm"
      },
      "source": [
        "## Load Data and Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNAIiG6tLVIm"
      },
      "source": [
        "if DATA_LOCAL:\n",
        "    test_dict = unpickle('../cifar-100-python/test')\n",
        "    train_dict = unpickle('../cifar-100-python/train')\n",
        "    meta = unpickle('../cifar-100-python/meta')\n",
        "    label_names = meta[b'fine_label_names']\n",
        "    #load to local\n",
        "    train_data = torch.from_numpy(train_dict[b'data'])\n",
        "    train_y = torch.tensor(train_dict[b'fine_labels'])\n",
        "    test_data = torch.from_numpy(test_dict[b'data'])\n",
        "    test_y = torch.tensor(test_dict[b'fine_labels'])\n",
        "    \n",
        "    def see_plot(phase, sample_id, test_y = test_y, label_names = label_names, test_data = test_data, train_y = train_y, train_data = train_data):\n",
        "    \n",
        "      if phase == 'train':\n",
        "          data = train_data\n",
        "          y = train_y\n",
        "      elif phase == 'test':\n",
        "          data = test_data\n",
        "          y = test_y\n",
        "      assert sample_id < len(data)\n",
        "      plt.imshow(data[sample_id].numpy().reshape(-1,3, order = 'F').reshape(32,32,3))\n",
        "      labeli = y[sample_id].item()\n",
        "      plt.title('label: ' + label_names[labeli].decode(\"utf-8\") + ', label id: ' + str(labeli))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fITfAvHdLVIm"
      },
      "source": [
        "if DATA_LOCAL:\n",
        "    # see pictures by sample id\n",
        "    see_plot('train', 16)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzkWaOhTLVIn"
      },
      "source": [
        "def get_training_dataloader(mean, std, batch_size=16, num_workers=2, shuffle=True, large_subset = False):\n",
        "    \"\"\" return training dataloader\n",
        "    Args:\n",
        "        mean: mean of cifar100 training dataset\n",
        "        std: std of cifar100 training dataset\n",
        "        path: path to cifar100 training python dataset\n",
        "        batch_size: dataloader batchsize\n",
        "        num_workers: dataloader num_works\n",
        "        shuffle: whether to shuffle\n",
        "    Returns: train_data_loader:torch dataloader object\n",
        "    \"\"\"\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        #transforms.ToPILImage(),\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "    ])\n",
        "\n",
        "    cifar100_training = torchvision.datasets.CIFAR100(root='cifar-100-python', train=True, download=True, transform=transform_train)\n",
        "    if subset:\n",
        "        cifar100_training = torch.utils.data.Subset(cifar100_training, [i for i in range(100)])\n",
        "    elif large_subset:\n",
        "        cifar100_training = torch.utils.data.Subset(cifar100_training, list(range(0, len(cifar100_training), 10)))\n",
        "\n",
        "    cifar100_training_loader = DataLoader(\n",
        "        cifar100_training, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n",
        "\n",
        "    return cifar100_training_loader"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_-3P9TwLVIn"
      },
      "source": [
        "def get_test_dataloader(mean, std, batch_size=16, num_workers=2, shuffle=True):\n",
        "    \"\"\" return training dataloader\n",
        "    Args:\n",
        "        mean: mean of cifar100 test dataset\n",
        "        std: std of cifar100 test dataset\n",
        "        path: path to cifar100 test python dataset\n",
        "        batch_size: dataloader batchsize\n",
        "        num_workers: dataloader num_works\n",
        "        shuffle: whether to shuffle\n",
        "    Returns: cifar100_test_loader:torch dataloader object\n",
        "    \"\"\"\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "    ])\n",
        "\n",
        "    cifar100_test = torchvision.datasets.CIFAR100(root='cifar-100-python', train=False, download=True, transform=transform_test)\n",
        "    if subset:\n",
        "        cifar100_test = torch.utils.data.Subset(cifar100_test, [i for i in range(100)])\n",
        "    cifar100_test_loader = DataLoader(\n",
        "        cifar100_test, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n",
        "\n",
        "    return cifar100_test_loader"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "0d19fd17a04b4728bb2b2195c58b327f",
            "82fc5752759f443fa6bca30c329425a6",
            "5d760e44eb6f43d99bd41926620c7a8a",
            "45842d4ff78145ed98f8279516a9a9d1",
            "964b997747da408695955d0ab0703841",
            "343a233f8ef8401da2eb98f879c2ed81",
            "cad94dcee1904a6c8441a380429eace7",
            "629498ba1aea4dada359a892d9aedf13"
          ]
        },
        "id": "doCD-3QhLVIn",
        "outputId": "98c34e5a-f4bd-4cb7-aeef-3ef88e202723"
      },
      "source": [
        "CIFAR100_TRAIN_MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
        "CIFAR100_TRAIN_STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
        "cifar100_test_loader = get_test_dataloader(\n",
        "    CIFAR100_TRAIN_MEAN,\n",
        "    CIFAR100_TRAIN_STD,\n",
        "    num_workers = 4,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = False\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to cifar-100-python/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d19fd17a04b4728bb2b2195c58b327f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting cifar-100-python/cifar-100-python.tar.gz to cifar-100-python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEGPXHtwLVIn",
        "outputId": "cb2bc49b-49bf-44f8-9f8a-cb93cc49ed36"
      },
      "source": [
        "cifar100_training_loader = get_training_dataloader(\n",
        "    CIFAR100_TRAIN_MEAN,\n",
        "    CIFAR100_TRAIN_STD,\n",
        "    num_workers = 4,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyGiVH5IU7SV",
        "outputId": "89cd1bcc-e2a3-49fb-93c3-4e706029c301"
      },
      "source": [
        "cifar100_training_loader_subset = get_training_dataloader(\n",
        "    CIFAR100_TRAIN_MEAN,\n",
        "    CIFAR100_TRAIN_STD,\n",
        "    num_workers = 4,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = False,\n",
        "    large_subset = True\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrR6Ao7sLVIn"
      },
      "source": [
        "dset_loaders = {'train': cifar100_training_loader, \n",
        "                'train_large_subset': cifar100_training_loader_subset, \n",
        "                'test': cifar100_test_loader}\n",
        "dset_sizes = {'train': len(cifar100_training_loader.dataset), \n",
        "              'train_large_subset': len(cifar100_training_loader_subset.dataset), \n",
        "              'test': len(cifar100_test_loader.dataset)}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqObOH8WLVIn"
      },
      "source": [
        "## Load Model and Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9eseX6yLVIn"
      },
      "source": [
        "#train model\n",
        "def train_model(model, criterion, optimizer, lr_scheduler, num_epochs=5):\n",
        "    \n",
        "    model.to(DEVICE)\n",
        "    since = time.time()\n",
        "\n",
        "    best_model = model\n",
        "    best_acc = 0.0\n",
        "    if ENABLE_VAL:\n",
        "        phases = ['train', 'val']\n",
        "    else:\n",
        "        phases = ['train']\n",
        "        \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in phases:\n",
        "            if phase == 'train':\n",
        "                mode='train'\n",
        "                optimizer = lr_scheduler(optimizer, epoch)\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()\n",
        "                mode='val'\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for index, (inputs, labels) in enumerate(dset_loaders[phase]):\n",
        "                \n",
        "                inputs, labels = inputs.float().to(DEVICE), labels.long().to(DEVICE)\n",
        "\n",
        "                # Set gradient to zero to delete history of computations in previous epoch. Track operations so that differentiation can be done automatically.\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs.data, 1)\n",
        "                \n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    loss = Variable(loss, requires_grad = True)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    \n",
        "                running_loss += loss.item()\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "                if index % 500 == 0 and index > 0:\n",
        "                    print('{}/{} with loss {:.4f}'.format(index, dset_sizes['train']/16, running_loss/index))\n",
        "                \n",
        "            epoch_loss = running_loss / dset_sizes[phase]\n",
        "            epoch_acc = running_corrects.item() / float(dset_sizes[phase])\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val':\n",
        "                if USE_TENSORBOARD:\n",
        "                    foo.add_scalar('epoch_loss',epoch_loss,epoch)\n",
        "                    foo.add_scalar('epoch_acc',epoch_acc,epoch)\n",
        "                if epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model = copy.deepcopy(model)\n",
        "                    pickle.dump(best_model, open('best_model.pkl', 'wb'))\n",
        "                    print('new best accuracy = ',best_acc)\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    print('returning and looping back')\n",
        "    if USE_TENSORBOARD:\n",
        "        foo.close()\n",
        "    return best_model\n",
        "\n",
        "# This function changes the learning rate over the training model.\n",
        "def exp_lr_scheduler(optimizer, epoch, init_lr=BASE_LR, lr_decay_epoch=EPOCH_DECAY):\n",
        "    \"\"\"Decay learning rate by a factor of DECAY_WEIGHT every lr_decay_epoch epochs.\"\"\"\n",
        "    lr = init_lr * (DECAY_WEIGHT**(epoch // lr_decay_epoch))\n",
        "\n",
        "    if epoch % lr_decay_epoch == 0:\n",
        "        print('LR is set to {}'.format(lr))\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "#test model\n",
        "def test_model(model, data = 'test'):\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    \n",
        "    running_loss = 0\n",
        "    running_corrects = 0\n",
        "    with torch.no_grad():\n",
        "      for batch_index, (inputs, labels) in enumerate(dset_loaders[data]):\n",
        "          inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "          outputs = model(inputs)\n",
        "          _, preds = torch.max(outputs.data, 1)\n",
        "          corrects = torch.sum(preds == labels.data) \n",
        "          loss = criterion(outputs, labels)\n",
        "          running_loss += loss\n",
        "          running_corrects += corrects\n",
        "          del inputs\n",
        "          del labels\n",
        "          del outputs\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "    accuracy = (running_corrects / float(dset_sizes['test'])).item()\n",
        "    loss = (running_loss / dset_sizes['test']).item()\n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                'test', loss, accuracy))\n",
        "    return loss, accuracy"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-aNKs-VLVIn",
        "outputId": "f26d94dd-3bdf-49c0-d9ec-e6ebe4ada024"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "cfg = {\n",
        "    'A' : [64,     'M', 128,      'M', 256, 256,           'M', 512, 512,           'M', 512, 512,           'M'],\n",
        "    'B' : [64, 64, 'M', 128, 128, 'M', 256, 256,           'M', 512, 512,           'M', 512, 512,           'M'],\n",
        "    'D' : [64, 64, 'M', 128, 128, 'M', 256, 256, 256,      'M', 512, 512, 512,      'M', 512, 512, 512,      'M'],\n",
        "    'E' : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
        "}\n",
        "\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, features, num_class=100):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.features(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.classifier(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "\n",
        "    input_channel = 3\n",
        "    for l in cfg:\n",
        "        if l == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            continue\n",
        "\n",
        "        layers += [nn.Conv2d(input_channel, l, kernel_size=3, padding=1)]\n",
        "\n",
        "        if batch_norm:\n",
        "            layers += [nn.BatchNorm2d(l)]\n",
        "\n",
        "        layers += [nn.ReLU(inplace=True)]\n",
        "        input_channel = l\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def vgg11_bn():\n",
        "    return VGG(make_layers(cfg['A'], batch_norm=True))\n",
        "\n",
        "def vgg13_bn():\n",
        "    return VGG(make_layers(cfg['B'], batch_norm=True))\n",
        "\n",
        "def vgg16_bn():\n",
        "    return VGG(make_layers(cfg['D'], batch_norm=True))\n",
        "\n",
        "def vgg19_bn():\n",
        "    return VGG(make_layers(cfg['E'], batch_norm=True))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC5eAMvYLVIn"
      },
      "source": [
        "def load_vgg(path):\n",
        "    model = vgg16_bn()\n",
        "    weights = torch.load(path, map_location=DEVICE)\n",
        "    model.load_state_dict(weights)\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od8kKoigLVIn"
      },
      "source": [
        "#vgg16 = load_vgg('../vgg16-197-best.pth')\n",
        "vgg16 = load_vgg('./drive/MyDrive/vgg16-197-best.pth')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AGXh8UqLVIn"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(vgg16.parameters(), lr=0.001)\n",
        "#train_model(vgg16, criterion, optimizer, exp_lr_scheduler, num_epochs = 3);"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a66C8znnLVIn",
        "outputId": "6069e0af-51e0-4b82-cdec-4d6f47db530c"
      },
      "source": [
        "start = time.time()\n",
        "loss, accuracy = test_model(vgg16)\n",
        "end = time.time()\n",
        "print(loss, accuracy)\n",
        "print('time seconds:', end - start)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Loss: 0.1027 Acc: 0.7201\n",
            "0.10269515216350555 0.7200999855995178\n",
            "time seconds: 143.80495238304138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3R_6hh6LVIn"
      },
      "source": [
        "#visualize tensorboard -- a little buggy...\n",
        "if USE_TENSORBOARD:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir=runs"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvE0OaypLVIn"
      },
      "source": [
        "## Quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFcL3iEDLVIn"
      },
      "source": [
        "def print_size_of_model(model, label=\"\"):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    size=os.path.getsize(\"temp.p\")\n",
        "    print(\"model: \",label,' \\t','Size (KB):', size/1e3)\n",
        "    os.remove('temp.p')\n",
        "    return size"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tORzc3jnvQ3S"
      },
      "source": [
        "### Quant Binarization?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-em3XtDm6-DF"
      },
      "source": [
        "import torch.nn as nn\n",
        "import numpy\n",
        "\n",
        "class BinOp():\n",
        "    def __init__(self, model):\n",
        "        # count the number of Conv2d\n",
        "        count_Conv2d = 0\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                count_Conv2d = count_Conv2d + 1\n",
        "\n",
        "        start_range = 1\n",
        "        end_range = count_Conv2d-2\n",
        "        self.bin_range = numpy.linspace(start_range,\n",
        "                end_range, end_range-start_range+1)\\\n",
        "                        .astype('int').tolist()\n",
        "        self.num_of_params = len(self.bin_range)\n",
        "        self.saved_params = []\n",
        "        self.target_params = []\n",
        "        self.target_modules = []\n",
        "        index = -1\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                index = index + 1\n",
        "                if index in self.bin_range:\n",
        "                    tmp = m.weight.data.clone()\n",
        "                    self.saved_params.append(tmp)\n",
        "                    self.target_modules.append(m.weight)\n",
        "\n",
        "    def binarization(self):\n",
        "        self.meancenterConvParams()\n",
        "        self.clampConvParams()\n",
        "        self.save_params()\n",
        "        self.binarizeConvParams()\n",
        "\n",
        "    def meancenterConvParams(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            s = self.target_modules[index].data.size()\n",
        "            negMean = self.target_modules[index].data.mean(1, keepdim=True).\\\n",
        "                    mul(-1).expand_as(self.target_modules[index].data)\n",
        "            self.target_modules[index].data = self.target_modules[index].data.add(negMean)\n",
        "\n",
        "    def clampConvParams(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            self.target_modules[index].data = \\\n",
        "                    self.target_modules[index].data.clamp(-1.0, 1.0)\n",
        "\n",
        "    def save_params(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            self.saved_params[index].copy_(self.target_modules[index].data)\n",
        "\n",
        "    def binarizeConvParams(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            n = self.target_modules[index].data[0].nelement()\n",
        "            s = self.target_modules[index].data.size()\n",
        "            m = self.target_modules[index].data.norm(1, 3, keepdim=True)\\\n",
        "                    .sum(2, keepdim=True).sum(1, keepdim=True).div(n)\n",
        "            self.target_modules[index].data = \\\n",
        "                    self.target_modules[index].data.sign().mul(m.expand(s))\n",
        "\n",
        "    def restore(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            self.target_modules[index].data.copy_(self.saved_params[index])\n",
        "\n",
        "    def updateBinaryGradWeight(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            weight = self.target_modules[index].data\n",
        "            n = weight[0].nelement()\n",
        "            s = weight.size()\n",
        "            m = weight.norm(1, 3, keepdim=True)\\\n",
        "                    .sum(2, keepdim=True).sum(1, keepdim=True).div(n).expand(s)\n",
        "            m[weight.lt(-1.0)] = 0 \n",
        "            m[weight.gt(1.0)] = 0\n",
        "            # m = m.add(1.0/n).mul(1.0-1.0/s[1]).mul(n)\n",
        "            # self.target_modules[index].grad.data = \\\n",
        "            #         self.target_modules[index].grad.data.mul(m)\n",
        "            m = m.mul(self.target_modules[index].grad.data)\n",
        "            m_add = weight.sign().mul(self.target_modules[index].grad.data)\n",
        "            m_add = m_add.sum(3, keepdim=True)\\\n",
        "                    .sum(2, keepdim=True).sum(1, keepdim=True).div(n).expand(s)\n",
        "            m_add = m_add.mul(weight.sign())\n",
        "            self.target_modules[index].grad.data = m.add(m_add).mul(1.0-1.0/s[1]).mul(n)\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pA6g_9H6_IW",
        "outputId": "b5b32a98-4212-46d0-a342-27c1df33818e"
      },
      "source": [
        "vgg_q1 = copy.deepcopy(vgg16)\n",
        "vgg_q1 = BinOp(vgg_q1)\n",
        "bin_op.binarization()\n",
        "start = time.time()\n",
        "loss, accuracy = test_model(vgg_q1)\n",
        "end = time.time()\n",
        "print(loss, accuracy)\n",
        "print('time seconds:', end - start)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Loss: 0.8506 Acc: 0.0141\n",
            "0.8505955934524536 0.014100000262260437\n",
            "time seconds: 146.4947156906128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnkcCfKVvYRH"
      },
      "source": [
        "# vgg_q1 = copy.deepcopy(vgg16)\n",
        "# for k, v in vgg_q1.state_dict().items():\n",
        "#     print(\"Layer {}\".format(k))\n",
        "#     #print(v)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAjPxo6oLVIn"
      },
      "source": [
        "### Quant Dynamics with no retrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEyFaf11LVIn",
        "outputId": "b82a75ad-369b-44cb-fb27-69ebea04758e"
      },
      "source": [
        "DEVICE = 'cpu'\n",
        "vgg16_quant1 = torch.quantization.quantize_dynamic(\n",
        "    vgg16.to(DEVICE),  # the original model\n",
        "    {torch.nn.Linear},  # a set of layers to dynamically quantize\n",
        "    dtype=torch.qint8)  # the target dtype for quantized weights\n",
        "start = time.time()\n",
        "loss, accuracy = test_model(vgg16_quant1)\n",
        "end = time.time()\n",
        "print(loss, accuracy)\n",
        "print('time seconds:', end - start)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Loss: 0.1027 Acc: 0.7201\n",
            "0.1027042344212532 0.7200999855995178\n",
            "time seconds: 139.6137957572937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TE61B1wLVIn",
        "outputId": "ad287f74-8d04-4b48-8893-be12c98b7bd7"
      },
      "source": [
        "# compare the sizes\n",
        "f=print_size_of_model(vgg16,\"baseline\")\n",
        "q=print_size_of_model(vgg16_quant1,\"dynamic quantization\")\n",
        "print(\"{0:.2f} times smaller\".format(f/q))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model:  baseline  \t Size (KB): 136126.773\n",
            "model:  dynamic quantization  \t Size (KB): 78277.182\n",
            "1.74 times smaller\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bf06HFZLVIo"
      },
      "source": [
        "### Quant Static with no retrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30Lc6xioLVIo"
      },
      "source": [
        "my_qconfig = torch.quantization.QConfig(activation=torch.quantization.MovingAverageMinMaxObserver.with_args(dtype=torch.quint8), \n",
        "                                        weight=torch.quantization.default_observer.with_args(dtype=torch.qint8))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aovIk9j3LVIo",
        "outputId": "66e73e09-b162-424d-8c93-9de6a2bb5ba5"
      },
      "source": [
        "vgg16_quant2 = copy.deepcopy(vgg16)\n",
        "#add layers\n",
        "#set_parameter_requires_grad(vgg16_quant2, feature_extracting = True)\n",
        "vgg16_quant2.features = nn.Sequential(torch.quantization.QuantStub(), vgg16_quant2.features)\n",
        "vgg16_quant2.classifier = nn.Sequential(vgg16_quant2.classifier, torch.quantization.DeQuantStub())\n",
        "#set configs\n",
        "#vgg16_quant2.qconfig = torch.quantization.get_default_qconfig('fbgemm')#qnnpack\n",
        "vgg16_quant2.qconfig = my_qconfig\n",
        "print(vgg16_quant2.qconfig)\n",
        "vgg16_quant2 = torch.quantization.fuse_modules(vgg16_quant2, [['features.1.0', 'features.1.1', 'features.1.2'],\n",
        "                                                             ['features.1.3', 'features.1.4', 'features.1.5'],\n",
        "                                                             ['features.1.7', 'features.1.8', 'features.1.9'],\n",
        "                                                             ['features.1.10', 'features.1.11', 'features.1.12'],\n",
        "                                                             ['features.1.14', 'features.1.15', 'features.1.16'],\n",
        "                                                             ['features.1.17', 'features.1.18', 'features.1.19'],\n",
        "                                                             ['features.1.20', 'features.1.21', 'features.1.22'],\n",
        "                                                             ['features.1.24', 'features.1.25', 'features.1.26'],\n",
        "                                                             ['features.1.27', 'features.1.28', 'features.1.29'],\n",
        "                                                             ['features.1.30', 'features.1.31', 'features.1.32'],\n",
        "                                                             ['features.1.34', 'features.1.35', 'features.1.36'],\n",
        "                                                             ['features.1.37', 'features.1.38', 'features.1.39'],\n",
        "                                                             ['features.1.40', 'features.1.41', 'features.1.42']])\n",
        "vgg16_quant2 = torch.quantization.prepare(vgg16_quant2)\n",
        "loss, accuracy = test_model(vgg16_quant2, data = 'train_large_subset')\n",
        "print(loss, accuracy)\n",
        "vgg16_quant2 = torch.quantization.convert(vgg16_quant2)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QConfig(activation=functools.partial(<class 'torch.quantization.observer.MovingAverageMinMaxObserver'>, dtype=torch.quint8), weight=functools.partial(functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), dtype=torch.qint8))\n",
            "test Loss: 0.0002 Acc: 0.4991\n",
            "0.0002012648619711399 0.499099999666214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/quantization/observer.py:121: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk0t0mlhLVIo",
        "outputId": "94cf13cf-992c-45e7-ffba-97be42db4cfa"
      },
      "source": [
        "start = time.time()\n",
        "loss, accuracy = test_model(vgg16_quant2)\n",
        "end = time.time()\n",
        "print(loss, accuracy)\n",
        "print('time seconds:', end - start)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Loss: 0.1028 Acc: 0.7196\n",
            "0.10283544659614563 0.7196000218391418\n",
            "time seconds: 70.84712171554565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le0u4YLGLVIo",
        "outputId": "539078dc-12d3-4754-f5cc-b8c892a0859f"
      },
      "source": [
        "# compare the sizes\n",
        "f=print_size_of_model(vgg16,\"baseline\")\n",
        "q=print_size_of_model(vgg16_quant2,\"static quantization\")\n",
        "print(\"{0:.2f} times smaller\".format(f/q))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model:  baseline  \t Size (KB): 136126.773\n",
            "model:  static quantization  \t Size (KB): 34067.253\n",
            "4.00 times smaller\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szZ1liJZLVIo"
      },
      "source": [
        "### Quant Static with Retrain -- BUGGY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5HibH0JLVIo",
        "outputId": "3530c627-4e0c-4b8e-8f97-cf32b3f9e8d9"
      },
      "source": [
        "vgg16_quant3 = copy.deepcopy(vgg16)\n",
        "#add layers\n",
        "vgg16_quant3.features = nn.Sequential(torch.quantization.QuantStub(), vgg16_quant3.features)\n",
        "vgg16_quant3.classifier = nn.Sequential(vgg16_quant3.classifier, torch.quantization.DeQuantStub())\n",
        "#set configs\n",
        "vgg16_quant3.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "vgg16_quant3 = torch.quantization.prepare_qat(vgg16_quant3)\n",
        "#retrain\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vgg16_quant3.parameters(), lr=0.001)\n",
        "train_model(vgg16_quant3, criterion, optimizer, exp_lr_scheduler, num_epochs = 1);\n",
        "vgg16_quant3.eval()\n",
        "vgg16_quant3 = torch.quantization.convert(vgg16_quant3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/0\n",
            "----------\n",
            "LR is set to 0.001\n",
            "train Loss: 0.1743 Acc: 0.4400\n",
            "Training complete in 0m 52s\n",
            "Best val Acc: 0.000000\n",
            "returning and looping back\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbg-xC7nLVIo",
        "outputId": "2c5358bb-8342-4993-dfef-1024b1bcaec7"
      },
      "source": [
        "loss, accuracy = test_model(vgg16_quant3)\n",
        "print(loss, accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Loss: 0.0485 Acc: 0.0200\n",
            "0.048465121537446976 0.019999999552965164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4nH7QVcLVIo",
        "outputId": "69d7ebc6-0772-4a71-8ccb-b156771c7d6e"
      },
      "source": [
        "# compare the sizes\n",
        "f=print_size_of_model(vgg16,\"baseline\")\n",
        "q=print_size_of_model(vgg16_quant3,\"static quantization with retrain\")\n",
        "print(\"{0:.2f} times smaller\".format(f/q))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model:  baseline  \t Size (KB): 538686.817\n",
            "model:  static quantization with retrain  \t Size (KB): 134857.157\n",
            "3.99 times smaller\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXiKbe_HLVIo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}