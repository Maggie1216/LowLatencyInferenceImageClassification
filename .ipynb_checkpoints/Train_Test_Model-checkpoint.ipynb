{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read files\n",
    "def unpickle(file):\n",
    "    \n",
    "    with open(file, 'rb') as fo:\n",
    "        dictionary = pickle.load(fo, encoding='bytes')\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "def reshape_images(data_dict):\n",
    "    reshaped = data_dict.numpy().reshape(len(data_dict), 1024, 3, order = 'F').reshape(len(data_dict), 32,32,3)\n",
    "    reshaped_processed = torch.from_numpy(reshaped).float().permute(0, 3, 1, 2)\n",
    "    return reshaped_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data settings\n",
    "subset = False #for local running\n",
    "k = 10 #number of samples needed to each class in validation set, because we need to split train and validation\n",
    "\n",
    "#model settings\n",
    "USE_TENSORBOARD = False\n",
    "if USE_TENSORBOARD:\n",
    "    foo = SummaryWriter()\n",
    "use_gpu = True\n",
    "\n",
    "#lr scheduler\n",
    "BASE_LR = 0.001\n",
    "EPOCH_DECAY = 4\n",
    "DECAY_WEIGHT = 0.5\n",
    "\n",
    "device = 'cpu'\n",
    "if use_gpu and torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = unpickle('./cifar-100-python/test')\n",
    "train_dict = unpickle('./cifar-100-python/train')\n",
    "meta = unpickle('./cifar-100-python/meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = meta[b'fine_label_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if subset:\n",
    "    train_data = torch.from_numpy(train_dict[b'data'][:1000])\n",
    "    train_y = torch.tensor(train_dict[b'fine_labels'][:1000])\n",
    "    test_data = torch.from_numpy(test_dict[b'data'][:100])\n",
    "    test_y = torch.tensor(test_dict[b'fine_labels'][:100])\n",
    "else:\n",
    "    train_data = torch.from_numpy(train_dict[b'data'])\n",
    "    train_y = torch.tensor(train_dict[b'fine_labels'])\n",
    "    test_data = torch.from_numpy(test_dict[b'data'])\n",
    "    test_y = torch.tensor(test_dict[b'fine_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_plot(phase, sample_id, test_y = test_y, label_names = label_names, test_data = test_data, train_y = train_y, train_data = train_data):\n",
    "    \n",
    "    if phase == 'train':\n",
    "        data = train_data\n",
    "        y = train_y\n",
    "    elif phase == 'test':\n",
    "        data = test_data\n",
    "        y = test_y\n",
    "    assert sample_id < len(data)\n",
    "    plt.imshow(data[sample_id].numpy().reshape(-1,3, order = 'F').reshape(32,32,3))\n",
    "    labeli = y[sample_id].item()\n",
    "    plt.title('label: ' + label_names[labeli].decode(\"utf-8\") + ', label id: ' + str(labeli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see pictures by sample id\n",
    "see_plot('train', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleFromClass(ds, k): \n",
    "    #k: number of samples needed to each class in test set\n",
    "    class_counts = {}\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "    for data, label in ds:\n",
    "        c = label.item()\n",
    "        class_counts[c] = class_counts.get(c, 0) + 1\n",
    "        if class_counts[c] > k:\n",
    "            train_data.append(data)\n",
    "            train_label.append(torch.unsqueeze(label, 0))\n",
    "        else:\n",
    "            test_data.append(data)\n",
    "            test_label.append(torch.unsqueeze(label, 0))\n",
    "    train_data = torch.stack(train_data)\n",
    "    train_label = torch.cat(train_label)\n",
    "    test_data = torch.stack(test_data)\n",
    "    test_label = torch.cat(test_label)\n",
    "\n",
    "    return ((train_data, train_label), \n",
    "        (test_data, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset = sampleFromClass(list(zip(train_data, train_y)), k)\n",
    "test_dataset = test_data, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean for 3 channels :  tensor([85.5980, 85.5980, 85.5980])\n",
      "std  for 3 channels :  tensor([68.1695, 65.3810, 70.4030])\n"
     ]
    }
   ],
   "source": [
    "print(\"mean for 3 channels : \", reshape_images(train_dataset[0]).mean((0, 2, 3)))\n",
    "print(\"std  for 3 channels : \", reshape_images(train_dataset[0]).std((0, 2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform_image = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        # transforms.Normalize(mean=[85.5980, 85.5980, 85.5980], std=[68.1695, 65.3810, 70.4030])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform_image = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        # transforms.Normalize(mean=[85.5980, 85.5980, 85.5980], std=[68.1695, 65.3810, 70.4030])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, Y, transforms = None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.X[index]\n",
    "        label = self.Y[index]\n",
    "        \n",
    "        if self.transforms != None:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = CIFAR_Dataset(reshape_images(train_dataset[0]), train_dataset[1], transforms = train_transform_image)\n",
    "val_images = CIFAR_Dataset(reshape_images(validation_dataset[0]), validation_dataset[1], transforms =  val_transform_image)\n",
    "test_images = CIFAR_Dataset(reshape_images(test_dataset[0]), test_dataset[1], transforms =  val_transform_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_images, batch_size=16, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_images, batch_size=16, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_images, batch_size=len(test_images), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders = {'train': trainloader, 'val': valloader, 'test': testloader}\n",
    "dset_sizes = {'train': len(trainloader.dataset), 'val': len(valloader.dataset), 'test': len(testloader.dataset)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "def train_model(model, criterion, optimizer, lr_scheduler, num_epochs=5):\n",
    "    \n",
    "    model.to(device)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                mode='train'\n",
    "                optimizer = lr_scheduler(optimizer, epoch)\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()\n",
    "                mode='val'\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for index, (inputs, labels) in enumerate(dset_loaders[phase]):\n",
    "                \n",
    "                inputs, labels = inputs.float().to(device), labels.long().to(device)\n",
    "\n",
    "                # Set gradient to zero to delete history of computations in previous epoch. Track operations so that differentiation can be done automatically.\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                if index % 500 == 0 and index > 0:\n",
    "                    print('{}/{} with loss {:.4f}'.format(index, dset_sizes['train']/16, running_loss/index))\n",
    "                \n",
    "            epoch_loss = running_loss / dset_sizes[phase]\n",
    "            epoch_acc = running_corrects.item() / float(dset_sizes[phase])\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                if USE_TENSORBOARD:\n",
    "                    foo.add_scalar('epoch_loss',epoch_loss,epoch)\n",
    "                    foo.add_scalar('epoch_acc',epoch_acc,epoch)\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model = copy.deepcopy(model)\n",
    "                    pickle.dump(best_model, open('best_model.pkl', 'wb'))\n",
    "                    print('new best accuracy = ',best_acc)\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print('returning and looping back')\n",
    "    if USE_TENSORBOARD:\n",
    "        foo.close()\n",
    "    return best_model\n",
    "\n",
    "# This function changes the learning rate over the training model.\n",
    "def exp_lr_scheduler(optimizer, epoch, init_lr=BASE_LR, lr_decay_epoch=EPOCH_DECAY):\n",
    "    \"\"\"Decay learning rate by a factor of DECAY_WEIGHT every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (DECAY_WEIGHT**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "#test model\n",
    "def test_model(model):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, labels in dset_loaders['test']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        corrects = torch.sum(preds == labels.data) \n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss\n",
    "        running_corrects += corrects\n",
    "    accuracy = (running_corrects / float(dset_sizes['test'])).item()\n",
    "    loss = (running_loss / dset_sizes['test']).item()\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                'test', loss, accuracy))\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting = True):\n",
    "    if feature_extracting:\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting model, criterion and optimers\n",
    "vgg16 = models.vgg16(pretrained = True)\n",
    "#change target output features count into 100\n",
    "set_parameter_requires_grad(vgg16, feature_extracting = True)\n",
    "vgg16.classifier[-1] = nn.Linear(in_features=4096, out_features=100, bias = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(vgg16.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/69\n",
      "----------\n",
      "LR is set to 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-0a920c725e50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-b11951c94362>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, lr_scheduler, num_epochs)\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m                 \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python3.5\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python3.5\\lib\\site-packages\\torchvision\\models\\vgg.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python3.5\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python3.5\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python3.5\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python3.5\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python3.5\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(vgg16, criterion, optimizer, exp_lr_scheduler, num_epochs = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = test_model(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize tensorboard -- a little buggy...\n",
    "if USE_TENSORBOARD:\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_weights(model, threshold, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
