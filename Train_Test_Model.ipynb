{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read files\n",
    "def unpickle(file):\n",
    "    \n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "def reshape_images(data_dict):\n",
    "    reshaped = data_dict.numpy().reshape(len(data_dict), 1024, 3, order = 'F').reshape(len(data_dict), 32,32,3)\n",
    "    reshaped_processed = torch.from_numpy(reshaped).float().permute(0, 3, 1, 2)\n",
    "    return reshaped_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data settings\n",
    "subset = True #for local running\n",
    "k = 3 #number of samples needed to each class in validation set, because we need to split train and validation\n",
    "\n",
    "#model settings\n",
    "USE_TENSORBOARD = False\n",
    "if USE_TENSORBOARD:\n",
    "    foo = SummaryWriter()\n",
    "use_gpu = False\n",
    "\n",
    "#lr scheduler\n",
    "BASE_LR = 0.001\n",
    "EPOCH_DECAY = 4\n",
    "DECAY_WEIGHT = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = unpickle('./cifar-100-python/test')\n",
    "train_dict = unpickle('./cifar-100-python/train')\n",
    "meta = unpickle('./cifar-100-python/meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = meta[b'fine_label_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if subset:\n",
    "    train_data = torch.from_numpy(train_dict[b'data'][:1000])\n",
    "    train_y = torch.tensor(train_dict[b'fine_labels'][:1000])\n",
    "    test_data = torch.from_numpy(test_dict[b'data'][:100])\n",
    "    test_y = torch.tensor(test_dict[b'fine_labels'][:100])\n",
    "else:\n",
    "    train_data = torch.from_numpy(train_dict[b'data'])\n",
    "    train_y = torch.tensor(train_dict[b'fine_labels'])\n",
    "    test_data = torch.from_numpy(test_dict[b'data'])\n",
    "    test_y = torch.tensor(test_dict[b'fine_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_plot(phase, sample_id, test_y = test_y, label_names = label_names, test_data = test_data, train_y = train_y, train_data = train_data):\n",
    "    \n",
    "    if phase == 'train':\n",
    "        data = train_data\n",
    "        y = train_y\n",
    "    elif phase == 'test':\n",
    "        data = test_data\n",
    "        y = test_y\n",
    "    assert sample_id < len(data)\n",
    "    plt.imshow(data[sample_id].numpy().reshape(-1,3, order = 'F').reshape(32,32,3))\n",
    "    labeli = y[sample_id].item()\n",
    "    plt.title('label: ' + label_names[labeli].decode(\"utf-8\") + ', label id: ' + str(labeli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see pictures by sample id\n",
    "see_plot('train', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleFromClass(ds, k): \n",
    "    #k: number of samples needed to each class in test set\n",
    "    class_counts = {}\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "    for data, label in ds:\n",
    "        c = label.item()\n",
    "        class_counts[c] = class_counts.get(c, 0) + 1\n",
    "        if class_counts[c] > k:\n",
    "            train_data.append(data)\n",
    "            train_label.append(torch.unsqueeze(label, 0))\n",
    "        else:\n",
    "            test_data.append(data)\n",
    "            test_label.append(torch.unsqueeze(label, 0))\n",
    "    train_data = torch.stack(train_data)\n",
    "    train_label = torch.cat(train_label)\n",
    "    test_data = torch.stack(test_data)\n",
    "    test_label = torch.cat(test_label)\n",
    "\n",
    "    return ((train_data, train_label), \n",
    "        (test_data, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset = sampleFromClass(list(zip(train_data, train_y)), k)\n",
    "test_dataset = test_data, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = TensorDataset(reshape_images(train_dataset[0]), train_dataset[1])\n",
    "val_images = TensorDataset(reshape_images(validation_dataset[0]), validation_dataset[1])\n",
    "test_images = TensorDataset(reshape_images(test_dataset[0]), test_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_images, batch_size=64, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_images, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_images, batch_size=len(test_images), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders = {'train': trainloader, 'val': valloader, 'test': testloader}\n",
    "dset_sizes = {'train': len(trainloader.dataset), 'val': len(valloader.dataset), 'test': len(testloader.dataset)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "def train_model(model, criterion, optimizer, lr_scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                mode='train'\n",
    "                optimizer = lr_scheduler(optimizer, epoch)\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()\n",
    "                mode='val'\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            counter=0\n",
    "            # Iterate over data.\n",
    "            for data in dset_loaders[phase]:\n",
    "                inputs, labels = data\n",
    "                #print(inputs.size())\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    try:\n",
    "                        inputs, labels = Variable(inputs.float().cuda()),                             \n",
    "                        Variable(labels.long().cuda())\n",
    "                    except:\n",
    "                        print(inputs,labels)\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # Set gradient to zero to delete history of computations in previous epoch. Track operations so that differentiation can be done automatically.\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                # print('loss done')                \n",
    "                # Just so that you can keep track that something's happening and don't feel like the program isn't running.\n",
    "                # if counter%10==0:\n",
    "                #     print(\"Reached iteration \",counter)\n",
    "                counter+=1\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    # print('loss backward')\n",
    "                    loss.backward()\n",
    "                    # print('done loss backward')\n",
    "                    optimizer.step()\n",
    "                    # print('done optim')\n",
    "                # print evaluation statistics\n",
    "                try:\n",
    "                    # running_loss += loss.data[0]\n",
    "                    running_loss += loss.item()\n",
    "                    # print(labels.data)\n",
    "                    # print(preds)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                    # print('running correct =',running_corrects)\n",
    "                except:\n",
    "                    print('unexpected error, could not calculate loss or do a sum.')\n",
    "            epoch_loss = running_loss / dset_sizes[phase]\n",
    "            epoch_acc = running_corrects.item() / float(dset_sizes[phase])\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                if USE_TENSORBOARD:\n",
    "                    foo.add_scalar('epoch_loss',epoch_loss,epoch)\n",
    "                    foo.add_scalar('epoch_acc',epoch_acc,epoch)\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model = copy.deepcopy(model)\n",
    "                    print('new best accuracy = ',best_acc)\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print('returning and looping back')\n",
    "    if USE_TENSORBOARD:\n",
    "        foo.close()\n",
    "    return best_model\n",
    "\n",
    "# This function changes the learning rate over the training model.\n",
    "def exp_lr_scheduler(optimizer, epoch, init_lr=BASE_LR, lr_decay_epoch=EPOCH_DECAY):\n",
    "    \"\"\"Decay learning rate by a factor of DECAY_WEIGHT every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (DECAY_WEIGHT**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "#test model\n",
    "def test_model(model):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "    for data in dset_loaders['test']:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        corrects = torch.sum(preds == labels.data) \n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss\n",
    "        running_corrects += corrects\n",
    "    accuracy = (running_corrects / float(dset_sizes['test'])).item()\n",
    "    loss = (running_loss / dset_sizes['test']).item()\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                'test', loss, accuracy))\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting model, criterion and optimers\n",
    "vgg16 = models.vgg16(pretrained = True)\n",
    "#change target output features count into 100\n",
    "vgg16.classifier[-1] = nn.Linear(in_features=4096, out_features=100, bias = True)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(vgg16.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n",
      "LR is set to 0.001\n",
      "trying epoch loss\n",
      "train Loss: 0.1695 Acc: 0.0143\n",
      "trying epoch loss\n",
      "val Loss: 0.0869 Acc: 0.0100\n",
      "new best accuracy =  0.01\n",
      "Epoch 1/1\n",
      "----------\n",
      "trying epoch loss\n",
      "train Loss: 0.0750 Acc: 0.0100\n",
      "trying epoch loss\n",
      "val Loss: 0.0783 Acc: 0.0100\n",
      "Training complete in 1m 26s\n",
      "Best val Acc: 0.010000\n",
      "returning and looping back\n"
     ]
    }
   ],
   "source": [
    "train_model(vgg16, criterion, optimizer, exp_lr_scheduler, num_epochs=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0469 Acc: 0.0100\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = test_model(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/protobuf_archive/src/google/protobuf/descriptor_database.cc:334] Invalid file descriptor data passed to EncodedDescriptorDatabase::Add().\r\n",
      "[libprotobuf FATAL external/protobuf_archive/src/google/protobuf/descriptor.cc:1370] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): \r\n",
      "libc++abi.dylib: terminating with uncaught exception of type google::protobuf::FatalException: CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): \r\n"
     ]
    }
   ],
   "source": [
    "#visualize tensorboard -- a little buggy...\n",
    "if USE_TENSORBOARD:\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir=runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
