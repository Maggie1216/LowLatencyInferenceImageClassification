{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from models import vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean and std of cifar100 dataset\n",
    "CIFAR100_TRAIN_MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
    "CIFAR100_TRAIN_STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "WARM = False # typically used in new training\n",
    "\n",
    "DATE_FORMAT = '%A_%d_%B_%Y_%Hh_%Mm_%Ss'\n",
    "#time of we run the script\n",
    "TIME_NOW = datetime.datetime.now().strftime(DATE_FORMAT)\n",
    "#data settings\n",
    "subset = False #for local running\n",
    "k = 10 #number of samples needed to each class in validation set, because we need to split train and validation\n",
    "\n",
    "#model settings\n",
    "USE_TENSORBOARD = False\n",
    "if USE_TENSORBOARD:\n",
    "    foo = SummaryWriter()\n",
    "use_gpu = True\n",
    "\n",
    "#lr scheduler\n",
    "BASE_LR = 0.001\n",
    "EPOCH_DECAY = 4\n",
    "DECAY_WEIGHT = 0.5\n",
    "\n",
    "DEVICE = 'cpu'\n",
    "if use_gpu and torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read files\n",
    "def unpickle(file):\n",
    "    \n",
    "    with open(file, 'rb') as fo:\n",
    "        dictionary = pickle.load(fo, encoding='bytes')\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(cifar100_dataset):\n",
    "    \"\"\"compute the mean and std of cifar100 dataset\n",
    "    Args:\n",
    "        cifar100_training_dataset or cifar100_test_dataset\n",
    "        witch derived from class torch.utils.data\n",
    "\n",
    "    Returns:\n",
    "        a tuple contains mean, std value of entire dataset\n",
    "    \"\"\"\n",
    "\n",
    "    data_r = numpy.dstack([cifar100_dataset[i][1][:, :, 0] for i in range(len(cifar100_dataset))])\n",
    "    data_g = numpy.dstack([cifar100_dataset[i][1][:, :, 1] for i in range(len(cifar100_dataset))])\n",
    "    data_b = numpy.dstack([cifar100_dataset[i][1][:, :, 2] for i in range(len(cifar100_dataset))])\n",
    "    mean = numpy.mean(data_r), numpy.mean(data_g), numpy.mean(data_b)\n",
    "    std = numpy.std(data_r), numpy.std(data_g), numpy.std(data_b)\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "def reshape_images(data_dict):\n",
    "    reshaped = data_dict.numpy().reshape(len(data_dict), 1024, 3, order = 'F').reshape(len(data_dict), 32,32,3)\n",
    "    reshaped_processed = torch.from_numpy(reshaped).float().permute(0, 3, 1, 2)\n",
    "    return reshaped_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_dataloader(mean, std, batch_size=16, num_workers=2, shuffle=True):\n",
    "    \"\"\" return training dataloader\n",
    "    Args:\n",
    "        mean: mean of cifar100 training dataset\n",
    "        std: std of cifar100 training dataset\n",
    "        path: path to cifar100 training python dataset\n",
    "        batch_size: dataloader batchsize\n",
    "        num_workers: dataloader num_works\n",
    "        shuffle: whether to shuffle\n",
    "    Returns: train_data_loader:torch dataloader object\n",
    "    \"\"\"\n",
    "\n",
    "    transform_train = transforms.Compose([\n",
    "        #transforms.ToPILImage(),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    #cifar100_training = CIFAR100Train(path, transform=transform_train)\n",
    "    cifar100_training = torchvision.datasets.CIFAR100(root='', train=True, download=True, transform=transform_train)\n",
    "    \n",
    "    try:\n",
    "        random_index = pickle.load(open(\"random_index.pkl\", 'rb'))\n",
    "    except:\n",
    "        random_index = np.random.permutation([i for i in range(50000)])\n",
    "        pickle.dump(random_index, open(\"random_index.pkl\", 'wb'))\n",
    "    \n",
    "    \n",
    "    train_dataset = torch.utils.data.Subset(cifar100_training, train_index)\n",
    "    validation_dataset = torch.utils.data.Subset(cifar100_training, validation_index)\n",
    "    \n",
    "    cifar100_training_loader = DataLoader(\n",
    "        train_dataset, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n",
    "    \n",
    "    cifar100_validation_loader = DataLoader(\n",
    "        validation_dataset, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n",
    "\n",
    "    return cifar100_training_loader, cifar100_validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataloader(mean, std, batch_size=16, num_workers=2, shuffle=True):\n",
    "    \"\"\" return training dataloader\n",
    "    Args:\n",
    "        mean: mean of cifar100 test dataset\n",
    "        std: std of cifar100 test dataset\n",
    "        path: path to cifar100 test python dataset\n",
    "        batch_size: dataloader batchsize\n",
    "        num_workers: dataloader num_works\n",
    "        shuffle: whether to shuffle\n",
    "    Returns: cifar100_test_loader:torch dataloader object\n",
    "    \"\"\"\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    #cifar100_test = CIFAR100Test(path, transform=transform_test)\n",
    "    cifar100_test = torchvision.datasets.CIFAR100(root='', train=False, download=True, transform=transform_test)\n",
    "    cifar100_test_loader = DataLoader(\n",
    "        cifar100_test, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n",
    "\n",
    "    return cifar100_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipWeightCallBack():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.zeros_mask = None\n",
    "    \n",
    "    # on batch begin\n",
    "    def get_zeros_mask(self, model):\n",
    "        \n",
    "        self.zeros_mask= []\n",
    "\n",
    "        for weights_matrix in model.parameters():\n",
    "            self.zeros_mask.append(torch.where(weights_matrix == 0, \\\n",
    "                                     torch.zeros(weights_matrix.data.shape).to(DEVICE), \\\n",
    "                                     torch.ones(weights_matrix.data.shape).to(DEVICE)))\n",
    "    # on batch end\n",
    "    def apply_zeros_mask(self, model):\n",
    "        \n",
    "        for index, weights_matrix in enumerate(model.parameters()):\n",
    "            weights_matrix.data = weights_matrix.data * self.zeros_mask[index].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, train_dataloader, optimizer, loss_function, callbacks = None):\n",
    "\n",
    "    start = time.time()\n",
    "    model.to(DEVICE)\n",
    "    model.train()\n",
    "    # keep track of the zero mask\n",
    "    if callbacks != None:\n",
    "        callbacks.get_zeros_mask(model)\n",
    "    \n",
    "    for batch_index, (images, labels) in enumerate(train_dataloader):\n",
    "        if epoch <= WARM:\n",
    "            warmup_scheduler.step()\n",
    "\n",
    "        if use_gpu:\n",
    "            labels = labels.to(DEVICE)\n",
    "            images = images.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if callbacks != None:\n",
    "            callbacks.apply_zeros_mask(model)\n",
    "            \n",
    "        n_iter = (epoch - 1) * len(train_dataloader) + batch_index + 1\n",
    "\n",
    "        last_layer = list(model.children())[-1]\n",
    "        for name, para in last_layer.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                writer.add_scalar('LastLayerGradients/grad_norm2_weights', para.grad.norm(), n_iter)\n",
    "            if 'bias' in name:\n",
    "                writer.add_scalar('LastLayerGradients/grad_norm2_bias', para.grad.norm(), n_iter)\n",
    "\n",
    "        print('Training Epoch: {epoch} [{trained_samples}/{total_samples}]\\tLoss: {:0.4f}\\tLR: {:0.6f}'.format(\n",
    "            loss.item(),\n",
    "            optimizer.param_groups[0]['lr'],\n",
    "            epoch=epoch,\n",
    "            trained_samples=batch_index * BATCH_SIZE + len(images),\n",
    "            total_samples=len(train_dataloader.dataset)\n",
    "        ))\n",
    "\n",
    "        #update training loss for each iteration\n",
    "        writer.add_scalar('Train/loss', loss.item(), n_iter)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        layer, attr = os.path.splitext(name)\n",
    "        attr = attr[1:]\n",
    "        writer.add_histogram(\"{}/{}\".format(layer, attr), param, epoch)\n",
    "\n",
    "    finish = time.time()\n",
    "\n",
    "    print('epoch {} training time consumed: {:.2f}s'.format(epoch, finish - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_dataloader):\n",
    "    # for validation set or testing set\n",
    "    start = time.time()\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    total_preds = 0\n",
    "    total_corrects = 0\n",
    "    \n",
    "    for batch_index, (images, labels) in enumerate(val_dataloader):\n",
    "        if use_gpu:\n",
    "            # labels = labels.to(DEVICE)\n",
    "            images = images.to(DEVICE)\n",
    "            \n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        \n",
    "        total_preds += len(labels)\n",
    "        total_corrects += np.sum(preds.cpu().numpy() == labels.numpy())\n",
    "    \n",
    "    print(\"Accuracy is {:.5f}\".format(total_corrects/total_preds))\n",
    "    \n",
    "    return total_corrects/total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar100_training_loader, cifar100_validation_loader = get_training_dataloader(\n",
    "    CIFAR100_TRAIN_MEAN,\n",
    "    CIFAR100_TRAIN_STD,\n",
    "    num_workers = 4,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "cifar100_test_loader = get_test_dataloader(\n",
    "    CIFAR100_TRAIN_MEAN,\n",
    "    CIFAR100_TRAIN_STD,\n",
    "    num_workers = 4,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg():\n",
    "    model = vgg.vgg16_bn()\n",
    "    weights = torch.load(\"checkpoints/vgg16-197-best.pth\")\n",
    "    model.load_state_dict(weights)\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.10350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1035"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, cifar100_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\1\\Anaconda3\\envs\\python3.5\\lib\\multiprocessing\\queues.py\", line 230, in _feed\n",
      "    close()\n",
      "  File \"C:\\Users\\1\\Anaconda3\\envs\\python3.5\\lib\\multiprocessing\\connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"C:\\Users\\1\\Anaconda3\\envs\\python3.5\\lib\\multiprocessing\\connection.py\", line 277, in _close\n",
      "    _CloseHandle(self._handle)\n",
      "OSError: [WinError 6] 句柄无效。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using local port 19288\n",
      "INFO:tensorflow:Using local port 18335\n",
      "INFO:tensorflow:Using local port 17170\n",
      "INFO:tensorflow:Using local port 21253\n",
      "INFO:tensorflow:Using local port 24034\n",
      "INFO:tensorflow:Using local port 17593\n",
      "INFO:tensorflow:Using local port 20321\n",
      "INFO:tensorflow:Using local port 16590\n",
      "INFO:tensorflow:Using local port 21716\n",
      "INFO:tensorflow:Using local port 17480\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir=os.path.join(\n",
    "            'logs', 'vgg', TIME_NOW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_optimizer = optim.SGD(model.parameters(), lr= 0.0000001, momentum=0.9, weight_decay=5e-4)\n",
    "crossEntropyLoss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 10 [16/45000]\tLoss: 0.6150\tLR: 0.000000\n",
      "Training Epoch: 10 [32/45000]\tLoss: 0.0147\tLR: 0.000000\n",
      "Training Epoch: 10 [48/45000]\tLoss: 0.9975\tLR: 0.000000\n",
      "Training Epoch: 10 [64/45000]\tLoss: 0.0630\tLR: 0.000000\n",
      "Training Epoch: 10 [80/45000]\tLoss: 0.3064\tLR: 0.000000\n",
      "Training Epoch: 10 [96/45000]\tLoss: 0.4618\tLR: 0.000000\n",
      "Training Epoch: 10 [112/45000]\tLoss: 0.2743\tLR: 0.000000\n",
      "Training Epoch: 10 [128/45000]\tLoss: 0.0054\tLR: 0.000000\n",
      "Training Epoch: 10 [144/45000]\tLoss: 0.0624\tLR: 0.000000\n",
      "Training Epoch: 10 [160/45000]\tLoss: 0.0349\tLR: 0.000000\n",
      "Training Epoch: 10 [176/45000]\tLoss: 0.0556\tLR: 0.000000\n",
      "Training Epoch: 10 [192/45000]\tLoss: 0.0627\tLR: 0.000000\n",
      "Training Epoch: 10 [208/45000]\tLoss: 0.2487\tLR: 0.000000\n",
      "Training Epoch: 10 [224/45000]\tLoss: 0.4779\tLR: 0.000000\n",
      "Training Epoch: 10 [240/45000]\tLoss: 0.5389\tLR: 0.000000\n",
      "Training Epoch: 10 [256/45000]\tLoss: 0.1566\tLR: 0.000000\n",
      "Training Epoch: 10 [272/45000]\tLoss: 0.0897\tLR: 0.000000\n",
      "Training Epoch: 10 [288/45000]\tLoss: 0.0231\tLR: 0.000000\n",
      "Training Epoch: 10 [304/45000]\tLoss: 0.0053\tLR: 0.000000\n",
      "Training Epoch: 10 [320/45000]\tLoss: 0.1717\tLR: 0.000000\n",
      "Training Epoch: 10 [336/45000]\tLoss: 0.3522\tLR: 0.000000\n",
      "Training Epoch: 10 [352/45000]\tLoss: 0.0327\tLR: 0.000000\n",
      "Training Epoch: 10 [368/45000]\tLoss: 0.1359\tLR: 0.000000\n",
      "Training Epoch: 10 [384/45000]\tLoss: 0.0797\tLR: 0.000000\n",
      "Training Epoch: 10 [400/45000]\tLoss: 0.0454\tLR: 0.000000\n",
      "Training Epoch: 10 [416/45000]\tLoss: 0.0321\tLR: 0.000000\n",
      "Training Epoch: 10 [432/45000]\tLoss: 0.1060\tLR: 0.000000\n",
      "Training Epoch: 10 [448/45000]\tLoss: 0.0894\tLR: 0.000000\n",
      "Training Epoch: 10 [464/45000]\tLoss: 0.2997\tLR: 0.000000\n",
      "Training Epoch: 10 [480/45000]\tLoss: 0.1198\tLR: 0.000000\n",
      "Training Epoch: 10 [496/45000]\tLoss: 0.1363\tLR: 0.000000\n",
      "Training Epoch: 10 [512/45000]\tLoss: 0.0127\tLR: 0.000000\n",
      "Training Epoch: 10 [528/45000]\tLoss: 0.7936\tLR: 0.000000\n",
      "Training Epoch: 10 [544/45000]\tLoss: 0.6299\tLR: 0.000000\n",
      "Training Epoch: 10 [560/45000]\tLoss: 0.0042\tLR: 0.000000\n",
      "Training Epoch: 10 [576/45000]\tLoss: 0.3106\tLR: 0.000000\n",
      "Training Epoch: 10 [592/45000]\tLoss: 0.0464\tLR: 0.000000\n",
      "Training Epoch: 10 [608/45000]\tLoss: 0.1841\tLR: 0.000000\n",
      "Training Epoch: 10 [624/45000]\tLoss: 0.0225\tLR: 0.000000\n",
      "Training Epoch: 10 [640/45000]\tLoss: 0.0980\tLR: 0.000000\n",
      "Training Epoch: 10 [656/45000]\tLoss: 0.0850\tLR: 0.000000\n",
      "Training Epoch: 10 [672/45000]\tLoss: 0.1315\tLR: 0.000000\n",
      "Training Epoch: 10 [688/45000]\tLoss: 0.0191\tLR: 0.000000\n",
      "Training Epoch: 10 [704/45000]\tLoss: 0.0342\tLR: 0.000000\n",
      "Training Epoch: 10 [720/45000]\tLoss: 0.1469\tLR: 0.000000\n",
      "Training Epoch: 10 [736/45000]\tLoss: 0.3916\tLR: 0.000000\n",
      "Training Epoch: 10 [752/45000]\tLoss: 0.3812\tLR: 0.000000\n",
      "Training Epoch: 10 [768/45000]\tLoss: 0.4677\tLR: 0.000000\n",
      "Training Epoch: 10 [784/45000]\tLoss: 0.0047\tLR: 0.000000\n",
      "Training Epoch: 10 [800/45000]\tLoss: 0.2041\tLR: 0.000000\n",
      "Training Epoch: 10 [816/45000]\tLoss: 0.0092\tLR: 0.000000\n",
      "Training Epoch: 10 [832/45000]\tLoss: 0.1685\tLR: 0.000000\n",
      "Training Epoch: 10 [848/45000]\tLoss: 0.2714\tLR: 0.000000\n",
      "Training Epoch: 10 [864/45000]\tLoss: 0.4020\tLR: 0.000000\n",
      "Training Epoch: 10 [880/45000]\tLoss: 0.2333\tLR: 0.000000\n",
      "Training Epoch: 10 [896/45000]\tLoss: 0.7264\tLR: 0.000000\n",
      "Training Epoch: 10 [912/45000]\tLoss: 0.1085\tLR: 0.000000\n",
      "Training Epoch: 10 [928/45000]\tLoss: 0.5913\tLR: 0.000000\n",
      "Training Epoch: 10 [944/45000]\tLoss: 0.1239\tLR: 0.000000\n",
      "Training Epoch: 10 [960/45000]\tLoss: 0.3941\tLR: 0.000000\n",
      "Training Epoch: 10 [976/45000]\tLoss: 0.0281\tLR: 0.000000\n",
      "Training Epoch: 10 [992/45000]\tLoss: 0.1050\tLR: 0.000000\n",
      "Training Epoch: 10 [1008/45000]\tLoss: 0.5636\tLR: 0.000000\n",
      "Training Epoch: 10 [1024/45000]\tLoss: 0.2235\tLR: 0.000000\n",
      "Training Epoch: 10 [1040/45000]\tLoss: 0.6846\tLR: 0.000000\n",
      "Training Epoch: 10 [1056/45000]\tLoss: 0.0163\tLR: 0.000000\n",
      "Training Epoch: 10 [1072/45000]\tLoss: 0.0193\tLR: 0.000000\n",
      "Training Epoch: 10 [1088/45000]\tLoss: 0.1522\tLR: 0.000000\n",
      "Training Epoch: 10 [1104/45000]\tLoss: 0.2019\tLR: 0.000000\n",
      "Training Epoch: 10 [1120/45000]\tLoss: 0.2031\tLR: 0.000000\n",
      "Training Epoch: 10 [1136/45000]\tLoss: 0.8366\tLR: 0.000000\n",
      "Training Epoch: 10 [1152/45000]\tLoss: 0.0770\tLR: 0.000000\n",
      "Training Epoch: 10 [1168/45000]\tLoss: 0.0017\tLR: 0.000000\n",
      "Training Epoch: 10 [1184/45000]\tLoss: 0.3440\tLR: 0.000000\n",
      "Training Epoch: 10 [1200/45000]\tLoss: 0.7569\tLR: 0.000000\n",
      "Training Epoch: 10 [1216/45000]\tLoss: 0.0608\tLR: 0.000000\n",
      "Training Epoch: 10 [1232/45000]\tLoss: 0.1348\tLR: 0.000000\n",
      "Training Epoch: 10 [1248/45000]\tLoss: 0.1634\tLR: 0.000000\n",
      "Training Epoch: 10 [1264/45000]\tLoss: 0.0229\tLR: 0.000000\n",
      "Training Epoch: 10 [1280/45000]\tLoss: 0.1003\tLR: 0.000000\n",
      "Training Epoch: 10 [1296/45000]\tLoss: 0.3236\tLR: 0.000000\n",
      "Training Epoch: 10 [1312/45000]\tLoss: 0.0483\tLR: 0.000000\n",
      "Training Epoch: 10 [1328/45000]\tLoss: 0.0445\tLR: 0.000000\n",
      "Training Epoch: 10 [1344/45000]\tLoss: 0.0668\tLR: 0.000000\n",
      "Training Epoch: 10 [1360/45000]\tLoss: 0.2213\tLR: 0.000000\n",
      "Training Epoch: 10 [1376/45000]\tLoss: 0.2190\tLR: 0.000000\n",
      "Training Epoch: 10 [1392/45000]\tLoss: 0.1350\tLR: 0.000000\n",
      "Training Epoch: 10 [1408/45000]\tLoss: 0.1168\tLR: 0.000000\n",
      "Training Epoch: 10 [1424/45000]\tLoss: 0.0119\tLR: 0.000000\n",
      "Training Epoch: 10 [1440/45000]\tLoss: 0.4584\tLR: 0.000000\n",
      "Training Epoch: 10 [1456/45000]\tLoss: 0.1228\tLR: 0.000000\n",
      "Training Epoch: 10 [1472/45000]\tLoss: 0.0072\tLR: 0.000000\n",
      "Training Epoch: 10 [1488/45000]\tLoss: 0.3871\tLR: 0.000000\n",
      "Training Epoch: 10 [1504/45000]\tLoss: 0.1876\tLR: 0.000000\n",
      "Training Epoch: 10 [1520/45000]\tLoss: 0.1552\tLR: 0.000000\n",
      "Training Epoch: 10 [1536/45000]\tLoss: 0.2383\tLR: 0.000000\n",
      "Training Epoch: 10 [1552/45000]\tLoss: 0.0599\tLR: 0.000000\n",
      "Training Epoch: 10 [1568/45000]\tLoss: 0.2084\tLR: 0.000000\n",
      "Training Epoch: 10 [1584/45000]\tLoss: 0.0405\tLR: 0.000000\n",
      "Training Epoch: 10 [1600/45000]\tLoss: 0.0932\tLR: 0.000000\n",
      "Training Epoch: 10 [1616/45000]\tLoss: 0.1238\tLR: 0.000000\n",
      "Training Epoch: 10 [1632/45000]\tLoss: 0.5006\tLR: 0.000000\n",
      "Training Epoch: 10 [1648/45000]\tLoss: 0.5439\tLR: 0.000000\n",
      "Training Epoch: 10 [1664/45000]\tLoss: 0.0015\tLR: 0.000000\n",
      "Training Epoch: 10 [1680/45000]\tLoss: 0.0533\tLR: 0.000000\n",
      "Training Epoch: 10 [1696/45000]\tLoss: 0.0157\tLR: 0.000000\n",
      "Training Epoch: 10 [1712/45000]\tLoss: 0.2655\tLR: 0.000000\n",
      "Training Epoch: 10 [1728/45000]\tLoss: 0.3332\tLR: 0.000000\n",
      "Training Epoch: 10 [1744/45000]\tLoss: 0.1759\tLR: 0.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-85bbc83bef53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcifar100_training_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msgd_optimizer\u001b[0m\u001b[1;33m,\u001b[0m                                                           \u001b[0mloss_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrossEntropyLoss_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-123-2aa229be2c58>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epoch, train_dataloader, optimizer, loss_function)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         print('Training Epoch: {epoch} [{trained_samples}/{total_samples}]\\tLoss: {:0.4f}\\tLR: {:0.6f}'.format(\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader = cifar100_training_loader, epoch = 10, optimizer = sgd_optimizer, \\\n",
    "                                                          loss_function = crossEntropyLoss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_report(model, dataloader):\n",
    "    # local final score on validation data\n",
    "    num_zeros = sum([(i.detach().cpu().numpy() == 0).sum() for i in model.parameters()])\n",
    "    total_parameters = sum([np.prod(i.shape) for i in model.parameters()])\n",
    "    accuracy = evaluate_model(model, dataloader)\n",
    "    result = (accuracy + num_zeros/total_parameters)/2\n",
    "    print(\"num_zeros / total_parameters ratio is \", num_zeros/total_parameters)\n",
    "    print(\"accuracy is \", accuracy)\n",
    "    print(\"overall score is \", result)\n",
    "    return num_zeros/total_parameters, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_network(model, threshold = 0.01):\n",
    "    \n",
    "    # vgg has classifier and features\n",
    "    for weights_matrix in model.parameters():\n",
    "        weights_matrix.data = torch.where(torch.abs(weights_matrix.data) >= threshold, \\\n",
    "                                          weights_matrix.data, torch.zeros(weights_matrix.data.shape).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_prune(model, rounds, epoches, train_dataloader, val_dataloader, lr = 0.00001, threshold = 0.001):\n",
    "    print(\"Model performance at the beginning...\")\n",
    "    model_report(model, val_dataloader)\n",
    "    sgd_optimizer = optim.SGD(model.parameters(), lr = lr, momentum = 0.9, weight_decay = 5e-4)\n",
    "    crossEntropyLoss_function = nn.CrossEntropyLoss()\n",
    "    prune_callback = ClipWeightCallBack()\n",
    "    \n",
    "    print(\"Start pruning..\")\n",
    "    for i in range(rounds):\n",
    "        print(\"Round {}/{}:\".format(i + 1, rounds))\n",
    "        prune_network(model)\n",
    "        train(model, epoches, train_dataloader, sgd_optimizer, crossEntropyLoss_function, callbacks = prune_callback)\n",
    "        model_report(model, val_dataloader)\n",
    "    \n",
    "    print(\"Done pruning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance at the beginning...\n",
      "Accuracy is 0.99760\n",
      "num_zeros / total_parameters ratio is  0.0\n",
      "accuracy is  0.9976\n",
      "overall score is  0.4988\n",
      "Start pruning..\n",
      "Round 1/3:\n",
      "Training Epoch: 4 [16/45000]\tLoss: 3.7904\tLR: 0.000010\n",
      "Training Epoch: 4 [32/45000]\tLoss: 3.8272\tLR: 0.000010\n",
      "Training Epoch: 4 [48/45000]\tLoss: 3.9181\tLR: 0.000010\n",
      "Training Epoch: 4 [64/45000]\tLoss: 3.7499\tLR: 0.000010\n",
      "Training Epoch: 4 [80/45000]\tLoss: 3.7629\tLR: 0.000010\n",
      "Training Epoch: 4 [96/45000]\tLoss: 3.7529\tLR: 0.000010\n",
      "Training Epoch: 4 [112/45000]\tLoss: 3.7358\tLR: 0.000010\n",
      "Training Epoch: 4 [128/45000]\tLoss: 3.6645\tLR: 0.000010\n",
      "Training Epoch: 4 [144/45000]\tLoss: 3.8374\tLR: 0.000010\n",
      "Training Epoch: 4 [160/45000]\tLoss: 3.7710\tLR: 0.000010\n",
      "Training Epoch: 4 [176/45000]\tLoss: 3.7711\tLR: 0.000010\n",
      "Training Epoch: 4 [192/45000]\tLoss: 3.8007\tLR: 0.000010\n",
      "Training Epoch: 4 [208/45000]\tLoss: 3.6681\tLR: 0.000010\n",
      "Training Epoch: 4 [224/45000]\tLoss: 3.7318\tLR: 0.000010\n",
      "Training Epoch: 4 [240/45000]\tLoss: 3.7945\tLR: 0.000010\n",
      "Training Epoch: 4 [256/45000]\tLoss: 3.7877\tLR: 0.000010\n",
      "Training Epoch: 4 [272/45000]\tLoss: 3.6028\tLR: 0.000010\n",
      "Training Epoch: 4 [288/45000]\tLoss: 3.7784\tLR: 0.000010\n",
      "Training Epoch: 4 [304/45000]\tLoss: 3.7500\tLR: 0.000010\n",
      "Training Epoch: 4 [320/45000]\tLoss: 3.7999\tLR: 0.000010\n",
      "Training Epoch: 4 [336/45000]\tLoss: 3.6821\tLR: 0.000010\n",
      "Training Epoch: 4 [352/45000]\tLoss: 3.8109\tLR: 0.000010\n",
      "Training Epoch: 4 [368/45000]\tLoss: 3.7573\tLR: 0.000010\n",
      "Training Epoch: 4 [384/45000]\tLoss: 3.7137\tLR: 0.000010\n",
      "Training Epoch: 4 [400/45000]\tLoss: 3.7511\tLR: 0.000010\n",
      "Training Epoch: 4 [416/45000]\tLoss: 3.7736\tLR: 0.000010\n",
      "Training Epoch: 4 [432/45000]\tLoss: 3.6855\tLR: 0.000010\n",
      "Training Epoch: 4 [448/45000]\tLoss: 3.7352\tLR: 0.000010\n",
      "Training Epoch: 4 [464/45000]\tLoss: 3.7375\tLR: 0.000010\n",
      "Training Epoch: 4 [480/45000]\tLoss: 3.8357\tLR: 0.000010\n",
      "Training Epoch: 4 [496/45000]\tLoss: 3.7196\tLR: 0.000010\n",
      "Training Epoch: 4 [512/45000]\tLoss: 3.7059\tLR: 0.000010\n",
      "Training Epoch: 4 [528/45000]\tLoss: 3.8610\tLR: 0.000010\n",
      "Training Epoch: 4 [544/45000]\tLoss: 3.7834\tLR: 0.000010\n",
      "Training Epoch: 4 [560/45000]\tLoss: 3.7691\tLR: 0.000010\n",
      "Training Epoch: 4 [576/45000]\tLoss: 3.7562\tLR: 0.000010\n",
      "Training Epoch: 4 [592/45000]\tLoss: 3.7031\tLR: 0.000010\n",
      "Training Epoch: 4 [608/45000]\tLoss: 3.5563\tLR: 0.000010\n",
      "Training Epoch: 4 [624/45000]\tLoss: 3.7132\tLR: 0.000010\n",
      "Training Epoch: 4 [640/45000]\tLoss: 3.7617\tLR: 0.000010\n",
      "Training Epoch: 4 [656/45000]\tLoss: 3.7828\tLR: 0.000010\n",
      "Training Epoch: 4 [672/45000]\tLoss: 3.8110\tLR: 0.000010\n",
      "Training Epoch: 4 [688/45000]\tLoss: 3.8263\tLR: 0.000010\n",
      "Training Epoch: 4 [704/45000]\tLoss: 3.6973\tLR: 0.000010\n",
      "Training Epoch: 4 [720/45000]\tLoss: 3.8961\tLR: 0.000010\n",
      "Training Epoch: 4 [736/45000]\tLoss: 3.6970\tLR: 0.000010\n",
      "Training Epoch: 4 [752/45000]\tLoss: 3.6286\tLR: 0.000010\n",
      "Training Epoch: 4 [768/45000]\tLoss: 3.7050\tLR: 0.000010\n",
      "Training Epoch: 4 [784/45000]\tLoss: 3.7643\tLR: 0.000010\n",
      "Training Epoch: 4 [800/45000]\tLoss: 3.6329\tLR: 0.000010\n",
      "Training Epoch: 4 [816/45000]\tLoss: 3.8594\tLR: 0.000010\n",
      "Training Epoch: 4 [832/45000]\tLoss: 3.7492\tLR: 0.000010\n",
      "Training Epoch: 4 [848/45000]\tLoss: 3.8347\tLR: 0.000010\n",
      "Training Epoch: 4 [864/45000]\tLoss: 3.7719\tLR: 0.000010\n",
      "Training Epoch: 4 [880/45000]\tLoss: 3.6848\tLR: 0.000010\n",
      "Training Epoch: 4 [896/45000]\tLoss: 3.8140\tLR: 0.000010\n",
      "Training Epoch: 4 [912/45000]\tLoss: 3.6993\tLR: 0.000010\n",
      "Training Epoch: 4 [928/45000]\tLoss: 3.8001\tLR: 0.000010\n",
      "Training Epoch: 4 [944/45000]\tLoss: 3.7087\tLR: 0.000010\n",
      "Training Epoch: 4 [960/45000]\tLoss: 3.6906\tLR: 0.000010\n",
      "Training Epoch: 4 [976/45000]\tLoss: 3.6344\tLR: 0.000010\n",
      "Training Epoch: 4 [992/45000]\tLoss: 3.6711\tLR: 0.000010\n",
      "Training Epoch: 4 [1008/45000]\tLoss: 3.6695\tLR: 0.000010\n",
      "Training Epoch: 4 [1024/45000]\tLoss: 3.8089\tLR: 0.000010\n",
      "Training Epoch: 4 [1040/45000]\tLoss: 3.7228\tLR: 0.000010\n",
      "Training Epoch: 4 [1056/45000]\tLoss: 3.7014\tLR: 0.000010\n",
      "Training Epoch: 4 [1072/45000]\tLoss: 3.6744\tLR: 0.000010\n",
      "Training Epoch: 4 [1088/45000]\tLoss: 3.9322\tLR: 0.000010\n",
      "Training Epoch: 4 [1104/45000]\tLoss: 3.6097\tLR: 0.000010\n",
      "Training Epoch: 4 [1120/45000]\tLoss: 3.6686\tLR: 0.000010\n",
      "Training Epoch: 4 [1136/45000]\tLoss: 3.6707\tLR: 0.000010\n",
      "Training Epoch: 4 [1152/45000]\tLoss: 3.7339\tLR: 0.000010\n",
      "Training Epoch: 4 [1168/45000]\tLoss: 3.7422\tLR: 0.000010\n",
      "Training Epoch: 4 [1184/45000]\tLoss: 3.7106\tLR: 0.000010\n",
      "Training Epoch: 4 [1200/45000]\tLoss: 3.6918\tLR: 0.000010\n",
      "Training Epoch: 4 [1216/45000]\tLoss: 3.7365\tLR: 0.000010\n",
      "Training Epoch: 4 [1232/45000]\tLoss: 3.7207\tLR: 0.000010\n",
      "Training Epoch: 4 [1248/45000]\tLoss: 3.6750\tLR: 0.000010\n",
      "Training Epoch: 4 [1264/45000]\tLoss: 3.7433\tLR: 0.000010\n",
      "Training Epoch: 4 [1280/45000]\tLoss: 3.7812\tLR: 0.000010\n",
      "Training Epoch: 4 [1296/45000]\tLoss: 3.6446\tLR: 0.000010\n",
      "Training Epoch: 4 [1312/45000]\tLoss: 3.7212\tLR: 0.000010\n",
      "Training Epoch: 4 [1328/45000]\tLoss: 3.7878\tLR: 0.000010\n",
      "Training Epoch: 4 [1344/45000]\tLoss: 3.6848\tLR: 0.000010\n",
      "Training Epoch: 4 [1360/45000]\tLoss: 3.7787\tLR: 0.000010\n",
      "Training Epoch: 4 [1376/45000]\tLoss: 3.7961\tLR: 0.000010\n",
      "Training Epoch: 4 [1392/45000]\tLoss: 3.7334\tLR: 0.000010\n",
      "Training Epoch: 4 [1408/45000]\tLoss: 3.8314\tLR: 0.000010\n",
      "Training Epoch: 4 [1424/45000]\tLoss: 3.7468\tLR: 0.000010\n",
      "Training Epoch: 4 [1440/45000]\tLoss: 3.7298\tLR: 0.000010\n",
      "Training Epoch: 4 [1456/45000]\tLoss: 3.6235\tLR: 0.000010\n",
      "Training Epoch: 4 [1472/45000]\tLoss: 3.7533\tLR: 0.000010\n",
      "Training Epoch: 4 [1488/45000]\tLoss: 3.7796\tLR: 0.000010\n",
      "Training Epoch: 4 [1504/45000]\tLoss: 3.6406\tLR: 0.000010\n",
      "Training Epoch: 4 [1520/45000]\tLoss: 3.6700\tLR: 0.000010\n",
      "Training Epoch: 4 [1536/45000]\tLoss: 3.7459\tLR: 0.000010\n",
      "Training Epoch: 4 [1552/45000]\tLoss: 3.7152\tLR: 0.000010\n",
      "Training Epoch: 4 [1568/45000]\tLoss: 3.7009\tLR: 0.000010\n",
      "Training Epoch: 4 [1584/45000]\tLoss: 3.6290\tLR: 0.000010\n",
      "Training Epoch: 4 [1600/45000]\tLoss: 3.7321\tLR: 0.000010\n",
      "Training Epoch: 4 [1616/45000]\tLoss: 3.7572\tLR: 0.000010\n",
      "Training Epoch: 4 [1632/45000]\tLoss: 3.6700\tLR: 0.000010\n",
      "Training Epoch: 4 [1648/45000]\tLoss: 3.7965\tLR: 0.000010\n",
      "Training Epoch: 4 [1664/45000]\tLoss: 3.8562\tLR: 0.000010\n",
      "Training Epoch: 4 [1680/45000]\tLoss: 3.9024\tLR: 0.000010\n",
      "Training Epoch: 4 [1696/45000]\tLoss: 3.6504\tLR: 0.000010\n",
      "Training Epoch: 4 [1712/45000]\tLoss: 3.7487\tLR: 0.000010\n",
      "Training Epoch: 4 [1728/45000]\tLoss: 3.7042\tLR: 0.000010\n",
      "Training Epoch: 4 [1744/45000]\tLoss: 3.8058\tLR: 0.000010\n",
      "Training Epoch: 4 [1760/45000]\tLoss: 3.7719\tLR: 0.000010\n",
      "Training Epoch: 4 [1776/45000]\tLoss: 3.7802\tLR: 0.000010\n",
      "Training Epoch: 4 [1792/45000]\tLoss: 3.7367\tLR: 0.000010\n",
      "Training Epoch: 4 [1808/45000]\tLoss: 3.6187\tLR: 0.000010\n",
      "Training Epoch: 4 [1824/45000]\tLoss: 3.7818\tLR: 0.000010\n",
      "Training Epoch: 4 [1840/45000]\tLoss: 3.8029\tLR: 0.000010\n",
      "Training Epoch: 4 [1856/45000]\tLoss: 3.6986\tLR: 0.000010\n",
      "Training Epoch: 4 [1872/45000]\tLoss: 3.6629\tLR: 0.000010\n",
      "Training Epoch: 4 [1888/45000]\tLoss: 3.6855\tLR: 0.000010\n",
      "Training Epoch: 4 [1904/45000]\tLoss: 3.6769\tLR: 0.000010\n",
      "Training Epoch: 4 [1920/45000]\tLoss: 3.7232\tLR: 0.000010\n",
      "Training Epoch: 4 [1936/45000]\tLoss: 3.7809\tLR: 0.000010\n",
      "Training Epoch: 4 [1952/45000]\tLoss: 3.6952\tLR: 0.000010\n",
      "Training Epoch: 4 [1968/45000]\tLoss: 3.6703\tLR: 0.000010\n",
      "Training Epoch: 4 [1984/45000]\tLoss: 3.6785\tLR: 0.000010\n",
      "Training Epoch: 4 [2000/45000]\tLoss: 3.8285\tLR: 0.000010\n",
      "Training Epoch: 4 [2016/45000]\tLoss: 3.7270\tLR: 0.000010\n",
      "Training Epoch: 4 [2032/45000]\tLoss: 3.7586\tLR: 0.000010\n",
      "Training Epoch: 4 [2048/45000]\tLoss: 3.7516\tLR: 0.000010\n",
      "Training Epoch: 4 [2064/45000]\tLoss: 3.7727\tLR: 0.000010\n",
      "Training Epoch: 4 [2080/45000]\tLoss: 3.8423\tLR: 0.000010\n",
      "Training Epoch: 4 [2096/45000]\tLoss: 3.7847\tLR: 0.000010\n",
      "Training Epoch: 4 [2112/45000]\tLoss: 3.7295\tLR: 0.000010\n",
      "Training Epoch: 4 [2128/45000]\tLoss: 3.7591\tLR: 0.000010\n",
      "Training Epoch: 4 [2144/45000]\tLoss: 3.7546\tLR: 0.000010\n",
      "Training Epoch: 4 [2160/45000]\tLoss: 3.8180\tLR: 0.000010\n",
      "Training Epoch: 4 [2176/45000]\tLoss: 3.7676\tLR: 0.000010\n",
      "Training Epoch: 4 [2192/45000]\tLoss: 3.7662\tLR: 0.000010\n",
      "Training Epoch: 4 [2208/45000]\tLoss: 3.7713\tLR: 0.000010\n",
      "Training Epoch: 4 [2224/45000]\tLoss: 3.7603\tLR: 0.000010\n",
      "Training Epoch: 4 [2240/45000]\tLoss: 3.7775\tLR: 0.000010\n",
      "Training Epoch: 4 [2256/45000]\tLoss: 3.7718\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [2272/45000]\tLoss: 3.7129\tLR: 0.000010\n",
      "Training Epoch: 4 [2288/45000]\tLoss: 3.6547\tLR: 0.000010\n",
      "Training Epoch: 4 [2304/45000]\tLoss: 3.8550\tLR: 0.000010\n",
      "Training Epoch: 4 [2320/45000]\tLoss: 3.8525\tLR: 0.000010\n",
      "Training Epoch: 4 [2336/45000]\tLoss: 3.6647\tLR: 0.000010\n",
      "Training Epoch: 4 [2352/45000]\tLoss: 3.7079\tLR: 0.000010\n",
      "Training Epoch: 4 [2368/45000]\tLoss: 3.7819\tLR: 0.000010\n",
      "Training Epoch: 4 [2384/45000]\tLoss: 3.6827\tLR: 0.000010\n",
      "Training Epoch: 4 [2400/45000]\tLoss: 3.7995\tLR: 0.000010\n",
      "Training Epoch: 4 [2416/45000]\tLoss: 3.8147\tLR: 0.000010\n",
      "Training Epoch: 4 [2432/45000]\tLoss: 3.8041\tLR: 0.000010\n",
      "Training Epoch: 4 [2448/45000]\tLoss: 3.7642\tLR: 0.000010\n",
      "Training Epoch: 4 [2464/45000]\tLoss: 3.7419\tLR: 0.000010\n",
      "Training Epoch: 4 [2480/45000]\tLoss: 3.7686\tLR: 0.000010\n",
      "Training Epoch: 4 [2496/45000]\tLoss: 3.8753\tLR: 0.000010\n",
      "Training Epoch: 4 [2512/45000]\tLoss: 3.8604\tLR: 0.000010\n",
      "Training Epoch: 4 [2528/45000]\tLoss: 3.7495\tLR: 0.000010\n",
      "Training Epoch: 4 [2544/45000]\tLoss: 3.7642\tLR: 0.000010\n",
      "Training Epoch: 4 [2560/45000]\tLoss: 3.8713\tLR: 0.000010\n",
      "Training Epoch: 4 [2576/45000]\tLoss: 3.7319\tLR: 0.000010\n",
      "Training Epoch: 4 [2592/45000]\tLoss: 3.7522\tLR: 0.000010\n",
      "Training Epoch: 4 [2608/45000]\tLoss: 3.6945\tLR: 0.000010\n",
      "Training Epoch: 4 [2624/45000]\tLoss: 3.7268\tLR: 0.000010\n",
      "Training Epoch: 4 [2640/45000]\tLoss: 3.8056\tLR: 0.000010\n",
      "Training Epoch: 4 [2656/45000]\tLoss: 3.8397\tLR: 0.000010\n",
      "Training Epoch: 4 [2672/45000]\tLoss: 3.7244\tLR: 0.000010\n",
      "Training Epoch: 4 [2688/45000]\tLoss: 3.6754\tLR: 0.000010\n",
      "Training Epoch: 4 [2704/45000]\tLoss: 3.6841\tLR: 0.000010\n",
      "Training Epoch: 4 [2720/45000]\tLoss: 3.8244\tLR: 0.000010\n",
      "Training Epoch: 4 [2736/45000]\tLoss: 3.8229\tLR: 0.000010\n",
      "Training Epoch: 4 [2752/45000]\tLoss: 3.6822\tLR: 0.000010\n",
      "Training Epoch: 4 [2768/45000]\tLoss: 3.7263\tLR: 0.000010\n",
      "Training Epoch: 4 [2784/45000]\tLoss: 3.7912\tLR: 0.000010\n",
      "Training Epoch: 4 [2800/45000]\tLoss: 3.7943\tLR: 0.000010\n",
      "Training Epoch: 4 [2816/45000]\tLoss: 3.8589\tLR: 0.000010\n",
      "Training Epoch: 4 [2832/45000]\tLoss: 3.7507\tLR: 0.000010\n",
      "Training Epoch: 4 [2848/45000]\tLoss: 3.6397\tLR: 0.000010\n",
      "Training Epoch: 4 [2864/45000]\tLoss: 3.7553\tLR: 0.000010\n",
      "Training Epoch: 4 [2880/45000]\tLoss: 3.7918\tLR: 0.000010\n",
      "Training Epoch: 4 [2896/45000]\tLoss: 3.8567\tLR: 0.000010\n",
      "Training Epoch: 4 [2912/45000]\tLoss: 3.8079\tLR: 0.000010\n",
      "Training Epoch: 4 [2928/45000]\tLoss: 3.8090\tLR: 0.000010\n",
      "Training Epoch: 4 [2944/45000]\tLoss: 3.7994\tLR: 0.000010\n",
      "Training Epoch: 4 [2960/45000]\tLoss: 3.6707\tLR: 0.000010\n",
      "Training Epoch: 4 [2976/45000]\tLoss: 3.8121\tLR: 0.000010\n",
      "Training Epoch: 4 [2992/45000]\tLoss: 3.7398\tLR: 0.000010\n",
      "Training Epoch: 4 [3008/45000]\tLoss: 3.7073\tLR: 0.000010\n",
      "Training Epoch: 4 [3024/45000]\tLoss: 3.8205\tLR: 0.000010\n",
      "Training Epoch: 4 [3040/45000]\tLoss: 3.6921\tLR: 0.000010\n",
      "Training Epoch: 4 [3056/45000]\tLoss: 3.7264\tLR: 0.000010\n",
      "Training Epoch: 4 [3072/45000]\tLoss: 3.7899\tLR: 0.000010\n",
      "Training Epoch: 4 [3088/45000]\tLoss: 3.7594\tLR: 0.000010\n",
      "Training Epoch: 4 [3104/45000]\tLoss: 3.6316\tLR: 0.000010\n",
      "Training Epoch: 4 [3120/45000]\tLoss: 3.7009\tLR: 0.000010\n",
      "Training Epoch: 4 [3136/45000]\tLoss: 3.7231\tLR: 0.000010\n",
      "Training Epoch: 4 [3152/45000]\tLoss: 3.7309\tLR: 0.000010\n",
      "Training Epoch: 4 [3168/45000]\tLoss: 3.8056\tLR: 0.000010\n",
      "Training Epoch: 4 [3184/45000]\tLoss: 3.6250\tLR: 0.000010\n",
      "Training Epoch: 4 [3200/45000]\tLoss: 3.6429\tLR: 0.000010\n",
      "Training Epoch: 4 [3216/45000]\tLoss: 3.6900\tLR: 0.000010\n",
      "Training Epoch: 4 [3232/45000]\tLoss: 3.6720\tLR: 0.000010\n",
      "Training Epoch: 4 [3248/45000]\tLoss: 3.7740\tLR: 0.000010\n",
      "Training Epoch: 4 [3264/45000]\tLoss: 3.8268\tLR: 0.000010\n",
      "Training Epoch: 4 [3280/45000]\tLoss: 3.6615\tLR: 0.000010\n",
      "Training Epoch: 4 [3296/45000]\tLoss: 3.7089\tLR: 0.000010\n",
      "Training Epoch: 4 [3312/45000]\tLoss: 3.7266\tLR: 0.000010\n",
      "Training Epoch: 4 [3328/45000]\tLoss: 3.7907\tLR: 0.000010\n",
      "Training Epoch: 4 [3344/45000]\tLoss: 3.6885\tLR: 0.000010\n",
      "Training Epoch: 4 [3360/45000]\tLoss: 3.6467\tLR: 0.000010\n",
      "Training Epoch: 4 [3376/45000]\tLoss: 3.7404\tLR: 0.000010\n",
      "Training Epoch: 4 [3392/45000]\tLoss: 3.6452\tLR: 0.000010\n",
      "Training Epoch: 4 [3408/45000]\tLoss: 3.7282\tLR: 0.000010\n",
      "Training Epoch: 4 [3424/45000]\tLoss: 3.8292\tLR: 0.000010\n",
      "Training Epoch: 4 [3440/45000]\tLoss: 3.8142\tLR: 0.000010\n",
      "Training Epoch: 4 [3456/45000]\tLoss: 3.7110\tLR: 0.000010\n",
      "Training Epoch: 4 [3472/45000]\tLoss: 3.8588\tLR: 0.000010\n",
      "Training Epoch: 4 [3488/45000]\tLoss: 3.7449\tLR: 0.000010\n",
      "Training Epoch: 4 [3504/45000]\tLoss: 3.7826\tLR: 0.000010\n",
      "Training Epoch: 4 [3520/45000]\tLoss: 3.7652\tLR: 0.000010\n",
      "Training Epoch: 4 [3536/45000]\tLoss: 3.8140\tLR: 0.000010\n",
      "Training Epoch: 4 [3552/45000]\tLoss: 3.7996\tLR: 0.000010\n",
      "Training Epoch: 4 [3568/45000]\tLoss: 3.7868\tLR: 0.000010\n",
      "Training Epoch: 4 [3584/45000]\tLoss: 3.7941\tLR: 0.000010\n",
      "Training Epoch: 4 [3600/45000]\tLoss: 3.7218\tLR: 0.000010\n",
      "Training Epoch: 4 [3616/45000]\tLoss: 3.7003\tLR: 0.000010\n",
      "Training Epoch: 4 [3632/45000]\tLoss: 3.8359\tLR: 0.000010\n",
      "Training Epoch: 4 [3648/45000]\tLoss: 3.7036\tLR: 0.000010\n",
      "Training Epoch: 4 [3664/45000]\tLoss: 3.7660\tLR: 0.000010\n",
      "Training Epoch: 4 [3680/45000]\tLoss: 3.6755\tLR: 0.000010\n",
      "Training Epoch: 4 [3696/45000]\tLoss: 3.8059\tLR: 0.000010\n",
      "Training Epoch: 4 [3712/45000]\tLoss: 3.5870\tLR: 0.000010\n",
      "Training Epoch: 4 [3728/45000]\tLoss: 3.7377\tLR: 0.000010\n",
      "Training Epoch: 4 [3744/45000]\tLoss: 3.7480\tLR: 0.000010\n",
      "Training Epoch: 4 [3760/45000]\tLoss: 3.7182\tLR: 0.000010\n",
      "Training Epoch: 4 [3776/45000]\tLoss: 3.7586\tLR: 0.000010\n",
      "Training Epoch: 4 [3792/45000]\tLoss: 3.6768\tLR: 0.000010\n",
      "Training Epoch: 4 [3808/45000]\tLoss: 3.9452\tLR: 0.000010\n",
      "Training Epoch: 4 [3824/45000]\tLoss: 3.7638\tLR: 0.000010\n",
      "Training Epoch: 4 [3840/45000]\tLoss: 3.7185\tLR: 0.000010\n",
      "Training Epoch: 4 [3856/45000]\tLoss: 3.5694\tLR: 0.000010\n",
      "Training Epoch: 4 [3872/45000]\tLoss: 3.8400\tLR: 0.000010\n",
      "Training Epoch: 4 [3888/45000]\tLoss: 3.8406\tLR: 0.000010\n",
      "Training Epoch: 4 [3904/45000]\tLoss: 3.6488\tLR: 0.000010\n",
      "Training Epoch: 4 [3920/45000]\tLoss: 3.7685\tLR: 0.000010\n",
      "Training Epoch: 4 [3936/45000]\tLoss: 3.7498\tLR: 0.000010\n",
      "Training Epoch: 4 [3952/45000]\tLoss: 3.8173\tLR: 0.000010\n",
      "Training Epoch: 4 [3968/45000]\tLoss: 3.6897\tLR: 0.000010\n",
      "Training Epoch: 4 [3984/45000]\tLoss: 3.8219\tLR: 0.000010\n",
      "Training Epoch: 4 [4000/45000]\tLoss: 3.6452\tLR: 0.000010\n",
      "Training Epoch: 4 [4016/45000]\tLoss: 3.7324\tLR: 0.000010\n",
      "Training Epoch: 4 [4032/45000]\tLoss: 3.7615\tLR: 0.000010\n",
      "Training Epoch: 4 [4048/45000]\tLoss: 3.8215\tLR: 0.000010\n",
      "Training Epoch: 4 [4064/45000]\tLoss: 3.6713\tLR: 0.000010\n",
      "Training Epoch: 4 [4080/45000]\tLoss: 3.6431\tLR: 0.000010\n",
      "Training Epoch: 4 [4096/45000]\tLoss: 3.6838\tLR: 0.000010\n",
      "Training Epoch: 4 [4112/45000]\tLoss: 3.5916\tLR: 0.000010\n",
      "Training Epoch: 4 [4128/45000]\tLoss: 3.7701\tLR: 0.000010\n",
      "Training Epoch: 4 [4144/45000]\tLoss: 3.7389\tLR: 0.000010\n",
      "Training Epoch: 4 [4160/45000]\tLoss: 3.6802\tLR: 0.000010\n",
      "Training Epoch: 4 [4176/45000]\tLoss: 3.7976\tLR: 0.000010\n",
      "Training Epoch: 4 [4192/45000]\tLoss: 3.8279\tLR: 0.000010\n",
      "Training Epoch: 4 [4208/45000]\tLoss: 3.6621\tLR: 0.000010\n",
      "Training Epoch: 4 [4224/45000]\tLoss: 3.7083\tLR: 0.000010\n",
      "Training Epoch: 4 [4240/45000]\tLoss: 3.7612\tLR: 0.000010\n",
      "Training Epoch: 4 [4256/45000]\tLoss: 3.9452\tLR: 0.000010\n",
      "Training Epoch: 4 [4272/45000]\tLoss: 3.7126\tLR: 0.000010\n",
      "Training Epoch: 4 [4288/45000]\tLoss: 3.7756\tLR: 0.000010\n",
      "Training Epoch: 4 [4304/45000]\tLoss: 3.7606\tLR: 0.000010\n",
      "Training Epoch: 4 [4320/45000]\tLoss: 3.8516\tLR: 0.000010\n",
      "Training Epoch: 4 [4336/45000]\tLoss: 3.9363\tLR: 0.000010\n",
      "Training Epoch: 4 [4352/45000]\tLoss: 3.6590\tLR: 0.000010\n",
      "Training Epoch: 4 [4368/45000]\tLoss: 3.7595\tLR: 0.000010\n",
      "Training Epoch: 4 [4384/45000]\tLoss: 3.5892\tLR: 0.000010\n",
      "Training Epoch: 4 [4400/45000]\tLoss: 3.6597\tLR: 0.000010\n",
      "Training Epoch: 4 [4416/45000]\tLoss: 3.8145\tLR: 0.000010\n",
      "Training Epoch: 4 [4432/45000]\tLoss: 3.7730\tLR: 0.000010\n",
      "Training Epoch: 4 [4448/45000]\tLoss: 3.8085\tLR: 0.000010\n",
      "Training Epoch: 4 [4464/45000]\tLoss: 3.7600\tLR: 0.000010\n",
      "Training Epoch: 4 [4480/45000]\tLoss: 3.6588\tLR: 0.000010\n",
      "Training Epoch: 4 [4496/45000]\tLoss: 3.7460\tLR: 0.000010\n",
      "Training Epoch: 4 [4512/45000]\tLoss: 3.7966\tLR: 0.000010\n",
      "Training Epoch: 4 [4528/45000]\tLoss: 3.7450\tLR: 0.000010\n",
      "Training Epoch: 4 [4544/45000]\tLoss: 3.8031\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [4560/45000]\tLoss: 3.8540\tLR: 0.000010\n",
      "Training Epoch: 4 [4576/45000]\tLoss: 3.7653\tLR: 0.000010\n",
      "Training Epoch: 4 [4592/45000]\tLoss: 3.7507\tLR: 0.000010\n",
      "Training Epoch: 4 [4608/45000]\tLoss: 3.6676\tLR: 0.000010\n",
      "Training Epoch: 4 [4624/45000]\tLoss: 3.7224\tLR: 0.000010\n",
      "Training Epoch: 4 [4640/45000]\tLoss: 3.7452\tLR: 0.000010\n",
      "Training Epoch: 4 [4656/45000]\tLoss: 3.7591\tLR: 0.000010\n",
      "Training Epoch: 4 [4672/45000]\tLoss: 3.7407\tLR: 0.000010\n",
      "Training Epoch: 4 [4688/45000]\tLoss: 3.8202\tLR: 0.000010\n",
      "Training Epoch: 4 [4704/45000]\tLoss: 3.6663\tLR: 0.000010\n",
      "Training Epoch: 4 [4720/45000]\tLoss: 3.7411\tLR: 0.000010\n",
      "Training Epoch: 4 [4736/45000]\tLoss: 3.6545\tLR: 0.000010\n",
      "Training Epoch: 4 [4752/45000]\tLoss: 3.6572\tLR: 0.000010\n",
      "Training Epoch: 4 [4768/45000]\tLoss: 3.8032\tLR: 0.000010\n",
      "Training Epoch: 4 [4784/45000]\tLoss: 3.7601\tLR: 0.000010\n",
      "Training Epoch: 4 [4800/45000]\tLoss: 3.6859\tLR: 0.000010\n",
      "Training Epoch: 4 [4816/45000]\tLoss: 3.7074\tLR: 0.000010\n",
      "Training Epoch: 4 [4832/45000]\tLoss: 3.6385\tLR: 0.000010\n",
      "Training Epoch: 4 [4848/45000]\tLoss: 3.8218\tLR: 0.000010\n",
      "Training Epoch: 4 [4864/45000]\tLoss: 3.7683\tLR: 0.000010\n",
      "Training Epoch: 4 [4880/45000]\tLoss: 3.7826\tLR: 0.000010\n",
      "Training Epoch: 4 [4896/45000]\tLoss: 3.7538\tLR: 0.000010\n",
      "Training Epoch: 4 [4912/45000]\tLoss: 3.6716\tLR: 0.000010\n",
      "Training Epoch: 4 [4928/45000]\tLoss: 3.7424\tLR: 0.000010\n",
      "Training Epoch: 4 [4944/45000]\tLoss: 3.6278\tLR: 0.000010\n",
      "Training Epoch: 4 [4960/45000]\tLoss: 3.7141\tLR: 0.000010\n",
      "Training Epoch: 4 [4976/45000]\tLoss: 3.7620\tLR: 0.000010\n",
      "Training Epoch: 4 [4992/45000]\tLoss: 3.7328\tLR: 0.000010\n",
      "Training Epoch: 4 [5008/45000]\tLoss: 3.6443\tLR: 0.000010\n",
      "Training Epoch: 4 [5024/45000]\tLoss: 3.8020\tLR: 0.000010\n",
      "Training Epoch: 4 [5040/45000]\tLoss: 3.6789\tLR: 0.000010\n",
      "Training Epoch: 4 [5056/45000]\tLoss: 3.7222\tLR: 0.000010\n",
      "Training Epoch: 4 [5072/45000]\tLoss: 3.6811\tLR: 0.000010\n",
      "Training Epoch: 4 [5088/45000]\tLoss: 3.7775\tLR: 0.000010\n",
      "Training Epoch: 4 [5104/45000]\tLoss: 3.7058\tLR: 0.000010\n",
      "Training Epoch: 4 [5120/45000]\tLoss: 3.7893\tLR: 0.000010\n",
      "Training Epoch: 4 [5136/45000]\tLoss: 3.7081\tLR: 0.000010\n",
      "Training Epoch: 4 [5152/45000]\tLoss: 3.7377\tLR: 0.000010\n",
      "Training Epoch: 4 [5168/45000]\tLoss: 3.7611\tLR: 0.000010\n",
      "Training Epoch: 4 [5184/45000]\tLoss: 3.6982\tLR: 0.000010\n",
      "Training Epoch: 4 [5200/45000]\tLoss: 3.6367\tLR: 0.000010\n",
      "Training Epoch: 4 [5216/45000]\tLoss: 3.7989\tLR: 0.000010\n",
      "Training Epoch: 4 [5232/45000]\tLoss: 3.6839\tLR: 0.000010\n",
      "Training Epoch: 4 [5248/45000]\tLoss: 3.7967\tLR: 0.000010\n",
      "Training Epoch: 4 [5264/45000]\tLoss: 3.8521\tLR: 0.000010\n",
      "Training Epoch: 4 [5280/45000]\tLoss: 3.7049\tLR: 0.000010\n",
      "Training Epoch: 4 [5296/45000]\tLoss: 3.6705\tLR: 0.000010\n",
      "Training Epoch: 4 [5312/45000]\tLoss: 3.7957\tLR: 0.000010\n",
      "Training Epoch: 4 [5328/45000]\tLoss: 3.8492\tLR: 0.000010\n",
      "Training Epoch: 4 [5344/45000]\tLoss: 3.7516\tLR: 0.000010\n",
      "Training Epoch: 4 [5360/45000]\tLoss: 3.7416\tLR: 0.000010\n",
      "Training Epoch: 4 [5376/45000]\tLoss: 3.7534\tLR: 0.000010\n",
      "Training Epoch: 4 [5392/45000]\tLoss: 3.8021\tLR: 0.000010\n",
      "Training Epoch: 4 [5408/45000]\tLoss: 3.7993\tLR: 0.000010\n",
      "Training Epoch: 4 [5424/45000]\tLoss: 3.7196\tLR: 0.000010\n",
      "Training Epoch: 4 [5440/45000]\tLoss: 3.7740\tLR: 0.000010\n",
      "Training Epoch: 4 [5456/45000]\tLoss: 3.8555\tLR: 0.000010\n",
      "Training Epoch: 4 [5472/45000]\tLoss: 3.8228\tLR: 0.000010\n",
      "Training Epoch: 4 [5488/45000]\tLoss: 3.7536\tLR: 0.000010\n",
      "Training Epoch: 4 [5504/45000]\tLoss: 3.8080\tLR: 0.000010\n",
      "Training Epoch: 4 [5520/45000]\tLoss: 3.8262\tLR: 0.000010\n",
      "Training Epoch: 4 [5536/45000]\tLoss: 3.7962\tLR: 0.000010\n",
      "Training Epoch: 4 [5552/45000]\tLoss: 3.8062\tLR: 0.000010\n",
      "Training Epoch: 4 [5568/45000]\tLoss: 3.7949\tLR: 0.000010\n",
      "Training Epoch: 4 [5584/45000]\tLoss: 3.7944\tLR: 0.000010\n",
      "Training Epoch: 4 [5600/45000]\tLoss: 3.8311\tLR: 0.000010\n",
      "Training Epoch: 4 [5616/45000]\tLoss: 3.8040\tLR: 0.000010\n",
      "Training Epoch: 4 [5632/45000]\tLoss: 3.8435\tLR: 0.000010\n",
      "Training Epoch: 4 [5648/45000]\tLoss: 3.7814\tLR: 0.000010\n",
      "Training Epoch: 4 [5664/45000]\tLoss: 3.6676\tLR: 0.000010\n",
      "Training Epoch: 4 [5680/45000]\tLoss: 3.7280\tLR: 0.000010\n",
      "Training Epoch: 4 [5696/45000]\tLoss: 3.8015\tLR: 0.000010\n",
      "Training Epoch: 4 [5712/45000]\tLoss: 3.7084\tLR: 0.000010\n",
      "Training Epoch: 4 [5728/45000]\tLoss: 3.7448\tLR: 0.000010\n",
      "Training Epoch: 4 [5744/45000]\tLoss: 3.6931\tLR: 0.000010\n",
      "Training Epoch: 4 [5760/45000]\tLoss: 3.7421\tLR: 0.000010\n",
      "Training Epoch: 4 [5776/45000]\tLoss: 3.6958\tLR: 0.000010\n",
      "Training Epoch: 4 [5792/45000]\tLoss: 3.7482\tLR: 0.000010\n",
      "Training Epoch: 4 [5808/45000]\tLoss: 3.6157\tLR: 0.000010\n",
      "Training Epoch: 4 [5824/45000]\tLoss: 3.7625\tLR: 0.000010\n",
      "Training Epoch: 4 [5840/45000]\tLoss: 3.6978\tLR: 0.000010\n",
      "Training Epoch: 4 [5856/45000]\tLoss: 3.6518\tLR: 0.000010\n",
      "Training Epoch: 4 [5872/45000]\tLoss: 3.7176\tLR: 0.000010\n",
      "Training Epoch: 4 [5888/45000]\tLoss: 3.8475\tLR: 0.000010\n",
      "Training Epoch: 4 [5904/45000]\tLoss: 3.7293\tLR: 0.000010\n",
      "Training Epoch: 4 [5920/45000]\tLoss: 3.8697\tLR: 0.000010\n",
      "Training Epoch: 4 [5936/45000]\tLoss: 3.6661\tLR: 0.000010\n",
      "Training Epoch: 4 [5952/45000]\tLoss: 3.6758\tLR: 0.000010\n",
      "Training Epoch: 4 [5968/45000]\tLoss: 3.8051\tLR: 0.000010\n",
      "Training Epoch: 4 [5984/45000]\tLoss: 3.7120\tLR: 0.000010\n",
      "Training Epoch: 4 [6000/45000]\tLoss: 3.8272\tLR: 0.000010\n",
      "Training Epoch: 4 [6016/45000]\tLoss: 3.7184\tLR: 0.000010\n",
      "Training Epoch: 4 [6032/45000]\tLoss: 3.7554\tLR: 0.000010\n",
      "Training Epoch: 4 [6048/45000]\tLoss: 3.8233\tLR: 0.000010\n",
      "Training Epoch: 4 [6064/45000]\tLoss: 3.8151\tLR: 0.000010\n",
      "Training Epoch: 4 [6080/45000]\tLoss: 3.7355\tLR: 0.000010\n",
      "Training Epoch: 4 [6096/45000]\tLoss: 3.8001\tLR: 0.000010\n",
      "Training Epoch: 4 [6112/45000]\tLoss: 3.7657\tLR: 0.000010\n",
      "Training Epoch: 4 [6128/45000]\tLoss: 3.6269\tLR: 0.000010\n",
      "Training Epoch: 4 [6144/45000]\tLoss: 3.6913\tLR: 0.000010\n",
      "Training Epoch: 4 [6160/45000]\tLoss: 3.8638\tLR: 0.000010\n",
      "Training Epoch: 4 [6176/45000]\tLoss: 3.9115\tLR: 0.000010\n",
      "Training Epoch: 4 [6192/45000]\tLoss: 3.7221\tLR: 0.000010\n",
      "Training Epoch: 4 [6208/45000]\tLoss: 3.7301\tLR: 0.000010\n",
      "Training Epoch: 4 [6224/45000]\tLoss: 3.8337\tLR: 0.000010\n",
      "Training Epoch: 4 [6240/45000]\tLoss: 3.8016\tLR: 0.000010\n",
      "Training Epoch: 4 [6256/45000]\tLoss: 3.7609\tLR: 0.000010\n",
      "Training Epoch: 4 [6272/45000]\tLoss: 3.7681\tLR: 0.000010\n",
      "Training Epoch: 4 [6288/45000]\tLoss: 3.7110\tLR: 0.000010\n",
      "Training Epoch: 4 [6304/45000]\tLoss: 3.6954\tLR: 0.000010\n",
      "Training Epoch: 4 [6320/45000]\tLoss: 3.7111\tLR: 0.000010\n",
      "Training Epoch: 4 [6336/45000]\tLoss: 3.7327\tLR: 0.000010\n",
      "Training Epoch: 4 [6352/45000]\tLoss: 3.7843\tLR: 0.000010\n",
      "Training Epoch: 4 [6368/45000]\tLoss: 3.7314\tLR: 0.000010\n",
      "Training Epoch: 4 [6384/45000]\tLoss: 3.6827\tLR: 0.000010\n",
      "Training Epoch: 4 [6400/45000]\tLoss: 3.7342\tLR: 0.000010\n",
      "Training Epoch: 4 [6416/45000]\tLoss: 3.8130\tLR: 0.000010\n",
      "Training Epoch: 4 [6432/45000]\tLoss: 3.7081\tLR: 0.000010\n",
      "Training Epoch: 4 [6448/45000]\tLoss: 3.7484\tLR: 0.000010\n",
      "Training Epoch: 4 [6464/45000]\tLoss: 3.7388\tLR: 0.000010\n",
      "Training Epoch: 4 [6480/45000]\tLoss: 3.8325\tLR: 0.000010\n",
      "Training Epoch: 4 [6496/45000]\tLoss: 3.8225\tLR: 0.000010\n",
      "Training Epoch: 4 [6512/45000]\tLoss: 3.7315\tLR: 0.000010\n",
      "Training Epoch: 4 [6528/45000]\tLoss: 3.7209\tLR: 0.000010\n",
      "Training Epoch: 4 [6544/45000]\tLoss: 3.8476\tLR: 0.000010\n",
      "Training Epoch: 4 [6560/45000]\tLoss: 3.6955\tLR: 0.000010\n",
      "Training Epoch: 4 [6576/45000]\tLoss: 3.6637\tLR: 0.000010\n",
      "Training Epoch: 4 [6592/45000]\tLoss: 3.7926\tLR: 0.000010\n",
      "Training Epoch: 4 [6608/45000]\tLoss: 3.7110\tLR: 0.000010\n",
      "Training Epoch: 4 [6624/45000]\tLoss: 3.7767\tLR: 0.000010\n",
      "Training Epoch: 4 [6640/45000]\tLoss: 3.6125\tLR: 0.000010\n",
      "Training Epoch: 4 [6656/45000]\tLoss: 3.7318\tLR: 0.000010\n",
      "Training Epoch: 4 [6672/45000]\tLoss: 3.7292\tLR: 0.000010\n",
      "Training Epoch: 4 [6688/45000]\tLoss: 3.8197\tLR: 0.000010\n",
      "Training Epoch: 4 [6704/45000]\tLoss: 3.6650\tLR: 0.000010\n",
      "Training Epoch: 4 [6720/45000]\tLoss: 3.7507\tLR: 0.000010\n",
      "Training Epoch: 4 [6736/45000]\tLoss: 3.8111\tLR: 0.000010\n",
      "Training Epoch: 4 [6752/45000]\tLoss: 3.7712\tLR: 0.000010\n",
      "Training Epoch: 4 [6768/45000]\tLoss: 3.8067\tLR: 0.000010\n",
      "Training Epoch: 4 [6784/45000]\tLoss: 3.7617\tLR: 0.000010\n",
      "Training Epoch: 4 [6800/45000]\tLoss: 3.7341\tLR: 0.000010\n",
      "Training Epoch: 4 [6816/45000]\tLoss: 3.7113\tLR: 0.000010\n",
      "Training Epoch: 4 [6832/45000]\tLoss: 3.7887\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [6848/45000]\tLoss: 3.7772\tLR: 0.000010\n",
      "Training Epoch: 4 [6864/45000]\tLoss: 3.6900\tLR: 0.000010\n",
      "Training Epoch: 4 [6880/45000]\tLoss: 3.7608\tLR: 0.000010\n",
      "Training Epoch: 4 [6896/45000]\tLoss: 3.7645\tLR: 0.000010\n",
      "Training Epoch: 4 [6912/45000]\tLoss: 3.7133\tLR: 0.000010\n",
      "Training Epoch: 4 [6928/45000]\tLoss: 3.7122\tLR: 0.000010\n",
      "Training Epoch: 4 [6944/45000]\tLoss: 3.7668\tLR: 0.000010\n",
      "Training Epoch: 4 [6960/45000]\tLoss: 3.7831\tLR: 0.000010\n",
      "Training Epoch: 4 [6976/45000]\tLoss: 3.9332\tLR: 0.000010\n",
      "Training Epoch: 4 [6992/45000]\tLoss: 3.7050\tLR: 0.000010\n",
      "Training Epoch: 4 [7008/45000]\tLoss: 3.6058\tLR: 0.000010\n",
      "Training Epoch: 4 [7024/45000]\tLoss: 3.6509\tLR: 0.000010\n",
      "Training Epoch: 4 [7040/45000]\tLoss: 3.8079\tLR: 0.000010\n",
      "Training Epoch: 4 [7056/45000]\tLoss: 3.7766\tLR: 0.000010\n",
      "Training Epoch: 4 [7072/45000]\tLoss: 3.6859\tLR: 0.000010\n",
      "Training Epoch: 4 [7088/45000]\tLoss: 3.7767\tLR: 0.000010\n",
      "Training Epoch: 4 [7104/45000]\tLoss: 3.7135\tLR: 0.000010\n",
      "Training Epoch: 4 [7120/45000]\tLoss: 3.7930\tLR: 0.000010\n",
      "Training Epoch: 4 [7136/45000]\tLoss: 3.7303\tLR: 0.000010\n",
      "Training Epoch: 4 [7152/45000]\tLoss: 3.7932\tLR: 0.000010\n",
      "Training Epoch: 4 [7168/45000]\tLoss: 3.7098\tLR: 0.000010\n",
      "Training Epoch: 4 [7184/45000]\tLoss: 3.7743\tLR: 0.000010\n",
      "Training Epoch: 4 [7200/45000]\tLoss: 3.6628\tLR: 0.000010\n",
      "Training Epoch: 4 [7216/45000]\tLoss: 3.8107\tLR: 0.000010\n",
      "Training Epoch: 4 [7232/45000]\tLoss: 3.7662\tLR: 0.000010\n",
      "Training Epoch: 4 [7248/45000]\tLoss: 3.6423\tLR: 0.000010\n",
      "Training Epoch: 4 [7264/45000]\tLoss: 3.8517\tLR: 0.000010\n",
      "Training Epoch: 4 [7280/45000]\tLoss: 3.7360\tLR: 0.000010\n",
      "Training Epoch: 4 [7296/45000]\tLoss: 3.6990\tLR: 0.000010\n",
      "Training Epoch: 4 [7312/45000]\tLoss: 3.8311\tLR: 0.000010\n",
      "Training Epoch: 4 [7328/45000]\tLoss: 3.8339\tLR: 0.000010\n",
      "Training Epoch: 4 [7344/45000]\tLoss: 3.8948\tLR: 0.000010\n",
      "Training Epoch: 4 [7360/45000]\tLoss: 3.7602\tLR: 0.000010\n",
      "Training Epoch: 4 [7376/45000]\tLoss: 3.7730\tLR: 0.000010\n",
      "Training Epoch: 4 [7392/45000]\tLoss: 3.7954\tLR: 0.000010\n",
      "Training Epoch: 4 [7408/45000]\tLoss: 3.6312\tLR: 0.000010\n",
      "Training Epoch: 4 [7424/45000]\tLoss: 3.7736\tLR: 0.000010\n",
      "Training Epoch: 4 [7440/45000]\tLoss: 3.6871\tLR: 0.000010\n",
      "Training Epoch: 4 [7456/45000]\tLoss: 3.7379\tLR: 0.000010\n",
      "Training Epoch: 4 [7472/45000]\tLoss: 3.8921\tLR: 0.000010\n",
      "Training Epoch: 4 [7488/45000]\tLoss: 3.6566\tLR: 0.000010\n",
      "Training Epoch: 4 [7504/45000]\tLoss: 3.7360\tLR: 0.000010\n",
      "Training Epoch: 4 [7520/45000]\tLoss: 3.7355\tLR: 0.000010\n",
      "Training Epoch: 4 [7536/45000]\tLoss: 3.7847\tLR: 0.000010\n",
      "Training Epoch: 4 [7552/45000]\tLoss: 3.8071\tLR: 0.000010\n",
      "Training Epoch: 4 [7568/45000]\tLoss: 3.7283\tLR: 0.000010\n",
      "Training Epoch: 4 [7584/45000]\tLoss: 3.7763\tLR: 0.000010\n",
      "Training Epoch: 4 [7600/45000]\tLoss: 3.8437\tLR: 0.000010\n",
      "Training Epoch: 4 [7616/45000]\tLoss: 3.7061\tLR: 0.000010\n",
      "Training Epoch: 4 [7632/45000]\tLoss: 3.7946\tLR: 0.000010\n",
      "Training Epoch: 4 [7648/45000]\tLoss: 3.8755\tLR: 0.000010\n",
      "Training Epoch: 4 [7664/45000]\tLoss: 3.7136\tLR: 0.000010\n",
      "Training Epoch: 4 [7680/45000]\tLoss: 3.8059\tLR: 0.000010\n",
      "Training Epoch: 4 [7696/45000]\tLoss: 3.7064\tLR: 0.000010\n",
      "Training Epoch: 4 [7712/45000]\tLoss: 3.7626\tLR: 0.000010\n",
      "Training Epoch: 4 [7728/45000]\tLoss: 3.7770\tLR: 0.000010\n",
      "Training Epoch: 4 [7744/45000]\tLoss: 3.6759\tLR: 0.000010\n",
      "Training Epoch: 4 [7760/45000]\tLoss: 3.8172\tLR: 0.000010\n",
      "Training Epoch: 4 [7776/45000]\tLoss: 3.6047\tLR: 0.000010\n",
      "Training Epoch: 4 [7792/45000]\tLoss: 3.7912\tLR: 0.000010\n",
      "Training Epoch: 4 [7808/45000]\tLoss: 3.6505\tLR: 0.000010\n",
      "Training Epoch: 4 [7824/45000]\tLoss: 3.8100\tLR: 0.000010\n",
      "Training Epoch: 4 [7840/45000]\tLoss: 3.7772\tLR: 0.000010\n",
      "Training Epoch: 4 [7856/45000]\tLoss: 3.7344\tLR: 0.000010\n",
      "Training Epoch: 4 [7872/45000]\tLoss: 3.6108\tLR: 0.000010\n",
      "Training Epoch: 4 [7888/45000]\tLoss: 3.7783\tLR: 0.000010\n",
      "Training Epoch: 4 [7904/45000]\tLoss: 3.7274\tLR: 0.000010\n",
      "Training Epoch: 4 [7920/45000]\tLoss: 3.6570\tLR: 0.000010\n",
      "Training Epoch: 4 [7936/45000]\tLoss: 3.7844\tLR: 0.000010\n",
      "Training Epoch: 4 [7952/45000]\tLoss: 3.7747\tLR: 0.000010\n",
      "Training Epoch: 4 [7968/45000]\tLoss: 3.6347\tLR: 0.000010\n",
      "Training Epoch: 4 [7984/45000]\tLoss: 3.7448\tLR: 0.000010\n",
      "Training Epoch: 4 [8000/45000]\tLoss: 3.7114\tLR: 0.000010\n",
      "Training Epoch: 4 [8016/45000]\tLoss: 3.8417\tLR: 0.000010\n",
      "Training Epoch: 4 [8032/45000]\tLoss: 3.8960\tLR: 0.000010\n",
      "Training Epoch: 4 [8048/45000]\tLoss: 3.6811\tLR: 0.000010\n",
      "Training Epoch: 4 [8064/45000]\tLoss: 3.8178\tLR: 0.000010\n",
      "Training Epoch: 4 [8080/45000]\tLoss: 3.6925\tLR: 0.000010\n",
      "Training Epoch: 4 [8096/45000]\tLoss: 3.7972\tLR: 0.000010\n",
      "Training Epoch: 4 [8112/45000]\tLoss: 3.7196\tLR: 0.000010\n",
      "Training Epoch: 4 [8128/45000]\tLoss: 3.6462\tLR: 0.000010\n",
      "Training Epoch: 4 [8144/45000]\tLoss: 3.6622\tLR: 0.000010\n",
      "Training Epoch: 4 [8160/45000]\tLoss: 3.7221\tLR: 0.000010\n",
      "Training Epoch: 4 [8176/45000]\tLoss: 3.7808\tLR: 0.000010\n",
      "Training Epoch: 4 [8192/45000]\tLoss: 3.6666\tLR: 0.000010\n",
      "Training Epoch: 4 [8208/45000]\tLoss: 3.7041\tLR: 0.000010\n",
      "Training Epoch: 4 [8224/45000]\tLoss: 3.7346\tLR: 0.000010\n",
      "Training Epoch: 4 [8240/45000]\tLoss: 3.7434\tLR: 0.000010\n",
      "Training Epoch: 4 [8256/45000]\tLoss: 3.7207\tLR: 0.000010\n",
      "Training Epoch: 4 [8272/45000]\tLoss: 3.6749\tLR: 0.000010\n",
      "Training Epoch: 4 [8288/45000]\tLoss: 3.7414\tLR: 0.000010\n",
      "Training Epoch: 4 [8304/45000]\tLoss: 3.8216\tLR: 0.000010\n",
      "Training Epoch: 4 [8320/45000]\tLoss: 3.7709\tLR: 0.000010\n",
      "Training Epoch: 4 [8336/45000]\tLoss: 3.8565\tLR: 0.000010\n",
      "Training Epoch: 4 [8352/45000]\tLoss: 3.6993\tLR: 0.000010\n",
      "Training Epoch: 4 [8368/45000]\tLoss: 3.6272\tLR: 0.000010\n",
      "Training Epoch: 4 [8384/45000]\tLoss: 3.6313\tLR: 0.000010\n",
      "Training Epoch: 4 [8400/45000]\tLoss: 3.6698\tLR: 0.000010\n",
      "Training Epoch: 4 [8416/45000]\tLoss: 3.8023\tLR: 0.000010\n",
      "Training Epoch: 4 [8432/45000]\tLoss: 3.7419\tLR: 0.000010\n",
      "Training Epoch: 4 [8448/45000]\tLoss: 3.6670\tLR: 0.000010\n",
      "Training Epoch: 4 [8464/45000]\tLoss: 3.7296\tLR: 0.000010\n",
      "Training Epoch: 4 [8480/45000]\tLoss: 3.7358\tLR: 0.000010\n",
      "Training Epoch: 4 [8496/45000]\tLoss: 3.7764\tLR: 0.000010\n",
      "Training Epoch: 4 [8512/45000]\tLoss: 3.7439\tLR: 0.000010\n",
      "Training Epoch: 4 [8528/45000]\tLoss: 3.8371\tLR: 0.000010\n",
      "Training Epoch: 4 [8544/45000]\tLoss: 3.6739\tLR: 0.000010\n",
      "Training Epoch: 4 [8560/45000]\tLoss: 3.8012\tLR: 0.000010\n",
      "Training Epoch: 4 [8576/45000]\tLoss: 3.7998\tLR: 0.000010\n",
      "Training Epoch: 4 [8592/45000]\tLoss: 3.7751\tLR: 0.000010\n",
      "Training Epoch: 4 [8608/45000]\tLoss: 3.7260\tLR: 0.000010\n",
      "Training Epoch: 4 [8624/45000]\tLoss: 3.8089\tLR: 0.000010\n",
      "Training Epoch: 4 [8640/45000]\tLoss: 3.7640\tLR: 0.000010\n",
      "Training Epoch: 4 [8656/45000]\tLoss: 3.9036\tLR: 0.000010\n",
      "Training Epoch: 4 [8672/45000]\tLoss: 3.8092\tLR: 0.000010\n",
      "Training Epoch: 4 [8688/45000]\tLoss: 3.8308\tLR: 0.000010\n",
      "Training Epoch: 4 [8704/45000]\tLoss: 3.6620\tLR: 0.000010\n",
      "Training Epoch: 4 [8720/45000]\tLoss: 3.6763\tLR: 0.000010\n",
      "Training Epoch: 4 [8736/45000]\tLoss: 3.7262\tLR: 0.000010\n",
      "Training Epoch: 4 [8752/45000]\tLoss: 3.7782\tLR: 0.000010\n",
      "Training Epoch: 4 [8768/45000]\tLoss: 3.7650\tLR: 0.000010\n",
      "Training Epoch: 4 [8784/45000]\tLoss: 3.6960\tLR: 0.000010\n",
      "Training Epoch: 4 [8800/45000]\tLoss: 3.7104\tLR: 0.000010\n",
      "Training Epoch: 4 [8816/45000]\tLoss: 3.7839\tLR: 0.000010\n",
      "Training Epoch: 4 [8832/45000]\tLoss: 3.7004\tLR: 0.000010\n",
      "Training Epoch: 4 [8848/45000]\tLoss: 3.7004\tLR: 0.000010\n",
      "Training Epoch: 4 [8864/45000]\tLoss: 3.7041\tLR: 0.000010\n",
      "Training Epoch: 4 [8880/45000]\tLoss: 3.5653\tLR: 0.000010\n",
      "Training Epoch: 4 [8896/45000]\tLoss: 3.8050\tLR: 0.000010\n",
      "Training Epoch: 4 [8912/45000]\tLoss: 3.7797\tLR: 0.000010\n",
      "Training Epoch: 4 [8928/45000]\tLoss: 3.8352\tLR: 0.000010\n",
      "Training Epoch: 4 [8944/45000]\tLoss: 3.7438\tLR: 0.000010\n",
      "Training Epoch: 4 [8960/45000]\tLoss: 3.7904\tLR: 0.000010\n",
      "Training Epoch: 4 [8976/45000]\tLoss: 3.7981\tLR: 0.000010\n",
      "Training Epoch: 4 [8992/45000]\tLoss: 3.6812\tLR: 0.000010\n",
      "Training Epoch: 4 [9008/45000]\tLoss: 3.7421\tLR: 0.000010\n",
      "Training Epoch: 4 [9024/45000]\tLoss: 3.7158\tLR: 0.000010\n",
      "Training Epoch: 4 [9040/45000]\tLoss: 3.6853\tLR: 0.000010\n",
      "Training Epoch: 4 [9056/45000]\tLoss: 3.7070\tLR: 0.000010\n",
      "Training Epoch: 4 [9072/45000]\tLoss: 3.7288\tLR: 0.000010\n",
      "Training Epoch: 4 [9088/45000]\tLoss: 3.7403\tLR: 0.000010\n",
      "Training Epoch: 4 [9104/45000]\tLoss: 3.6883\tLR: 0.000010\n",
      "Training Epoch: 4 [9120/45000]\tLoss: 3.7744\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [9136/45000]\tLoss: 3.7258\tLR: 0.000010\n",
      "Training Epoch: 4 [9152/45000]\tLoss: 3.8331\tLR: 0.000010\n",
      "Training Epoch: 4 [9168/45000]\tLoss: 3.7882\tLR: 0.000010\n",
      "Training Epoch: 4 [9184/45000]\tLoss: 3.7677\tLR: 0.000010\n",
      "Training Epoch: 4 [9200/45000]\tLoss: 3.7325\tLR: 0.000010\n",
      "Training Epoch: 4 [9216/45000]\tLoss: 3.8087\tLR: 0.000010\n",
      "Training Epoch: 4 [9232/45000]\tLoss: 3.7956\tLR: 0.000010\n",
      "Training Epoch: 4 [9248/45000]\tLoss: 3.7199\tLR: 0.000010\n",
      "Training Epoch: 4 [9264/45000]\tLoss: 3.7916\tLR: 0.000010\n",
      "Training Epoch: 4 [9280/45000]\tLoss: 3.6539\tLR: 0.000010\n",
      "Training Epoch: 4 [9296/45000]\tLoss: 3.7435\tLR: 0.000010\n",
      "Training Epoch: 4 [9312/45000]\tLoss: 3.7041\tLR: 0.000010\n",
      "Training Epoch: 4 [9328/45000]\tLoss: 3.8245\tLR: 0.000010\n",
      "Training Epoch: 4 [9344/45000]\tLoss: 3.6994\tLR: 0.000010\n",
      "Training Epoch: 4 [9360/45000]\tLoss: 3.7495\tLR: 0.000010\n",
      "Training Epoch: 4 [9376/45000]\tLoss: 3.7602\tLR: 0.000010\n",
      "Training Epoch: 4 [9392/45000]\tLoss: 3.6992\tLR: 0.000010\n",
      "Training Epoch: 4 [9408/45000]\tLoss: 3.7090\tLR: 0.000010\n",
      "Training Epoch: 4 [9424/45000]\tLoss: 3.7163\tLR: 0.000010\n",
      "Training Epoch: 4 [9440/45000]\tLoss: 3.6690\tLR: 0.000010\n",
      "Training Epoch: 4 [9456/45000]\tLoss: 3.7959\tLR: 0.000010\n",
      "Training Epoch: 4 [9472/45000]\tLoss: 3.6734\tLR: 0.000010\n",
      "Training Epoch: 4 [9488/45000]\tLoss: 3.7555\tLR: 0.000010\n",
      "Training Epoch: 4 [9504/45000]\tLoss: 3.7097\tLR: 0.000010\n",
      "Training Epoch: 4 [9520/45000]\tLoss: 3.9246\tLR: 0.000010\n",
      "Training Epoch: 4 [9536/45000]\tLoss: 3.7545\tLR: 0.000010\n",
      "Training Epoch: 4 [9552/45000]\tLoss: 3.7668\tLR: 0.000010\n",
      "Training Epoch: 4 [9568/45000]\tLoss: 3.7083\tLR: 0.000010\n",
      "Training Epoch: 4 [9584/45000]\tLoss: 3.8738\tLR: 0.000010\n",
      "Training Epoch: 4 [9600/45000]\tLoss: 3.6630\tLR: 0.000010\n",
      "Training Epoch: 4 [9616/45000]\tLoss: 3.6418\tLR: 0.000010\n",
      "Training Epoch: 4 [9632/45000]\tLoss: 3.7190\tLR: 0.000010\n",
      "Training Epoch: 4 [9648/45000]\tLoss: 3.7828\tLR: 0.000010\n",
      "Training Epoch: 4 [9664/45000]\tLoss: 3.6058\tLR: 0.000010\n",
      "Training Epoch: 4 [9680/45000]\tLoss: 3.6681\tLR: 0.000010\n",
      "Training Epoch: 4 [9696/45000]\tLoss: 3.8016\tLR: 0.000010\n",
      "Training Epoch: 4 [9712/45000]\tLoss: 3.6229\tLR: 0.000010\n",
      "Training Epoch: 4 [9728/45000]\tLoss: 3.7789\tLR: 0.000010\n",
      "Training Epoch: 4 [9744/45000]\tLoss: 3.6683\tLR: 0.000010\n",
      "Training Epoch: 4 [9760/45000]\tLoss: 3.7375\tLR: 0.000010\n",
      "Training Epoch: 4 [9776/45000]\tLoss: 3.7187\tLR: 0.000010\n",
      "Training Epoch: 4 [9792/45000]\tLoss: 3.7622\tLR: 0.000010\n",
      "Training Epoch: 4 [9808/45000]\tLoss: 3.6868\tLR: 0.000010\n",
      "Training Epoch: 4 [9824/45000]\tLoss: 3.6601\tLR: 0.000010\n",
      "Training Epoch: 4 [9840/45000]\tLoss: 3.7783\tLR: 0.000010\n",
      "Training Epoch: 4 [9856/45000]\tLoss: 3.6395\tLR: 0.000010\n",
      "Training Epoch: 4 [9872/45000]\tLoss: 3.6091\tLR: 0.000010\n",
      "Training Epoch: 4 [9888/45000]\tLoss: 3.7454\tLR: 0.000010\n",
      "Training Epoch: 4 [9904/45000]\tLoss: 3.6723\tLR: 0.000010\n",
      "Training Epoch: 4 [9920/45000]\tLoss: 3.6925\tLR: 0.000010\n",
      "Training Epoch: 4 [9936/45000]\tLoss: 3.8529\tLR: 0.000010\n",
      "Training Epoch: 4 [9952/45000]\tLoss: 3.7924\tLR: 0.000010\n",
      "Training Epoch: 4 [9968/45000]\tLoss: 3.8077\tLR: 0.000010\n",
      "Training Epoch: 4 [9984/45000]\tLoss: 3.6055\tLR: 0.000010\n",
      "Training Epoch: 4 [10000/45000]\tLoss: 3.6700\tLR: 0.000010\n",
      "Training Epoch: 4 [10016/45000]\tLoss: 3.7381\tLR: 0.000010\n",
      "Training Epoch: 4 [10032/45000]\tLoss: 3.7905\tLR: 0.000010\n",
      "Training Epoch: 4 [10048/45000]\tLoss: 3.6677\tLR: 0.000010\n",
      "Training Epoch: 4 [10064/45000]\tLoss: 3.7117\tLR: 0.000010\n",
      "Training Epoch: 4 [10080/45000]\tLoss: 3.7686\tLR: 0.000010\n",
      "Training Epoch: 4 [10096/45000]\tLoss: 3.7263\tLR: 0.000010\n",
      "Training Epoch: 4 [10112/45000]\tLoss: 3.7779\tLR: 0.000010\n",
      "Training Epoch: 4 [10128/45000]\tLoss: 3.8199\tLR: 0.000010\n",
      "Training Epoch: 4 [10144/45000]\tLoss: 3.6985\tLR: 0.000010\n",
      "Training Epoch: 4 [10160/45000]\tLoss: 3.7011\tLR: 0.000010\n",
      "Training Epoch: 4 [10176/45000]\tLoss: 3.7940\tLR: 0.000010\n",
      "Training Epoch: 4 [10192/45000]\tLoss: 3.7446\tLR: 0.000010\n",
      "Training Epoch: 4 [10208/45000]\tLoss: 3.8889\tLR: 0.000010\n",
      "Training Epoch: 4 [10224/45000]\tLoss: 3.7914\tLR: 0.000010\n",
      "Training Epoch: 4 [10240/45000]\tLoss: 3.7245\tLR: 0.000010\n",
      "Training Epoch: 4 [10256/45000]\tLoss: 3.8388\tLR: 0.000010\n",
      "Training Epoch: 4 [10272/45000]\tLoss: 3.7670\tLR: 0.000010\n",
      "Training Epoch: 4 [10288/45000]\tLoss: 3.7680\tLR: 0.000010\n",
      "Training Epoch: 4 [10304/45000]\tLoss: 3.8237\tLR: 0.000010\n",
      "Training Epoch: 4 [10320/45000]\tLoss: 3.7886\tLR: 0.000010\n",
      "Training Epoch: 4 [10336/45000]\tLoss: 3.7180\tLR: 0.000010\n",
      "Training Epoch: 4 [10352/45000]\tLoss: 3.8227\tLR: 0.000010\n",
      "Training Epoch: 4 [10368/45000]\tLoss: 3.7653\tLR: 0.000010\n",
      "Training Epoch: 4 [10384/45000]\tLoss: 3.6193\tLR: 0.000010\n",
      "Training Epoch: 4 [10400/45000]\tLoss: 3.8335\tLR: 0.000010\n",
      "Training Epoch: 4 [10416/45000]\tLoss: 3.7279\tLR: 0.000010\n",
      "Training Epoch: 4 [10432/45000]\tLoss: 3.8961\tLR: 0.000010\n",
      "Training Epoch: 4 [10448/45000]\tLoss: 3.6864\tLR: 0.000010\n",
      "Training Epoch: 4 [10464/45000]\tLoss: 3.7256\tLR: 0.000010\n",
      "Training Epoch: 4 [10480/45000]\tLoss: 3.7601\tLR: 0.000010\n",
      "Training Epoch: 4 [10496/45000]\tLoss: 3.7817\tLR: 0.000010\n",
      "Training Epoch: 4 [10512/45000]\tLoss: 3.7590\tLR: 0.000010\n",
      "Training Epoch: 4 [10528/45000]\tLoss: 3.7045\tLR: 0.000010\n",
      "Training Epoch: 4 [10544/45000]\tLoss: 3.7481\tLR: 0.000010\n",
      "Training Epoch: 4 [10560/45000]\tLoss: 3.8091\tLR: 0.000010\n",
      "Training Epoch: 4 [10576/45000]\tLoss: 3.7721\tLR: 0.000010\n",
      "Training Epoch: 4 [10592/45000]\tLoss: 3.7307\tLR: 0.000010\n",
      "Training Epoch: 4 [10608/45000]\tLoss: 3.7924\tLR: 0.000010\n",
      "Training Epoch: 4 [10624/45000]\tLoss: 3.6566\tLR: 0.000010\n",
      "Training Epoch: 4 [10640/45000]\tLoss: 3.8478\tLR: 0.000010\n",
      "Training Epoch: 4 [10656/45000]\tLoss: 3.8365\tLR: 0.000010\n",
      "Training Epoch: 4 [10672/45000]\tLoss: 3.7015\tLR: 0.000010\n",
      "Training Epoch: 4 [10688/45000]\tLoss: 3.8749\tLR: 0.000010\n",
      "Training Epoch: 4 [10704/45000]\tLoss: 3.6983\tLR: 0.000010\n",
      "Training Epoch: 4 [10720/45000]\tLoss: 3.6607\tLR: 0.000010\n",
      "Training Epoch: 4 [10736/45000]\tLoss: 3.7993\tLR: 0.000010\n",
      "Training Epoch: 4 [10752/45000]\tLoss: 3.7048\tLR: 0.000010\n",
      "Training Epoch: 4 [10768/45000]\tLoss: 3.7428\tLR: 0.000010\n",
      "Training Epoch: 4 [10784/45000]\tLoss: 3.5597\tLR: 0.000010\n",
      "Training Epoch: 4 [10800/45000]\tLoss: 3.7006\tLR: 0.000010\n",
      "Training Epoch: 4 [10816/45000]\tLoss: 3.7896\tLR: 0.000010\n",
      "Training Epoch: 4 [10832/45000]\tLoss: 3.6749\tLR: 0.000010\n",
      "Training Epoch: 4 [10848/45000]\tLoss: 3.6611\tLR: 0.000010\n",
      "Training Epoch: 4 [10864/45000]\tLoss: 3.6751\tLR: 0.000010\n",
      "Training Epoch: 4 [10880/45000]\tLoss: 3.7413\tLR: 0.000010\n",
      "Training Epoch: 4 [10896/45000]\tLoss: 3.7127\tLR: 0.000010\n",
      "Training Epoch: 4 [10912/45000]\tLoss: 3.7238\tLR: 0.000010\n",
      "Training Epoch: 4 [10928/45000]\tLoss: 3.7523\tLR: 0.000010\n",
      "Training Epoch: 4 [10944/45000]\tLoss: 3.7322\tLR: 0.000010\n",
      "Training Epoch: 4 [10960/45000]\tLoss: 3.7177\tLR: 0.000010\n",
      "Training Epoch: 4 [10976/45000]\tLoss: 3.7220\tLR: 0.000010\n",
      "Training Epoch: 4 [10992/45000]\tLoss: 3.7440\tLR: 0.000010\n",
      "Training Epoch: 4 [11008/45000]\tLoss: 3.6555\tLR: 0.000010\n",
      "Training Epoch: 4 [11024/45000]\tLoss: 3.8091\tLR: 0.000010\n",
      "Training Epoch: 4 [11040/45000]\tLoss: 3.6735\tLR: 0.000010\n",
      "Training Epoch: 4 [11056/45000]\tLoss: 3.8259\tLR: 0.000010\n",
      "Training Epoch: 4 [11072/45000]\tLoss: 3.8445\tLR: 0.000010\n",
      "Training Epoch: 4 [11088/45000]\tLoss: 3.7323\tLR: 0.000010\n",
      "Training Epoch: 4 [11104/45000]\tLoss: 3.7095\tLR: 0.000010\n",
      "Training Epoch: 4 [11120/45000]\tLoss: 3.6812\tLR: 0.000010\n",
      "Training Epoch: 4 [11136/45000]\tLoss: 3.6475\tLR: 0.000010\n",
      "Training Epoch: 4 [11152/45000]\tLoss: 3.6635\tLR: 0.000010\n",
      "Training Epoch: 4 [11168/45000]\tLoss: 3.7623\tLR: 0.000010\n",
      "Training Epoch: 4 [11184/45000]\tLoss: 3.6984\tLR: 0.000010\n",
      "Training Epoch: 4 [11200/45000]\tLoss: 3.7097\tLR: 0.000010\n",
      "Training Epoch: 4 [11216/45000]\tLoss: 3.7586\tLR: 0.000010\n",
      "Training Epoch: 4 [11232/45000]\tLoss: 3.6838\tLR: 0.000010\n",
      "Training Epoch: 4 [11248/45000]\tLoss: 3.7486\tLR: 0.000010\n",
      "Training Epoch: 4 [11264/45000]\tLoss: 3.7860\tLR: 0.000010\n",
      "Training Epoch: 4 [11280/45000]\tLoss: 3.7153\tLR: 0.000010\n",
      "Training Epoch: 4 [11296/45000]\tLoss: 3.7920\tLR: 0.000010\n",
      "Training Epoch: 4 [11312/45000]\tLoss: 3.7097\tLR: 0.000010\n",
      "Training Epoch: 4 [11328/45000]\tLoss: 3.6794\tLR: 0.000010\n",
      "Training Epoch: 4 [11344/45000]\tLoss: 3.6943\tLR: 0.000010\n",
      "Training Epoch: 4 [11360/45000]\tLoss: 3.7788\tLR: 0.000010\n",
      "Training Epoch: 4 [11376/45000]\tLoss: 3.8003\tLR: 0.000010\n",
      "Training Epoch: 4 [11392/45000]\tLoss: 3.8344\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [11408/45000]\tLoss: 3.5949\tLR: 0.000010\n",
      "Training Epoch: 4 [11424/45000]\tLoss: 3.6124\tLR: 0.000010\n",
      "Training Epoch: 4 [11440/45000]\tLoss: 3.8585\tLR: 0.000010\n",
      "Training Epoch: 4 [11456/45000]\tLoss: 3.7474\tLR: 0.000010\n",
      "Training Epoch: 4 [11472/45000]\tLoss: 3.9333\tLR: 0.000010\n",
      "Training Epoch: 4 [11488/45000]\tLoss: 3.8916\tLR: 0.000010\n",
      "Training Epoch: 4 [11504/45000]\tLoss: 3.9061\tLR: 0.000010\n",
      "Training Epoch: 4 [11520/45000]\tLoss: 3.6512\tLR: 0.000010\n",
      "Training Epoch: 4 [11536/45000]\tLoss: 3.8190\tLR: 0.000010\n",
      "Training Epoch: 4 [11552/45000]\tLoss: 3.7804\tLR: 0.000010\n",
      "Training Epoch: 4 [11568/45000]\tLoss: 3.7965\tLR: 0.000010\n",
      "Training Epoch: 4 [11584/45000]\tLoss: 3.7710\tLR: 0.000010\n",
      "Training Epoch: 4 [11600/45000]\tLoss: 3.8427\tLR: 0.000010\n",
      "Training Epoch: 4 [11616/45000]\tLoss: 3.7830\tLR: 0.000010\n",
      "Training Epoch: 4 [11632/45000]\tLoss: 3.6872\tLR: 0.000010\n",
      "Training Epoch: 4 [11648/45000]\tLoss: 3.6249\tLR: 0.000010\n",
      "Training Epoch: 4 [11664/45000]\tLoss: 3.6875\tLR: 0.000010\n",
      "Training Epoch: 4 [11680/45000]\tLoss: 3.7794\tLR: 0.000010\n",
      "Training Epoch: 4 [11696/45000]\tLoss: 3.7565\tLR: 0.000010\n",
      "Training Epoch: 4 [11712/45000]\tLoss: 3.7398\tLR: 0.000010\n",
      "Training Epoch: 4 [11728/45000]\tLoss: 3.7448\tLR: 0.000010\n",
      "Training Epoch: 4 [11744/45000]\tLoss: 3.7729\tLR: 0.000010\n",
      "Training Epoch: 4 [11760/45000]\tLoss: 3.7873\tLR: 0.000010\n",
      "Training Epoch: 4 [11776/45000]\tLoss: 3.6759\tLR: 0.000010\n",
      "Training Epoch: 4 [11792/45000]\tLoss: 3.8157\tLR: 0.000010\n",
      "Training Epoch: 4 [11808/45000]\tLoss: 3.6855\tLR: 0.000010\n",
      "Training Epoch: 4 [11824/45000]\tLoss: 3.7237\tLR: 0.000010\n",
      "Training Epoch: 4 [11840/45000]\tLoss: 3.8738\tLR: 0.000010\n",
      "Training Epoch: 4 [11856/45000]\tLoss: 3.8147\tLR: 0.000010\n",
      "Training Epoch: 4 [11872/45000]\tLoss: 3.8038\tLR: 0.000010\n",
      "Training Epoch: 4 [11888/45000]\tLoss: 3.7095\tLR: 0.000010\n",
      "Training Epoch: 4 [11904/45000]\tLoss: 3.6318\tLR: 0.000010\n",
      "Training Epoch: 4 [11920/45000]\tLoss: 3.6855\tLR: 0.000010\n",
      "Training Epoch: 4 [11936/45000]\tLoss: 3.7556\tLR: 0.000010\n",
      "Training Epoch: 4 [11952/45000]\tLoss: 3.7680\tLR: 0.000010\n",
      "Training Epoch: 4 [11968/45000]\tLoss: 3.6457\tLR: 0.000010\n",
      "Training Epoch: 4 [11984/45000]\tLoss: 3.8218\tLR: 0.000010\n",
      "Training Epoch: 4 [12000/45000]\tLoss: 3.8088\tLR: 0.000010\n",
      "Training Epoch: 4 [12016/45000]\tLoss: 3.6305\tLR: 0.000010\n",
      "Training Epoch: 4 [12032/45000]\tLoss: 3.9150\tLR: 0.000010\n",
      "Training Epoch: 4 [12048/45000]\tLoss: 3.8103\tLR: 0.000010\n",
      "Training Epoch: 4 [12064/45000]\tLoss: 3.6172\tLR: 0.000010\n",
      "Training Epoch: 4 [12080/45000]\tLoss: 3.8178\tLR: 0.000010\n",
      "Training Epoch: 4 [12096/45000]\tLoss: 3.8212\tLR: 0.000010\n",
      "Training Epoch: 4 [12112/45000]\tLoss: 3.6828\tLR: 0.000010\n",
      "Training Epoch: 4 [12128/45000]\tLoss: 3.5853\tLR: 0.000010\n",
      "Training Epoch: 4 [12144/45000]\tLoss: 3.7186\tLR: 0.000010\n",
      "Training Epoch: 4 [12160/45000]\tLoss: 3.7724\tLR: 0.000010\n",
      "Training Epoch: 4 [12176/45000]\tLoss: 3.7533\tLR: 0.000010\n",
      "Training Epoch: 4 [12192/45000]\tLoss: 3.8450\tLR: 0.000010\n",
      "Training Epoch: 4 [12208/45000]\tLoss: 3.7625\tLR: 0.000010\n",
      "Training Epoch: 4 [12224/45000]\tLoss: 3.6883\tLR: 0.000010\n",
      "Training Epoch: 4 [12240/45000]\tLoss: 3.7908\tLR: 0.000010\n",
      "Training Epoch: 4 [12256/45000]\tLoss: 3.7174\tLR: 0.000010\n",
      "Training Epoch: 4 [12272/45000]\tLoss: 3.7695\tLR: 0.000010\n",
      "Training Epoch: 4 [12288/45000]\tLoss: 3.7782\tLR: 0.000010\n",
      "Training Epoch: 4 [12304/45000]\tLoss: 3.6149\tLR: 0.000010\n",
      "Training Epoch: 4 [12320/45000]\tLoss: 3.5823\tLR: 0.000010\n",
      "Training Epoch: 4 [12336/45000]\tLoss: 3.7429\tLR: 0.000010\n",
      "Training Epoch: 4 [12352/45000]\tLoss: 3.6651\tLR: 0.000010\n",
      "Training Epoch: 4 [12368/45000]\tLoss: 3.7484\tLR: 0.000010\n",
      "Training Epoch: 4 [12384/45000]\tLoss: 3.6964\tLR: 0.000010\n",
      "Training Epoch: 4 [12400/45000]\tLoss: 3.7479\tLR: 0.000010\n",
      "Training Epoch: 4 [12416/45000]\tLoss: 3.7611\tLR: 0.000010\n",
      "Training Epoch: 4 [12432/45000]\tLoss: 3.8314\tLR: 0.000010\n",
      "Training Epoch: 4 [12448/45000]\tLoss: 3.7141\tLR: 0.000010\n",
      "Training Epoch: 4 [12464/45000]\tLoss: 3.7092\tLR: 0.000010\n",
      "Training Epoch: 4 [12480/45000]\tLoss: 3.7486\tLR: 0.000010\n",
      "Training Epoch: 4 [12496/45000]\tLoss: 3.7821\tLR: 0.000010\n",
      "Training Epoch: 4 [12512/45000]\tLoss: 3.7888\tLR: 0.000010\n",
      "Training Epoch: 4 [12528/45000]\tLoss: 3.7624\tLR: 0.000010\n",
      "Training Epoch: 4 [12544/45000]\tLoss: 3.6815\tLR: 0.000010\n",
      "Training Epoch: 4 [12560/45000]\tLoss: 3.7277\tLR: 0.000010\n",
      "Training Epoch: 4 [12576/45000]\tLoss: 3.6544\tLR: 0.000010\n",
      "Training Epoch: 4 [12592/45000]\tLoss: 3.6518\tLR: 0.000010\n",
      "Training Epoch: 4 [12608/45000]\tLoss: 3.6906\tLR: 0.000010\n",
      "Training Epoch: 4 [12624/45000]\tLoss: 3.7208\tLR: 0.000010\n",
      "Training Epoch: 4 [12640/45000]\tLoss: 3.8394\tLR: 0.000010\n",
      "Training Epoch: 4 [12656/45000]\tLoss: 3.7025\tLR: 0.000010\n",
      "Training Epoch: 4 [12672/45000]\tLoss: 3.6744\tLR: 0.000010\n",
      "Training Epoch: 4 [12688/45000]\tLoss: 3.6188\tLR: 0.000010\n",
      "Training Epoch: 4 [12704/45000]\tLoss: 3.7237\tLR: 0.000010\n",
      "Training Epoch: 4 [12720/45000]\tLoss: 3.6600\tLR: 0.000010\n",
      "Training Epoch: 4 [12736/45000]\tLoss: 3.6914\tLR: 0.000010\n",
      "Training Epoch: 4 [12752/45000]\tLoss: 3.9022\tLR: 0.000010\n",
      "Training Epoch: 4 [12768/45000]\tLoss: 3.6762\tLR: 0.000010\n",
      "Training Epoch: 4 [12784/45000]\tLoss: 3.7542\tLR: 0.000010\n",
      "Training Epoch: 4 [12800/45000]\tLoss: 3.6028\tLR: 0.000010\n",
      "Training Epoch: 4 [12816/45000]\tLoss: 3.7491\tLR: 0.000010\n",
      "Training Epoch: 4 [12832/45000]\tLoss: 3.6913\tLR: 0.000010\n",
      "Training Epoch: 4 [12848/45000]\tLoss: 3.7858\tLR: 0.000010\n",
      "Training Epoch: 4 [12864/45000]\tLoss: 3.7160\tLR: 0.000010\n",
      "Training Epoch: 4 [12880/45000]\tLoss: 3.7614\tLR: 0.000010\n",
      "Training Epoch: 4 [12896/45000]\tLoss: 3.5751\tLR: 0.000010\n",
      "Training Epoch: 4 [12912/45000]\tLoss: 3.6442\tLR: 0.000010\n",
      "Training Epoch: 4 [12928/45000]\tLoss: 3.6179\tLR: 0.000010\n",
      "Training Epoch: 4 [12944/45000]\tLoss: 3.6316\tLR: 0.000010\n",
      "Training Epoch: 4 [12960/45000]\tLoss: 3.6277\tLR: 0.000010\n",
      "Training Epoch: 4 [12976/45000]\tLoss: 3.6941\tLR: 0.000010\n",
      "Training Epoch: 4 [12992/45000]\tLoss: 3.7231\tLR: 0.000010\n",
      "Training Epoch: 4 [13008/45000]\tLoss: 3.5902\tLR: 0.000010\n",
      "Training Epoch: 4 [13024/45000]\tLoss: 3.6988\tLR: 0.000010\n",
      "Training Epoch: 4 [13040/45000]\tLoss: 3.7039\tLR: 0.000010\n",
      "Training Epoch: 4 [13056/45000]\tLoss: 3.5777\tLR: 0.000010\n",
      "Training Epoch: 4 [13072/45000]\tLoss: 3.7132\tLR: 0.000010\n",
      "Training Epoch: 4 [13088/45000]\tLoss: 3.6757\tLR: 0.000010\n",
      "Training Epoch: 4 [13104/45000]\tLoss: 3.8337\tLR: 0.000010\n",
      "Training Epoch: 4 [13120/45000]\tLoss: 3.7853\tLR: 0.000010\n",
      "Training Epoch: 4 [13136/45000]\tLoss: 3.6175\tLR: 0.000010\n",
      "Training Epoch: 4 [13152/45000]\tLoss: 3.6688\tLR: 0.000010\n",
      "Training Epoch: 4 [13168/45000]\tLoss: 3.5530\tLR: 0.000010\n",
      "Training Epoch: 4 [13184/45000]\tLoss: 3.7208\tLR: 0.000010\n",
      "Training Epoch: 4 [13200/45000]\tLoss: 3.8136\tLR: 0.000010\n",
      "Training Epoch: 4 [13216/45000]\tLoss: 3.6465\tLR: 0.000010\n",
      "Training Epoch: 4 [13232/45000]\tLoss: 3.6615\tLR: 0.000010\n",
      "Training Epoch: 4 [13248/45000]\tLoss: 3.7986\tLR: 0.000010\n",
      "Training Epoch: 4 [13264/45000]\tLoss: 3.8503\tLR: 0.000010\n",
      "Training Epoch: 4 [13280/45000]\tLoss: 3.7132\tLR: 0.000010\n",
      "Training Epoch: 4 [13296/45000]\tLoss: 3.7095\tLR: 0.000010\n",
      "Training Epoch: 4 [13312/45000]\tLoss: 3.7818\tLR: 0.000010\n",
      "Training Epoch: 4 [13328/45000]\tLoss: 3.6983\tLR: 0.000010\n",
      "Training Epoch: 4 [13344/45000]\tLoss: 3.7032\tLR: 0.000010\n",
      "Training Epoch: 4 [13360/45000]\tLoss: 3.6570\tLR: 0.000010\n",
      "Training Epoch: 4 [13376/45000]\tLoss: 3.6763\tLR: 0.000010\n",
      "Training Epoch: 4 [13392/45000]\tLoss: 3.7616\tLR: 0.000010\n",
      "Training Epoch: 4 [13408/45000]\tLoss: 3.7378\tLR: 0.000010\n",
      "Training Epoch: 4 [13424/45000]\tLoss: 3.6593\tLR: 0.000010\n",
      "Training Epoch: 4 [13440/45000]\tLoss: 3.8060\tLR: 0.000010\n",
      "Training Epoch: 4 [13456/45000]\tLoss: 3.7486\tLR: 0.000010\n",
      "Training Epoch: 4 [13472/45000]\tLoss: 3.6285\tLR: 0.000010\n",
      "Training Epoch: 4 [13488/45000]\tLoss: 3.8501\tLR: 0.000010\n",
      "Training Epoch: 4 [13504/45000]\tLoss: 3.6396\tLR: 0.000010\n",
      "Training Epoch: 4 [13520/45000]\tLoss: 3.7964\tLR: 0.000010\n",
      "Training Epoch: 4 [13536/45000]\tLoss: 3.7108\tLR: 0.000010\n",
      "Training Epoch: 4 [13552/45000]\tLoss: 3.6977\tLR: 0.000010\n",
      "Training Epoch: 4 [13568/45000]\tLoss: 3.7348\tLR: 0.000010\n",
      "Training Epoch: 4 [13584/45000]\tLoss: 3.7679\tLR: 0.000010\n",
      "Training Epoch: 4 [13600/45000]\tLoss: 3.6711\tLR: 0.000010\n",
      "Training Epoch: 4 [13616/45000]\tLoss: 3.7937\tLR: 0.000010\n",
      "Training Epoch: 4 [13632/45000]\tLoss: 3.8133\tLR: 0.000010\n",
      "Training Epoch: 4 [13648/45000]\tLoss: 3.9155\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [13664/45000]\tLoss: 3.7703\tLR: 0.000010\n",
      "Training Epoch: 4 [13680/45000]\tLoss: 3.7276\tLR: 0.000010\n",
      "Training Epoch: 4 [13696/45000]\tLoss: 3.7527\tLR: 0.000010\n",
      "Training Epoch: 4 [13712/45000]\tLoss: 3.7272\tLR: 0.000010\n",
      "Training Epoch: 4 [13728/45000]\tLoss: 3.7339\tLR: 0.000010\n",
      "Training Epoch: 4 [13744/45000]\tLoss: 3.8014\tLR: 0.000010\n",
      "Training Epoch: 4 [13760/45000]\tLoss: 3.6513\tLR: 0.000010\n",
      "Training Epoch: 4 [13776/45000]\tLoss: 3.6460\tLR: 0.000010\n",
      "Training Epoch: 4 [13792/45000]\tLoss: 3.7985\tLR: 0.000010\n",
      "Training Epoch: 4 [13808/45000]\tLoss: 3.6186\tLR: 0.000010\n",
      "Training Epoch: 4 [13824/45000]\tLoss: 3.8098\tLR: 0.000010\n",
      "Training Epoch: 4 [13840/45000]\tLoss: 3.7039\tLR: 0.000010\n",
      "Training Epoch: 4 [13856/45000]\tLoss: 3.7263\tLR: 0.000010\n",
      "Training Epoch: 4 [13872/45000]\tLoss: 3.6384\tLR: 0.000010\n",
      "Training Epoch: 4 [13888/45000]\tLoss: 3.7418\tLR: 0.000010\n",
      "Training Epoch: 4 [13904/45000]\tLoss: 3.6805\tLR: 0.000010\n",
      "Training Epoch: 4 [13920/45000]\tLoss: 3.7460\tLR: 0.000010\n",
      "Training Epoch: 4 [13936/45000]\tLoss: 3.6460\tLR: 0.000010\n",
      "Training Epoch: 4 [13952/45000]\tLoss: 3.7549\tLR: 0.000010\n",
      "Training Epoch: 4 [13968/45000]\tLoss: 3.6692\tLR: 0.000010\n",
      "Training Epoch: 4 [13984/45000]\tLoss: 3.7540\tLR: 0.000010\n",
      "Training Epoch: 4 [14000/45000]\tLoss: 3.7339\tLR: 0.000010\n",
      "Training Epoch: 4 [14016/45000]\tLoss: 3.8910\tLR: 0.000010\n",
      "Training Epoch: 4 [14032/45000]\tLoss: 3.7367\tLR: 0.000010\n",
      "Training Epoch: 4 [14048/45000]\tLoss: 3.7580\tLR: 0.000010\n",
      "Training Epoch: 4 [14064/45000]\tLoss: 3.7118\tLR: 0.000010\n",
      "Training Epoch: 4 [14080/45000]\tLoss: 3.7876\tLR: 0.000010\n",
      "Training Epoch: 4 [14096/45000]\tLoss: 3.6747\tLR: 0.000010\n",
      "Training Epoch: 4 [14112/45000]\tLoss: 3.6717\tLR: 0.000010\n",
      "Training Epoch: 4 [14128/45000]\tLoss: 3.6786\tLR: 0.000010\n",
      "Training Epoch: 4 [14144/45000]\tLoss: 3.6401\tLR: 0.000010\n",
      "Training Epoch: 4 [14160/45000]\tLoss: 3.6942\tLR: 0.000010\n",
      "Training Epoch: 4 [14176/45000]\tLoss: 3.8603\tLR: 0.000010\n",
      "Training Epoch: 4 [14192/45000]\tLoss: 3.6529\tLR: 0.000010\n",
      "Training Epoch: 4 [14208/45000]\tLoss: 3.6569\tLR: 0.000010\n",
      "Training Epoch: 4 [14224/45000]\tLoss: 3.7603\tLR: 0.000010\n",
      "Training Epoch: 4 [14240/45000]\tLoss: 3.7638\tLR: 0.000010\n",
      "Training Epoch: 4 [14256/45000]\tLoss: 3.8230\tLR: 0.000010\n",
      "Training Epoch: 4 [14272/45000]\tLoss: 3.7265\tLR: 0.000010\n",
      "Training Epoch: 4 [14288/45000]\tLoss: 3.7016\tLR: 0.000010\n",
      "Training Epoch: 4 [14304/45000]\tLoss: 3.6732\tLR: 0.000010\n",
      "Training Epoch: 4 [14320/45000]\tLoss: 3.6074\tLR: 0.000010\n",
      "Training Epoch: 4 [14336/45000]\tLoss: 3.7059\tLR: 0.000010\n",
      "Training Epoch: 4 [14352/45000]\tLoss: 3.6661\tLR: 0.000010\n",
      "Training Epoch: 4 [14368/45000]\tLoss: 3.7182\tLR: 0.000010\n",
      "Training Epoch: 4 [14384/45000]\tLoss: 3.6755\tLR: 0.000010\n",
      "Training Epoch: 4 [14400/45000]\tLoss: 3.6479\tLR: 0.000010\n",
      "Training Epoch: 4 [14416/45000]\tLoss: 3.6912\tLR: 0.000010\n",
      "Training Epoch: 4 [14432/45000]\tLoss: 3.7124\tLR: 0.000010\n",
      "Training Epoch: 4 [14448/45000]\tLoss: 3.7548\tLR: 0.000010\n",
      "Training Epoch: 4 [14464/45000]\tLoss: 3.7807\tLR: 0.000010\n",
      "Training Epoch: 4 [14480/45000]\tLoss: 3.7365\tLR: 0.000010\n",
      "Training Epoch: 4 [14496/45000]\tLoss: 3.9020\tLR: 0.000010\n",
      "Training Epoch: 4 [14512/45000]\tLoss: 3.7285\tLR: 0.000010\n",
      "Training Epoch: 4 [14528/45000]\tLoss: 3.7474\tLR: 0.000010\n",
      "Training Epoch: 4 [14544/45000]\tLoss: 3.7755\tLR: 0.000010\n",
      "Training Epoch: 4 [14560/45000]\tLoss: 3.8707\tLR: 0.000010\n",
      "Training Epoch: 4 [14576/45000]\tLoss: 3.8560\tLR: 0.000010\n",
      "Training Epoch: 4 [14592/45000]\tLoss: 3.7755\tLR: 0.000010\n",
      "Training Epoch: 4 [14608/45000]\tLoss: 3.7491\tLR: 0.000010\n",
      "Training Epoch: 4 [14624/45000]\tLoss: 3.6353\tLR: 0.000010\n",
      "Training Epoch: 4 [14640/45000]\tLoss: 3.7870\tLR: 0.000010\n",
      "Training Epoch: 4 [14656/45000]\tLoss: 3.6789\tLR: 0.000010\n",
      "Training Epoch: 4 [14672/45000]\tLoss: 3.6617\tLR: 0.000010\n",
      "Training Epoch: 4 [14688/45000]\tLoss: 3.7833\tLR: 0.000010\n",
      "Training Epoch: 4 [14704/45000]\tLoss: 3.6083\tLR: 0.000010\n",
      "Training Epoch: 4 [14720/45000]\tLoss: 3.7123\tLR: 0.000010\n",
      "Training Epoch: 4 [14736/45000]\tLoss: 3.6289\tLR: 0.000010\n",
      "Training Epoch: 4 [14752/45000]\tLoss: 3.7223\tLR: 0.000010\n",
      "Training Epoch: 4 [14768/45000]\tLoss: 3.7296\tLR: 0.000010\n",
      "Training Epoch: 4 [14784/45000]\tLoss: 3.7809\tLR: 0.000010\n",
      "Training Epoch: 4 [14800/45000]\tLoss: 3.7803\tLR: 0.000010\n",
      "Training Epoch: 4 [14816/45000]\tLoss: 3.7869\tLR: 0.000010\n",
      "Training Epoch: 4 [14832/45000]\tLoss: 3.6848\tLR: 0.000010\n",
      "Training Epoch: 4 [14848/45000]\tLoss: 3.8398\tLR: 0.000010\n",
      "Training Epoch: 4 [14864/45000]\tLoss: 3.6803\tLR: 0.000010\n",
      "Training Epoch: 4 [14880/45000]\tLoss: 3.7091\tLR: 0.000010\n",
      "Training Epoch: 4 [14896/45000]\tLoss: 3.7976\tLR: 0.000010\n",
      "Training Epoch: 4 [14912/45000]\tLoss: 3.7538\tLR: 0.000010\n",
      "Training Epoch: 4 [14928/45000]\tLoss: 3.7163\tLR: 0.000010\n",
      "Training Epoch: 4 [14944/45000]\tLoss: 3.7190\tLR: 0.000010\n",
      "Training Epoch: 4 [14960/45000]\tLoss: 3.7401\tLR: 0.000010\n",
      "Training Epoch: 4 [14976/45000]\tLoss: 3.7680\tLR: 0.000010\n",
      "Training Epoch: 4 [14992/45000]\tLoss: 3.7618\tLR: 0.000010\n",
      "Training Epoch: 4 [15008/45000]\tLoss: 3.6146\tLR: 0.000010\n",
      "Training Epoch: 4 [15024/45000]\tLoss: 3.7392\tLR: 0.000010\n",
      "Training Epoch: 4 [15040/45000]\tLoss: 3.6931\tLR: 0.000010\n",
      "Training Epoch: 4 [15056/45000]\tLoss: 3.7579\tLR: 0.000010\n",
      "Training Epoch: 4 [15072/45000]\tLoss: 3.6154\tLR: 0.000010\n",
      "Training Epoch: 4 [15088/45000]\tLoss: 3.6538\tLR: 0.000010\n",
      "Training Epoch: 4 [15104/45000]\tLoss: 3.5932\tLR: 0.000010\n",
      "Training Epoch: 4 [15120/45000]\tLoss: 3.7642\tLR: 0.000010\n",
      "Training Epoch: 4 [15136/45000]\tLoss: 3.5670\tLR: 0.000010\n",
      "Training Epoch: 4 [15152/45000]\tLoss: 3.7101\tLR: 0.000010\n",
      "Training Epoch: 4 [15168/45000]\tLoss: 3.7361\tLR: 0.000010\n",
      "Training Epoch: 4 [15184/45000]\tLoss: 3.8852\tLR: 0.000010\n",
      "Training Epoch: 4 [15200/45000]\tLoss: 3.7612\tLR: 0.000010\n",
      "Training Epoch: 4 [15216/45000]\tLoss: 3.6679\tLR: 0.000010\n",
      "Training Epoch: 4 [15232/45000]\tLoss: 3.7512\tLR: 0.000010\n",
      "Training Epoch: 4 [15248/45000]\tLoss: 3.7352\tLR: 0.000010\n",
      "Training Epoch: 4 [15264/45000]\tLoss: 3.8070\tLR: 0.000010\n",
      "Training Epoch: 4 [15280/45000]\tLoss: 3.9100\tLR: 0.000010\n",
      "Training Epoch: 4 [15296/45000]\tLoss: 3.7866\tLR: 0.000010\n",
      "Training Epoch: 4 [15312/45000]\tLoss: 3.6776\tLR: 0.000010\n",
      "Training Epoch: 4 [15328/45000]\tLoss: 3.7747\tLR: 0.000010\n",
      "Training Epoch: 4 [15344/45000]\tLoss: 3.8022\tLR: 0.000010\n",
      "Training Epoch: 4 [15360/45000]\tLoss: 3.6866\tLR: 0.000010\n",
      "Training Epoch: 4 [15376/45000]\tLoss: 3.7693\tLR: 0.000010\n",
      "Training Epoch: 4 [15392/45000]\tLoss: 3.6757\tLR: 0.000010\n",
      "Training Epoch: 4 [15408/45000]\tLoss: 3.6404\tLR: 0.000010\n",
      "Training Epoch: 4 [15424/45000]\tLoss: 3.7454\tLR: 0.000010\n",
      "Training Epoch: 4 [15440/45000]\tLoss: 3.6693\tLR: 0.000010\n",
      "Training Epoch: 4 [15456/45000]\tLoss: 3.6442\tLR: 0.000010\n",
      "Training Epoch: 4 [15472/45000]\tLoss: 3.6633\tLR: 0.000010\n",
      "Training Epoch: 4 [15488/45000]\tLoss: 3.7840\tLR: 0.000010\n",
      "Training Epoch: 4 [15504/45000]\tLoss: 3.7207\tLR: 0.000010\n",
      "Training Epoch: 4 [15520/45000]\tLoss: 3.7586\tLR: 0.000010\n",
      "Training Epoch: 4 [15536/45000]\tLoss: 3.6909\tLR: 0.000010\n",
      "Training Epoch: 4 [15552/45000]\tLoss: 3.7332\tLR: 0.000010\n",
      "Training Epoch: 4 [15568/45000]\tLoss: 3.8715\tLR: 0.000010\n",
      "Training Epoch: 4 [15584/45000]\tLoss: 3.7823\tLR: 0.000010\n",
      "Training Epoch: 4 [15600/45000]\tLoss: 3.7473\tLR: 0.000010\n",
      "Training Epoch: 4 [15616/45000]\tLoss: 3.7786\tLR: 0.000010\n",
      "Training Epoch: 4 [15632/45000]\tLoss: 3.7272\tLR: 0.000010\n",
      "Training Epoch: 4 [15648/45000]\tLoss: 3.6588\tLR: 0.000010\n",
      "Training Epoch: 4 [15664/45000]\tLoss: 3.6119\tLR: 0.000010\n",
      "Training Epoch: 4 [15680/45000]\tLoss: 3.9173\tLR: 0.000010\n",
      "Training Epoch: 4 [15696/45000]\tLoss: 3.7667\tLR: 0.000010\n",
      "Training Epoch: 4 [15712/45000]\tLoss: 3.7595\tLR: 0.000010\n",
      "Training Epoch: 4 [15728/45000]\tLoss: 3.8069\tLR: 0.000010\n",
      "Training Epoch: 4 [15744/45000]\tLoss: 3.7791\tLR: 0.000010\n",
      "Training Epoch: 4 [15760/45000]\tLoss: 3.7189\tLR: 0.000010\n",
      "Training Epoch: 4 [15776/45000]\tLoss: 3.7620\tLR: 0.000010\n",
      "Training Epoch: 4 [15792/45000]\tLoss: 3.8468\tLR: 0.000010\n",
      "Training Epoch: 4 [15808/45000]\tLoss: 3.6735\tLR: 0.000010\n",
      "Training Epoch: 4 [15824/45000]\tLoss: 3.6233\tLR: 0.000010\n",
      "Training Epoch: 4 [15840/45000]\tLoss: 3.7414\tLR: 0.000010\n",
      "Training Epoch: 4 [15856/45000]\tLoss: 3.7306\tLR: 0.000010\n",
      "Training Epoch: 4 [15872/45000]\tLoss: 3.8029\tLR: 0.000010\n",
      "Training Epoch: 4 [15888/45000]\tLoss: 3.8119\tLR: 0.000010\n",
      "Training Epoch: 4 [15904/45000]\tLoss: 3.7428\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [15920/45000]\tLoss: 3.8179\tLR: 0.000010\n",
      "Training Epoch: 4 [15936/45000]\tLoss: 3.7124\tLR: 0.000010\n",
      "Training Epoch: 4 [15952/45000]\tLoss: 3.8369\tLR: 0.000010\n",
      "Training Epoch: 4 [15968/45000]\tLoss: 3.8171\tLR: 0.000010\n",
      "Training Epoch: 4 [15984/45000]\tLoss: 3.7284\tLR: 0.000010\n",
      "Training Epoch: 4 [16000/45000]\tLoss: 3.7753\tLR: 0.000010\n",
      "Training Epoch: 4 [16016/45000]\tLoss: 3.6459\tLR: 0.000010\n",
      "Training Epoch: 4 [16032/45000]\tLoss: 3.6852\tLR: 0.000010\n",
      "Training Epoch: 4 [16048/45000]\tLoss: 3.6716\tLR: 0.000010\n",
      "Training Epoch: 4 [16064/45000]\tLoss: 3.5664\tLR: 0.000010\n",
      "Training Epoch: 4 [16080/45000]\tLoss: 3.6548\tLR: 0.000010\n",
      "Training Epoch: 4 [16096/45000]\tLoss: 3.7451\tLR: 0.000010\n",
      "Training Epoch: 4 [16112/45000]\tLoss: 3.6803\tLR: 0.000010\n",
      "Training Epoch: 4 [16128/45000]\tLoss: 3.6314\tLR: 0.000010\n",
      "Training Epoch: 4 [16144/45000]\tLoss: 3.6538\tLR: 0.000010\n",
      "Training Epoch: 4 [16160/45000]\tLoss: 3.7159\tLR: 0.000010\n",
      "Training Epoch: 4 [16176/45000]\tLoss: 3.6113\tLR: 0.000010\n",
      "Training Epoch: 4 [16192/45000]\tLoss: 3.8107\tLR: 0.000010\n",
      "Training Epoch: 4 [16208/45000]\tLoss: 3.7084\tLR: 0.000010\n",
      "Training Epoch: 4 [16224/45000]\tLoss: 3.7330\tLR: 0.000010\n",
      "Training Epoch: 4 [16240/45000]\tLoss: 3.7147\tLR: 0.000010\n",
      "Training Epoch: 4 [16256/45000]\tLoss: 3.8099\tLR: 0.000010\n",
      "Training Epoch: 4 [16272/45000]\tLoss: 3.8101\tLR: 0.000010\n",
      "Training Epoch: 4 [16288/45000]\tLoss: 3.6708\tLR: 0.000010\n",
      "Training Epoch: 4 [16304/45000]\tLoss: 3.8493\tLR: 0.000010\n",
      "Training Epoch: 4 [16320/45000]\tLoss: 3.7279\tLR: 0.000010\n",
      "Training Epoch: 4 [16336/45000]\tLoss: 3.8499\tLR: 0.000010\n",
      "Training Epoch: 4 [16352/45000]\tLoss: 3.7731\tLR: 0.000010\n",
      "Training Epoch: 4 [16368/45000]\tLoss: 3.7487\tLR: 0.000010\n",
      "Training Epoch: 4 [16384/45000]\tLoss: 3.6312\tLR: 0.000010\n",
      "Training Epoch: 4 [16400/45000]\tLoss: 3.7635\tLR: 0.000010\n",
      "Training Epoch: 4 [16416/45000]\tLoss: 3.5553\tLR: 0.000010\n",
      "Training Epoch: 4 [16432/45000]\tLoss: 3.7601\tLR: 0.000010\n",
      "Training Epoch: 4 [16448/45000]\tLoss: 3.8011\tLR: 0.000010\n",
      "Training Epoch: 4 [16464/45000]\tLoss: 3.6475\tLR: 0.000010\n",
      "Training Epoch: 4 [16480/45000]\tLoss: 3.8498\tLR: 0.000010\n",
      "Training Epoch: 4 [16496/45000]\tLoss: 3.7174\tLR: 0.000010\n",
      "Training Epoch: 4 [16512/45000]\tLoss: 3.7720\tLR: 0.000010\n",
      "Training Epoch: 4 [16528/45000]\tLoss: 3.7759\tLR: 0.000010\n",
      "Training Epoch: 4 [16544/45000]\tLoss: 3.7314\tLR: 0.000010\n",
      "Training Epoch: 4 [16560/45000]\tLoss: 3.7032\tLR: 0.000010\n",
      "Training Epoch: 4 [16576/45000]\tLoss: 3.6930\tLR: 0.000010\n",
      "Training Epoch: 4 [16592/45000]\tLoss: 3.9813\tLR: 0.000010\n",
      "Training Epoch: 4 [16608/45000]\tLoss: 3.6374\tLR: 0.000010\n",
      "Training Epoch: 4 [16624/45000]\tLoss: 3.7578\tLR: 0.000010\n",
      "Training Epoch: 4 [16640/45000]\tLoss: 3.6859\tLR: 0.000010\n",
      "Training Epoch: 4 [16656/45000]\tLoss: 3.8145\tLR: 0.000010\n",
      "Training Epoch: 4 [16672/45000]\tLoss: 3.6976\tLR: 0.000010\n",
      "Training Epoch: 4 [16688/45000]\tLoss: 3.8089\tLR: 0.000010\n",
      "Training Epoch: 4 [16704/45000]\tLoss: 3.6922\tLR: 0.000010\n",
      "Training Epoch: 4 [16720/45000]\tLoss: 3.8428\tLR: 0.000010\n",
      "Training Epoch: 4 [16736/45000]\tLoss: 3.7230\tLR: 0.000010\n",
      "Training Epoch: 4 [16752/45000]\tLoss: 3.7102\tLR: 0.000010\n",
      "Training Epoch: 4 [16768/45000]\tLoss: 3.6536\tLR: 0.000010\n",
      "Training Epoch: 4 [16784/45000]\tLoss: 3.7260\tLR: 0.000010\n",
      "Training Epoch: 4 [16800/45000]\tLoss: 3.8013\tLR: 0.000010\n",
      "Training Epoch: 4 [16816/45000]\tLoss: 3.6944\tLR: 0.000010\n",
      "Training Epoch: 4 [16832/45000]\tLoss: 3.6323\tLR: 0.000010\n",
      "Training Epoch: 4 [16848/45000]\tLoss: 3.8284\tLR: 0.000010\n",
      "Training Epoch: 4 [16864/45000]\tLoss: 3.7233\tLR: 0.000010\n",
      "Training Epoch: 4 [16880/45000]\tLoss: 3.6705\tLR: 0.000010\n",
      "Training Epoch: 4 [16896/45000]\tLoss: 3.7830\tLR: 0.000010\n",
      "Training Epoch: 4 [16912/45000]\tLoss: 3.7148\tLR: 0.000010\n",
      "Training Epoch: 4 [16928/45000]\tLoss: 3.7870\tLR: 0.000010\n",
      "Training Epoch: 4 [16944/45000]\tLoss: 3.6947\tLR: 0.000010\n",
      "Training Epoch: 4 [16960/45000]\tLoss: 3.6571\tLR: 0.000010\n",
      "Training Epoch: 4 [16976/45000]\tLoss: 3.7363\tLR: 0.000010\n",
      "Training Epoch: 4 [16992/45000]\tLoss: 3.8201\tLR: 0.000010\n",
      "Training Epoch: 4 [17008/45000]\tLoss: 3.7794\tLR: 0.000010\n",
      "Training Epoch: 4 [17024/45000]\tLoss: 3.7764\tLR: 0.000010\n",
      "Training Epoch: 4 [17040/45000]\tLoss: 3.6567\tLR: 0.000010\n",
      "Training Epoch: 4 [17056/45000]\tLoss: 3.7278\tLR: 0.000010\n",
      "Training Epoch: 4 [17072/45000]\tLoss: 3.6982\tLR: 0.000010\n",
      "Training Epoch: 4 [17088/45000]\tLoss: 3.7622\tLR: 0.000010\n",
      "Training Epoch: 4 [17104/45000]\tLoss: 3.8158\tLR: 0.000010\n",
      "Training Epoch: 4 [17120/45000]\tLoss: 3.7308\tLR: 0.000010\n",
      "Training Epoch: 4 [17136/45000]\tLoss: 3.6982\tLR: 0.000010\n",
      "Training Epoch: 4 [17152/45000]\tLoss: 3.7348\tLR: 0.000010\n",
      "Training Epoch: 4 [17168/45000]\tLoss: 3.7035\tLR: 0.000010\n",
      "Training Epoch: 4 [17184/45000]\tLoss: 3.7543\tLR: 0.000010\n",
      "Training Epoch: 4 [17200/45000]\tLoss: 3.7288\tLR: 0.000010\n",
      "Training Epoch: 4 [17216/45000]\tLoss: 3.9137\tLR: 0.000010\n",
      "Training Epoch: 4 [17232/45000]\tLoss: 3.7760\tLR: 0.000010\n",
      "Training Epoch: 4 [17248/45000]\tLoss: 3.7378\tLR: 0.000010\n",
      "Training Epoch: 4 [17264/45000]\tLoss: 3.7499\tLR: 0.000010\n",
      "Training Epoch: 4 [17280/45000]\tLoss: 3.7280\tLR: 0.000010\n",
      "Training Epoch: 4 [17296/45000]\tLoss: 3.7221\tLR: 0.000010\n",
      "Training Epoch: 4 [17312/45000]\tLoss: 3.7677\tLR: 0.000010\n",
      "Training Epoch: 4 [17328/45000]\tLoss: 3.7067\tLR: 0.000010\n",
      "Training Epoch: 4 [17344/45000]\tLoss: 3.7300\tLR: 0.000010\n",
      "Training Epoch: 4 [17360/45000]\tLoss: 3.7646\tLR: 0.000010\n",
      "Training Epoch: 4 [17376/45000]\tLoss: 3.7057\tLR: 0.000010\n",
      "Training Epoch: 4 [17392/45000]\tLoss: 3.7652\tLR: 0.000010\n",
      "Training Epoch: 4 [17408/45000]\tLoss: 3.6921\tLR: 0.000010\n",
      "Training Epoch: 4 [17424/45000]\tLoss: 3.7255\tLR: 0.000010\n",
      "Training Epoch: 4 [17440/45000]\tLoss: 3.7796\tLR: 0.000010\n",
      "Training Epoch: 4 [17456/45000]\tLoss: 3.8034\tLR: 0.000010\n",
      "Training Epoch: 4 [17472/45000]\tLoss: 3.7962\tLR: 0.000010\n",
      "Training Epoch: 4 [17488/45000]\tLoss: 3.7494\tLR: 0.000010\n",
      "Training Epoch: 4 [17504/45000]\tLoss: 3.6752\tLR: 0.000010\n",
      "Training Epoch: 4 [17520/45000]\tLoss: 3.5958\tLR: 0.000010\n",
      "Training Epoch: 4 [17536/45000]\tLoss: 3.7649\tLR: 0.000010\n",
      "Training Epoch: 4 [17552/45000]\tLoss: 3.7120\tLR: 0.000010\n",
      "Training Epoch: 4 [17568/45000]\tLoss: 3.6920\tLR: 0.000010\n",
      "Training Epoch: 4 [17584/45000]\tLoss: 3.7738\tLR: 0.000010\n",
      "Training Epoch: 4 [17600/45000]\tLoss: 3.7755\tLR: 0.000010\n",
      "Training Epoch: 4 [17616/45000]\tLoss: 3.6925\tLR: 0.000010\n",
      "Training Epoch: 4 [17632/45000]\tLoss: 3.6741\tLR: 0.000010\n",
      "Training Epoch: 4 [17648/45000]\tLoss: 3.8045\tLR: 0.000010\n",
      "Training Epoch: 4 [17664/45000]\tLoss: 3.7984\tLR: 0.000010\n",
      "Training Epoch: 4 [17680/45000]\tLoss: 3.6905\tLR: 0.000010\n",
      "Training Epoch: 4 [17696/45000]\tLoss: 3.6820\tLR: 0.000010\n",
      "Training Epoch: 4 [17712/45000]\tLoss: 3.7803\tLR: 0.000010\n",
      "Training Epoch: 4 [17728/45000]\tLoss: 3.8707\tLR: 0.000010\n",
      "Training Epoch: 4 [17744/45000]\tLoss: 3.6724\tLR: 0.000010\n",
      "Training Epoch: 4 [17760/45000]\tLoss: 3.7683\tLR: 0.000010\n",
      "Training Epoch: 4 [17776/45000]\tLoss: 3.8186\tLR: 0.000010\n",
      "Training Epoch: 4 [17792/45000]\tLoss: 3.7510\tLR: 0.000010\n",
      "Training Epoch: 4 [17808/45000]\tLoss: 3.8480\tLR: 0.000010\n",
      "Training Epoch: 4 [17824/45000]\tLoss: 3.7239\tLR: 0.000010\n",
      "Training Epoch: 4 [17840/45000]\tLoss: 3.7175\tLR: 0.000010\n",
      "Training Epoch: 4 [17856/45000]\tLoss: 3.7167\tLR: 0.000010\n",
      "Training Epoch: 4 [17872/45000]\tLoss: 3.7726\tLR: 0.000010\n",
      "Training Epoch: 4 [17888/45000]\tLoss: 3.7056\tLR: 0.000010\n",
      "Training Epoch: 4 [17904/45000]\tLoss: 3.7253\tLR: 0.000010\n",
      "Training Epoch: 4 [17920/45000]\tLoss: 3.6705\tLR: 0.000010\n",
      "Training Epoch: 4 [17936/45000]\tLoss: 3.6767\tLR: 0.000010\n",
      "Training Epoch: 4 [17952/45000]\tLoss: 3.6877\tLR: 0.000010\n",
      "Training Epoch: 4 [17968/45000]\tLoss: 3.6762\tLR: 0.000010\n",
      "Training Epoch: 4 [17984/45000]\tLoss: 3.6405\tLR: 0.000010\n",
      "Training Epoch: 4 [18000/45000]\tLoss: 3.6706\tLR: 0.000010\n",
      "Training Epoch: 4 [18016/45000]\tLoss: 3.7423\tLR: 0.000010\n",
      "Training Epoch: 4 [18032/45000]\tLoss: 3.7123\tLR: 0.000010\n",
      "Training Epoch: 4 [18048/45000]\tLoss: 3.7522\tLR: 0.000010\n",
      "Training Epoch: 4 [18064/45000]\tLoss: 3.7587\tLR: 0.000010\n",
      "Training Epoch: 4 [18080/45000]\tLoss: 3.6185\tLR: 0.000010\n",
      "Training Epoch: 4 [18096/45000]\tLoss: 3.6427\tLR: 0.000010\n",
      "Training Epoch: 4 [18112/45000]\tLoss: 3.7855\tLR: 0.000010\n",
      "Training Epoch: 4 [18128/45000]\tLoss: 3.6165\tLR: 0.000010\n",
      "Training Epoch: 4 [18144/45000]\tLoss: 3.7445\tLR: 0.000010\n",
      "Training Epoch: 4 [18160/45000]\tLoss: 3.6432\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [18176/45000]\tLoss: 3.6756\tLR: 0.000010\n",
      "Training Epoch: 4 [18192/45000]\tLoss: 3.7938\tLR: 0.000010\n",
      "Training Epoch: 4 [18208/45000]\tLoss: 3.6008\tLR: 0.000010\n",
      "Training Epoch: 4 [18224/45000]\tLoss: 3.7145\tLR: 0.000010\n",
      "Training Epoch: 4 [18240/45000]\tLoss: 3.6867\tLR: 0.000010\n",
      "Training Epoch: 4 [18256/45000]\tLoss: 3.7833\tLR: 0.000010\n",
      "Training Epoch: 4 [18272/45000]\tLoss: 3.7137\tLR: 0.000010\n",
      "Training Epoch: 4 [18288/45000]\tLoss: 3.7047\tLR: 0.000010\n",
      "Training Epoch: 4 [18304/45000]\tLoss: 3.7047\tLR: 0.000010\n",
      "Training Epoch: 4 [18320/45000]\tLoss: 3.7551\tLR: 0.000010\n",
      "Training Epoch: 4 [18336/45000]\tLoss: 3.6832\tLR: 0.000010\n",
      "Training Epoch: 4 [18352/45000]\tLoss: 3.6081\tLR: 0.000010\n",
      "Training Epoch: 4 [18368/45000]\tLoss: 3.7113\tLR: 0.000010\n",
      "Training Epoch: 4 [18384/45000]\tLoss: 3.6726\tLR: 0.000010\n",
      "Training Epoch: 4 [18400/45000]\tLoss: 3.6774\tLR: 0.000010\n",
      "Training Epoch: 4 [18416/45000]\tLoss: 3.6711\tLR: 0.000010\n",
      "Training Epoch: 4 [18432/45000]\tLoss: 3.6789\tLR: 0.000010\n",
      "Training Epoch: 4 [18448/45000]\tLoss: 3.7806\tLR: 0.000010\n",
      "Training Epoch: 4 [18464/45000]\tLoss: 3.7349\tLR: 0.000010\n",
      "Training Epoch: 4 [18480/45000]\tLoss: 3.9090\tLR: 0.000010\n",
      "Training Epoch: 4 [18496/45000]\tLoss: 3.7126\tLR: 0.000010\n",
      "Training Epoch: 4 [18512/45000]\tLoss: 3.7096\tLR: 0.000010\n",
      "Training Epoch: 4 [18528/45000]\tLoss: 3.6200\tLR: 0.000010\n",
      "Training Epoch: 4 [18544/45000]\tLoss: 3.6550\tLR: 0.000010\n",
      "Training Epoch: 4 [18560/45000]\tLoss: 3.7158\tLR: 0.000010\n",
      "Training Epoch: 4 [18576/45000]\tLoss: 3.6761\tLR: 0.000010\n",
      "Training Epoch: 4 [18592/45000]\tLoss: 3.7873\tLR: 0.000010\n",
      "Training Epoch: 4 [18608/45000]\tLoss: 3.7875\tLR: 0.000010\n",
      "Training Epoch: 4 [18624/45000]\tLoss: 3.7786\tLR: 0.000010\n",
      "Training Epoch: 4 [18640/45000]\tLoss: 3.8341\tLR: 0.000010\n",
      "Training Epoch: 4 [18656/45000]\tLoss: 3.6063\tLR: 0.000010\n",
      "Training Epoch: 4 [18672/45000]\tLoss: 3.7417\tLR: 0.000010\n",
      "Training Epoch: 4 [18688/45000]\tLoss: 3.6972\tLR: 0.000010\n",
      "Training Epoch: 4 [18704/45000]\tLoss: 3.7979\tLR: 0.000010\n",
      "Training Epoch: 4 [18720/45000]\tLoss: 3.7297\tLR: 0.000010\n",
      "Training Epoch: 4 [18736/45000]\tLoss: 3.6836\tLR: 0.000010\n",
      "Training Epoch: 4 [18752/45000]\tLoss: 3.7010\tLR: 0.000010\n",
      "Training Epoch: 4 [18768/45000]\tLoss: 3.6962\tLR: 0.000010\n",
      "Training Epoch: 4 [18784/45000]\tLoss: 3.6886\tLR: 0.000010\n",
      "Training Epoch: 4 [18800/45000]\tLoss: 3.9127\tLR: 0.000010\n",
      "Training Epoch: 4 [18816/45000]\tLoss: 3.7673\tLR: 0.000010\n",
      "Training Epoch: 4 [18832/45000]\tLoss: 3.6944\tLR: 0.000010\n",
      "Training Epoch: 4 [18848/45000]\tLoss: 3.7627\tLR: 0.000010\n",
      "Training Epoch: 4 [18864/45000]\tLoss: 3.6366\tLR: 0.000010\n",
      "Training Epoch: 4 [18880/45000]\tLoss: 3.7737\tLR: 0.000010\n",
      "Training Epoch: 4 [18896/45000]\tLoss: 3.6466\tLR: 0.000010\n",
      "Training Epoch: 4 [18912/45000]\tLoss: 3.7477\tLR: 0.000010\n",
      "Training Epoch: 4 [18928/45000]\tLoss: 3.6932\tLR: 0.000010\n",
      "Training Epoch: 4 [18944/45000]\tLoss: 3.8183\tLR: 0.000010\n",
      "Training Epoch: 4 [18960/45000]\tLoss: 3.7961\tLR: 0.000010\n",
      "Training Epoch: 4 [18976/45000]\tLoss: 3.6969\tLR: 0.000010\n",
      "Training Epoch: 4 [18992/45000]\tLoss: 3.6328\tLR: 0.000010\n",
      "Training Epoch: 4 [19008/45000]\tLoss: 3.7377\tLR: 0.000010\n",
      "Training Epoch: 4 [19024/45000]\tLoss: 3.8375\tLR: 0.000010\n",
      "Training Epoch: 4 [19040/45000]\tLoss: 3.8014\tLR: 0.000010\n",
      "Training Epoch: 4 [19056/45000]\tLoss: 3.8940\tLR: 0.000010\n",
      "Training Epoch: 4 [19072/45000]\tLoss: 3.6692\tLR: 0.000010\n",
      "Training Epoch: 4 [19088/45000]\tLoss: 3.8526\tLR: 0.000010\n",
      "Training Epoch: 4 [19104/45000]\tLoss: 3.8196\tLR: 0.000010\n",
      "Training Epoch: 4 [19120/45000]\tLoss: 3.6166\tLR: 0.000010\n",
      "Training Epoch: 4 [19136/45000]\tLoss: 3.6070\tLR: 0.000010\n",
      "Training Epoch: 4 [19152/45000]\tLoss: 3.7225\tLR: 0.000010\n",
      "Training Epoch: 4 [19168/45000]\tLoss: 3.7355\tLR: 0.000010\n",
      "Training Epoch: 4 [19184/45000]\tLoss: 3.7969\tLR: 0.000010\n",
      "Training Epoch: 4 [19200/45000]\tLoss: 3.6470\tLR: 0.000010\n",
      "Training Epoch: 4 [19216/45000]\tLoss: 3.7567\tLR: 0.000010\n",
      "Training Epoch: 4 [19232/45000]\tLoss: 3.7342\tLR: 0.000010\n",
      "Training Epoch: 4 [19248/45000]\tLoss: 3.7245\tLR: 0.000010\n",
      "Training Epoch: 4 [19264/45000]\tLoss: 3.6481\tLR: 0.000010\n",
      "Training Epoch: 4 [19280/45000]\tLoss: 3.5302\tLR: 0.000010\n",
      "Training Epoch: 4 [19296/45000]\tLoss: 3.6929\tLR: 0.000010\n",
      "Training Epoch: 4 [19312/45000]\tLoss: 3.6946\tLR: 0.000010\n",
      "Training Epoch: 4 [19328/45000]\tLoss: 3.7306\tLR: 0.000010\n",
      "Training Epoch: 4 [19344/45000]\tLoss: 3.6742\tLR: 0.000010\n",
      "Training Epoch: 4 [19360/45000]\tLoss: 3.6911\tLR: 0.000010\n",
      "Training Epoch: 4 [19376/45000]\tLoss: 3.7540\tLR: 0.000010\n",
      "Training Epoch: 4 [19392/45000]\tLoss: 3.6749\tLR: 0.000010\n",
      "Training Epoch: 4 [19408/45000]\tLoss: 3.7445\tLR: 0.000010\n",
      "Training Epoch: 4 [19424/45000]\tLoss: 3.7776\tLR: 0.000010\n",
      "Training Epoch: 4 [19440/45000]\tLoss: 3.7272\tLR: 0.000010\n",
      "Training Epoch: 4 [19456/45000]\tLoss: 3.7114\tLR: 0.000010\n",
      "Training Epoch: 4 [19472/45000]\tLoss: 3.6339\tLR: 0.000010\n",
      "Training Epoch: 4 [19488/45000]\tLoss: 3.6332\tLR: 0.000010\n",
      "Training Epoch: 4 [19504/45000]\tLoss: 3.8088\tLR: 0.000010\n",
      "Training Epoch: 4 [19520/45000]\tLoss: 3.6495\tLR: 0.000010\n",
      "Training Epoch: 4 [19536/45000]\tLoss: 3.8121\tLR: 0.000010\n",
      "Training Epoch: 4 [19552/45000]\tLoss: 3.7837\tLR: 0.000010\n",
      "Training Epoch: 4 [19568/45000]\tLoss: 3.8170\tLR: 0.000010\n",
      "Training Epoch: 4 [19584/45000]\tLoss: 3.7384\tLR: 0.000010\n",
      "Training Epoch: 4 [19600/45000]\tLoss: 3.7269\tLR: 0.000010\n",
      "Training Epoch: 4 [19616/45000]\tLoss: 3.7171\tLR: 0.000010\n",
      "Training Epoch: 4 [19632/45000]\tLoss: 3.7596\tLR: 0.000010\n",
      "Training Epoch: 4 [19648/45000]\tLoss: 3.7498\tLR: 0.000010\n",
      "Training Epoch: 4 [19664/45000]\tLoss: 3.7517\tLR: 0.000010\n",
      "Training Epoch: 4 [19680/45000]\tLoss: 3.8428\tLR: 0.000010\n",
      "Training Epoch: 4 [19696/45000]\tLoss: 3.7685\tLR: 0.000010\n",
      "Training Epoch: 4 [19712/45000]\tLoss: 3.6987\tLR: 0.000010\n",
      "Training Epoch: 4 [19728/45000]\tLoss: 3.7951\tLR: 0.000010\n",
      "Training Epoch: 4 [19744/45000]\tLoss: 3.7853\tLR: 0.000010\n",
      "Training Epoch: 4 [19760/45000]\tLoss: 3.7085\tLR: 0.000010\n",
      "Training Epoch: 4 [19776/45000]\tLoss: 3.7639\tLR: 0.000010\n",
      "Training Epoch: 4 [19792/45000]\tLoss: 3.8603\tLR: 0.000010\n",
      "Training Epoch: 4 [19808/45000]\tLoss: 3.7947\tLR: 0.000010\n",
      "Training Epoch: 4 [19824/45000]\tLoss: 3.7144\tLR: 0.000010\n",
      "Training Epoch: 4 [19840/45000]\tLoss: 3.7663\tLR: 0.000010\n",
      "Training Epoch: 4 [19856/45000]\tLoss: 3.8297\tLR: 0.000010\n",
      "Training Epoch: 4 [19872/45000]\tLoss: 3.7048\tLR: 0.000010\n",
      "Training Epoch: 4 [19888/45000]\tLoss: 3.6147\tLR: 0.000010\n",
      "Training Epoch: 4 [19904/45000]\tLoss: 3.7306\tLR: 0.000010\n",
      "Training Epoch: 4 [19920/45000]\tLoss: 3.6433\tLR: 0.000010\n",
      "Training Epoch: 4 [19936/45000]\tLoss: 3.7882\tLR: 0.000010\n",
      "Training Epoch: 4 [19952/45000]\tLoss: 3.8380\tLR: 0.000010\n",
      "Training Epoch: 4 [19968/45000]\tLoss: 3.8053\tLR: 0.000010\n",
      "Training Epoch: 4 [19984/45000]\tLoss: 3.7213\tLR: 0.000010\n",
      "Training Epoch: 4 [20000/45000]\tLoss: 3.7896\tLR: 0.000010\n",
      "Training Epoch: 4 [20016/45000]\tLoss: 3.6814\tLR: 0.000010\n",
      "Training Epoch: 4 [20032/45000]\tLoss: 3.7906\tLR: 0.000010\n",
      "Training Epoch: 4 [20048/45000]\tLoss: 3.6916\tLR: 0.000010\n",
      "Training Epoch: 4 [20064/45000]\tLoss: 3.6672\tLR: 0.000010\n",
      "Training Epoch: 4 [20080/45000]\tLoss: 3.6572\tLR: 0.000010\n",
      "Training Epoch: 4 [20096/45000]\tLoss: 3.8124\tLR: 0.000010\n",
      "Training Epoch: 4 [20112/45000]\tLoss: 3.7201\tLR: 0.000010\n",
      "Training Epoch: 4 [20128/45000]\tLoss: 3.6182\tLR: 0.000010\n",
      "Training Epoch: 4 [20144/45000]\tLoss: 3.6904\tLR: 0.000010\n",
      "Training Epoch: 4 [20160/45000]\tLoss: 3.6290\tLR: 0.000010\n",
      "Training Epoch: 4 [20176/45000]\tLoss: 3.6978\tLR: 0.000010\n",
      "Training Epoch: 4 [20192/45000]\tLoss: 3.7933\tLR: 0.000010\n",
      "Training Epoch: 4 [20208/45000]\tLoss: 3.7687\tLR: 0.000010\n",
      "Training Epoch: 4 [20224/45000]\tLoss: 3.7453\tLR: 0.000010\n",
      "Training Epoch: 4 [20240/45000]\tLoss: 3.6703\tLR: 0.000010\n",
      "Training Epoch: 4 [20256/45000]\tLoss: 3.6418\tLR: 0.000010\n",
      "Training Epoch: 4 [20272/45000]\tLoss: 3.7206\tLR: 0.000010\n",
      "Training Epoch: 4 [20288/45000]\tLoss: 3.6104\tLR: 0.000010\n",
      "Training Epoch: 4 [20304/45000]\tLoss: 3.7202\tLR: 0.000010\n",
      "Training Epoch: 4 [20320/45000]\tLoss: 3.7488\tLR: 0.000010\n",
      "Training Epoch: 4 [20336/45000]\tLoss: 3.8217\tLR: 0.000010\n",
      "Training Epoch: 4 [20352/45000]\tLoss: 3.7233\tLR: 0.000010\n",
      "Training Epoch: 4 [20368/45000]\tLoss: 3.8283\tLR: 0.000010\n",
      "Training Epoch: 4 [20384/45000]\tLoss: 3.6981\tLR: 0.000010\n",
      "Training Epoch: 4 [20400/45000]\tLoss: 3.6524\tLR: 0.000010\n",
      "Training Epoch: 4 [20416/45000]\tLoss: 3.6935\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [20432/45000]\tLoss: 3.7584\tLR: 0.000010\n",
      "Training Epoch: 4 [20448/45000]\tLoss: 3.6099\tLR: 0.000010\n",
      "Training Epoch: 4 [20464/45000]\tLoss: 3.7514\tLR: 0.000010\n",
      "Training Epoch: 4 [20480/45000]\tLoss: 3.6989\tLR: 0.000010\n",
      "Training Epoch: 4 [20496/45000]\tLoss: 3.7237\tLR: 0.000010\n",
      "Training Epoch: 4 [20512/45000]\tLoss: 3.7759\tLR: 0.000010\n",
      "Training Epoch: 4 [20528/45000]\tLoss: 3.6784\tLR: 0.000010\n",
      "Training Epoch: 4 [20544/45000]\tLoss: 3.7015\tLR: 0.000010\n",
      "Training Epoch: 4 [20560/45000]\tLoss: 3.6348\tLR: 0.000010\n",
      "Training Epoch: 4 [20576/45000]\tLoss: 3.7819\tLR: 0.000010\n",
      "Training Epoch: 4 [20592/45000]\tLoss: 3.7009\tLR: 0.000010\n",
      "Training Epoch: 4 [20608/45000]\tLoss: 3.5975\tLR: 0.000010\n",
      "Training Epoch: 4 [20624/45000]\tLoss: 3.7772\tLR: 0.000010\n",
      "Training Epoch: 4 [20640/45000]\tLoss: 3.6321\tLR: 0.000010\n",
      "Training Epoch: 4 [20656/45000]\tLoss: 3.6062\tLR: 0.000010\n",
      "Training Epoch: 4 [20672/45000]\tLoss: 3.8540\tLR: 0.000010\n",
      "Training Epoch: 4 [20688/45000]\tLoss: 3.6846\tLR: 0.000010\n",
      "Training Epoch: 4 [20704/45000]\tLoss: 3.8103\tLR: 0.000010\n",
      "Training Epoch: 4 [20720/45000]\tLoss: 3.6598\tLR: 0.000010\n",
      "Training Epoch: 4 [20736/45000]\tLoss: 3.7703\tLR: 0.000010\n",
      "Training Epoch: 4 [20752/45000]\tLoss: 3.8172\tLR: 0.000010\n",
      "Training Epoch: 4 [20768/45000]\tLoss: 3.8718\tLR: 0.000010\n",
      "Training Epoch: 4 [20784/45000]\tLoss: 3.6966\tLR: 0.000010\n",
      "Training Epoch: 4 [20800/45000]\tLoss: 3.7637\tLR: 0.000010\n",
      "Training Epoch: 4 [20816/45000]\tLoss: 3.6737\tLR: 0.000010\n",
      "Training Epoch: 4 [20832/45000]\tLoss: 3.6829\tLR: 0.000010\n",
      "Training Epoch: 4 [20848/45000]\tLoss: 3.6948\tLR: 0.000010\n",
      "Training Epoch: 4 [20864/45000]\tLoss: 3.7828\tLR: 0.000010\n",
      "Training Epoch: 4 [20880/45000]\tLoss: 3.7175\tLR: 0.000010\n",
      "Training Epoch: 4 [20896/45000]\tLoss: 3.6894\tLR: 0.000010\n",
      "Training Epoch: 4 [20912/45000]\tLoss: 3.7570\tLR: 0.000010\n",
      "Training Epoch: 4 [20928/45000]\tLoss: 3.7918\tLR: 0.000010\n",
      "Training Epoch: 4 [20944/45000]\tLoss: 3.7809\tLR: 0.000010\n",
      "Training Epoch: 4 [20960/45000]\tLoss: 3.7320\tLR: 0.000010\n",
      "Training Epoch: 4 [20976/45000]\tLoss: 3.8495\tLR: 0.000010\n",
      "Training Epoch: 4 [20992/45000]\tLoss: 3.7120\tLR: 0.000010\n",
      "Training Epoch: 4 [21008/45000]\tLoss: 3.6757\tLR: 0.000010\n",
      "Training Epoch: 4 [21024/45000]\tLoss: 3.8097\tLR: 0.000010\n",
      "Training Epoch: 4 [21040/45000]\tLoss: 3.7921\tLR: 0.000010\n",
      "Training Epoch: 4 [21056/45000]\tLoss: 3.7457\tLR: 0.000010\n",
      "Training Epoch: 4 [21072/45000]\tLoss: 3.8856\tLR: 0.000010\n",
      "Training Epoch: 4 [21088/45000]\tLoss: 3.8625\tLR: 0.000010\n",
      "Training Epoch: 4 [21104/45000]\tLoss: 3.6063\tLR: 0.000010\n",
      "Training Epoch: 4 [21120/45000]\tLoss: 3.6819\tLR: 0.000010\n",
      "Training Epoch: 4 [21136/45000]\tLoss: 3.6592\tLR: 0.000010\n",
      "Training Epoch: 4 [21152/45000]\tLoss: 3.6870\tLR: 0.000010\n",
      "Training Epoch: 4 [21168/45000]\tLoss: 3.7571\tLR: 0.000010\n",
      "Training Epoch: 4 [21184/45000]\tLoss: 3.7948\tLR: 0.000010\n",
      "Training Epoch: 4 [21200/45000]\tLoss: 3.7043\tLR: 0.000010\n",
      "Training Epoch: 4 [21216/45000]\tLoss: 3.8407\tLR: 0.000010\n",
      "Training Epoch: 4 [21232/45000]\tLoss: 3.7822\tLR: 0.000010\n",
      "Training Epoch: 4 [21248/45000]\tLoss: 3.7611\tLR: 0.000010\n",
      "Training Epoch: 4 [21264/45000]\tLoss: 3.7165\tLR: 0.000010\n",
      "Training Epoch: 4 [21280/45000]\tLoss: 3.7224\tLR: 0.000010\n",
      "Training Epoch: 4 [21296/45000]\tLoss: 3.7721\tLR: 0.000010\n",
      "Training Epoch: 4 [21312/45000]\tLoss: 3.7255\tLR: 0.000010\n",
      "Training Epoch: 4 [21328/45000]\tLoss: 3.7614\tLR: 0.000010\n",
      "Training Epoch: 4 [21344/45000]\tLoss: 3.7174\tLR: 0.000010\n",
      "Training Epoch: 4 [21360/45000]\tLoss: 3.7735\tLR: 0.000010\n",
      "Training Epoch: 4 [21376/45000]\tLoss: 3.7861\tLR: 0.000010\n",
      "Training Epoch: 4 [21392/45000]\tLoss: 3.7697\tLR: 0.000010\n",
      "Training Epoch: 4 [21408/45000]\tLoss: 3.8027\tLR: 0.000010\n",
      "Training Epoch: 4 [21424/45000]\tLoss: 3.7094\tLR: 0.000010\n",
      "Training Epoch: 4 [21440/45000]\tLoss: 3.7689\tLR: 0.000010\n",
      "Training Epoch: 4 [21456/45000]\tLoss: 3.7271\tLR: 0.000010\n",
      "Training Epoch: 4 [21472/45000]\tLoss: 3.6374\tLR: 0.000010\n",
      "Training Epoch: 4 [21488/45000]\tLoss: 3.7374\tLR: 0.000010\n",
      "Training Epoch: 4 [21504/45000]\tLoss: 3.8826\tLR: 0.000010\n",
      "Training Epoch: 4 [21520/45000]\tLoss: 3.6719\tLR: 0.000010\n",
      "Training Epoch: 4 [21536/45000]\tLoss: 3.8119\tLR: 0.000010\n",
      "Training Epoch: 4 [21552/45000]\tLoss: 3.7768\tLR: 0.000010\n",
      "Training Epoch: 4 [21568/45000]\tLoss: 3.6983\tLR: 0.000010\n",
      "Training Epoch: 4 [21584/45000]\tLoss: 3.7600\tLR: 0.000010\n",
      "Training Epoch: 4 [21600/45000]\tLoss: 3.6685\tLR: 0.000010\n",
      "Training Epoch: 4 [21616/45000]\tLoss: 3.7115\tLR: 0.000010\n",
      "Training Epoch: 4 [21632/45000]\tLoss: 3.7952\tLR: 0.000010\n",
      "Training Epoch: 4 [21648/45000]\tLoss: 3.6627\tLR: 0.000010\n",
      "Training Epoch: 4 [21664/45000]\tLoss: 3.7042\tLR: 0.000010\n",
      "Training Epoch: 4 [21680/45000]\tLoss: 3.8077\tLR: 0.000010\n",
      "Training Epoch: 4 [21696/45000]\tLoss: 3.6146\tLR: 0.000010\n",
      "Training Epoch: 4 [21712/45000]\tLoss: 3.7097\tLR: 0.000010\n",
      "Training Epoch: 4 [21728/45000]\tLoss: 3.8753\tLR: 0.000010\n",
      "Training Epoch: 4 [21744/45000]\tLoss: 3.7779\tLR: 0.000010\n",
      "Training Epoch: 4 [21760/45000]\tLoss: 3.7945\tLR: 0.000010\n",
      "Training Epoch: 4 [21776/45000]\tLoss: 3.6912\tLR: 0.000010\n",
      "Training Epoch: 4 [21792/45000]\tLoss: 3.7570\tLR: 0.000010\n",
      "Training Epoch: 4 [21808/45000]\tLoss: 3.6598\tLR: 0.000010\n",
      "Training Epoch: 4 [21824/45000]\tLoss: 3.8299\tLR: 0.000010\n",
      "Training Epoch: 4 [21840/45000]\tLoss: 3.7064\tLR: 0.000010\n",
      "Training Epoch: 4 [21856/45000]\tLoss: 3.6101\tLR: 0.000010\n",
      "Training Epoch: 4 [21872/45000]\tLoss: 3.6725\tLR: 0.000010\n",
      "Training Epoch: 4 [21888/45000]\tLoss: 3.6361\tLR: 0.000010\n",
      "Training Epoch: 4 [21904/45000]\tLoss: 3.7014\tLR: 0.000010\n",
      "Training Epoch: 4 [21920/45000]\tLoss: 3.7960\tLR: 0.000010\n",
      "Training Epoch: 4 [21936/45000]\tLoss: 3.8198\tLR: 0.000010\n",
      "Training Epoch: 4 [21952/45000]\tLoss: 3.6908\tLR: 0.000010\n",
      "Training Epoch: 4 [21968/45000]\tLoss: 3.7656\tLR: 0.000010\n",
      "Training Epoch: 4 [21984/45000]\tLoss: 3.7434\tLR: 0.000010\n",
      "Training Epoch: 4 [22000/45000]\tLoss: 3.6721\tLR: 0.000010\n",
      "Training Epoch: 4 [22016/45000]\tLoss: 3.7339\tLR: 0.000010\n",
      "Training Epoch: 4 [22032/45000]\tLoss: 3.7069\tLR: 0.000010\n",
      "Training Epoch: 4 [22048/45000]\tLoss: 3.6443\tLR: 0.000010\n",
      "Training Epoch: 4 [22064/45000]\tLoss: 3.7064\tLR: 0.000010\n",
      "Training Epoch: 4 [22080/45000]\tLoss: 3.7924\tLR: 0.000010\n",
      "Training Epoch: 4 [22096/45000]\tLoss: 3.6224\tLR: 0.000010\n",
      "Training Epoch: 4 [22112/45000]\tLoss: 3.6880\tLR: 0.000010\n",
      "Training Epoch: 4 [22128/45000]\tLoss: 3.7707\tLR: 0.000010\n",
      "Training Epoch: 4 [22144/45000]\tLoss: 3.7537\tLR: 0.000010\n",
      "Training Epoch: 4 [22160/45000]\tLoss: 3.7960\tLR: 0.000010\n",
      "Training Epoch: 4 [22176/45000]\tLoss: 3.7974\tLR: 0.000010\n",
      "Training Epoch: 4 [22192/45000]\tLoss: 3.6926\tLR: 0.000010\n",
      "Training Epoch: 4 [22208/45000]\tLoss: 3.7258\tLR: 0.000010\n",
      "Training Epoch: 4 [22224/45000]\tLoss: 3.6744\tLR: 0.000010\n",
      "Training Epoch: 4 [22240/45000]\tLoss: 3.7096\tLR: 0.000010\n",
      "Training Epoch: 4 [22256/45000]\tLoss: 3.7452\tLR: 0.000010\n",
      "Training Epoch: 4 [22272/45000]\tLoss: 3.7062\tLR: 0.000010\n",
      "Training Epoch: 4 [22288/45000]\tLoss: 3.6949\tLR: 0.000010\n",
      "Training Epoch: 4 [22304/45000]\tLoss: 3.7029\tLR: 0.000010\n",
      "Training Epoch: 4 [22320/45000]\tLoss: 3.7133\tLR: 0.000010\n",
      "Training Epoch: 4 [22336/45000]\tLoss: 3.7910\tLR: 0.000010\n",
      "Training Epoch: 4 [22352/45000]\tLoss: 3.9414\tLR: 0.000010\n",
      "Training Epoch: 4 [22368/45000]\tLoss: 3.6729\tLR: 0.000010\n",
      "Training Epoch: 4 [22384/45000]\tLoss: 3.6916\tLR: 0.000010\n",
      "Training Epoch: 4 [22400/45000]\tLoss: 3.7232\tLR: 0.000010\n",
      "Training Epoch: 4 [22416/45000]\tLoss: 3.7176\tLR: 0.000010\n",
      "Training Epoch: 4 [22432/45000]\tLoss: 3.6859\tLR: 0.000010\n",
      "Training Epoch: 4 [22448/45000]\tLoss: 3.6720\tLR: 0.000010\n",
      "Training Epoch: 4 [22464/45000]\tLoss: 3.6396\tLR: 0.000010\n",
      "Training Epoch: 4 [22480/45000]\tLoss: 3.8015\tLR: 0.000010\n",
      "Training Epoch: 4 [22496/45000]\tLoss: 3.6872\tLR: 0.000010\n",
      "Training Epoch: 4 [22512/45000]\tLoss: 3.6266\tLR: 0.000010\n",
      "Training Epoch: 4 [22528/45000]\tLoss: 3.8411\tLR: 0.000010\n",
      "Training Epoch: 4 [22544/45000]\tLoss: 3.6841\tLR: 0.000010\n",
      "Training Epoch: 4 [22560/45000]\tLoss: 3.6434\tLR: 0.000010\n",
      "Training Epoch: 4 [22576/45000]\tLoss: 3.7394\tLR: 0.000010\n",
      "Training Epoch: 4 [22592/45000]\tLoss: 3.6917\tLR: 0.000010\n",
      "Training Epoch: 4 [22608/45000]\tLoss: 3.7945\tLR: 0.000010\n",
      "Training Epoch: 4 [22624/45000]\tLoss: 3.6962\tLR: 0.000010\n",
      "Training Epoch: 4 [22640/45000]\tLoss: 3.5641\tLR: 0.000010\n",
      "Training Epoch: 4 [22656/45000]\tLoss: 3.7257\tLR: 0.000010\n",
      "Training Epoch: 4 [22672/45000]\tLoss: 3.8019\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [22688/45000]\tLoss: 3.6581\tLR: 0.000010\n",
      "Training Epoch: 4 [22704/45000]\tLoss: 3.7055\tLR: 0.000010\n",
      "Training Epoch: 4 [22720/45000]\tLoss: 3.7470\tLR: 0.000010\n",
      "Training Epoch: 4 [22736/45000]\tLoss: 3.7049\tLR: 0.000010\n",
      "Training Epoch: 4 [22752/45000]\tLoss: 3.7160\tLR: 0.000010\n",
      "Training Epoch: 4 [22768/45000]\tLoss: 3.7014\tLR: 0.000010\n",
      "Training Epoch: 4 [22784/45000]\tLoss: 3.7862\tLR: 0.000010\n",
      "Training Epoch: 4 [22800/45000]\tLoss: 3.7569\tLR: 0.000010\n",
      "Training Epoch: 4 [22816/45000]\tLoss: 3.7693\tLR: 0.000010\n",
      "Training Epoch: 4 [22832/45000]\tLoss: 3.8861\tLR: 0.000010\n",
      "Training Epoch: 4 [22848/45000]\tLoss: 3.7356\tLR: 0.000010\n",
      "Training Epoch: 4 [22864/45000]\tLoss: 3.6507\tLR: 0.000010\n",
      "Training Epoch: 4 [22880/45000]\tLoss: 3.7108\tLR: 0.000010\n",
      "Training Epoch: 4 [22896/45000]\tLoss: 3.8108\tLR: 0.000010\n",
      "Training Epoch: 4 [22912/45000]\tLoss: 3.7956\tLR: 0.000010\n",
      "Training Epoch: 4 [22928/45000]\tLoss: 3.8171\tLR: 0.000010\n",
      "Training Epoch: 4 [22944/45000]\tLoss: 3.8387\tLR: 0.000010\n",
      "Training Epoch: 4 [22960/45000]\tLoss: 3.6404\tLR: 0.000010\n",
      "Training Epoch: 4 [22976/45000]\tLoss: 3.8192\tLR: 0.000010\n",
      "Training Epoch: 4 [22992/45000]\tLoss: 3.7030\tLR: 0.000010\n",
      "Training Epoch: 4 [23008/45000]\tLoss: 3.6813\tLR: 0.000010\n",
      "Training Epoch: 4 [23024/45000]\tLoss: 3.6659\tLR: 0.000010\n",
      "Training Epoch: 4 [23040/45000]\tLoss: 3.7502\tLR: 0.000010\n",
      "Training Epoch: 4 [23056/45000]\tLoss: 3.7816\tLR: 0.000010\n",
      "Training Epoch: 4 [23072/45000]\tLoss: 3.7675\tLR: 0.000010\n",
      "Training Epoch: 4 [23088/45000]\tLoss: 3.7143\tLR: 0.000010\n",
      "Training Epoch: 4 [23104/45000]\tLoss: 3.7875\tLR: 0.000010\n",
      "Training Epoch: 4 [23120/45000]\tLoss: 3.6486\tLR: 0.000010\n",
      "Training Epoch: 4 [23136/45000]\tLoss: 3.7565\tLR: 0.000010\n",
      "Training Epoch: 4 [23152/45000]\tLoss: 3.6168\tLR: 0.000010\n",
      "Training Epoch: 4 [23168/45000]\tLoss: 3.7344\tLR: 0.000010\n",
      "Training Epoch: 4 [23184/45000]\tLoss: 3.8499\tLR: 0.000010\n",
      "Training Epoch: 4 [23200/45000]\tLoss: 3.7766\tLR: 0.000010\n",
      "Training Epoch: 4 [23216/45000]\tLoss: 3.7953\tLR: 0.000010\n",
      "Training Epoch: 4 [23232/45000]\tLoss: 3.6275\tLR: 0.000010\n",
      "Training Epoch: 4 [23248/45000]\tLoss: 3.5828\tLR: 0.000010\n",
      "Training Epoch: 4 [23264/45000]\tLoss: 3.8242\tLR: 0.000010\n",
      "Training Epoch: 4 [23280/45000]\tLoss: 3.5668\tLR: 0.000010\n",
      "Training Epoch: 4 [23296/45000]\tLoss: 3.5670\tLR: 0.000010\n",
      "Training Epoch: 4 [23312/45000]\tLoss: 3.6899\tLR: 0.000010\n",
      "Training Epoch: 4 [23328/45000]\tLoss: 3.7291\tLR: 0.000010\n",
      "Training Epoch: 4 [23344/45000]\tLoss: 3.6769\tLR: 0.000010\n",
      "Training Epoch: 4 [23360/45000]\tLoss: 3.6748\tLR: 0.000010\n",
      "Training Epoch: 4 [23376/45000]\tLoss: 3.6630\tLR: 0.000010\n",
      "Training Epoch: 4 [23392/45000]\tLoss: 3.6898\tLR: 0.000010\n",
      "Training Epoch: 4 [23408/45000]\tLoss: 3.7810\tLR: 0.000010\n",
      "Training Epoch: 4 [23424/45000]\tLoss: 3.6779\tLR: 0.000010\n",
      "Training Epoch: 4 [23440/45000]\tLoss: 3.7646\tLR: 0.000010\n",
      "Training Epoch: 4 [23456/45000]\tLoss: 3.7436\tLR: 0.000010\n",
      "Training Epoch: 4 [23472/45000]\tLoss: 3.8241\tLR: 0.000010\n",
      "Training Epoch: 4 [23488/45000]\tLoss: 3.6567\tLR: 0.000010\n",
      "Training Epoch: 4 [23504/45000]\tLoss: 3.7148\tLR: 0.000010\n",
      "Training Epoch: 4 [23520/45000]\tLoss: 3.5850\tLR: 0.000010\n",
      "Training Epoch: 4 [23536/45000]\tLoss: 3.6610\tLR: 0.000010\n",
      "Training Epoch: 4 [23552/45000]\tLoss: 3.6860\tLR: 0.000010\n",
      "Training Epoch: 4 [23568/45000]\tLoss: 3.7270\tLR: 0.000010\n",
      "Training Epoch: 4 [23584/45000]\tLoss: 3.7017\tLR: 0.000010\n",
      "Training Epoch: 4 [23600/45000]\tLoss: 3.6322\tLR: 0.000010\n",
      "Training Epoch: 4 [23616/45000]\tLoss: 3.8317\tLR: 0.000010\n",
      "Training Epoch: 4 [23632/45000]\tLoss: 3.6449\tLR: 0.000010\n",
      "Training Epoch: 4 [23648/45000]\tLoss: 3.7955\tLR: 0.000010\n",
      "Training Epoch: 4 [23664/45000]\tLoss: 3.7558\tLR: 0.000010\n",
      "Training Epoch: 4 [23680/45000]\tLoss: 3.7191\tLR: 0.000010\n",
      "Training Epoch: 4 [23696/45000]\tLoss: 3.7055\tLR: 0.000010\n",
      "Training Epoch: 4 [23712/45000]\tLoss: 3.7209\tLR: 0.000010\n",
      "Training Epoch: 4 [23728/45000]\tLoss: 3.6667\tLR: 0.000010\n",
      "Training Epoch: 4 [23744/45000]\tLoss: 3.7607\tLR: 0.000010\n",
      "Training Epoch: 4 [23760/45000]\tLoss: 3.7173\tLR: 0.000010\n",
      "Training Epoch: 4 [23776/45000]\tLoss: 3.8120\tLR: 0.000010\n",
      "Training Epoch: 4 [23792/45000]\tLoss: 3.6702\tLR: 0.000010\n",
      "Training Epoch: 4 [23808/45000]\tLoss: 3.6618\tLR: 0.000010\n",
      "Training Epoch: 4 [23824/45000]\tLoss: 3.6677\tLR: 0.000010\n",
      "Training Epoch: 4 [23840/45000]\tLoss: 3.7732\tLR: 0.000010\n",
      "Training Epoch: 4 [23856/45000]\tLoss: 3.7602\tLR: 0.000010\n",
      "Training Epoch: 4 [23872/45000]\tLoss: 3.7150\tLR: 0.000010\n",
      "Training Epoch: 4 [23888/45000]\tLoss: 3.6747\tLR: 0.000010\n",
      "Training Epoch: 4 [23904/45000]\tLoss: 3.7188\tLR: 0.000010\n",
      "Training Epoch: 4 [23920/45000]\tLoss: 3.6534\tLR: 0.000010\n",
      "Training Epoch: 4 [23936/45000]\tLoss: 3.7163\tLR: 0.000010\n",
      "Training Epoch: 4 [23952/45000]\tLoss: 3.7295\tLR: 0.000010\n",
      "Training Epoch: 4 [23968/45000]\tLoss: 3.6722\tLR: 0.000010\n",
      "Training Epoch: 4 [23984/45000]\tLoss: 3.7999\tLR: 0.000010\n",
      "Training Epoch: 4 [24000/45000]\tLoss: 3.6448\tLR: 0.000010\n",
      "Training Epoch: 4 [24016/45000]\tLoss: 3.8462\tLR: 0.000010\n",
      "Training Epoch: 4 [24032/45000]\tLoss: 3.7818\tLR: 0.000010\n",
      "Training Epoch: 4 [24048/45000]\tLoss: 3.6708\tLR: 0.000010\n",
      "Training Epoch: 4 [24064/45000]\tLoss: 3.6991\tLR: 0.000010\n",
      "Training Epoch: 4 [24080/45000]\tLoss: 3.6890\tLR: 0.000010\n",
      "Training Epoch: 4 [24096/45000]\tLoss: 3.6425\tLR: 0.000010\n",
      "Training Epoch: 4 [24112/45000]\tLoss: 3.7203\tLR: 0.000010\n",
      "Training Epoch: 4 [24128/45000]\tLoss: 3.6002\tLR: 0.000010\n",
      "Training Epoch: 4 [24144/45000]\tLoss: 3.6012\tLR: 0.000010\n",
      "Training Epoch: 4 [24160/45000]\tLoss: 3.7218\tLR: 0.000010\n",
      "Training Epoch: 4 [24176/45000]\tLoss: 3.6130\tLR: 0.000010\n",
      "Training Epoch: 4 [24192/45000]\tLoss: 3.6875\tLR: 0.000010\n",
      "Training Epoch: 4 [24208/45000]\tLoss: 3.6366\tLR: 0.000010\n",
      "Training Epoch: 4 [24224/45000]\tLoss: 3.7406\tLR: 0.000010\n",
      "Training Epoch: 4 [24240/45000]\tLoss: 3.7423\tLR: 0.000010\n",
      "Training Epoch: 4 [24256/45000]\tLoss: 3.6019\tLR: 0.000010\n",
      "Training Epoch: 4 [24272/45000]\tLoss: 3.7578\tLR: 0.000010\n",
      "Training Epoch: 4 [24288/45000]\tLoss: 3.8674\tLR: 0.000010\n",
      "Training Epoch: 4 [24304/45000]\tLoss: 3.7789\tLR: 0.000010\n",
      "Training Epoch: 4 [24320/45000]\tLoss: 3.7039\tLR: 0.000010\n",
      "Training Epoch: 4 [24336/45000]\tLoss: 3.8683\tLR: 0.000010\n",
      "Training Epoch: 4 [24352/45000]\tLoss: 3.7317\tLR: 0.000010\n",
      "Training Epoch: 4 [24368/45000]\tLoss: 3.7773\tLR: 0.000010\n",
      "Training Epoch: 4 [24384/45000]\tLoss: 3.8364\tLR: 0.000010\n",
      "Training Epoch: 4 [24400/45000]\tLoss: 3.6550\tLR: 0.000010\n",
      "Training Epoch: 4 [24416/45000]\tLoss: 3.8033\tLR: 0.000010\n",
      "Training Epoch: 4 [24432/45000]\tLoss: 3.6510\tLR: 0.000010\n",
      "Training Epoch: 4 [24448/45000]\tLoss: 3.7420\tLR: 0.000010\n",
      "Training Epoch: 4 [24464/45000]\tLoss: 3.6789\tLR: 0.000010\n",
      "Training Epoch: 4 [24480/45000]\tLoss: 3.7115\tLR: 0.000010\n",
      "Training Epoch: 4 [24496/45000]\tLoss: 3.7376\tLR: 0.000010\n",
      "Training Epoch: 4 [24512/45000]\tLoss: 3.7602\tLR: 0.000010\n",
      "Training Epoch: 4 [24528/45000]\tLoss: 3.7405\tLR: 0.000010\n",
      "Training Epoch: 4 [24544/45000]\tLoss: 3.7118\tLR: 0.000010\n",
      "Training Epoch: 4 [24560/45000]\tLoss: 3.8138\tLR: 0.000010\n",
      "Training Epoch: 4 [24576/45000]\tLoss: 3.6861\tLR: 0.000010\n",
      "Training Epoch: 4 [24592/45000]\tLoss: 3.9263\tLR: 0.000010\n",
      "Training Epoch: 4 [24608/45000]\tLoss: 3.7258\tLR: 0.000010\n",
      "Training Epoch: 4 [24624/45000]\tLoss: 3.6593\tLR: 0.000010\n",
      "Training Epoch: 4 [24640/45000]\tLoss: 3.7080\tLR: 0.000010\n",
      "Training Epoch: 4 [24656/45000]\tLoss: 3.5979\tLR: 0.000010\n",
      "Training Epoch: 4 [24672/45000]\tLoss: 3.6095\tLR: 0.000010\n",
      "Training Epoch: 4 [24688/45000]\tLoss: 3.7253\tLR: 0.000010\n",
      "Training Epoch: 4 [24704/45000]\tLoss: 3.7579\tLR: 0.000010\n",
      "Training Epoch: 4 [24720/45000]\tLoss: 3.7400\tLR: 0.000010\n",
      "Training Epoch: 4 [24736/45000]\tLoss: 3.6431\tLR: 0.000010\n",
      "Training Epoch: 4 [24752/45000]\tLoss: 3.6990\tLR: 0.000010\n",
      "Training Epoch: 4 [24768/45000]\tLoss: 3.6339\tLR: 0.000010\n",
      "Training Epoch: 4 [24784/45000]\tLoss: 3.7695\tLR: 0.000010\n",
      "Training Epoch: 4 [24800/45000]\tLoss: 3.6960\tLR: 0.000010\n",
      "Training Epoch: 4 [24816/45000]\tLoss: 3.7151\tLR: 0.000010\n",
      "Training Epoch: 4 [24832/45000]\tLoss: 3.6765\tLR: 0.000010\n",
      "Training Epoch: 4 [24848/45000]\tLoss: 3.7955\tLR: 0.000010\n",
      "Training Epoch: 4 [24864/45000]\tLoss: 3.7200\tLR: 0.000010\n",
      "Training Epoch: 4 [24880/45000]\tLoss: 3.6317\tLR: 0.000010\n",
      "Training Epoch: 4 [24896/45000]\tLoss: 3.6488\tLR: 0.000010\n",
      "Training Epoch: 4 [24912/45000]\tLoss: 3.8032\tLR: 0.000010\n",
      "Training Epoch: 4 [24928/45000]\tLoss: 3.6923\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [24944/45000]\tLoss: 3.6895\tLR: 0.000010\n",
      "Training Epoch: 4 [24960/45000]\tLoss: 3.6078\tLR: 0.000010\n",
      "Training Epoch: 4 [24976/45000]\tLoss: 3.7621\tLR: 0.000010\n",
      "Training Epoch: 4 [24992/45000]\tLoss: 3.7115\tLR: 0.000010\n",
      "Training Epoch: 4 [25008/45000]\tLoss: 3.6756\tLR: 0.000010\n",
      "Training Epoch: 4 [25024/45000]\tLoss: 3.8116\tLR: 0.000010\n",
      "Training Epoch: 4 [25040/45000]\tLoss: 3.6886\tLR: 0.000010\n",
      "Training Epoch: 4 [25056/45000]\tLoss: 3.7725\tLR: 0.000010\n",
      "Training Epoch: 4 [25072/45000]\tLoss: 3.7385\tLR: 0.000010\n",
      "Training Epoch: 4 [25088/45000]\tLoss: 3.7424\tLR: 0.000010\n",
      "Training Epoch: 4 [25104/45000]\tLoss: 3.7940\tLR: 0.000010\n",
      "Training Epoch: 4 [25120/45000]\tLoss: 3.8181\tLR: 0.000010\n",
      "Training Epoch: 4 [25136/45000]\tLoss: 3.8256\tLR: 0.000010\n",
      "Training Epoch: 4 [25152/45000]\tLoss: 3.7352\tLR: 0.000010\n",
      "Training Epoch: 4 [25168/45000]\tLoss: 3.6754\tLR: 0.000010\n",
      "Training Epoch: 4 [25184/45000]\tLoss: 3.6202\tLR: 0.000010\n",
      "Training Epoch: 4 [25200/45000]\tLoss: 3.7076\tLR: 0.000010\n",
      "Training Epoch: 4 [25216/45000]\tLoss: 3.7237\tLR: 0.000010\n",
      "Training Epoch: 4 [25232/45000]\tLoss: 3.6563\tLR: 0.000010\n",
      "Training Epoch: 4 [25248/45000]\tLoss: 3.7375\tLR: 0.000010\n",
      "Training Epoch: 4 [25264/45000]\tLoss: 3.7445\tLR: 0.000010\n",
      "Training Epoch: 4 [25280/45000]\tLoss: 3.7445\tLR: 0.000010\n",
      "Training Epoch: 4 [25296/45000]\tLoss: 3.7579\tLR: 0.000010\n",
      "Training Epoch: 4 [25312/45000]\tLoss: 3.5563\tLR: 0.000010\n",
      "Training Epoch: 4 [25328/45000]\tLoss: 3.5751\tLR: 0.000010\n",
      "Training Epoch: 4 [25344/45000]\tLoss: 3.7204\tLR: 0.000010\n",
      "Training Epoch: 4 [25360/45000]\tLoss: 3.7108\tLR: 0.000010\n",
      "Training Epoch: 4 [25376/45000]\tLoss: 3.6069\tLR: 0.000010\n",
      "Training Epoch: 4 [25392/45000]\tLoss: 3.9300\tLR: 0.000010\n",
      "Training Epoch: 4 [25408/45000]\tLoss: 3.6657\tLR: 0.000010\n",
      "Training Epoch: 4 [25424/45000]\tLoss: 3.6579\tLR: 0.000010\n",
      "Training Epoch: 4 [25440/45000]\tLoss: 3.7736\tLR: 0.000010\n",
      "Training Epoch: 4 [25456/45000]\tLoss: 3.7358\tLR: 0.000010\n",
      "Training Epoch: 4 [25472/45000]\tLoss: 3.7610\tLR: 0.000010\n",
      "Training Epoch: 4 [25488/45000]\tLoss: 3.7829\tLR: 0.000010\n",
      "Training Epoch: 4 [25504/45000]\tLoss: 3.7938\tLR: 0.000010\n",
      "Training Epoch: 4 [25520/45000]\tLoss: 3.7861\tLR: 0.000010\n",
      "Training Epoch: 4 [25536/45000]\tLoss: 3.6313\tLR: 0.000010\n",
      "Training Epoch: 4 [25552/45000]\tLoss: 3.8037\tLR: 0.000010\n",
      "Training Epoch: 4 [25568/45000]\tLoss: 3.7841\tLR: 0.000010\n",
      "Training Epoch: 4 [25584/45000]\tLoss: 3.7366\tLR: 0.000010\n",
      "Training Epoch: 4 [25600/45000]\tLoss: 3.6943\tLR: 0.000010\n",
      "Training Epoch: 4 [25616/45000]\tLoss: 3.8024\tLR: 0.000010\n",
      "Training Epoch: 4 [25632/45000]\tLoss: 3.6988\tLR: 0.000010\n",
      "Training Epoch: 4 [25648/45000]\tLoss: 3.6979\tLR: 0.000010\n",
      "Training Epoch: 4 [25664/45000]\tLoss: 3.7601\tLR: 0.000010\n",
      "Training Epoch: 4 [25680/45000]\tLoss: 3.6771\tLR: 0.000010\n",
      "Training Epoch: 4 [25696/45000]\tLoss: 3.7028\tLR: 0.000010\n",
      "Training Epoch: 4 [25712/45000]\tLoss: 3.6784\tLR: 0.000010\n",
      "Training Epoch: 4 [25728/45000]\tLoss: 3.6238\tLR: 0.000010\n",
      "Training Epoch: 4 [25744/45000]\tLoss: 3.6527\tLR: 0.000010\n",
      "Training Epoch: 4 [25760/45000]\tLoss: 3.7074\tLR: 0.000010\n",
      "Training Epoch: 4 [25776/45000]\tLoss: 3.8097\tLR: 0.000010\n",
      "Training Epoch: 4 [25792/45000]\tLoss: 3.7774\tLR: 0.000010\n",
      "Training Epoch: 4 [25808/45000]\tLoss: 3.7685\tLR: 0.000010\n",
      "Training Epoch: 4 [25824/45000]\tLoss: 3.6719\tLR: 0.000010\n",
      "Training Epoch: 4 [25840/45000]\tLoss: 3.8445\tLR: 0.000010\n",
      "Training Epoch: 4 [25856/45000]\tLoss: 3.7524\tLR: 0.000010\n",
      "Training Epoch: 4 [25872/45000]\tLoss: 3.7216\tLR: 0.000010\n",
      "Training Epoch: 4 [25888/45000]\tLoss: 3.7536\tLR: 0.000010\n",
      "Training Epoch: 4 [25904/45000]\tLoss: 3.7430\tLR: 0.000010\n",
      "Training Epoch: 4 [25920/45000]\tLoss: 3.6349\tLR: 0.000010\n",
      "Training Epoch: 4 [25936/45000]\tLoss: 3.6786\tLR: 0.000010\n",
      "Training Epoch: 4 [25952/45000]\tLoss: 3.6346\tLR: 0.000010\n",
      "Training Epoch: 4 [25968/45000]\tLoss: 3.7066\tLR: 0.000010\n",
      "Training Epoch: 4 [25984/45000]\tLoss: 3.7571\tLR: 0.000010\n",
      "Training Epoch: 4 [26000/45000]\tLoss: 3.6707\tLR: 0.000010\n",
      "Training Epoch: 4 [26016/45000]\tLoss: 3.6985\tLR: 0.000010\n",
      "Training Epoch: 4 [26032/45000]\tLoss: 3.6416\tLR: 0.000010\n",
      "Training Epoch: 4 [26048/45000]\tLoss: 3.7032\tLR: 0.000010\n",
      "Training Epoch: 4 [26064/45000]\tLoss: 3.6873\tLR: 0.000010\n",
      "Training Epoch: 4 [26080/45000]\tLoss: 3.7346\tLR: 0.000010\n",
      "Training Epoch: 4 [26096/45000]\tLoss: 3.6967\tLR: 0.000010\n",
      "Training Epoch: 4 [26112/45000]\tLoss: 3.6588\tLR: 0.000010\n",
      "Training Epoch: 4 [26128/45000]\tLoss: 3.7286\tLR: 0.000010\n",
      "Training Epoch: 4 [26144/45000]\tLoss: 3.6833\tLR: 0.000010\n",
      "Training Epoch: 4 [26160/45000]\tLoss: 3.7207\tLR: 0.000010\n",
      "Training Epoch: 4 [26176/45000]\tLoss: 3.6104\tLR: 0.000010\n",
      "Training Epoch: 4 [26192/45000]\tLoss: 3.7638\tLR: 0.000010\n",
      "Training Epoch: 4 [26208/45000]\tLoss: 3.7230\tLR: 0.000010\n",
      "Training Epoch: 4 [26224/45000]\tLoss: 3.6711\tLR: 0.000010\n",
      "Training Epoch: 4 [26240/45000]\tLoss: 3.6823\tLR: 0.000010\n",
      "Training Epoch: 4 [26256/45000]\tLoss: 3.7391\tLR: 0.000010\n",
      "Training Epoch: 4 [26272/45000]\tLoss: 3.7145\tLR: 0.000010\n",
      "Training Epoch: 4 [26288/45000]\tLoss: 3.7868\tLR: 0.000010\n",
      "Training Epoch: 4 [26304/45000]\tLoss: 3.7876\tLR: 0.000010\n",
      "Training Epoch: 4 [26320/45000]\tLoss: 3.7670\tLR: 0.000010\n",
      "Training Epoch: 4 [26336/45000]\tLoss: 3.7498\tLR: 0.000010\n",
      "Training Epoch: 4 [26352/45000]\tLoss: 3.5549\tLR: 0.000010\n",
      "Training Epoch: 4 [26368/45000]\tLoss: 3.7878\tLR: 0.000010\n",
      "Training Epoch: 4 [26384/45000]\tLoss: 3.8466\tLR: 0.000010\n",
      "Training Epoch: 4 [26400/45000]\tLoss: 3.7298\tLR: 0.000010\n",
      "Training Epoch: 4 [26416/45000]\tLoss: 3.8249\tLR: 0.000010\n",
      "Training Epoch: 4 [26432/45000]\tLoss: 3.6898\tLR: 0.000010\n",
      "Training Epoch: 4 [26448/45000]\tLoss: 3.7382\tLR: 0.000010\n",
      "Training Epoch: 4 [26464/45000]\tLoss: 3.5984\tLR: 0.000010\n",
      "Training Epoch: 4 [26480/45000]\tLoss: 3.7127\tLR: 0.000010\n",
      "Training Epoch: 4 [26496/45000]\tLoss: 3.6688\tLR: 0.000010\n",
      "Training Epoch: 4 [26512/45000]\tLoss: 3.8907\tLR: 0.000010\n",
      "Training Epoch: 4 [26528/45000]\tLoss: 3.7094\tLR: 0.000010\n",
      "Training Epoch: 4 [26544/45000]\tLoss: 3.6487\tLR: 0.000010\n",
      "Training Epoch: 4 [26560/45000]\tLoss: 3.8182\tLR: 0.000010\n",
      "Training Epoch: 4 [26576/45000]\tLoss: 3.8076\tLR: 0.000010\n",
      "Training Epoch: 4 [26592/45000]\tLoss: 3.7520\tLR: 0.000010\n",
      "Training Epoch: 4 [26608/45000]\tLoss: 3.6584\tLR: 0.000010\n",
      "Training Epoch: 4 [26624/45000]\tLoss: 3.6044\tLR: 0.000010\n",
      "Training Epoch: 4 [26640/45000]\tLoss: 3.6052\tLR: 0.000010\n",
      "Training Epoch: 4 [26656/45000]\tLoss: 3.6803\tLR: 0.000010\n",
      "Training Epoch: 4 [26672/45000]\tLoss: 3.7763\tLR: 0.000010\n",
      "Training Epoch: 4 [26688/45000]\tLoss: 3.6909\tLR: 0.000010\n",
      "Training Epoch: 4 [26704/45000]\tLoss: 3.7428\tLR: 0.000010\n",
      "Training Epoch: 4 [26720/45000]\tLoss: 3.7168\tLR: 0.000010\n",
      "Training Epoch: 4 [26736/45000]\tLoss: 3.6125\tLR: 0.000010\n",
      "Training Epoch: 4 [26752/45000]\tLoss: 3.6557\tLR: 0.000010\n",
      "Training Epoch: 4 [26768/45000]\tLoss: 3.7391\tLR: 0.000010\n",
      "Training Epoch: 4 [26784/45000]\tLoss: 3.7718\tLR: 0.000010\n",
      "Training Epoch: 4 [26800/45000]\tLoss: 3.6761\tLR: 0.000010\n",
      "Training Epoch: 4 [26816/45000]\tLoss: 3.6948\tLR: 0.000010\n",
      "Training Epoch: 4 [26832/45000]\tLoss: 3.6739\tLR: 0.000010\n",
      "Training Epoch: 4 [26848/45000]\tLoss: 3.7727\tLR: 0.000010\n",
      "Training Epoch: 4 [26864/45000]\tLoss: 3.8349\tLR: 0.000010\n",
      "Training Epoch: 4 [26880/45000]\tLoss: 3.8308\tLR: 0.000010\n",
      "Training Epoch: 4 [26896/45000]\tLoss: 3.7267\tLR: 0.000010\n",
      "Training Epoch: 4 [26912/45000]\tLoss: 3.7758\tLR: 0.000010\n",
      "Training Epoch: 4 [26928/45000]\tLoss: 3.7214\tLR: 0.000010\n",
      "Training Epoch: 4 [26944/45000]\tLoss: 3.7470\tLR: 0.000010\n",
      "Training Epoch: 4 [26960/45000]\tLoss: 3.7969\tLR: 0.000010\n",
      "Training Epoch: 4 [26976/45000]\tLoss: 3.6502\tLR: 0.000010\n",
      "Training Epoch: 4 [26992/45000]\tLoss: 3.8239\tLR: 0.000010\n",
      "Training Epoch: 4 [27008/45000]\tLoss: 3.7938\tLR: 0.000010\n",
      "Training Epoch: 4 [27024/45000]\tLoss: 3.7139\tLR: 0.000010\n",
      "Training Epoch: 4 [27040/45000]\tLoss: 3.6482\tLR: 0.000010\n",
      "Training Epoch: 4 [27056/45000]\tLoss: 3.6732\tLR: 0.000010\n",
      "Training Epoch: 4 [27072/45000]\tLoss: 3.6864\tLR: 0.000010\n",
      "Training Epoch: 4 [27088/45000]\tLoss: 3.7966\tLR: 0.000010\n",
      "Training Epoch: 4 [27104/45000]\tLoss: 3.7153\tLR: 0.000010\n",
      "Training Epoch: 4 [27120/45000]\tLoss: 3.6640\tLR: 0.000010\n",
      "Training Epoch: 4 [27136/45000]\tLoss: 3.6360\tLR: 0.000010\n",
      "Training Epoch: 4 [27152/45000]\tLoss: 3.7050\tLR: 0.000010\n",
      "Training Epoch: 4 [27168/45000]\tLoss: 3.6997\tLR: 0.000010\n",
      "Training Epoch: 4 [27184/45000]\tLoss: 3.5801\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [27200/45000]\tLoss: 3.6925\tLR: 0.000010\n",
      "Training Epoch: 4 [27216/45000]\tLoss: 3.6384\tLR: 0.000010\n",
      "Training Epoch: 4 [27232/45000]\tLoss: 3.7958\tLR: 0.000010\n",
      "Training Epoch: 4 [27248/45000]\tLoss: 3.7180\tLR: 0.000010\n",
      "Training Epoch: 4 [27264/45000]\tLoss: 3.5742\tLR: 0.000010\n",
      "Training Epoch: 4 [27280/45000]\tLoss: 3.7573\tLR: 0.000010\n",
      "Training Epoch: 4 [27296/45000]\tLoss: 3.6341\tLR: 0.000010\n",
      "Training Epoch: 4 [27312/45000]\tLoss: 3.6113\tLR: 0.000010\n",
      "Training Epoch: 4 [27328/45000]\tLoss: 3.8139\tLR: 0.000010\n",
      "Training Epoch: 4 [27344/45000]\tLoss: 3.7200\tLR: 0.000010\n",
      "Training Epoch: 4 [27360/45000]\tLoss: 3.6883\tLR: 0.000010\n",
      "Training Epoch: 4 [27376/45000]\tLoss: 3.7181\tLR: 0.000010\n",
      "Training Epoch: 4 [27392/45000]\tLoss: 3.7043\tLR: 0.000010\n",
      "Training Epoch: 4 [27408/45000]\tLoss: 3.7866\tLR: 0.000010\n",
      "Training Epoch: 4 [27424/45000]\tLoss: 3.5910\tLR: 0.000010\n",
      "Training Epoch: 4 [27440/45000]\tLoss: 3.6860\tLR: 0.000010\n",
      "Training Epoch: 4 [27456/45000]\tLoss: 3.7261\tLR: 0.000010\n",
      "Training Epoch: 4 [27472/45000]\tLoss: 3.7016\tLR: 0.000010\n",
      "Training Epoch: 4 [27488/45000]\tLoss: 3.7693\tLR: 0.000010\n",
      "Training Epoch: 4 [27504/45000]\tLoss: 3.6531\tLR: 0.000010\n",
      "Training Epoch: 4 [27520/45000]\tLoss: 3.8058\tLR: 0.000010\n",
      "Training Epoch: 4 [27536/45000]\tLoss: 3.6797\tLR: 0.000010\n",
      "Training Epoch: 4 [27552/45000]\tLoss: 3.6245\tLR: 0.000010\n",
      "Training Epoch: 4 [27568/45000]\tLoss: 3.7506\tLR: 0.000010\n",
      "Training Epoch: 4 [27584/45000]\tLoss: 3.7057\tLR: 0.000010\n",
      "Training Epoch: 4 [27600/45000]\tLoss: 3.7438\tLR: 0.000010\n",
      "Training Epoch: 4 [27616/45000]\tLoss: 3.6331\tLR: 0.000010\n",
      "Training Epoch: 4 [27632/45000]\tLoss: 3.7389\tLR: 0.000010\n",
      "Training Epoch: 4 [27648/45000]\tLoss: 3.7417\tLR: 0.000010\n",
      "Training Epoch: 4 [27664/45000]\tLoss: 3.6885\tLR: 0.000010\n",
      "Training Epoch: 4 [27680/45000]\tLoss: 3.7896\tLR: 0.000010\n",
      "Training Epoch: 4 [27696/45000]\tLoss: 3.6375\tLR: 0.000010\n",
      "Training Epoch: 4 [27712/45000]\tLoss: 3.7117\tLR: 0.000010\n",
      "Training Epoch: 4 [27728/45000]\tLoss: 3.7950\tLR: 0.000010\n",
      "Training Epoch: 4 [27744/45000]\tLoss: 3.6147\tLR: 0.000010\n",
      "Training Epoch: 4 [27760/45000]\tLoss: 3.6988\tLR: 0.000010\n",
      "Training Epoch: 4 [27776/45000]\tLoss: 3.6071\tLR: 0.000010\n",
      "Training Epoch: 4 [27792/45000]\tLoss: 3.7194\tLR: 0.000010\n",
      "Training Epoch: 4 [27808/45000]\tLoss: 3.7306\tLR: 0.000010\n",
      "Training Epoch: 4 [27824/45000]\tLoss: 3.7310\tLR: 0.000010\n",
      "Training Epoch: 4 [27840/45000]\tLoss: 3.7066\tLR: 0.000010\n",
      "Training Epoch: 4 [27856/45000]\tLoss: 3.6816\tLR: 0.000010\n",
      "Training Epoch: 4 [27872/45000]\tLoss: 3.8361\tLR: 0.000010\n",
      "Training Epoch: 4 [27888/45000]\tLoss: 3.6808\tLR: 0.000010\n",
      "Training Epoch: 4 [27904/45000]\tLoss: 3.6600\tLR: 0.000010\n",
      "Training Epoch: 4 [27920/45000]\tLoss: 3.6769\tLR: 0.000010\n",
      "Training Epoch: 4 [27936/45000]\tLoss: 3.6379\tLR: 0.000010\n",
      "Training Epoch: 4 [27952/45000]\tLoss: 3.6327\tLR: 0.000010\n",
      "Training Epoch: 4 [27968/45000]\tLoss: 3.7726\tLR: 0.000010\n",
      "Training Epoch: 4 [27984/45000]\tLoss: 3.6757\tLR: 0.000010\n",
      "Training Epoch: 4 [28000/45000]\tLoss: 3.8354\tLR: 0.000010\n",
      "Training Epoch: 4 [28016/45000]\tLoss: 3.6002\tLR: 0.000010\n",
      "Training Epoch: 4 [28032/45000]\tLoss: 3.7485\tLR: 0.000010\n",
      "Training Epoch: 4 [28048/45000]\tLoss: 3.7687\tLR: 0.000010\n",
      "Training Epoch: 4 [28064/45000]\tLoss: 3.7395\tLR: 0.000010\n",
      "Training Epoch: 4 [28080/45000]\tLoss: 3.7211\tLR: 0.000010\n",
      "Training Epoch: 4 [28096/45000]\tLoss: 3.6485\tLR: 0.000010\n",
      "Training Epoch: 4 [28112/45000]\tLoss: 3.5870\tLR: 0.000010\n",
      "Training Epoch: 4 [28128/45000]\tLoss: 3.7677\tLR: 0.000010\n",
      "Training Epoch: 4 [28144/45000]\tLoss: 3.7417\tLR: 0.000010\n",
      "Training Epoch: 4 [28160/45000]\tLoss: 3.7963\tLR: 0.000010\n",
      "Training Epoch: 4 [28176/45000]\tLoss: 3.6692\tLR: 0.000010\n",
      "Training Epoch: 4 [28192/45000]\tLoss: 3.7170\tLR: 0.000010\n",
      "Training Epoch: 4 [28208/45000]\tLoss: 3.7793\tLR: 0.000010\n",
      "Training Epoch: 4 [28224/45000]\tLoss: 3.6708\tLR: 0.000010\n",
      "Training Epoch: 4 [28240/45000]\tLoss: 3.7762\tLR: 0.000010\n",
      "Training Epoch: 4 [28256/45000]\tLoss: 3.6884\tLR: 0.000010\n",
      "Training Epoch: 4 [28272/45000]\tLoss: 3.6496\tLR: 0.000010\n",
      "Training Epoch: 4 [28288/45000]\tLoss: 3.7029\tLR: 0.000010\n",
      "Training Epoch: 4 [28304/45000]\tLoss: 3.6056\tLR: 0.000010\n",
      "Training Epoch: 4 [28320/45000]\tLoss: 3.7052\tLR: 0.000010\n",
      "Training Epoch: 4 [28336/45000]\tLoss: 3.6861\tLR: 0.000010\n",
      "Training Epoch: 4 [28352/45000]\tLoss: 3.7259\tLR: 0.000010\n",
      "Training Epoch: 4 [28368/45000]\tLoss: 3.7071\tLR: 0.000010\n",
      "Training Epoch: 4 [28384/45000]\tLoss: 3.7326\tLR: 0.000010\n",
      "Training Epoch: 4 [28400/45000]\tLoss: 3.6741\tLR: 0.000010\n",
      "Training Epoch: 4 [28416/45000]\tLoss: 3.7279\tLR: 0.000010\n",
      "Training Epoch: 4 [28432/45000]\tLoss: 3.7521\tLR: 0.000010\n",
      "Training Epoch: 4 [28448/45000]\tLoss: 3.7049\tLR: 0.000010\n",
      "Training Epoch: 4 [28464/45000]\tLoss: 3.6778\tLR: 0.000010\n",
      "Training Epoch: 4 [28480/45000]\tLoss: 3.7219\tLR: 0.000010\n",
      "Training Epoch: 4 [28496/45000]\tLoss: 3.7691\tLR: 0.000010\n",
      "Training Epoch: 4 [28512/45000]\tLoss: 3.7419\tLR: 0.000010\n",
      "Training Epoch: 4 [28528/45000]\tLoss: 3.6591\tLR: 0.000010\n",
      "Training Epoch: 4 [28544/45000]\tLoss: 3.8444\tLR: 0.000010\n",
      "Training Epoch: 4 [28560/45000]\tLoss: 3.6443\tLR: 0.000010\n",
      "Training Epoch: 4 [28576/45000]\tLoss: 3.8096\tLR: 0.000010\n",
      "Training Epoch: 4 [28592/45000]\tLoss: 3.7454\tLR: 0.000010\n",
      "Training Epoch: 4 [28608/45000]\tLoss: 3.8061\tLR: 0.000010\n",
      "Training Epoch: 4 [28624/45000]\tLoss: 3.6483\tLR: 0.000010\n",
      "Training Epoch: 4 [28640/45000]\tLoss: 3.7755\tLR: 0.000010\n",
      "Training Epoch: 4 [28656/45000]\tLoss: 3.6778\tLR: 0.000010\n",
      "Training Epoch: 4 [28672/45000]\tLoss: 3.7107\tLR: 0.000010\n",
      "Training Epoch: 4 [28688/45000]\tLoss: 3.7524\tLR: 0.000010\n",
      "Training Epoch: 4 [28704/45000]\tLoss: 3.6078\tLR: 0.000010\n",
      "Training Epoch: 4 [28720/45000]\tLoss: 3.8448\tLR: 0.000010\n",
      "Training Epoch: 4 [28736/45000]\tLoss: 3.6953\tLR: 0.000010\n",
      "Training Epoch: 4 [28752/45000]\tLoss: 3.6589\tLR: 0.000010\n",
      "Training Epoch: 4 [28768/45000]\tLoss: 3.7471\tLR: 0.000010\n",
      "Training Epoch: 4 [28784/45000]\tLoss: 3.7419\tLR: 0.000010\n",
      "Training Epoch: 4 [28800/45000]\tLoss: 3.7069\tLR: 0.000010\n",
      "Training Epoch: 4 [28816/45000]\tLoss: 3.6459\tLR: 0.000010\n",
      "Training Epoch: 4 [28832/45000]\tLoss: 3.6588\tLR: 0.000010\n",
      "Training Epoch: 4 [28848/45000]\tLoss: 3.7449\tLR: 0.000010\n",
      "Training Epoch: 4 [28864/45000]\tLoss: 3.6381\tLR: 0.000010\n",
      "Training Epoch: 4 [28880/45000]\tLoss: 3.6147\tLR: 0.000010\n",
      "Training Epoch: 4 [28896/45000]\tLoss: 3.7752\tLR: 0.000010\n",
      "Training Epoch: 4 [28912/45000]\tLoss: 3.7114\tLR: 0.000010\n",
      "Training Epoch: 4 [28928/45000]\tLoss: 3.7567\tLR: 0.000010\n",
      "Training Epoch: 4 [28944/45000]\tLoss: 3.7501\tLR: 0.000010\n",
      "Training Epoch: 4 [28960/45000]\tLoss: 3.7041\tLR: 0.000010\n",
      "Training Epoch: 4 [28976/45000]\tLoss: 3.6667\tLR: 0.000010\n",
      "Training Epoch: 4 [28992/45000]\tLoss: 3.7805\tLR: 0.000010\n",
      "Training Epoch: 4 [29008/45000]\tLoss: 3.7169\tLR: 0.000010\n",
      "Training Epoch: 4 [29024/45000]\tLoss: 3.6579\tLR: 0.000010\n",
      "Training Epoch: 4 [29040/45000]\tLoss: 3.7209\tLR: 0.000010\n",
      "Training Epoch: 4 [29056/45000]\tLoss: 3.7276\tLR: 0.000010\n",
      "Training Epoch: 4 [29072/45000]\tLoss: 3.8177\tLR: 0.000010\n",
      "Training Epoch: 4 [29088/45000]\tLoss: 3.8586\tLR: 0.000010\n",
      "Training Epoch: 4 [29104/45000]\tLoss: 3.6214\tLR: 0.000010\n",
      "Training Epoch: 4 [29120/45000]\tLoss: 3.7547\tLR: 0.000010\n",
      "Training Epoch: 4 [29136/45000]\tLoss: 3.8122\tLR: 0.000010\n",
      "Training Epoch: 4 [29152/45000]\tLoss: 3.6901\tLR: 0.000010\n",
      "Training Epoch: 4 [29168/45000]\tLoss: 3.7083\tLR: 0.000010\n",
      "Training Epoch: 4 [29184/45000]\tLoss: 3.6953\tLR: 0.000010\n",
      "Training Epoch: 4 [29200/45000]\tLoss: 3.7526\tLR: 0.000010\n",
      "Training Epoch: 4 [29216/45000]\tLoss: 3.7694\tLR: 0.000010\n",
      "Training Epoch: 4 [29232/45000]\tLoss: 3.7489\tLR: 0.000010\n",
      "Training Epoch: 4 [29248/45000]\tLoss: 3.5848\tLR: 0.000010\n",
      "Training Epoch: 4 [29264/45000]\tLoss: 3.7606\tLR: 0.000010\n",
      "Training Epoch: 4 [29280/45000]\tLoss: 3.8162\tLR: 0.000010\n",
      "Training Epoch: 4 [29296/45000]\tLoss: 3.5976\tLR: 0.000010\n",
      "Training Epoch: 4 [29312/45000]\tLoss: 3.6696\tLR: 0.000010\n",
      "Training Epoch: 4 [29328/45000]\tLoss: 3.6003\tLR: 0.000010\n",
      "Training Epoch: 4 [29344/45000]\tLoss: 3.6634\tLR: 0.000010\n",
      "Training Epoch: 4 [29360/45000]\tLoss: 3.6335\tLR: 0.000010\n",
      "Training Epoch: 4 [29376/45000]\tLoss: 3.7022\tLR: 0.000010\n",
      "Training Epoch: 4 [29392/45000]\tLoss: 3.7063\tLR: 0.000010\n",
      "Training Epoch: 4 [29408/45000]\tLoss: 3.6694\tLR: 0.000010\n",
      "Training Epoch: 4 [29424/45000]\tLoss: 3.7079\tLR: 0.000010\n",
      "Training Epoch: 4 [29440/45000]\tLoss: 3.8294\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [29456/45000]\tLoss: 3.7862\tLR: 0.000010\n",
      "Training Epoch: 4 [29472/45000]\tLoss: 3.7231\tLR: 0.000010\n",
      "Training Epoch: 4 [29488/45000]\tLoss: 3.8408\tLR: 0.000010\n",
      "Training Epoch: 4 [29504/45000]\tLoss: 3.7174\tLR: 0.000010\n",
      "Training Epoch: 4 [29520/45000]\tLoss: 3.8545\tLR: 0.000010\n",
      "Training Epoch: 4 [29536/45000]\tLoss: 3.7217\tLR: 0.000010\n",
      "Training Epoch: 4 [29552/45000]\tLoss: 3.6246\tLR: 0.000010\n",
      "Training Epoch: 4 [29568/45000]\tLoss: 3.6894\tLR: 0.000010\n",
      "Training Epoch: 4 [29584/45000]\tLoss: 3.7664\tLR: 0.000010\n",
      "Training Epoch: 4 [29600/45000]\tLoss: 3.8138\tLR: 0.000010\n",
      "Training Epoch: 4 [29616/45000]\tLoss: 3.6813\tLR: 0.000010\n",
      "Training Epoch: 4 [29632/45000]\tLoss: 3.6984\tLR: 0.000010\n",
      "Training Epoch: 4 [29648/45000]\tLoss: 3.5948\tLR: 0.000010\n",
      "Training Epoch: 4 [29664/45000]\tLoss: 3.8385\tLR: 0.000010\n",
      "Training Epoch: 4 [29680/45000]\tLoss: 3.7333\tLR: 0.000010\n",
      "Training Epoch: 4 [29696/45000]\tLoss: 3.6801\tLR: 0.000010\n",
      "Training Epoch: 4 [29712/45000]\tLoss: 3.6076\tLR: 0.000010\n",
      "Training Epoch: 4 [29728/45000]\tLoss: 3.6289\tLR: 0.000010\n",
      "Training Epoch: 4 [29744/45000]\tLoss: 3.8079\tLR: 0.000010\n",
      "Training Epoch: 4 [29760/45000]\tLoss: 3.5871\tLR: 0.000010\n",
      "Training Epoch: 4 [29776/45000]\tLoss: 3.7743\tLR: 0.000010\n",
      "Training Epoch: 4 [29792/45000]\tLoss: 3.7174\tLR: 0.000010\n",
      "Training Epoch: 4 [29808/45000]\tLoss: 3.6630\tLR: 0.000010\n",
      "Training Epoch: 4 [29824/45000]\tLoss: 3.6494\tLR: 0.000010\n",
      "Training Epoch: 4 [29840/45000]\tLoss: 3.6828\tLR: 0.000010\n",
      "Training Epoch: 4 [29856/45000]\tLoss: 3.6808\tLR: 0.000010\n",
      "Training Epoch: 4 [29872/45000]\tLoss: 3.8561\tLR: 0.000010\n",
      "Training Epoch: 4 [29888/45000]\tLoss: 3.8174\tLR: 0.000010\n",
      "Training Epoch: 4 [29904/45000]\tLoss: 3.8340\tLR: 0.000010\n",
      "Training Epoch: 4 [29920/45000]\tLoss: 3.7607\tLR: 0.000010\n",
      "Training Epoch: 4 [29936/45000]\tLoss: 3.7375\tLR: 0.000010\n",
      "Training Epoch: 4 [29952/45000]\tLoss: 3.6769\tLR: 0.000010\n",
      "Training Epoch: 4 [29968/45000]\tLoss: 3.7716\tLR: 0.000010\n",
      "Training Epoch: 4 [29984/45000]\tLoss: 3.7956\tLR: 0.000010\n",
      "Training Epoch: 4 [30000/45000]\tLoss: 3.7818\tLR: 0.000010\n",
      "Training Epoch: 4 [30016/45000]\tLoss: 3.6793\tLR: 0.000010\n",
      "Training Epoch: 4 [30032/45000]\tLoss: 3.6769\tLR: 0.000010\n",
      "Training Epoch: 4 [30048/45000]\tLoss: 3.6808\tLR: 0.000010\n",
      "Training Epoch: 4 [30064/45000]\tLoss: 3.7498\tLR: 0.000010\n",
      "Training Epoch: 4 [30080/45000]\tLoss: 3.8135\tLR: 0.000010\n",
      "Training Epoch: 4 [30096/45000]\tLoss: 3.6640\tLR: 0.000010\n",
      "Training Epoch: 4 [30112/45000]\tLoss: 3.7458\tLR: 0.000010\n",
      "Training Epoch: 4 [30128/45000]\tLoss: 3.6114\tLR: 0.000010\n",
      "Training Epoch: 4 [30144/45000]\tLoss: 3.8149\tLR: 0.000010\n",
      "Training Epoch: 4 [30160/45000]\tLoss: 3.6483\tLR: 0.000010\n",
      "Training Epoch: 4 [30176/45000]\tLoss: 3.7325\tLR: 0.000010\n",
      "Training Epoch: 4 [30192/45000]\tLoss: 3.7331\tLR: 0.000010\n",
      "Training Epoch: 4 [30208/45000]\tLoss: 3.6588\tLR: 0.000010\n",
      "Training Epoch: 4 [30224/45000]\tLoss: 3.7304\tLR: 0.000010\n",
      "Training Epoch: 4 [30240/45000]\tLoss: 3.7785\tLR: 0.000010\n",
      "Training Epoch: 4 [30256/45000]\tLoss: 3.7400\tLR: 0.000010\n",
      "Training Epoch: 4 [30272/45000]\tLoss: 3.6635\tLR: 0.000010\n",
      "Training Epoch: 4 [30288/45000]\tLoss: 3.7918\tLR: 0.000010\n",
      "Training Epoch: 4 [30304/45000]\tLoss: 3.6051\tLR: 0.000010\n",
      "Training Epoch: 4 [30320/45000]\tLoss: 3.6421\tLR: 0.000010\n",
      "Training Epoch: 4 [30336/45000]\tLoss: 3.6452\tLR: 0.000010\n",
      "Training Epoch: 4 [30352/45000]\tLoss: 3.7042\tLR: 0.000010\n",
      "Training Epoch: 4 [30368/45000]\tLoss: 3.6744\tLR: 0.000010\n",
      "Training Epoch: 4 [30384/45000]\tLoss: 3.7254\tLR: 0.000010\n",
      "Training Epoch: 4 [30400/45000]\tLoss: 3.7562\tLR: 0.000010\n",
      "Training Epoch: 4 [30416/45000]\tLoss: 3.6699\tLR: 0.000010\n",
      "Training Epoch: 4 [30432/45000]\tLoss: 3.6541\tLR: 0.000010\n",
      "Training Epoch: 4 [30448/45000]\tLoss: 3.8626\tLR: 0.000010\n",
      "Training Epoch: 4 [30464/45000]\tLoss: 3.7032\tLR: 0.000010\n",
      "Training Epoch: 4 [30480/45000]\tLoss: 3.6258\tLR: 0.000010\n",
      "Training Epoch: 4 [30496/45000]\tLoss: 3.5997\tLR: 0.000010\n",
      "Training Epoch: 4 [30512/45000]\tLoss: 3.7031\tLR: 0.000010\n",
      "Training Epoch: 4 [30528/45000]\tLoss: 3.6297\tLR: 0.000010\n",
      "Training Epoch: 4 [30544/45000]\tLoss: 3.7974\tLR: 0.000010\n",
      "Training Epoch: 4 [30560/45000]\tLoss: 3.7352\tLR: 0.000010\n",
      "Training Epoch: 4 [30576/45000]\tLoss: 3.7289\tLR: 0.000010\n",
      "Training Epoch: 4 [30592/45000]\tLoss: 3.7038\tLR: 0.000010\n",
      "Training Epoch: 4 [30608/45000]\tLoss: 3.7705\tLR: 0.000010\n",
      "Training Epoch: 4 [30624/45000]\tLoss: 3.6075\tLR: 0.000010\n",
      "Training Epoch: 4 [30640/45000]\tLoss: 3.6925\tLR: 0.000010\n",
      "Training Epoch: 4 [30656/45000]\tLoss: 3.7489\tLR: 0.000010\n",
      "Training Epoch: 4 [30672/45000]\tLoss: 3.8155\tLR: 0.000010\n",
      "Training Epoch: 4 [30688/45000]\tLoss: 3.8227\tLR: 0.000010\n",
      "Training Epoch: 4 [30704/45000]\tLoss: 3.6905\tLR: 0.000010\n",
      "Training Epoch: 4 [30720/45000]\tLoss: 3.6090\tLR: 0.000010\n",
      "Training Epoch: 4 [30736/45000]\tLoss: 3.6527\tLR: 0.000010\n",
      "Training Epoch: 4 [30752/45000]\tLoss: 3.5964\tLR: 0.000010\n",
      "Training Epoch: 4 [30768/45000]\tLoss: 3.7364\tLR: 0.000010\n",
      "Training Epoch: 4 [30784/45000]\tLoss: 3.7319\tLR: 0.000010\n",
      "Training Epoch: 4 [30800/45000]\tLoss: 3.6776\tLR: 0.000010\n",
      "Training Epoch: 4 [30816/45000]\tLoss: 3.8098\tLR: 0.000010\n",
      "Training Epoch: 4 [30832/45000]\tLoss: 3.7002\tLR: 0.000010\n",
      "Training Epoch: 4 [30848/45000]\tLoss: 3.6013\tLR: 0.000010\n",
      "Training Epoch: 4 [30864/45000]\tLoss: 3.7386\tLR: 0.000010\n",
      "Training Epoch: 4 [30880/45000]\tLoss: 3.8654\tLR: 0.000010\n",
      "Training Epoch: 4 [30896/45000]\tLoss: 3.7711\tLR: 0.000010\n",
      "Training Epoch: 4 [30912/45000]\tLoss: 3.7334\tLR: 0.000010\n",
      "Training Epoch: 4 [30928/45000]\tLoss: 3.6734\tLR: 0.000010\n",
      "Training Epoch: 4 [30944/45000]\tLoss: 3.6503\tLR: 0.000010\n",
      "Training Epoch: 4 [30960/45000]\tLoss: 3.6315\tLR: 0.000010\n",
      "Training Epoch: 4 [30976/45000]\tLoss: 3.7158\tLR: 0.000010\n",
      "Training Epoch: 4 [30992/45000]\tLoss: 3.7005\tLR: 0.000010\n",
      "Training Epoch: 4 [31008/45000]\tLoss: 3.7673\tLR: 0.000010\n",
      "Training Epoch: 4 [31024/45000]\tLoss: 3.7222\tLR: 0.000010\n",
      "Training Epoch: 4 [31040/45000]\tLoss: 3.7861\tLR: 0.000010\n",
      "Training Epoch: 4 [31056/45000]\tLoss: 3.6613\tLR: 0.000010\n",
      "Training Epoch: 4 [31072/45000]\tLoss: 3.5673\tLR: 0.000010\n",
      "Training Epoch: 4 [31088/45000]\tLoss: 3.7193\tLR: 0.000010\n",
      "Training Epoch: 4 [31104/45000]\tLoss: 3.6777\tLR: 0.000010\n",
      "Training Epoch: 4 [31120/45000]\tLoss: 3.7206\tLR: 0.000010\n",
      "Training Epoch: 4 [31136/45000]\tLoss: 3.7148\tLR: 0.000010\n",
      "Training Epoch: 4 [31152/45000]\tLoss: 3.8041\tLR: 0.000010\n",
      "Training Epoch: 4 [31168/45000]\tLoss: 3.6409\tLR: 0.000010\n",
      "Training Epoch: 4 [31184/45000]\tLoss: 3.6930\tLR: 0.000010\n",
      "Training Epoch: 4 [31200/45000]\tLoss: 3.6220\tLR: 0.000010\n",
      "Training Epoch: 4 [31216/45000]\tLoss: 3.6187\tLR: 0.000010\n",
      "Training Epoch: 4 [31232/45000]\tLoss: 3.7306\tLR: 0.000010\n",
      "Training Epoch: 4 [31248/45000]\tLoss: 3.7204\tLR: 0.000010\n",
      "Training Epoch: 4 [31264/45000]\tLoss: 3.6607\tLR: 0.000010\n",
      "Training Epoch: 4 [31280/45000]\tLoss: 3.6786\tLR: 0.000010\n",
      "Training Epoch: 4 [31296/45000]\tLoss: 3.7072\tLR: 0.000010\n",
      "Training Epoch: 4 [31312/45000]\tLoss: 3.7620\tLR: 0.000010\n",
      "Training Epoch: 4 [31328/45000]\tLoss: 3.6431\tLR: 0.000010\n",
      "Training Epoch: 4 [31344/45000]\tLoss: 3.7475\tLR: 0.000010\n",
      "Training Epoch: 4 [31360/45000]\tLoss: 3.7260\tLR: 0.000010\n",
      "Training Epoch: 4 [31376/45000]\tLoss: 3.7164\tLR: 0.000010\n",
      "Training Epoch: 4 [31392/45000]\tLoss: 3.6533\tLR: 0.000010\n",
      "Training Epoch: 4 [31408/45000]\tLoss: 3.7073\tLR: 0.000010\n",
      "Training Epoch: 4 [31424/45000]\tLoss: 3.6581\tLR: 0.000010\n",
      "Training Epoch: 4 [31440/45000]\tLoss: 3.7939\tLR: 0.000010\n",
      "Training Epoch: 4 [31456/45000]\tLoss: 3.6848\tLR: 0.000010\n",
      "Training Epoch: 4 [31472/45000]\tLoss: 3.7193\tLR: 0.000010\n",
      "Training Epoch: 4 [31488/45000]\tLoss: 3.7375\tLR: 0.000010\n",
      "Training Epoch: 4 [31504/45000]\tLoss: 3.6755\tLR: 0.000010\n",
      "Training Epoch: 4 [31520/45000]\tLoss: 3.7613\tLR: 0.000010\n",
      "Training Epoch: 4 [31536/45000]\tLoss: 3.7285\tLR: 0.000010\n",
      "Training Epoch: 4 [31552/45000]\tLoss: 3.5834\tLR: 0.000010\n",
      "Training Epoch: 4 [31568/45000]\tLoss: 3.6643\tLR: 0.000010\n",
      "Training Epoch: 4 [31584/45000]\tLoss: 3.7358\tLR: 0.000010\n",
      "Training Epoch: 4 [31600/45000]\tLoss: 3.7713\tLR: 0.000010\n",
      "Training Epoch: 4 [31616/45000]\tLoss: 3.7485\tLR: 0.000010\n",
      "Training Epoch: 4 [31632/45000]\tLoss: 3.7527\tLR: 0.000010\n",
      "Training Epoch: 4 [31648/45000]\tLoss: 3.6701\tLR: 0.000010\n",
      "Training Epoch: 4 [31664/45000]\tLoss: 3.6816\tLR: 0.000010\n",
      "Training Epoch: 4 [31680/45000]\tLoss: 3.6450\tLR: 0.000010\n",
      "Training Epoch: 4 [31696/45000]\tLoss: 3.7875\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [31712/45000]\tLoss: 3.7728\tLR: 0.000010\n",
      "Training Epoch: 4 [31728/45000]\tLoss: 3.7206\tLR: 0.000010\n",
      "Training Epoch: 4 [31744/45000]\tLoss: 3.7456\tLR: 0.000010\n",
      "Training Epoch: 4 [31760/45000]\tLoss: 3.8056\tLR: 0.000010\n",
      "Training Epoch: 4 [31776/45000]\tLoss: 3.7441\tLR: 0.000010\n",
      "Training Epoch: 4 [31792/45000]\tLoss: 3.7164\tLR: 0.000010\n",
      "Training Epoch: 4 [31808/45000]\tLoss: 3.6171\tLR: 0.000010\n",
      "Training Epoch: 4 [31824/45000]\tLoss: 3.7852\tLR: 0.000010\n",
      "Training Epoch: 4 [31840/45000]\tLoss: 3.7840\tLR: 0.000010\n",
      "Training Epoch: 4 [31856/45000]\tLoss: 3.8118\tLR: 0.000010\n",
      "Training Epoch: 4 [31872/45000]\tLoss: 3.7899\tLR: 0.000010\n",
      "Training Epoch: 4 [31888/45000]\tLoss: 3.7707\tLR: 0.000010\n",
      "Training Epoch: 4 [31904/45000]\tLoss: 3.6304\tLR: 0.000010\n",
      "Training Epoch: 4 [31920/45000]\tLoss: 3.7081\tLR: 0.000010\n",
      "Training Epoch: 4 [31936/45000]\tLoss: 3.7566\tLR: 0.000010\n",
      "Training Epoch: 4 [31952/45000]\tLoss: 3.5475\tLR: 0.000010\n",
      "Training Epoch: 4 [31968/45000]\tLoss: 3.6885\tLR: 0.000010\n",
      "Training Epoch: 4 [31984/45000]\tLoss: 3.7362\tLR: 0.000010\n",
      "Training Epoch: 4 [32000/45000]\tLoss: 3.6381\tLR: 0.000010\n",
      "Training Epoch: 4 [32016/45000]\tLoss: 3.7459\tLR: 0.000010\n",
      "Training Epoch: 4 [32032/45000]\tLoss: 3.7320\tLR: 0.000010\n",
      "Training Epoch: 4 [32048/45000]\tLoss: 3.7623\tLR: 0.000010\n",
      "Training Epoch: 4 [32064/45000]\tLoss: 3.6510\tLR: 0.000010\n",
      "Training Epoch: 4 [32080/45000]\tLoss: 3.6844\tLR: 0.000010\n",
      "Training Epoch: 4 [32096/45000]\tLoss: 3.6866\tLR: 0.000010\n",
      "Training Epoch: 4 [32112/45000]\tLoss: 3.6162\tLR: 0.000010\n",
      "Training Epoch: 4 [32128/45000]\tLoss: 3.6424\tLR: 0.000010\n",
      "Training Epoch: 4 [32144/45000]\tLoss: 3.7477\tLR: 0.000010\n",
      "Training Epoch: 4 [32160/45000]\tLoss: 3.7251\tLR: 0.000010\n",
      "Training Epoch: 4 [32176/45000]\tLoss: 3.7084\tLR: 0.000010\n",
      "Training Epoch: 4 [32192/45000]\tLoss: 3.7403\tLR: 0.000010\n",
      "Training Epoch: 4 [32208/45000]\tLoss: 3.6927\tLR: 0.000010\n",
      "Training Epoch: 4 [32224/45000]\tLoss: 3.6866\tLR: 0.000010\n",
      "Training Epoch: 4 [32240/45000]\tLoss: 3.7652\tLR: 0.000010\n",
      "Training Epoch: 4 [32256/45000]\tLoss: 3.7411\tLR: 0.000010\n",
      "Training Epoch: 4 [32272/45000]\tLoss: 3.6019\tLR: 0.000010\n",
      "Training Epoch: 4 [32288/45000]\tLoss: 3.6770\tLR: 0.000010\n",
      "Training Epoch: 4 [32304/45000]\tLoss: 3.7466\tLR: 0.000010\n",
      "Training Epoch: 4 [32320/45000]\tLoss: 3.7939\tLR: 0.000010\n",
      "Training Epoch: 4 [32336/45000]\tLoss: 3.6652\tLR: 0.000010\n",
      "Training Epoch: 4 [32352/45000]\tLoss: 3.7296\tLR: 0.000010\n",
      "Training Epoch: 4 [32368/45000]\tLoss: 3.7067\tLR: 0.000010\n",
      "Training Epoch: 4 [32384/45000]\tLoss: 3.6945\tLR: 0.000010\n",
      "Training Epoch: 4 [32400/45000]\tLoss: 3.6688\tLR: 0.000010\n",
      "Training Epoch: 4 [32416/45000]\tLoss: 3.6960\tLR: 0.000010\n",
      "Training Epoch: 4 [32432/45000]\tLoss: 3.7322\tLR: 0.000010\n",
      "Training Epoch: 4 [32448/45000]\tLoss: 3.7721\tLR: 0.000010\n",
      "Training Epoch: 4 [32464/45000]\tLoss: 3.7471\tLR: 0.000010\n",
      "Training Epoch: 4 [32480/45000]\tLoss: 3.6712\tLR: 0.000010\n",
      "Training Epoch: 4 [32496/45000]\tLoss: 3.6950\tLR: 0.000010\n",
      "Training Epoch: 4 [32512/45000]\tLoss: 3.7282\tLR: 0.000010\n",
      "Training Epoch: 4 [32528/45000]\tLoss: 3.7107\tLR: 0.000010\n",
      "Training Epoch: 4 [32544/45000]\tLoss: 3.8399\tLR: 0.000010\n",
      "Training Epoch: 4 [32560/45000]\tLoss: 3.6955\tLR: 0.000010\n",
      "Training Epoch: 4 [32576/45000]\tLoss: 3.7623\tLR: 0.000010\n",
      "Training Epoch: 4 [32592/45000]\tLoss: 3.5996\tLR: 0.000010\n",
      "Training Epoch: 4 [32608/45000]\tLoss: 3.7074\tLR: 0.000010\n",
      "Training Epoch: 4 [32624/45000]\tLoss: 3.7951\tLR: 0.000010\n",
      "Training Epoch: 4 [32640/45000]\tLoss: 3.6815\tLR: 0.000010\n",
      "Training Epoch: 4 [32656/45000]\tLoss: 3.6833\tLR: 0.000010\n",
      "Training Epoch: 4 [32672/45000]\tLoss: 3.7577\tLR: 0.000010\n",
      "Training Epoch: 4 [32688/45000]\tLoss: 3.6253\tLR: 0.000010\n",
      "Training Epoch: 4 [32704/45000]\tLoss: 3.6556\tLR: 0.000010\n",
      "Training Epoch: 4 [32720/45000]\tLoss: 3.7162\tLR: 0.000010\n",
      "Training Epoch: 4 [32736/45000]\tLoss: 3.7825\tLR: 0.000010\n",
      "Training Epoch: 4 [32752/45000]\tLoss: 3.8229\tLR: 0.000010\n",
      "Training Epoch: 4 [32768/45000]\tLoss: 3.6020\tLR: 0.000010\n",
      "Training Epoch: 4 [32784/45000]\tLoss: 3.7750\tLR: 0.000010\n",
      "Training Epoch: 4 [32800/45000]\tLoss: 3.7237\tLR: 0.000010\n",
      "Training Epoch: 4 [32816/45000]\tLoss: 3.6732\tLR: 0.000010\n",
      "Training Epoch: 4 [32832/45000]\tLoss: 3.6954\tLR: 0.000010\n",
      "Training Epoch: 4 [32848/45000]\tLoss: 3.7261\tLR: 0.000010\n",
      "Training Epoch: 4 [32864/45000]\tLoss: 3.7757\tLR: 0.000010\n",
      "Training Epoch: 4 [32880/45000]\tLoss: 3.6467\tLR: 0.000010\n",
      "Training Epoch: 4 [32896/45000]\tLoss: 3.7277\tLR: 0.000010\n",
      "Training Epoch: 4 [32912/45000]\tLoss: 3.6972\tLR: 0.000010\n",
      "Training Epoch: 4 [32928/45000]\tLoss: 3.8889\tLR: 0.000010\n",
      "Training Epoch: 4 [32944/45000]\tLoss: 3.7351\tLR: 0.000010\n",
      "Training Epoch: 4 [32960/45000]\tLoss: 3.7574\tLR: 0.000010\n",
      "Training Epoch: 4 [32976/45000]\tLoss: 3.7701\tLR: 0.000010\n",
      "Training Epoch: 4 [32992/45000]\tLoss: 3.6321\tLR: 0.000010\n",
      "Training Epoch: 4 [33008/45000]\tLoss: 3.6186\tLR: 0.000010\n",
      "Training Epoch: 4 [33024/45000]\tLoss: 3.7355\tLR: 0.000010\n",
      "Training Epoch: 4 [33040/45000]\tLoss: 3.6689\tLR: 0.000010\n",
      "Training Epoch: 4 [33056/45000]\tLoss: 3.7438\tLR: 0.000010\n",
      "Training Epoch: 4 [33072/45000]\tLoss: 3.7854\tLR: 0.000010\n",
      "Training Epoch: 4 [33088/45000]\tLoss: 3.7103\tLR: 0.000010\n",
      "Training Epoch: 4 [33104/45000]\tLoss: 3.5667\tLR: 0.000010\n",
      "Training Epoch: 4 [33120/45000]\tLoss: 3.7565\tLR: 0.000010\n",
      "Training Epoch: 4 [33136/45000]\tLoss: 3.7036\tLR: 0.000010\n",
      "Training Epoch: 4 [33152/45000]\tLoss: 3.7570\tLR: 0.000010\n",
      "Training Epoch: 4 [33168/45000]\tLoss: 3.7904\tLR: 0.000010\n",
      "Training Epoch: 4 [33184/45000]\tLoss: 3.8067\tLR: 0.000010\n",
      "Training Epoch: 4 [33200/45000]\tLoss: 3.7888\tLR: 0.000010\n",
      "Training Epoch: 4 [33216/45000]\tLoss: 3.6537\tLR: 0.000010\n",
      "Training Epoch: 4 [33232/45000]\tLoss: 3.6955\tLR: 0.000010\n",
      "Training Epoch: 4 [33248/45000]\tLoss: 3.6572\tLR: 0.000010\n",
      "Training Epoch: 4 [33264/45000]\tLoss: 3.9363\tLR: 0.000010\n",
      "Training Epoch: 4 [33280/45000]\tLoss: 3.6578\tLR: 0.000010\n",
      "Training Epoch: 4 [33296/45000]\tLoss: 3.6644\tLR: 0.000010\n",
      "Training Epoch: 4 [33312/45000]\tLoss: 3.7297\tLR: 0.000010\n",
      "Training Epoch: 4 [33328/45000]\tLoss: 3.7044\tLR: 0.000010\n",
      "Training Epoch: 4 [33344/45000]\tLoss: 3.7755\tLR: 0.000010\n",
      "Training Epoch: 4 [33360/45000]\tLoss: 3.6066\tLR: 0.000010\n",
      "Training Epoch: 4 [33376/45000]\tLoss: 3.7462\tLR: 0.000010\n",
      "Training Epoch: 4 [33392/45000]\tLoss: 3.8070\tLR: 0.000010\n",
      "Training Epoch: 4 [33408/45000]\tLoss: 3.6921\tLR: 0.000010\n",
      "Training Epoch: 4 [33424/45000]\tLoss: 3.7546\tLR: 0.000010\n",
      "Training Epoch: 4 [33440/45000]\tLoss: 3.6861\tLR: 0.000010\n",
      "Training Epoch: 4 [33456/45000]\tLoss: 3.8275\tLR: 0.000010\n",
      "Training Epoch: 4 [33472/45000]\tLoss: 3.7187\tLR: 0.000010\n",
      "Training Epoch: 4 [33488/45000]\tLoss: 3.8280\tLR: 0.000010\n",
      "Training Epoch: 4 [33504/45000]\tLoss: 3.6630\tLR: 0.000010\n",
      "Training Epoch: 4 [33520/45000]\tLoss: 3.6412\tLR: 0.000010\n",
      "Training Epoch: 4 [33536/45000]\tLoss: 3.6874\tLR: 0.000010\n",
      "Training Epoch: 4 [33552/45000]\tLoss: 3.7368\tLR: 0.000010\n",
      "Training Epoch: 4 [33568/45000]\tLoss: 3.6879\tLR: 0.000010\n",
      "Training Epoch: 4 [33584/45000]\tLoss: 3.9008\tLR: 0.000010\n",
      "Training Epoch: 4 [33600/45000]\tLoss: 3.6984\tLR: 0.000010\n",
      "Training Epoch: 4 [33616/45000]\tLoss: 3.6711\tLR: 0.000010\n",
      "Training Epoch: 4 [33632/45000]\tLoss: 3.7189\tLR: 0.000010\n",
      "Training Epoch: 4 [33648/45000]\tLoss: 3.7523\tLR: 0.000010\n",
      "Training Epoch: 4 [33664/45000]\tLoss: 3.6479\tLR: 0.000010\n",
      "Training Epoch: 4 [33680/45000]\tLoss: 3.6095\tLR: 0.000010\n",
      "Training Epoch: 4 [33696/45000]\tLoss: 3.7564\tLR: 0.000010\n",
      "Training Epoch: 4 [33712/45000]\tLoss: 3.7297\tLR: 0.000010\n",
      "Training Epoch: 4 [33728/45000]\tLoss: 3.8086\tLR: 0.000010\n",
      "Training Epoch: 4 [33744/45000]\tLoss: 3.8066\tLR: 0.000010\n",
      "Training Epoch: 4 [33760/45000]\tLoss: 3.6583\tLR: 0.000010\n",
      "Training Epoch: 4 [33776/45000]\tLoss: 3.7533\tLR: 0.000010\n",
      "Training Epoch: 4 [33792/45000]\tLoss: 3.7532\tLR: 0.000010\n",
      "Training Epoch: 4 [33808/45000]\tLoss: 3.6827\tLR: 0.000010\n",
      "Training Epoch: 4 [33824/45000]\tLoss: 3.6096\tLR: 0.000010\n",
      "Training Epoch: 4 [33840/45000]\tLoss: 3.6841\tLR: 0.000010\n",
      "Training Epoch: 4 [33856/45000]\tLoss: 3.7274\tLR: 0.000010\n",
      "Training Epoch: 4 [33872/45000]\tLoss: 3.6359\tLR: 0.000010\n",
      "Training Epoch: 4 [33888/45000]\tLoss: 3.7162\tLR: 0.000010\n",
      "Training Epoch: 4 [33904/45000]\tLoss: 3.6876\tLR: 0.000010\n",
      "Training Epoch: 4 [33920/45000]\tLoss: 3.7591\tLR: 0.000010\n",
      "Training Epoch: 4 [33936/45000]\tLoss: 3.7075\tLR: 0.000010\n",
      "Training Epoch: 4 [33952/45000]\tLoss: 3.6973\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [33968/45000]\tLoss: 3.6408\tLR: 0.000010\n",
      "Training Epoch: 4 [33984/45000]\tLoss: 3.6788\tLR: 0.000010\n",
      "Training Epoch: 4 [34000/45000]\tLoss: 3.7573\tLR: 0.000010\n",
      "Training Epoch: 4 [34016/45000]\tLoss: 3.6469\tLR: 0.000010\n",
      "Training Epoch: 4 [34032/45000]\tLoss: 3.7036\tLR: 0.000010\n",
      "Training Epoch: 4 [34048/45000]\tLoss: 3.6715\tLR: 0.000010\n",
      "Training Epoch: 4 [34064/45000]\tLoss: 3.6658\tLR: 0.000010\n",
      "Training Epoch: 4 [34080/45000]\tLoss: 3.6666\tLR: 0.000010\n",
      "Training Epoch: 4 [34096/45000]\tLoss: 3.7345\tLR: 0.000010\n",
      "Training Epoch: 4 [34112/45000]\tLoss: 3.6479\tLR: 0.000010\n",
      "Training Epoch: 4 [34128/45000]\tLoss: 3.7009\tLR: 0.000010\n",
      "Training Epoch: 4 [34144/45000]\tLoss: 3.7976\tLR: 0.000010\n",
      "Training Epoch: 4 [34160/45000]\tLoss: 3.6853\tLR: 0.000010\n",
      "Training Epoch: 4 [34176/45000]\tLoss: 3.7585\tLR: 0.000010\n",
      "Training Epoch: 4 [34192/45000]\tLoss: 3.7395\tLR: 0.000010\n",
      "Training Epoch: 4 [34208/45000]\tLoss: 3.6528\tLR: 0.000010\n",
      "Training Epoch: 4 [34224/45000]\tLoss: 3.7508\tLR: 0.000010\n",
      "Training Epoch: 4 [34240/45000]\tLoss: 3.8042\tLR: 0.000010\n",
      "Training Epoch: 4 [34256/45000]\tLoss: 3.7438\tLR: 0.000010\n",
      "Training Epoch: 4 [34272/45000]\tLoss: 3.7392\tLR: 0.000010\n",
      "Training Epoch: 4 [34288/45000]\tLoss: 3.6611\tLR: 0.000010\n",
      "Training Epoch: 4 [34304/45000]\tLoss: 3.7152\tLR: 0.000010\n",
      "Training Epoch: 4 [34320/45000]\tLoss: 3.6890\tLR: 0.000010\n",
      "Training Epoch: 4 [34336/45000]\tLoss: 3.5947\tLR: 0.000010\n",
      "Training Epoch: 4 [34352/45000]\tLoss: 3.6387\tLR: 0.000010\n",
      "Training Epoch: 4 [34368/45000]\tLoss: 3.6880\tLR: 0.000010\n",
      "Training Epoch: 4 [34384/45000]\tLoss: 3.6532\tLR: 0.000010\n",
      "Training Epoch: 4 [34400/45000]\tLoss: 3.9147\tLR: 0.000010\n",
      "Training Epoch: 4 [34416/45000]\tLoss: 3.7753\tLR: 0.000010\n",
      "Training Epoch: 4 [34432/45000]\tLoss: 3.7561\tLR: 0.000010\n",
      "Training Epoch: 4 [34448/45000]\tLoss: 3.7510\tLR: 0.000010\n",
      "Training Epoch: 4 [34464/45000]\tLoss: 3.6857\tLR: 0.000010\n",
      "Training Epoch: 4 [34480/45000]\tLoss: 3.7602\tLR: 0.000010\n",
      "Training Epoch: 4 [34496/45000]\tLoss: 3.7360\tLR: 0.000010\n",
      "Training Epoch: 4 [34512/45000]\tLoss: 3.7291\tLR: 0.000010\n",
      "Training Epoch: 4 [34528/45000]\tLoss: 3.7072\tLR: 0.000010\n",
      "Training Epoch: 4 [34544/45000]\tLoss: 3.5460\tLR: 0.000010\n",
      "Training Epoch: 4 [34560/45000]\tLoss: 3.6736\tLR: 0.000010\n",
      "Training Epoch: 4 [34576/45000]\tLoss: 3.6333\tLR: 0.000010\n",
      "Training Epoch: 4 [34592/45000]\tLoss: 3.6753\tLR: 0.000010\n",
      "Training Epoch: 4 [34608/45000]\tLoss: 3.6900\tLR: 0.000010\n",
      "Training Epoch: 4 [34624/45000]\tLoss: 3.6595\tLR: 0.000010\n",
      "Training Epoch: 4 [34640/45000]\tLoss: 3.6891\tLR: 0.000010\n",
      "Training Epoch: 4 [34656/45000]\tLoss: 3.7616\tLR: 0.000010\n",
      "Training Epoch: 4 [34672/45000]\tLoss: 3.7157\tLR: 0.000010\n",
      "Training Epoch: 4 [34688/45000]\tLoss: 3.7976\tLR: 0.000010\n",
      "Training Epoch: 4 [34704/45000]\tLoss: 3.8174\tLR: 0.000010\n",
      "Training Epoch: 4 [34720/45000]\tLoss: 3.8081\tLR: 0.000010\n",
      "Training Epoch: 4 [34736/45000]\tLoss: 3.7572\tLR: 0.000010\n",
      "Training Epoch: 4 [34752/45000]\tLoss: 3.6214\tLR: 0.000010\n",
      "Training Epoch: 4 [34768/45000]\tLoss: 3.7480\tLR: 0.000010\n",
      "Training Epoch: 4 [34784/45000]\tLoss: 3.6351\tLR: 0.000010\n",
      "Training Epoch: 4 [34800/45000]\tLoss: 3.7423\tLR: 0.000010\n",
      "Training Epoch: 4 [34816/45000]\tLoss: 3.6684\tLR: 0.000010\n",
      "Training Epoch: 4 [34832/45000]\tLoss: 3.6505\tLR: 0.000010\n",
      "Training Epoch: 4 [34848/45000]\tLoss: 3.7374\tLR: 0.000010\n",
      "Training Epoch: 4 [34864/45000]\tLoss: 3.6455\tLR: 0.000010\n",
      "Training Epoch: 4 [34880/45000]\tLoss: 3.7247\tLR: 0.000010\n",
      "Training Epoch: 4 [34896/45000]\tLoss: 3.8829\tLR: 0.000010\n",
      "Training Epoch: 4 [34912/45000]\tLoss: 3.7295\tLR: 0.000010\n",
      "Training Epoch: 4 [34928/45000]\tLoss: 3.7542\tLR: 0.000010\n",
      "Training Epoch: 4 [34944/45000]\tLoss: 3.7914\tLR: 0.000010\n",
      "Training Epoch: 4 [34960/45000]\tLoss: 3.6861\tLR: 0.000010\n",
      "Training Epoch: 4 [34976/45000]\tLoss: 3.6351\tLR: 0.000010\n",
      "Training Epoch: 4 [34992/45000]\tLoss: 3.7770\tLR: 0.000010\n",
      "Training Epoch: 4 [35008/45000]\tLoss: 3.7255\tLR: 0.000010\n",
      "Training Epoch: 4 [35024/45000]\tLoss: 3.6447\tLR: 0.000010\n",
      "Training Epoch: 4 [35040/45000]\tLoss: 3.8143\tLR: 0.000010\n",
      "Training Epoch: 4 [35056/45000]\tLoss: 3.7786\tLR: 0.000010\n",
      "Training Epoch: 4 [35072/45000]\tLoss: 3.8583\tLR: 0.000010\n",
      "Training Epoch: 4 [35088/45000]\tLoss: 3.8211\tLR: 0.000010\n",
      "Training Epoch: 4 [35104/45000]\tLoss: 3.7306\tLR: 0.000010\n",
      "Training Epoch: 4 [35120/45000]\tLoss: 3.7341\tLR: 0.000010\n",
      "Training Epoch: 4 [35136/45000]\tLoss: 3.7115\tLR: 0.000010\n",
      "Training Epoch: 4 [35152/45000]\tLoss: 3.6547\tLR: 0.000010\n",
      "Training Epoch: 4 [35168/45000]\tLoss: 3.7384\tLR: 0.000010\n",
      "Training Epoch: 4 [35184/45000]\tLoss: 3.7596\tLR: 0.000010\n",
      "Training Epoch: 4 [35200/45000]\tLoss: 3.7813\tLR: 0.000010\n",
      "Training Epoch: 4 [35216/45000]\tLoss: 3.7517\tLR: 0.000010\n",
      "Training Epoch: 4 [35232/45000]\tLoss: 3.6478\tLR: 0.000010\n",
      "Training Epoch: 4 [35248/45000]\tLoss: 3.7080\tLR: 0.000010\n",
      "Training Epoch: 4 [35264/45000]\tLoss: 3.7769\tLR: 0.000010\n",
      "Training Epoch: 4 [35280/45000]\tLoss: 3.8039\tLR: 0.000010\n",
      "Training Epoch: 4 [35296/45000]\tLoss: 3.7324\tLR: 0.000010\n",
      "Training Epoch: 4 [35312/45000]\tLoss: 3.8590\tLR: 0.000010\n",
      "Training Epoch: 4 [35328/45000]\tLoss: 3.7143\tLR: 0.000010\n",
      "Training Epoch: 4 [35344/45000]\tLoss: 3.6445\tLR: 0.000010\n",
      "Training Epoch: 4 [35360/45000]\tLoss: 3.7367\tLR: 0.000010\n",
      "Training Epoch: 4 [35376/45000]\tLoss: 3.5993\tLR: 0.000010\n",
      "Training Epoch: 4 [35392/45000]\tLoss: 3.7775\tLR: 0.000010\n",
      "Training Epoch: 4 [35408/45000]\tLoss: 3.6709\tLR: 0.000010\n",
      "Training Epoch: 4 [35424/45000]\tLoss: 3.6859\tLR: 0.000010\n",
      "Training Epoch: 4 [35440/45000]\tLoss: 3.7416\tLR: 0.000010\n",
      "Training Epoch: 4 [35456/45000]\tLoss: 3.6375\tLR: 0.000010\n",
      "Training Epoch: 4 [35472/45000]\tLoss: 3.7956\tLR: 0.000010\n",
      "Training Epoch: 4 [35488/45000]\tLoss: 3.7486\tLR: 0.000010\n",
      "Training Epoch: 4 [35504/45000]\tLoss: 3.7656\tLR: 0.000010\n",
      "Training Epoch: 4 [35520/45000]\tLoss: 3.7163\tLR: 0.000010\n",
      "Training Epoch: 4 [35536/45000]\tLoss: 3.7430\tLR: 0.000010\n",
      "Training Epoch: 4 [35552/45000]\tLoss: 3.7442\tLR: 0.000010\n",
      "Training Epoch: 4 [35568/45000]\tLoss: 3.9075\tLR: 0.000010\n",
      "Training Epoch: 4 [35584/45000]\tLoss: 3.7346\tLR: 0.000010\n",
      "Training Epoch: 4 [35600/45000]\tLoss: 3.7837\tLR: 0.000010\n",
      "Training Epoch: 4 [35616/45000]\tLoss: 3.6909\tLR: 0.000010\n",
      "Training Epoch: 4 [35632/45000]\tLoss: 3.6522\tLR: 0.000010\n",
      "Training Epoch: 4 [35648/45000]\tLoss: 3.6935\tLR: 0.000010\n",
      "Training Epoch: 4 [35664/45000]\tLoss: 3.7877\tLR: 0.000010\n",
      "Training Epoch: 4 [35680/45000]\tLoss: 3.8180\tLR: 0.000010\n",
      "Training Epoch: 4 [35696/45000]\tLoss: 3.7246\tLR: 0.000010\n",
      "Training Epoch: 4 [35712/45000]\tLoss: 3.6329\tLR: 0.000010\n",
      "Training Epoch: 4 [35728/45000]\tLoss: 3.7650\tLR: 0.000010\n",
      "Training Epoch: 4 [35744/45000]\tLoss: 3.7814\tLR: 0.000010\n",
      "Training Epoch: 4 [35760/45000]\tLoss: 3.7199\tLR: 0.000010\n",
      "Training Epoch: 4 [35776/45000]\tLoss: 3.6342\tLR: 0.000010\n",
      "Training Epoch: 4 [35792/45000]\tLoss: 3.6692\tLR: 0.000010\n",
      "Training Epoch: 4 [35808/45000]\tLoss: 3.7223\tLR: 0.000010\n",
      "Training Epoch: 4 [35824/45000]\tLoss: 3.8106\tLR: 0.000010\n",
      "Training Epoch: 4 [35840/45000]\tLoss: 3.6483\tLR: 0.000010\n",
      "Training Epoch: 4 [35856/45000]\tLoss: 3.7189\tLR: 0.000010\n",
      "Training Epoch: 4 [35872/45000]\tLoss: 3.7085\tLR: 0.000010\n",
      "Training Epoch: 4 [35888/45000]\tLoss: 3.6593\tLR: 0.000010\n",
      "Training Epoch: 4 [35904/45000]\tLoss: 3.6227\tLR: 0.000010\n",
      "Training Epoch: 4 [35920/45000]\tLoss: 3.6568\tLR: 0.000010\n",
      "Training Epoch: 4 [35936/45000]\tLoss: 3.6500\tLR: 0.000010\n",
      "Training Epoch: 4 [35952/45000]\tLoss: 3.5648\tLR: 0.000010\n",
      "Training Epoch: 4 [35968/45000]\tLoss: 3.7074\tLR: 0.000010\n",
      "Training Epoch: 4 [35984/45000]\tLoss: 3.6783\tLR: 0.000010\n",
      "Training Epoch: 4 [36000/45000]\tLoss: 3.6670\tLR: 0.000010\n",
      "Training Epoch: 4 [36016/45000]\tLoss: 3.7031\tLR: 0.000010\n",
      "Training Epoch: 4 [36032/45000]\tLoss: 3.7128\tLR: 0.000010\n",
      "Training Epoch: 4 [36048/45000]\tLoss: 3.7839\tLR: 0.000010\n",
      "Training Epoch: 4 [36064/45000]\tLoss: 3.7694\tLR: 0.000010\n",
      "Training Epoch: 4 [36080/45000]\tLoss: 3.7740\tLR: 0.000010\n",
      "Training Epoch: 4 [36096/45000]\tLoss: 3.7912\tLR: 0.000010\n",
      "Training Epoch: 4 [36112/45000]\tLoss: 3.7014\tLR: 0.000010\n",
      "Training Epoch: 4 [36128/45000]\tLoss: 3.6919\tLR: 0.000010\n",
      "Training Epoch: 4 [36144/45000]\tLoss: 3.7336\tLR: 0.000010\n",
      "Training Epoch: 4 [36160/45000]\tLoss: 3.6941\tLR: 0.000010\n",
      "Training Epoch: 4 [36176/45000]\tLoss: 3.6938\tLR: 0.000010\n",
      "Training Epoch: 4 [36192/45000]\tLoss: 3.6068\tLR: 0.000010\n",
      "Training Epoch: 4 [36208/45000]\tLoss: 3.8137\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [36224/45000]\tLoss: 3.6787\tLR: 0.000010\n",
      "Training Epoch: 4 [36240/45000]\tLoss: 3.5786\tLR: 0.000010\n",
      "Training Epoch: 4 [36256/45000]\tLoss: 3.7421\tLR: 0.000010\n",
      "Training Epoch: 4 [36272/45000]\tLoss: 3.7167\tLR: 0.000010\n",
      "Training Epoch: 4 [36288/45000]\tLoss: 3.6622\tLR: 0.000010\n",
      "Training Epoch: 4 [36304/45000]\tLoss: 3.7558\tLR: 0.000010\n",
      "Training Epoch: 4 [36320/45000]\tLoss: 3.8007\tLR: 0.000010\n",
      "Training Epoch: 4 [36336/45000]\tLoss: 3.5443\tLR: 0.000010\n",
      "Training Epoch: 4 [36352/45000]\tLoss: 3.7423\tLR: 0.000010\n",
      "Training Epoch: 4 [36368/45000]\tLoss: 3.5581\tLR: 0.000010\n",
      "Training Epoch: 4 [36384/45000]\tLoss: 3.6973\tLR: 0.000010\n",
      "Training Epoch: 4 [36400/45000]\tLoss: 3.7165\tLR: 0.000010\n",
      "Training Epoch: 4 [36416/45000]\tLoss: 3.7396\tLR: 0.000010\n",
      "Training Epoch: 4 [36432/45000]\tLoss: 3.5683\tLR: 0.000010\n",
      "Training Epoch: 4 [36448/45000]\tLoss: 3.6604\tLR: 0.000010\n",
      "Training Epoch: 4 [36464/45000]\tLoss: 3.6470\tLR: 0.000010\n",
      "Training Epoch: 4 [36480/45000]\tLoss: 3.6619\tLR: 0.000010\n",
      "Training Epoch: 4 [36496/45000]\tLoss: 3.6668\tLR: 0.000010\n",
      "Training Epoch: 4 [36512/45000]\tLoss: 3.7467\tLR: 0.000010\n",
      "Training Epoch: 4 [36528/45000]\tLoss: 3.7494\tLR: 0.000010\n",
      "Training Epoch: 4 [36544/45000]\tLoss: 3.6798\tLR: 0.000010\n",
      "Training Epoch: 4 [36560/45000]\tLoss: 3.4924\tLR: 0.000010\n",
      "Training Epoch: 4 [36576/45000]\tLoss: 3.6344\tLR: 0.000010\n",
      "Training Epoch: 4 [36592/45000]\tLoss: 3.6291\tLR: 0.000010\n",
      "Training Epoch: 4 [36608/45000]\tLoss: 3.6418\tLR: 0.000010\n",
      "Training Epoch: 4 [36624/45000]\tLoss: 3.6847\tLR: 0.000010\n",
      "Training Epoch: 4 [36640/45000]\tLoss: 3.7842\tLR: 0.000010\n",
      "Training Epoch: 4 [36656/45000]\tLoss: 3.7566\tLR: 0.000010\n",
      "Training Epoch: 4 [36672/45000]\tLoss: 3.8005\tLR: 0.000010\n",
      "Training Epoch: 4 [36688/45000]\tLoss: 3.6042\tLR: 0.000010\n",
      "Training Epoch: 4 [36704/45000]\tLoss: 3.6446\tLR: 0.000010\n",
      "Training Epoch: 4 [36720/45000]\tLoss: 3.7208\tLR: 0.000010\n",
      "Training Epoch: 4 [36736/45000]\tLoss: 3.7989\tLR: 0.000010\n",
      "Training Epoch: 4 [36752/45000]\tLoss: 3.7092\tLR: 0.000010\n",
      "Training Epoch: 4 [36768/45000]\tLoss: 3.6339\tLR: 0.000010\n",
      "Training Epoch: 4 [36784/45000]\tLoss: 3.8253\tLR: 0.000010\n",
      "Training Epoch: 4 [36800/45000]\tLoss: 3.6317\tLR: 0.000010\n",
      "Training Epoch: 4 [36816/45000]\tLoss: 3.7137\tLR: 0.000010\n",
      "Training Epoch: 4 [36832/45000]\tLoss: 3.6070\tLR: 0.000010\n",
      "Training Epoch: 4 [36848/45000]\tLoss: 3.7202\tLR: 0.000010\n",
      "Training Epoch: 4 [36864/45000]\tLoss: 3.7565\tLR: 0.000010\n",
      "Training Epoch: 4 [36880/45000]\tLoss: 3.5453\tLR: 0.000010\n",
      "Training Epoch: 4 [36896/45000]\tLoss: 3.6811\tLR: 0.000010\n",
      "Training Epoch: 4 [36912/45000]\tLoss: 3.6878\tLR: 0.000010\n",
      "Training Epoch: 4 [36928/45000]\tLoss: 3.6374\tLR: 0.000010\n",
      "Training Epoch: 4 [36944/45000]\tLoss: 3.6365\tLR: 0.000010\n",
      "Training Epoch: 4 [36960/45000]\tLoss: 3.6912\tLR: 0.000010\n",
      "Training Epoch: 4 [36976/45000]\tLoss: 3.6904\tLR: 0.000010\n",
      "Training Epoch: 4 [36992/45000]\tLoss: 3.6310\tLR: 0.000010\n",
      "Training Epoch: 4 [37008/45000]\tLoss: 3.6980\tLR: 0.000010\n",
      "Training Epoch: 4 [37024/45000]\tLoss: 3.7559\tLR: 0.000010\n",
      "Training Epoch: 4 [37040/45000]\tLoss: 3.7538\tLR: 0.000010\n",
      "Training Epoch: 4 [37056/45000]\tLoss: 3.7083\tLR: 0.000010\n",
      "Training Epoch: 4 [37072/45000]\tLoss: 3.6494\tLR: 0.000010\n",
      "Training Epoch: 4 [37088/45000]\tLoss: 3.8759\tLR: 0.000010\n",
      "Training Epoch: 4 [37104/45000]\tLoss: 3.7363\tLR: 0.000010\n",
      "Training Epoch: 4 [37120/45000]\tLoss: 3.7416\tLR: 0.000010\n",
      "Training Epoch: 4 [37136/45000]\tLoss: 3.7526\tLR: 0.000010\n",
      "Training Epoch: 4 [37152/45000]\tLoss: 3.6737\tLR: 0.000010\n",
      "Training Epoch: 4 [37168/45000]\tLoss: 3.5523\tLR: 0.000010\n",
      "Training Epoch: 4 [37184/45000]\tLoss: 3.6298\tLR: 0.000010\n",
      "Training Epoch: 4 [37200/45000]\tLoss: 3.6915\tLR: 0.000010\n",
      "Training Epoch: 4 [37216/45000]\tLoss: 3.7578\tLR: 0.000010\n",
      "Training Epoch: 4 [37232/45000]\tLoss: 3.7890\tLR: 0.000010\n",
      "Training Epoch: 4 [37248/45000]\tLoss: 3.6601\tLR: 0.000010\n",
      "Training Epoch: 4 [37264/45000]\tLoss: 3.5585\tLR: 0.000010\n",
      "Training Epoch: 4 [37280/45000]\tLoss: 3.7053\tLR: 0.000010\n",
      "Training Epoch: 4 [37296/45000]\tLoss: 3.7070\tLR: 0.000010\n",
      "Training Epoch: 4 [37312/45000]\tLoss: 3.7109\tLR: 0.000010\n",
      "Training Epoch: 4 [37328/45000]\tLoss: 3.8135\tLR: 0.000010\n",
      "Training Epoch: 4 [37344/45000]\tLoss: 3.7481\tLR: 0.000010\n",
      "Training Epoch: 4 [37360/45000]\tLoss: 3.7528\tLR: 0.000010\n",
      "Training Epoch: 4 [37376/45000]\tLoss: 3.7378\tLR: 0.000010\n",
      "Training Epoch: 4 [37392/45000]\tLoss: 3.7898\tLR: 0.000010\n",
      "Training Epoch: 4 [37408/45000]\tLoss: 3.6884\tLR: 0.000010\n",
      "Training Epoch: 4 [37424/45000]\tLoss: 3.6784\tLR: 0.000010\n",
      "Training Epoch: 4 [37440/45000]\tLoss: 3.7366\tLR: 0.000010\n",
      "Training Epoch: 4 [37456/45000]\tLoss: 3.7351\tLR: 0.000010\n",
      "Training Epoch: 4 [37472/45000]\tLoss: 3.6362\tLR: 0.000010\n",
      "Training Epoch: 4 [37488/45000]\tLoss: 3.7237\tLR: 0.000010\n",
      "Training Epoch: 4 [37504/45000]\tLoss: 3.6918\tLR: 0.000010\n",
      "Training Epoch: 4 [37520/45000]\tLoss: 3.8085\tLR: 0.000010\n",
      "Training Epoch: 4 [37536/45000]\tLoss: 3.6149\tLR: 0.000010\n",
      "Training Epoch: 4 [37552/45000]\tLoss: 3.7125\tLR: 0.000010\n",
      "Training Epoch: 4 [37568/45000]\tLoss: 3.6652\tLR: 0.000010\n",
      "Training Epoch: 4 [37584/45000]\tLoss: 3.6187\tLR: 0.000010\n",
      "Training Epoch: 4 [37600/45000]\tLoss: 3.7537\tLR: 0.000010\n",
      "Training Epoch: 4 [37616/45000]\tLoss: 3.6770\tLR: 0.000010\n",
      "Training Epoch: 4 [37632/45000]\tLoss: 3.7136\tLR: 0.000010\n",
      "Training Epoch: 4 [37648/45000]\tLoss: 3.7742\tLR: 0.000010\n",
      "Training Epoch: 4 [37664/45000]\tLoss: 3.7080\tLR: 0.000010\n",
      "Training Epoch: 4 [37680/45000]\tLoss: 3.6573\tLR: 0.000010\n",
      "Training Epoch: 4 [37696/45000]\tLoss: 3.7388\tLR: 0.000010\n",
      "Training Epoch: 4 [37712/45000]\tLoss: 3.6724\tLR: 0.000010\n",
      "Training Epoch: 4 [37728/45000]\tLoss: 3.6440\tLR: 0.000010\n",
      "Training Epoch: 4 [37744/45000]\tLoss: 3.6518\tLR: 0.000010\n",
      "Training Epoch: 4 [37760/45000]\tLoss: 3.6842\tLR: 0.000010\n",
      "Training Epoch: 4 [37776/45000]\tLoss: 3.6333\tLR: 0.000010\n",
      "Training Epoch: 4 [37792/45000]\tLoss: 3.7446\tLR: 0.000010\n",
      "Training Epoch: 4 [37808/45000]\tLoss: 3.5930\tLR: 0.000010\n",
      "Training Epoch: 4 [37824/45000]\tLoss: 3.7081\tLR: 0.000010\n",
      "Training Epoch: 4 [37840/45000]\tLoss: 3.6696\tLR: 0.000010\n",
      "Training Epoch: 4 [37856/45000]\tLoss: 3.7701\tLR: 0.000010\n",
      "Training Epoch: 4 [37872/45000]\tLoss: 3.6792\tLR: 0.000010\n",
      "Training Epoch: 4 [37888/45000]\tLoss: 3.7000\tLR: 0.000010\n",
      "Training Epoch: 4 [37904/45000]\tLoss: 3.6534\tLR: 0.000010\n",
      "Training Epoch: 4 [37920/45000]\tLoss: 3.7026\tLR: 0.000010\n",
      "Training Epoch: 4 [37936/45000]\tLoss: 3.5745\tLR: 0.000010\n",
      "Training Epoch: 4 [37952/45000]\tLoss: 3.7388\tLR: 0.000010\n",
      "Training Epoch: 4 [37968/45000]\tLoss: 3.8143\tLR: 0.000010\n",
      "Training Epoch: 4 [37984/45000]\tLoss: 3.6622\tLR: 0.000010\n",
      "Training Epoch: 4 [38000/45000]\tLoss: 3.7368\tLR: 0.000010\n",
      "Training Epoch: 4 [38016/45000]\tLoss: 3.5874\tLR: 0.000010\n",
      "Training Epoch: 4 [38032/45000]\tLoss: 3.6950\tLR: 0.000010\n",
      "Training Epoch: 4 [38048/45000]\tLoss: 3.7353\tLR: 0.000010\n",
      "Training Epoch: 4 [38064/45000]\tLoss: 3.7229\tLR: 0.000010\n",
      "Training Epoch: 4 [38080/45000]\tLoss: 3.6555\tLR: 0.000010\n",
      "Training Epoch: 4 [38096/45000]\tLoss: 3.6744\tLR: 0.000010\n",
      "Training Epoch: 4 [38112/45000]\tLoss: 3.7019\tLR: 0.000010\n",
      "Training Epoch: 4 [38128/45000]\tLoss: 3.7512\tLR: 0.000010\n",
      "Training Epoch: 4 [38144/45000]\tLoss: 3.8388\tLR: 0.000010\n",
      "Training Epoch: 4 [38160/45000]\tLoss: 3.6957\tLR: 0.000010\n",
      "Training Epoch: 4 [38176/45000]\tLoss: 3.7589\tLR: 0.000010\n",
      "Training Epoch: 4 [38192/45000]\tLoss: 3.7670\tLR: 0.000010\n",
      "Training Epoch: 4 [38208/45000]\tLoss: 3.7524\tLR: 0.000010\n",
      "Training Epoch: 4 [38224/45000]\tLoss: 3.7896\tLR: 0.000010\n",
      "Training Epoch: 4 [38240/45000]\tLoss: 3.7476\tLR: 0.000010\n",
      "Training Epoch: 4 [38256/45000]\tLoss: 3.8452\tLR: 0.000010\n",
      "Training Epoch: 4 [38272/45000]\tLoss: 3.7050\tLR: 0.000010\n",
      "Training Epoch: 4 [38288/45000]\tLoss: 3.7576\tLR: 0.000010\n",
      "Training Epoch: 4 [38304/45000]\tLoss: 3.6233\tLR: 0.000010\n",
      "Training Epoch: 4 [38320/45000]\tLoss: 3.6167\tLR: 0.000010\n",
      "Training Epoch: 4 [38336/45000]\tLoss: 3.7274\tLR: 0.000010\n",
      "Training Epoch: 4 [38352/45000]\tLoss: 3.6468\tLR: 0.000010\n",
      "Training Epoch: 4 [38368/45000]\tLoss: 3.7448\tLR: 0.000010\n",
      "Training Epoch: 4 [38384/45000]\tLoss: 3.7398\tLR: 0.000010\n",
      "Training Epoch: 4 [38400/45000]\tLoss: 3.7456\tLR: 0.000010\n",
      "Training Epoch: 4 [38416/45000]\tLoss: 3.5869\tLR: 0.000010\n",
      "Training Epoch: 4 [38432/45000]\tLoss: 3.7010\tLR: 0.000010\n",
      "Training Epoch: 4 [38448/45000]\tLoss: 3.6859\tLR: 0.000010\n",
      "Training Epoch: 4 [38464/45000]\tLoss: 3.6512\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [38480/45000]\tLoss: 3.8270\tLR: 0.000010\n",
      "Training Epoch: 4 [38496/45000]\tLoss: 3.7462\tLR: 0.000010\n",
      "Training Epoch: 4 [38512/45000]\tLoss: 3.7228\tLR: 0.000010\n",
      "Training Epoch: 4 [38528/45000]\tLoss: 3.7920\tLR: 0.000010\n",
      "Training Epoch: 4 [38544/45000]\tLoss: 3.6640\tLR: 0.000010\n",
      "Training Epoch: 4 [38560/45000]\tLoss: 3.7044\tLR: 0.000010\n",
      "Training Epoch: 4 [38576/45000]\tLoss: 3.7340\tLR: 0.000010\n",
      "Training Epoch: 4 [38592/45000]\tLoss: 3.7134\tLR: 0.000010\n",
      "Training Epoch: 4 [38608/45000]\tLoss: 3.6850\tLR: 0.000010\n",
      "Training Epoch: 4 [38624/45000]\tLoss: 3.7479\tLR: 0.000010\n",
      "Training Epoch: 4 [38640/45000]\tLoss: 3.7362\tLR: 0.000010\n",
      "Training Epoch: 4 [38656/45000]\tLoss: 3.7486\tLR: 0.000010\n",
      "Training Epoch: 4 [38672/45000]\tLoss: 3.7251\tLR: 0.000010\n",
      "Training Epoch: 4 [38688/45000]\tLoss: 3.7126\tLR: 0.000010\n",
      "Training Epoch: 4 [38704/45000]\tLoss: 3.7124\tLR: 0.000010\n",
      "Training Epoch: 4 [38720/45000]\tLoss: 3.7534\tLR: 0.000010\n",
      "Training Epoch: 4 [38736/45000]\tLoss: 3.7156\tLR: 0.000010\n",
      "Training Epoch: 4 [38752/45000]\tLoss: 3.7434\tLR: 0.000010\n",
      "Training Epoch: 4 [38768/45000]\tLoss: 3.6661\tLR: 0.000010\n",
      "Training Epoch: 4 [38784/45000]\tLoss: 3.7260\tLR: 0.000010\n",
      "Training Epoch: 4 [38800/45000]\tLoss: 3.6858\tLR: 0.000010\n",
      "Training Epoch: 4 [38816/45000]\tLoss: 3.7140\tLR: 0.000010\n",
      "Training Epoch: 4 [38832/45000]\tLoss: 3.5706\tLR: 0.000010\n",
      "Training Epoch: 4 [38848/45000]\tLoss: 3.7080\tLR: 0.000010\n",
      "Training Epoch: 4 [38864/45000]\tLoss: 3.7304\tLR: 0.000010\n",
      "Training Epoch: 4 [38880/45000]\tLoss: 3.7182\tLR: 0.000010\n",
      "Training Epoch: 4 [38896/45000]\tLoss: 3.6711\tLR: 0.000010\n",
      "Training Epoch: 4 [38912/45000]\tLoss: 3.6692\tLR: 0.000010\n",
      "Training Epoch: 4 [38928/45000]\tLoss: 3.6786\tLR: 0.000010\n",
      "Training Epoch: 4 [38944/45000]\tLoss: 3.7492\tLR: 0.000010\n",
      "Training Epoch: 4 [38960/45000]\tLoss: 3.8303\tLR: 0.000010\n",
      "Training Epoch: 4 [38976/45000]\tLoss: 3.7318\tLR: 0.000010\n",
      "Training Epoch: 4 [38992/45000]\tLoss: 3.7865\tLR: 0.000010\n",
      "Training Epoch: 4 [39008/45000]\tLoss: 3.5855\tLR: 0.000010\n",
      "Training Epoch: 4 [39024/45000]\tLoss: 3.5948\tLR: 0.000010\n",
      "Training Epoch: 4 [39040/45000]\tLoss: 3.6569\tLR: 0.000010\n",
      "Training Epoch: 4 [39056/45000]\tLoss: 3.6779\tLR: 0.000010\n",
      "Training Epoch: 4 [39072/45000]\tLoss: 3.6141\tLR: 0.000010\n",
      "Training Epoch: 4 [39088/45000]\tLoss: 3.7012\tLR: 0.000010\n",
      "Training Epoch: 4 [39104/45000]\tLoss: 3.6303\tLR: 0.000010\n",
      "Training Epoch: 4 [39120/45000]\tLoss: 3.7249\tLR: 0.000010\n",
      "Training Epoch: 4 [39136/45000]\tLoss: 3.7253\tLR: 0.000010\n",
      "Training Epoch: 4 [39152/45000]\tLoss: 3.7012\tLR: 0.000010\n",
      "Training Epoch: 4 [39168/45000]\tLoss: 3.5972\tLR: 0.000010\n",
      "Training Epoch: 4 [39184/45000]\tLoss: 3.7646\tLR: 0.000010\n",
      "Training Epoch: 4 [39200/45000]\tLoss: 3.5397\tLR: 0.000010\n",
      "Training Epoch: 4 [39216/45000]\tLoss: 3.7113\tLR: 0.000010\n",
      "Training Epoch: 4 [39232/45000]\tLoss: 3.7570\tLR: 0.000010\n",
      "Training Epoch: 4 [39248/45000]\tLoss: 3.6116\tLR: 0.000010\n",
      "Training Epoch: 4 [39264/45000]\tLoss: 3.5839\tLR: 0.000010\n",
      "Training Epoch: 4 [39280/45000]\tLoss: 3.6273\tLR: 0.000010\n",
      "Training Epoch: 4 [39296/45000]\tLoss: 3.6597\tLR: 0.000010\n",
      "Training Epoch: 4 [39312/45000]\tLoss: 3.6643\tLR: 0.000010\n",
      "Training Epoch: 4 [39328/45000]\tLoss: 3.7440\tLR: 0.000010\n",
      "Training Epoch: 4 [39344/45000]\tLoss: 3.6127\tLR: 0.000010\n",
      "Training Epoch: 4 [39360/45000]\tLoss: 3.8513\tLR: 0.000010\n",
      "Training Epoch: 4 [39376/45000]\tLoss: 3.7022\tLR: 0.000010\n",
      "Training Epoch: 4 [39392/45000]\tLoss: 3.7366\tLR: 0.000010\n",
      "Training Epoch: 4 [39408/45000]\tLoss: 3.7401\tLR: 0.000010\n",
      "Training Epoch: 4 [39424/45000]\tLoss: 3.8228\tLR: 0.000010\n",
      "Training Epoch: 4 [39440/45000]\tLoss: 3.7694\tLR: 0.000010\n",
      "Training Epoch: 4 [39456/45000]\tLoss: 3.7469\tLR: 0.000010\n",
      "Training Epoch: 4 [39472/45000]\tLoss: 3.7520\tLR: 0.000010\n",
      "Training Epoch: 4 [39488/45000]\tLoss: 3.7749\tLR: 0.000010\n",
      "Training Epoch: 4 [39504/45000]\tLoss: 3.6768\tLR: 0.000010\n",
      "Training Epoch: 4 [39520/45000]\tLoss: 3.5840\tLR: 0.000010\n",
      "Training Epoch: 4 [39536/45000]\tLoss: 3.7895\tLR: 0.000010\n",
      "Training Epoch: 4 [39552/45000]\tLoss: 3.7734\tLR: 0.000010\n",
      "Training Epoch: 4 [39568/45000]\tLoss: 3.6958\tLR: 0.000010\n",
      "Training Epoch: 4 [39584/45000]\tLoss: 3.7013\tLR: 0.000010\n",
      "Training Epoch: 4 [39600/45000]\tLoss: 3.6836\tLR: 0.000010\n",
      "Training Epoch: 4 [39616/45000]\tLoss: 3.5549\tLR: 0.000010\n",
      "Training Epoch: 4 [39632/45000]\tLoss: 3.6853\tLR: 0.000010\n",
      "Training Epoch: 4 [39648/45000]\tLoss: 3.8047\tLR: 0.000010\n",
      "Training Epoch: 4 [39664/45000]\tLoss: 3.5929\tLR: 0.000010\n",
      "Training Epoch: 4 [39680/45000]\tLoss: 3.6884\tLR: 0.000010\n",
      "Training Epoch: 4 [39696/45000]\tLoss: 3.7352\tLR: 0.000010\n",
      "Training Epoch: 4 [39712/45000]\tLoss: 3.7396\tLR: 0.000010\n",
      "Training Epoch: 4 [39728/45000]\tLoss: 3.6794\tLR: 0.000010\n",
      "Training Epoch: 4 [39744/45000]\tLoss: 3.6767\tLR: 0.000010\n",
      "Training Epoch: 4 [39760/45000]\tLoss: 3.7389\tLR: 0.000010\n",
      "Training Epoch: 4 [39776/45000]\tLoss: 3.5671\tLR: 0.000010\n",
      "Training Epoch: 4 [39792/45000]\tLoss: 3.7108\tLR: 0.000010\n",
      "Training Epoch: 4 [39808/45000]\tLoss: 3.7294\tLR: 0.000010\n",
      "Training Epoch: 4 [39824/45000]\tLoss: 3.5868\tLR: 0.000010\n",
      "Training Epoch: 4 [39840/45000]\tLoss: 3.7122\tLR: 0.000010\n",
      "Training Epoch: 4 [39856/45000]\tLoss: 3.5368\tLR: 0.000010\n",
      "Training Epoch: 4 [39872/45000]\tLoss: 3.7352\tLR: 0.000010\n",
      "Training Epoch: 4 [39888/45000]\tLoss: 3.7478\tLR: 0.000010\n",
      "Training Epoch: 4 [39904/45000]\tLoss: 3.7525\tLR: 0.000010\n",
      "Training Epoch: 4 [39920/45000]\tLoss: 3.6969\tLR: 0.000010\n",
      "Training Epoch: 4 [39936/45000]\tLoss: 3.7173\tLR: 0.000010\n",
      "Training Epoch: 4 [39952/45000]\tLoss: 3.6061\tLR: 0.000010\n",
      "Training Epoch: 4 [39968/45000]\tLoss: 3.7715\tLR: 0.000010\n",
      "Training Epoch: 4 [39984/45000]\tLoss: 3.7067\tLR: 0.000010\n",
      "Training Epoch: 4 [40000/45000]\tLoss: 3.7533\tLR: 0.000010\n",
      "Training Epoch: 4 [40016/45000]\tLoss: 3.8031\tLR: 0.000010\n",
      "Training Epoch: 4 [40032/45000]\tLoss: 3.7725\tLR: 0.000010\n",
      "Training Epoch: 4 [40048/45000]\tLoss: 3.7170\tLR: 0.000010\n",
      "Training Epoch: 4 [40064/45000]\tLoss: 3.6838\tLR: 0.000010\n",
      "Training Epoch: 4 [40080/45000]\tLoss: 3.7054\tLR: 0.000010\n",
      "Training Epoch: 4 [40096/45000]\tLoss: 3.7057\tLR: 0.000010\n",
      "Training Epoch: 4 [40112/45000]\tLoss: 3.6405\tLR: 0.000010\n",
      "Training Epoch: 4 [40128/45000]\tLoss: 3.7874\tLR: 0.000010\n",
      "Training Epoch: 4 [40144/45000]\tLoss: 3.6468\tLR: 0.000010\n",
      "Training Epoch: 4 [40160/45000]\tLoss: 3.7205\tLR: 0.000010\n",
      "Training Epoch: 4 [40176/45000]\tLoss: 3.6230\tLR: 0.000010\n",
      "Training Epoch: 4 [40192/45000]\tLoss: 3.7842\tLR: 0.000010\n",
      "Training Epoch: 4 [40208/45000]\tLoss: 3.8464\tLR: 0.000010\n",
      "Training Epoch: 4 [40224/45000]\tLoss: 3.6753\tLR: 0.000010\n",
      "Training Epoch: 4 [40240/45000]\tLoss: 3.6743\tLR: 0.000010\n",
      "Training Epoch: 4 [40256/45000]\tLoss: 3.7127\tLR: 0.000010\n",
      "Training Epoch: 4 [40272/45000]\tLoss: 3.7312\tLR: 0.000010\n",
      "Training Epoch: 4 [40288/45000]\tLoss: 3.7468\tLR: 0.000010\n",
      "Training Epoch: 4 [40304/45000]\tLoss: 3.7695\tLR: 0.000010\n",
      "Training Epoch: 4 [40320/45000]\tLoss: 3.7106\tLR: 0.000010\n",
      "Training Epoch: 4 [40336/45000]\tLoss: 3.6028\tLR: 0.000010\n",
      "Training Epoch: 4 [40352/45000]\tLoss: 3.6422\tLR: 0.000010\n",
      "Training Epoch: 4 [40368/45000]\tLoss: 3.7337\tLR: 0.000010\n",
      "Training Epoch: 4 [40384/45000]\tLoss: 3.7022\tLR: 0.000010\n",
      "Training Epoch: 4 [40400/45000]\tLoss: 3.6966\tLR: 0.000010\n",
      "Training Epoch: 4 [40416/45000]\tLoss: 3.6296\tLR: 0.000010\n",
      "Training Epoch: 4 [40432/45000]\tLoss: 3.7863\tLR: 0.000010\n",
      "Training Epoch: 4 [40448/45000]\tLoss: 3.6748\tLR: 0.000010\n",
      "Training Epoch: 4 [40464/45000]\tLoss: 3.7179\tLR: 0.000010\n",
      "Training Epoch: 4 [40480/45000]\tLoss: 3.7752\tLR: 0.000010\n",
      "Training Epoch: 4 [40496/45000]\tLoss: 3.5840\tLR: 0.000010\n",
      "Training Epoch: 4 [40512/45000]\tLoss: 3.6717\tLR: 0.000010\n",
      "Training Epoch: 4 [40528/45000]\tLoss: 3.7756\tLR: 0.000010\n",
      "Training Epoch: 4 [40544/45000]\tLoss: 3.6906\tLR: 0.000010\n",
      "Training Epoch: 4 [40560/45000]\tLoss: 3.8060\tLR: 0.000010\n",
      "Training Epoch: 4 [40576/45000]\tLoss: 3.7631\tLR: 0.000010\n",
      "Training Epoch: 4 [40592/45000]\tLoss: 3.7100\tLR: 0.000010\n",
      "Training Epoch: 4 [40608/45000]\tLoss: 3.7230\tLR: 0.000010\n",
      "Training Epoch: 4 [40624/45000]\tLoss: 3.6344\tLR: 0.000010\n",
      "Training Epoch: 4 [40640/45000]\tLoss: 3.6732\tLR: 0.000010\n",
      "Training Epoch: 4 [40656/45000]\tLoss: 3.6755\tLR: 0.000010\n",
      "Training Epoch: 4 [40672/45000]\tLoss: 3.7114\tLR: 0.000010\n",
      "Training Epoch: 4 [40688/45000]\tLoss: 3.8462\tLR: 0.000010\n",
      "Training Epoch: 4 [40704/45000]\tLoss: 3.8600\tLR: 0.000010\n",
      "Training Epoch: 4 [40720/45000]\tLoss: 3.6632\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [40736/45000]\tLoss: 3.6564\tLR: 0.000010\n",
      "Training Epoch: 4 [40752/45000]\tLoss: 3.6705\tLR: 0.000010\n",
      "Training Epoch: 4 [40768/45000]\tLoss: 3.7975\tLR: 0.000010\n",
      "Training Epoch: 4 [40784/45000]\tLoss: 3.6675\tLR: 0.000010\n",
      "Training Epoch: 4 [40800/45000]\tLoss: 3.6601\tLR: 0.000010\n",
      "Training Epoch: 4 [40816/45000]\tLoss: 3.7111\tLR: 0.000010\n",
      "Training Epoch: 4 [40832/45000]\tLoss: 3.8834\tLR: 0.000010\n",
      "Training Epoch: 4 [40848/45000]\tLoss: 3.7706\tLR: 0.000010\n",
      "Training Epoch: 4 [40864/45000]\tLoss: 3.6753\tLR: 0.000010\n",
      "Training Epoch: 4 [40880/45000]\tLoss: 3.7706\tLR: 0.000010\n",
      "Training Epoch: 4 [40896/45000]\tLoss: 3.6989\tLR: 0.000010\n",
      "Training Epoch: 4 [40912/45000]\tLoss: 3.6005\tLR: 0.000010\n",
      "Training Epoch: 4 [40928/45000]\tLoss: 3.7444\tLR: 0.000010\n",
      "Training Epoch: 4 [40944/45000]\tLoss: 3.8306\tLR: 0.000010\n",
      "Training Epoch: 4 [40960/45000]\tLoss: 3.7629\tLR: 0.000010\n",
      "Training Epoch: 4 [40976/45000]\tLoss: 3.7366\tLR: 0.000010\n",
      "Training Epoch: 4 [40992/45000]\tLoss: 3.7165\tLR: 0.000010\n",
      "Training Epoch: 4 [41008/45000]\tLoss: 3.7479\tLR: 0.000010\n",
      "Training Epoch: 4 [41024/45000]\tLoss: 3.6950\tLR: 0.000010\n",
      "Training Epoch: 4 [41040/45000]\tLoss: 3.5922\tLR: 0.000010\n",
      "Training Epoch: 4 [41056/45000]\tLoss: 3.6936\tLR: 0.000010\n",
      "Training Epoch: 4 [41072/45000]\tLoss: 3.6389\tLR: 0.000010\n",
      "Training Epoch: 4 [41088/45000]\tLoss: 3.6837\tLR: 0.000010\n",
      "Training Epoch: 4 [41104/45000]\tLoss: 3.6729\tLR: 0.000010\n",
      "Training Epoch: 4 [41120/45000]\tLoss: 3.7066\tLR: 0.000010\n",
      "Training Epoch: 4 [41136/45000]\tLoss: 3.5959\tLR: 0.000010\n",
      "Training Epoch: 4 [41152/45000]\tLoss: 3.7683\tLR: 0.000010\n",
      "Training Epoch: 4 [41168/45000]\tLoss: 3.6808\tLR: 0.000010\n",
      "Training Epoch: 4 [41184/45000]\tLoss: 3.6485\tLR: 0.000010\n",
      "Training Epoch: 4 [41200/45000]\tLoss: 3.5936\tLR: 0.000010\n",
      "Training Epoch: 4 [41216/45000]\tLoss: 3.7469\tLR: 0.000010\n",
      "Training Epoch: 4 [41232/45000]\tLoss: 3.8074\tLR: 0.000010\n",
      "Training Epoch: 4 [41248/45000]\tLoss: 3.6912\tLR: 0.000010\n",
      "Training Epoch: 4 [41264/45000]\tLoss: 3.6673\tLR: 0.000010\n",
      "Training Epoch: 4 [41280/45000]\tLoss: 3.6292\tLR: 0.000010\n",
      "Training Epoch: 4 [41296/45000]\tLoss: 3.7034\tLR: 0.000010\n",
      "Training Epoch: 4 [41312/45000]\tLoss: 3.6416\tLR: 0.000010\n",
      "Training Epoch: 4 [41328/45000]\tLoss: 3.7110\tLR: 0.000010\n",
      "Training Epoch: 4 [41344/45000]\tLoss: 3.6631\tLR: 0.000010\n",
      "Training Epoch: 4 [41360/45000]\tLoss: 3.5756\tLR: 0.000010\n",
      "Training Epoch: 4 [41376/45000]\tLoss: 3.7432\tLR: 0.000010\n",
      "Training Epoch: 4 [41392/45000]\tLoss: 3.7601\tLR: 0.000010\n",
      "Training Epoch: 4 [41408/45000]\tLoss: 3.6903\tLR: 0.000010\n",
      "Training Epoch: 4 [41424/45000]\tLoss: 3.6772\tLR: 0.000010\n",
      "Training Epoch: 4 [41440/45000]\tLoss: 3.6900\tLR: 0.000010\n",
      "Training Epoch: 4 [41456/45000]\tLoss: 3.6915\tLR: 0.000010\n",
      "Training Epoch: 4 [41472/45000]\tLoss: 3.7338\tLR: 0.000010\n",
      "Training Epoch: 4 [41488/45000]\tLoss: 3.7001\tLR: 0.000010\n",
      "Training Epoch: 4 [41504/45000]\tLoss: 3.6758\tLR: 0.000010\n",
      "Training Epoch: 4 [41520/45000]\tLoss: 3.5544\tLR: 0.000010\n",
      "Training Epoch: 4 [41536/45000]\tLoss: 3.6657\tLR: 0.000010\n",
      "Training Epoch: 4 [41552/45000]\tLoss: 3.5486\tLR: 0.000010\n",
      "Training Epoch: 4 [41568/45000]\tLoss: 3.6234\tLR: 0.000010\n",
      "Training Epoch: 4 [41584/45000]\tLoss: 3.7085\tLR: 0.000010\n",
      "Training Epoch: 4 [41600/45000]\tLoss: 3.7355\tLR: 0.000010\n",
      "Training Epoch: 4 [41616/45000]\tLoss: 3.6373\tLR: 0.000010\n",
      "Training Epoch: 4 [41632/45000]\tLoss: 3.7891\tLR: 0.000010\n",
      "Training Epoch: 4 [41648/45000]\tLoss: 3.6798\tLR: 0.000010\n",
      "Training Epoch: 4 [41664/45000]\tLoss: 3.7039\tLR: 0.000010\n",
      "Training Epoch: 4 [41680/45000]\tLoss: 3.6629\tLR: 0.000010\n",
      "Training Epoch: 4 [41696/45000]\tLoss: 3.6918\tLR: 0.000010\n",
      "Training Epoch: 4 [41712/45000]\tLoss: 3.7368\tLR: 0.000010\n",
      "Training Epoch: 4 [41728/45000]\tLoss: 3.7659\tLR: 0.000010\n",
      "Training Epoch: 4 [41744/45000]\tLoss: 3.7868\tLR: 0.000010\n",
      "Training Epoch: 4 [41760/45000]\tLoss: 3.7004\tLR: 0.000010\n",
      "Training Epoch: 4 [41776/45000]\tLoss: 3.7673\tLR: 0.000010\n",
      "Training Epoch: 4 [41792/45000]\tLoss: 3.7951\tLR: 0.000010\n",
      "Training Epoch: 4 [41808/45000]\tLoss: 3.6867\tLR: 0.000010\n",
      "Training Epoch: 4 [41824/45000]\tLoss: 3.6709\tLR: 0.000010\n",
      "Training Epoch: 4 [41840/45000]\tLoss: 3.6599\tLR: 0.000010\n",
      "Training Epoch: 4 [41856/45000]\tLoss: 3.7385\tLR: 0.000010\n",
      "Training Epoch: 4 [41872/45000]\tLoss: 3.6781\tLR: 0.000010\n",
      "Training Epoch: 4 [41888/45000]\tLoss: 3.6803\tLR: 0.000010\n",
      "Training Epoch: 4 [41904/45000]\tLoss: 3.6016\tLR: 0.000010\n",
      "Training Epoch: 4 [41920/45000]\tLoss: 3.8185\tLR: 0.000010\n",
      "Training Epoch: 4 [41936/45000]\tLoss: 3.7165\tLR: 0.000010\n",
      "Training Epoch: 4 [41952/45000]\tLoss: 3.5861\tLR: 0.000010\n",
      "Training Epoch: 4 [41968/45000]\tLoss: 3.6832\tLR: 0.000010\n",
      "Training Epoch: 4 [41984/45000]\tLoss: 3.6175\tLR: 0.000010\n",
      "Training Epoch: 4 [42000/45000]\tLoss: 3.5796\tLR: 0.000010\n",
      "Training Epoch: 4 [42016/45000]\tLoss: 3.6366\tLR: 0.000010\n",
      "Training Epoch: 4 [42032/45000]\tLoss: 3.7573\tLR: 0.000010\n",
      "Training Epoch: 4 [42048/45000]\tLoss: 3.7648\tLR: 0.000010\n",
      "Training Epoch: 4 [42064/45000]\tLoss: 3.6762\tLR: 0.000010\n",
      "Training Epoch: 4 [42080/45000]\tLoss: 3.7085\tLR: 0.000010\n",
      "Training Epoch: 4 [42096/45000]\tLoss: 3.6725\tLR: 0.000010\n",
      "Training Epoch: 4 [42112/45000]\tLoss: 3.6797\tLR: 0.000010\n",
      "Training Epoch: 4 [42128/45000]\tLoss: 3.7826\tLR: 0.000010\n",
      "Training Epoch: 4 [42144/45000]\tLoss: 3.5982\tLR: 0.000010\n",
      "Training Epoch: 4 [42160/45000]\tLoss: 3.7486\tLR: 0.000010\n",
      "Training Epoch: 4 [42176/45000]\tLoss: 3.7468\tLR: 0.000010\n",
      "Training Epoch: 4 [42192/45000]\tLoss: 3.7664\tLR: 0.000010\n",
      "Training Epoch: 4 [42208/45000]\tLoss: 3.6954\tLR: 0.000010\n",
      "Training Epoch: 4 [42224/45000]\tLoss: 3.7220\tLR: 0.000010\n",
      "Training Epoch: 4 [42240/45000]\tLoss: 3.7608\tLR: 0.000010\n",
      "Training Epoch: 4 [42256/45000]\tLoss: 3.6154\tLR: 0.000010\n",
      "Training Epoch: 4 [42272/45000]\tLoss: 3.6915\tLR: 0.000010\n",
      "Training Epoch: 4 [42288/45000]\tLoss: 3.6688\tLR: 0.000010\n",
      "Training Epoch: 4 [42304/45000]\tLoss: 3.5640\tLR: 0.000010\n",
      "Training Epoch: 4 [42320/45000]\tLoss: 3.7889\tLR: 0.000010\n",
      "Training Epoch: 4 [42336/45000]\tLoss: 3.6783\tLR: 0.000010\n",
      "Training Epoch: 4 [42352/45000]\tLoss: 3.6590\tLR: 0.000010\n",
      "Training Epoch: 4 [42368/45000]\tLoss: 3.8204\tLR: 0.000010\n",
      "Training Epoch: 4 [42384/45000]\tLoss: 3.6860\tLR: 0.000010\n",
      "Training Epoch: 4 [42400/45000]\tLoss: 3.6545\tLR: 0.000010\n",
      "Training Epoch: 4 [42416/45000]\tLoss: 3.6726\tLR: 0.000010\n",
      "Training Epoch: 4 [42432/45000]\tLoss: 3.7546\tLR: 0.000010\n",
      "Training Epoch: 4 [42448/45000]\tLoss: 3.7493\tLR: 0.000010\n",
      "Training Epoch: 4 [42464/45000]\tLoss: 3.7807\tLR: 0.000010\n",
      "Training Epoch: 4 [42480/45000]\tLoss: 3.6347\tLR: 0.000010\n",
      "Training Epoch: 4 [42496/45000]\tLoss: 3.7157\tLR: 0.000010\n",
      "Training Epoch: 4 [42512/45000]\tLoss: 3.6158\tLR: 0.000010\n",
      "Training Epoch: 4 [42528/45000]\tLoss: 3.8813\tLR: 0.000010\n",
      "Training Epoch: 4 [42544/45000]\tLoss: 3.8394\tLR: 0.000010\n",
      "Training Epoch: 4 [42560/45000]\tLoss: 3.7100\tLR: 0.000010\n",
      "Training Epoch: 4 [42576/45000]\tLoss: 3.6608\tLR: 0.000010\n",
      "Training Epoch: 4 [42592/45000]\tLoss: 3.6738\tLR: 0.000010\n",
      "Training Epoch: 4 [42608/45000]\tLoss: 3.7042\tLR: 0.000010\n",
      "Training Epoch: 4 [42624/45000]\tLoss: 3.6983\tLR: 0.000010\n",
      "Training Epoch: 4 [42640/45000]\tLoss: 3.6451\tLR: 0.000010\n",
      "Training Epoch: 4 [42656/45000]\tLoss: 3.6620\tLR: 0.000010\n",
      "Training Epoch: 4 [42672/45000]\tLoss: 3.7627\tLR: 0.000010\n",
      "Training Epoch: 4 [42688/45000]\tLoss: 3.6157\tLR: 0.000010\n",
      "Training Epoch: 4 [42704/45000]\tLoss: 3.6576\tLR: 0.000010\n",
      "Training Epoch: 4 [42720/45000]\tLoss: 3.7667\tLR: 0.000010\n",
      "Training Epoch: 4 [42736/45000]\tLoss: 3.7294\tLR: 0.000010\n",
      "Training Epoch: 4 [42752/45000]\tLoss: 3.6533\tLR: 0.000010\n",
      "Training Epoch: 4 [42768/45000]\tLoss: 3.7906\tLR: 0.000010\n",
      "Training Epoch: 4 [42784/45000]\tLoss: 3.7391\tLR: 0.000010\n",
      "Training Epoch: 4 [42800/45000]\tLoss: 3.6228\tLR: 0.000010\n",
      "Training Epoch: 4 [42816/45000]\tLoss: 3.6241\tLR: 0.000010\n",
      "Training Epoch: 4 [42832/45000]\tLoss: 3.6253\tLR: 0.000010\n",
      "Training Epoch: 4 [42848/45000]\tLoss: 3.7661\tLR: 0.000010\n",
      "Training Epoch: 4 [42864/45000]\tLoss: 3.7355\tLR: 0.000010\n",
      "Training Epoch: 4 [42880/45000]\tLoss: 3.7484\tLR: 0.000010\n",
      "Training Epoch: 4 [42896/45000]\tLoss: 3.7519\tLR: 0.000010\n",
      "Training Epoch: 4 [42912/45000]\tLoss: 3.7702\tLR: 0.000010\n",
      "Training Epoch: 4 [42928/45000]\tLoss: 3.6766\tLR: 0.000010\n",
      "Training Epoch: 4 [42944/45000]\tLoss: 3.6446\tLR: 0.000010\n",
      "Training Epoch: 4 [42960/45000]\tLoss: 3.6460\tLR: 0.000010\n",
      "Training Epoch: 4 [42976/45000]\tLoss: 3.7779\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [42992/45000]\tLoss: 3.6454\tLR: 0.000010\n",
      "Training Epoch: 4 [43008/45000]\tLoss: 3.7762\tLR: 0.000010\n",
      "Training Epoch: 4 [43024/45000]\tLoss: 3.6431\tLR: 0.000010\n",
      "Training Epoch: 4 [43040/45000]\tLoss: 3.7137\tLR: 0.000010\n",
      "Training Epoch: 4 [43056/45000]\tLoss: 3.7792\tLR: 0.000010\n",
      "Training Epoch: 4 [43072/45000]\tLoss: 3.6754\tLR: 0.000010\n",
      "Training Epoch: 4 [43088/45000]\tLoss: 3.5831\tLR: 0.000010\n",
      "Training Epoch: 4 [43104/45000]\tLoss: 3.6990\tLR: 0.000010\n",
      "Training Epoch: 4 [43120/45000]\tLoss: 3.7390\tLR: 0.000010\n",
      "Training Epoch: 4 [43136/45000]\tLoss: 3.7079\tLR: 0.000010\n",
      "Training Epoch: 4 [43152/45000]\tLoss: 3.6866\tLR: 0.000010\n",
      "Training Epoch: 4 [43168/45000]\tLoss: 3.6740\tLR: 0.000010\n",
      "Training Epoch: 4 [43184/45000]\tLoss: 3.5913\tLR: 0.000010\n",
      "Training Epoch: 4 [43200/45000]\tLoss: 3.7268\tLR: 0.000010\n",
      "Training Epoch: 4 [43216/45000]\tLoss: 3.7365\tLR: 0.000010\n",
      "Training Epoch: 4 [43232/45000]\tLoss: 3.6354\tLR: 0.000010\n",
      "Training Epoch: 4 [43248/45000]\tLoss: 3.7555\tLR: 0.000010\n",
      "Training Epoch: 4 [43264/45000]\tLoss: 3.6837\tLR: 0.000010\n",
      "Training Epoch: 4 [43280/45000]\tLoss: 3.7012\tLR: 0.000010\n",
      "Training Epoch: 4 [43296/45000]\tLoss: 3.6545\tLR: 0.000010\n",
      "Training Epoch: 4 [43312/45000]\tLoss: 3.5959\tLR: 0.000010\n",
      "Training Epoch: 4 [43328/45000]\tLoss: 3.6716\tLR: 0.000010\n",
      "Training Epoch: 4 [43344/45000]\tLoss: 3.7120\tLR: 0.000010\n",
      "Training Epoch: 4 [43360/45000]\tLoss: 3.6742\tLR: 0.000010\n",
      "Training Epoch: 4 [43376/45000]\tLoss: 3.7842\tLR: 0.000010\n",
      "Training Epoch: 4 [43392/45000]\tLoss: 3.6490\tLR: 0.000010\n",
      "Training Epoch: 4 [43408/45000]\tLoss: 3.8067\tLR: 0.000010\n",
      "Training Epoch: 4 [43424/45000]\tLoss: 3.7118\tLR: 0.000010\n",
      "Training Epoch: 4 [43440/45000]\tLoss: 3.6710\tLR: 0.000010\n",
      "Training Epoch: 4 [43456/45000]\tLoss: 3.6803\tLR: 0.000010\n",
      "Training Epoch: 4 [43472/45000]\tLoss: 3.6707\tLR: 0.000010\n",
      "Training Epoch: 4 [43488/45000]\tLoss: 3.7038\tLR: 0.000010\n",
      "Training Epoch: 4 [43504/45000]\tLoss: 3.6709\tLR: 0.000010\n",
      "Training Epoch: 4 [43520/45000]\tLoss: 3.6815\tLR: 0.000010\n",
      "Training Epoch: 4 [43536/45000]\tLoss: 3.7210\tLR: 0.000010\n",
      "Training Epoch: 4 [43552/45000]\tLoss: 3.6746\tLR: 0.000010\n",
      "Training Epoch: 4 [43568/45000]\tLoss: 3.5930\tLR: 0.000010\n",
      "Training Epoch: 4 [43584/45000]\tLoss: 3.6595\tLR: 0.000010\n",
      "Training Epoch: 4 [43600/45000]\tLoss: 3.7553\tLR: 0.000010\n",
      "Training Epoch: 4 [43616/45000]\tLoss: 3.7592\tLR: 0.000010\n",
      "Training Epoch: 4 [43632/45000]\tLoss: 3.6386\tLR: 0.000010\n",
      "Training Epoch: 4 [43648/45000]\tLoss: 3.7364\tLR: 0.000010\n",
      "Training Epoch: 4 [43664/45000]\tLoss: 3.7064\tLR: 0.000010\n",
      "Training Epoch: 4 [43680/45000]\tLoss: 3.7394\tLR: 0.000010\n",
      "Training Epoch: 4 [43696/45000]\tLoss: 3.6580\tLR: 0.000010\n",
      "Training Epoch: 4 [43712/45000]\tLoss: 3.8259\tLR: 0.000010\n",
      "Training Epoch: 4 [43728/45000]\tLoss: 3.7032\tLR: 0.000010\n",
      "Training Epoch: 4 [43744/45000]\tLoss: 3.8045\tLR: 0.000010\n",
      "Training Epoch: 4 [43760/45000]\tLoss: 3.7413\tLR: 0.000010\n",
      "Training Epoch: 4 [43776/45000]\tLoss: 3.7136\tLR: 0.000010\n",
      "Training Epoch: 4 [43792/45000]\tLoss: 3.6776\tLR: 0.000010\n",
      "Training Epoch: 4 [43808/45000]\tLoss: 3.7475\tLR: 0.000010\n",
      "Training Epoch: 4 [43824/45000]\tLoss: 3.7522\tLR: 0.000010\n",
      "Training Epoch: 4 [43840/45000]\tLoss: 3.6270\tLR: 0.000010\n",
      "Training Epoch: 4 [43856/45000]\tLoss: 3.7491\tLR: 0.000010\n",
      "Training Epoch: 4 [43872/45000]\tLoss: 3.6483\tLR: 0.000010\n",
      "Training Epoch: 4 [43888/45000]\tLoss: 3.8083\tLR: 0.000010\n",
      "Training Epoch: 4 [43904/45000]\tLoss: 3.6781\tLR: 0.000010\n",
      "Training Epoch: 4 [43920/45000]\tLoss: 3.5599\tLR: 0.000010\n",
      "Training Epoch: 4 [43936/45000]\tLoss: 3.5706\tLR: 0.000010\n",
      "Training Epoch: 4 [43952/45000]\tLoss: 3.7293\tLR: 0.000010\n",
      "Training Epoch: 4 [43968/45000]\tLoss: 3.6437\tLR: 0.000010\n",
      "Training Epoch: 4 [43984/45000]\tLoss: 3.7009\tLR: 0.000010\n",
      "Training Epoch: 4 [44000/45000]\tLoss: 3.7087\tLR: 0.000010\n",
      "Training Epoch: 4 [44016/45000]\tLoss: 3.6828\tLR: 0.000010\n",
      "Training Epoch: 4 [44032/45000]\tLoss: 3.7923\tLR: 0.000010\n",
      "Training Epoch: 4 [44048/45000]\tLoss: 3.7723\tLR: 0.000010\n",
      "Training Epoch: 4 [44064/45000]\tLoss: 3.6157\tLR: 0.000010\n",
      "Training Epoch: 4 [44080/45000]\tLoss: 3.7118\tLR: 0.000010\n",
      "Training Epoch: 4 [44096/45000]\tLoss: 3.7971\tLR: 0.000010\n",
      "Training Epoch: 4 [44112/45000]\tLoss: 3.5986\tLR: 0.000010\n",
      "Training Epoch: 4 [44128/45000]\tLoss: 3.7298\tLR: 0.000010\n",
      "Training Epoch: 4 [44144/45000]\tLoss: 3.5639\tLR: 0.000010\n",
      "Training Epoch: 4 [44160/45000]\tLoss: 3.7829\tLR: 0.000010\n",
      "Training Epoch: 4 [44176/45000]\tLoss: 3.6422\tLR: 0.000010\n",
      "Training Epoch: 4 [44192/45000]\tLoss: 3.6715\tLR: 0.000010\n",
      "Training Epoch: 4 [44208/45000]\tLoss: 3.7422\tLR: 0.000010\n",
      "Training Epoch: 4 [44224/45000]\tLoss: 3.7286\tLR: 0.000010\n",
      "Training Epoch: 4 [44240/45000]\tLoss: 3.6138\tLR: 0.000010\n",
      "Training Epoch: 4 [44256/45000]\tLoss: 3.7287\tLR: 0.000010\n",
      "Training Epoch: 4 [44272/45000]\tLoss: 3.6465\tLR: 0.000010\n",
      "Training Epoch: 4 [44288/45000]\tLoss: 3.7730\tLR: 0.000010\n",
      "Training Epoch: 4 [44304/45000]\tLoss: 3.7362\tLR: 0.000010\n",
      "Training Epoch: 4 [44320/45000]\tLoss: 3.7366\tLR: 0.000010\n",
      "Training Epoch: 4 [44336/45000]\tLoss: 3.6407\tLR: 0.000010\n",
      "Training Epoch: 4 [44352/45000]\tLoss: 3.7171\tLR: 0.000010\n",
      "Training Epoch: 4 [44368/45000]\tLoss: 3.6576\tLR: 0.000010\n",
      "Training Epoch: 4 [44384/45000]\tLoss: 3.6648\tLR: 0.000010\n",
      "Training Epoch: 4 [44400/45000]\tLoss: 3.7220\tLR: 0.000010\n",
      "Training Epoch: 4 [44416/45000]\tLoss: 3.6981\tLR: 0.000010\n",
      "Training Epoch: 4 [44432/45000]\tLoss: 3.6961\tLR: 0.000010\n",
      "Training Epoch: 4 [44448/45000]\tLoss: 3.7685\tLR: 0.000010\n",
      "Training Epoch: 4 [44464/45000]\tLoss: 3.7593\tLR: 0.000010\n",
      "Training Epoch: 4 [44480/45000]\tLoss: 3.7013\tLR: 0.000010\n",
      "Training Epoch: 4 [44496/45000]\tLoss: 3.6691\tLR: 0.000010\n",
      "Training Epoch: 4 [44512/45000]\tLoss: 3.7160\tLR: 0.000010\n",
      "Training Epoch: 4 [44528/45000]\tLoss: 3.6659\tLR: 0.000010\n",
      "Training Epoch: 4 [44544/45000]\tLoss: 3.6412\tLR: 0.000010\n",
      "Training Epoch: 4 [44560/45000]\tLoss: 3.8012\tLR: 0.000010\n",
      "Training Epoch: 4 [44576/45000]\tLoss: 3.7645\tLR: 0.000010\n",
      "Training Epoch: 4 [44592/45000]\tLoss: 3.6881\tLR: 0.000010\n",
      "Training Epoch: 4 [44608/45000]\tLoss: 3.7100\tLR: 0.000010\n",
      "Training Epoch: 4 [44624/45000]\tLoss: 3.7707\tLR: 0.000010\n",
      "Training Epoch: 4 [44640/45000]\tLoss: 3.6163\tLR: 0.000010\n",
      "Training Epoch: 4 [44656/45000]\tLoss: 3.5702\tLR: 0.000010\n",
      "Training Epoch: 4 [44672/45000]\tLoss: 3.7408\tLR: 0.000010\n",
      "Training Epoch: 4 [44688/45000]\tLoss: 3.5683\tLR: 0.000010\n",
      "Training Epoch: 4 [44704/45000]\tLoss: 3.8171\tLR: 0.000010\n",
      "Training Epoch: 4 [44720/45000]\tLoss: 3.7270\tLR: 0.000010\n",
      "Training Epoch: 4 [44736/45000]\tLoss: 3.7826\tLR: 0.000010\n",
      "Training Epoch: 4 [44752/45000]\tLoss: 3.6336\tLR: 0.000010\n",
      "Training Epoch: 4 [44768/45000]\tLoss: 3.7377\tLR: 0.000010\n",
      "Training Epoch: 4 [44784/45000]\tLoss: 3.6632\tLR: 0.000010\n",
      "Training Epoch: 4 [44800/45000]\tLoss: 3.5105\tLR: 0.000010\n",
      "Training Epoch: 4 [44816/45000]\tLoss: 3.6764\tLR: 0.000010\n",
      "Training Epoch: 4 [44832/45000]\tLoss: 3.6936\tLR: 0.000010\n",
      "Training Epoch: 4 [44848/45000]\tLoss: 3.6958\tLR: 0.000010\n",
      "Training Epoch: 4 [44864/45000]\tLoss: 3.6686\tLR: 0.000010\n",
      "Training Epoch: 4 [44880/45000]\tLoss: 3.7763\tLR: 0.000010\n",
      "Training Epoch: 4 [44896/45000]\tLoss: 3.7585\tLR: 0.000010\n",
      "Training Epoch: 4 [44912/45000]\tLoss: 3.6783\tLR: 0.000010\n",
      "Training Epoch: 4 [44928/45000]\tLoss: 3.7186\tLR: 0.000010\n",
      "Training Epoch: 4 [44944/45000]\tLoss: 3.6664\tLR: 0.000010\n",
      "Training Epoch: 4 [44960/45000]\tLoss: 3.7522\tLR: 0.000010\n",
      "Training Epoch: 4 [44976/45000]\tLoss: 3.6077\tLR: 0.000010\n",
      "Training Epoch: 4 [44992/45000]\tLoss: 3.8580\tLR: 0.000010\n",
      "Training Epoch: 4 [45000/45000]\tLoss: 3.9013\tLR: 0.000010\n",
      "epoch 4 training time consumed: 171.50s\n",
      "Accuracy is 0.95340\n",
      "num_zeros / total_parameters ratio is  0.8846256559823675\n",
      "accuracy is  0.9534\n",
      "overall score is  0.9190128279911838\n",
      "Round 2/3:\n",
      "Training Epoch: 4 [16/45000]\tLoss: 3.7900\tLR: 0.000010\n",
      "Training Epoch: 4 [32/45000]\tLoss: 3.7346\tLR: 0.000010\n",
      "Training Epoch: 4 [48/45000]\tLoss: 3.5977\tLR: 0.000010\n",
      "Training Epoch: 4 [64/45000]\tLoss: 3.6427\tLR: 0.000010\n",
      "Training Epoch: 4 [80/45000]\tLoss: 3.7827\tLR: 0.000010\n",
      "Training Epoch: 4 [96/45000]\tLoss: 3.6808\tLR: 0.000010\n",
      "Training Epoch: 4 [112/45000]\tLoss: 3.8950\tLR: 0.000010\n",
      "Training Epoch: 4 [128/45000]\tLoss: 3.7068\tLR: 0.000010\n",
      "Training Epoch: 4 [144/45000]\tLoss: 3.7071\tLR: 0.000010\n",
      "Training Epoch: 4 [160/45000]\tLoss: 3.6069\tLR: 0.000010\n",
      "Training Epoch: 4 [176/45000]\tLoss: 3.7656\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [192/45000]\tLoss: 3.7468\tLR: 0.000010\n",
      "Training Epoch: 4 [208/45000]\tLoss: 3.6986\tLR: 0.000010\n",
      "Training Epoch: 4 [224/45000]\tLoss: 3.6986\tLR: 0.000010\n",
      "Training Epoch: 4 [240/45000]\tLoss: 3.6672\tLR: 0.000010\n",
      "Training Epoch: 4 [256/45000]\tLoss: 3.6597\tLR: 0.000010\n",
      "Training Epoch: 4 [272/45000]\tLoss: 3.6581\tLR: 0.000010\n",
      "Training Epoch: 4 [288/45000]\tLoss: 3.5825\tLR: 0.000010\n",
      "Training Epoch: 4 [304/45000]\tLoss: 3.5349\tLR: 0.000010\n",
      "Training Epoch: 4 [320/45000]\tLoss: 3.7635\tLR: 0.000010\n",
      "Training Epoch: 4 [336/45000]\tLoss: 3.5964\tLR: 0.000010\n",
      "Training Epoch: 4 [352/45000]\tLoss: 3.8038\tLR: 0.000010\n",
      "Training Epoch: 4 [368/45000]\tLoss: 3.6471\tLR: 0.000010\n",
      "Training Epoch: 4 [384/45000]\tLoss: 3.6075\tLR: 0.000010\n",
      "Training Epoch: 4 [400/45000]\tLoss: 3.6648\tLR: 0.000010\n",
      "Training Epoch: 4 [416/45000]\tLoss: 3.8103\tLR: 0.000010\n",
      "Training Epoch: 4 [432/45000]\tLoss: 3.6975\tLR: 0.000010\n",
      "Training Epoch: 4 [448/45000]\tLoss: 3.6101\tLR: 0.000010\n",
      "Training Epoch: 4 [464/45000]\tLoss: 3.6244\tLR: 0.000010\n",
      "Training Epoch: 4 [480/45000]\tLoss: 3.6987\tLR: 0.000010\n",
      "Training Epoch: 4 [496/45000]\tLoss: 3.5914\tLR: 0.000010\n",
      "Training Epoch: 4 [512/45000]\tLoss: 3.6553\tLR: 0.000010\n",
      "Training Epoch: 4 [528/45000]\tLoss: 3.6460\tLR: 0.000010\n",
      "Training Epoch: 4 [544/45000]\tLoss: 3.7382\tLR: 0.000010\n",
      "Training Epoch: 4 [560/45000]\tLoss: 3.7494\tLR: 0.000010\n",
      "Training Epoch: 4 [576/45000]\tLoss: 3.7069\tLR: 0.000010\n",
      "Training Epoch: 4 [592/45000]\tLoss: 3.6442\tLR: 0.000010\n",
      "Training Epoch: 4 [608/45000]\tLoss: 3.7469\tLR: 0.000010\n",
      "Training Epoch: 4 [624/45000]\tLoss: 3.7041\tLR: 0.000010\n",
      "Training Epoch: 4 [640/45000]\tLoss: 3.6683\tLR: 0.000010\n",
      "Training Epoch: 4 [656/45000]\tLoss: 3.7915\tLR: 0.000010\n",
      "Training Epoch: 4 [672/45000]\tLoss: 3.6556\tLR: 0.000010\n",
      "Training Epoch: 4 [688/45000]\tLoss: 3.6728\tLR: 0.000010\n",
      "Training Epoch: 4 [704/45000]\tLoss: 3.6747\tLR: 0.000010\n",
      "Training Epoch: 4 [720/45000]\tLoss: 3.6161\tLR: 0.000010\n",
      "Training Epoch: 4 [736/45000]\tLoss: 3.6967\tLR: 0.000010\n",
      "Training Epoch: 4 [752/45000]\tLoss: 3.6439\tLR: 0.000010\n",
      "Training Epoch: 4 [768/45000]\tLoss: 3.8415\tLR: 0.000010\n",
      "Training Epoch: 4 [784/45000]\tLoss: 3.6408\tLR: 0.000010\n",
      "Training Epoch: 4 [800/45000]\tLoss: 3.7769\tLR: 0.000010\n",
      "Training Epoch: 4 [816/45000]\tLoss: 3.6224\tLR: 0.000010\n",
      "Training Epoch: 4 [832/45000]\tLoss: 3.8311\tLR: 0.000010\n",
      "Training Epoch: 4 [848/45000]\tLoss: 3.7889\tLR: 0.000010\n",
      "Training Epoch: 4 [864/45000]\tLoss: 3.7292\tLR: 0.000010\n",
      "Training Epoch: 4 [880/45000]\tLoss: 3.6496\tLR: 0.000010\n",
      "Training Epoch: 4 [896/45000]\tLoss: 3.6747\tLR: 0.000010\n",
      "Training Epoch: 4 [912/45000]\tLoss: 3.7182\tLR: 0.000010\n",
      "Training Epoch: 4 [928/45000]\tLoss: 3.6897\tLR: 0.000010\n",
      "Training Epoch: 4 [944/45000]\tLoss: 3.6026\tLR: 0.000010\n",
      "Training Epoch: 4 [960/45000]\tLoss: 3.6904\tLR: 0.000010\n",
      "Training Epoch: 4 [976/45000]\tLoss: 3.7050\tLR: 0.000010\n",
      "Training Epoch: 4 [992/45000]\tLoss: 3.5935\tLR: 0.000010\n",
      "Training Epoch: 4 [1008/45000]\tLoss: 3.6495\tLR: 0.000010\n",
      "Training Epoch: 4 [1024/45000]\tLoss: 3.6758\tLR: 0.000010\n",
      "Training Epoch: 4 [1040/45000]\tLoss: 3.7069\tLR: 0.000010\n",
      "Training Epoch: 4 [1056/45000]\tLoss: 3.6292\tLR: 0.000010\n",
      "Training Epoch: 4 [1072/45000]\tLoss: 3.6999\tLR: 0.000010\n",
      "Training Epoch: 4 [1088/45000]\tLoss: 3.6679\tLR: 0.000010\n",
      "Training Epoch: 4 [1104/45000]\tLoss: 3.5898\tLR: 0.000010\n",
      "Training Epoch: 4 [1120/45000]\tLoss: 3.6703\tLR: 0.000010\n",
      "Training Epoch: 4 [1136/45000]\tLoss: 3.6488\tLR: 0.000010\n",
      "Training Epoch: 4 [1152/45000]\tLoss: 3.6276\tLR: 0.000010\n",
      "Training Epoch: 4 [1168/45000]\tLoss: 3.5717\tLR: 0.000010\n",
      "Training Epoch: 4 [1184/45000]\tLoss: 3.5382\tLR: 0.000010\n",
      "Training Epoch: 4 [1200/45000]\tLoss: 3.6711\tLR: 0.000010\n",
      "Training Epoch: 4 [1216/45000]\tLoss: 3.7799\tLR: 0.000010\n",
      "Training Epoch: 4 [1232/45000]\tLoss: 3.7546\tLR: 0.000010\n",
      "Training Epoch: 4 [1248/45000]\tLoss: 3.6203\tLR: 0.000010\n",
      "Training Epoch: 4 [1264/45000]\tLoss: 3.8242\tLR: 0.000010\n",
      "Training Epoch: 4 [1280/45000]\tLoss: 3.6509\tLR: 0.000010\n",
      "Training Epoch: 4 [1296/45000]\tLoss: 3.7221\tLR: 0.000010\n",
      "Training Epoch: 4 [1312/45000]\tLoss: 3.7298\tLR: 0.000010\n",
      "Training Epoch: 4 [1328/45000]\tLoss: 3.6623\tLR: 0.000010\n",
      "Training Epoch: 4 [1344/45000]\tLoss: 3.6117\tLR: 0.000010\n",
      "Training Epoch: 4 [1360/45000]\tLoss: 3.7043\tLR: 0.000010\n",
      "Training Epoch: 4 [1376/45000]\tLoss: 3.8533\tLR: 0.000010\n",
      "Training Epoch: 4 [1392/45000]\tLoss: 3.8010\tLR: 0.000010\n",
      "Training Epoch: 4 [1408/45000]\tLoss: 3.6264\tLR: 0.000010\n",
      "Training Epoch: 4 [1424/45000]\tLoss: 3.6609\tLR: 0.000010\n",
      "Training Epoch: 4 [1440/45000]\tLoss: 3.6444\tLR: 0.000010\n",
      "Training Epoch: 4 [1456/45000]\tLoss: 3.5890\tLR: 0.000010\n",
      "Training Epoch: 4 [1472/45000]\tLoss: 3.6465\tLR: 0.000010\n",
      "Training Epoch: 4 [1488/45000]\tLoss: 3.6315\tLR: 0.000010\n",
      "Training Epoch: 4 [1504/45000]\tLoss: 3.6348\tLR: 0.000010\n",
      "Training Epoch: 4 [1520/45000]\tLoss: 3.6961\tLR: 0.000010\n",
      "Training Epoch: 4 [1536/45000]\tLoss: 3.6025\tLR: 0.000010\n",
      "Training Epoch: 4 [1552/45000]\tLoss: 3.7000\tLR: 0.000010\n",
      "Training Epoch: 4 [1568/45000]\tLoss: 3.7246\tLR: 0.000010\n",
      "Training Epoch: 4 [1584/45000]\tLoss: 3.5934\tLR: 0.000010\n",
      "Training Epoch: 4 [1600/45000]\tLoss: 3.6637\tLR: 0.000010\n",
      "Training Epoch: 4 [1616/45000]\tLoss: 3.6372\tLR: 0.000010\n",
      "Training Epoch: 4 [1632/45000]\tLoss: 3.7063\tLR: 0.000010\n",
      "Training Epoch: 4 [1648/45000]\tLoss: 3.6075\tLR: 0.000010\n",
      "Training Epoch: 4 [1664/45000]\tLoss: 3.7411\tLR: 0.000010\n",
      "Training Epoch: 4 [1680/45000]\tLoss: 3.7243\tLR: 0.000010\n",
      "Training Epoch: 4 [1696/45000]\tLoss: 3.6520\tLR: 0.000010\n",
      "Training Epoch: 4 [1712/45000]\tLoss: 3.6998\tLR: 0.000010\n",
      "Training Epoch: 4 [1728/45000]\tLoss: 3.6904\tLR: 0.000010\n",
      "Training Epoch: 4 [1744/45000]\tLoss: 3.8051\tLR: 0.000010\n",
      "Training Epoch: 4 [1760/45000]\tLoss: 3.6334\tLR: 0.000010\n",
      "Training Epoch: 4 [1776/45000]\tLoss: 3.7151\tLR: 0.000010\n",
      "Training Epoch: 4 [1792/45000]\tLoss: 3.7098\tLR: 0.000010\n",
      "Training Epoch: 4 [1808/45000]\tLoss: 3.6510\tLR: 0.000010\n",
      "Training Epoch: 4 [1824/45000]\tLoss: 3.6246\tLR: 0.000010\n",
      "Training Epoch: 4 [1840/45000]\tLoss: 3.6912\tLR: 0.000010\n",
      "Training Epoch: 4 [1856/45000]\tLoss: 3.6655\tLR: 0.000010\n",
      "Training Epoch: 4 [1872/45000]\tLoss: 3.6331\tLR: 0.000010\n",
      "Training Epoch: 4 [1888/45000]\tLoss: 3.7162\tLR: 0.000010\n",
      "Training Epoch: 4 [1904/45000]\tLoss: 3.6496\tLR: 0.000010\n",
      "Training Epoch: 4 [1920/45000]\tLoss: 3.6348\tLR: 0.000010\n",
      "Training Epoch: 4 [1936/45000]\tLoss: 3.6456\tLR: 0.000010\n",
      "Training Epoch: 4 [1952/45000]\tLoss: 3.6410\tLR: 0.000010\n",
      "Training Epoch: 4 [1968/45000]\tLoss: 3.6368\tLR: 0.000010\n",
      "Training Epoch: 4 [1984/45000]\tLoss: 3.7220\tLR: 0.000010\n",
      "Training Epoch: 4 [2000/45000]\tLoss: 3.5628\tLR: 0.000010\n",
      "Training Epoch: 4 [2016/45000]\tLoss: 3.6997\tLR: 0.000010\n",
      "Training Epoch: 4 [2032/45000]\tLoss: 3.7111\tLR: 0.000010\n",
      "Training Epoch: 4 [2048/45000]\tLoss: 3.6762\tLR: 0.000010\n",
      "Training Epoch: 4 [2064/45000]\tLoss: 3.6022\tLR: 0.000010\n",
      "Training Epoch: 4 [2080/45000]\tLoss: 3.6841\tLR: 0.000010\n",
      "Training Epoch: 4 [2096/45000]\tLoss: 3.7060\tLR: 0.000010\n",
      "Training Epoch: 4 [2112/45000]\tLoss: 3.6947\tLR: 0.000010\n",
      "Training Epoch: 4 [2128/45000]\tLoss: 3.6113\tLR: 0.000010\n",
      "Training Epoch: 4 [2144/45000]\tLoss: 3.8127\tLR: 0.000010\n",
      "Training Epoch: 4 [2160/45000]\tLoss: 3.5753\tLR: 0.000010\n",
      "Training Epoch: 4 [2176/45000]\tLoss: 3.6985\tLR: 0.000010\n",
      "Training Epoch: 4 [2192/45000]\tLoss: 3.7518\tLR: 0.000010\n",
      "Training Epoch: 4 [2208/45000]\tLoss: 3.5727\tLR: 0.000010\n",
      "Training Epoch: 4 [2224/45000]\tLoss: 3.5545\tLR: 0.000010\n",
      "Training Epoch: 4 [2240/45000]\tLoss: 3.7780\tLR: 0.000010\n",
      "Training Epoch: 4 [2256/45000]\tLoss: 3.7194\tLR: 0.000010\n",
      "Training Epoch: 4 [2272/45000]\tLoss: 3.6356\tLR: 0.000010\n",
      "Training Epoch: 4 [2288/45000]\tLoss: 3.7129\tLR: 0.000010\n",
      "Training Epoch: 4 [2304/45000]\tLoss: 3.7275\tLR: 0.000010\n",
      "Training Epoch: 4 [2320/45000]\tLoss: 3.6922\tLR: 0.000010\n",
      "Training Epoch: 4 [2336/45000]\tLoss: 3.6725\tLR: 0.000010\n",
      "Training Epoch: 4 [2352/45000]\tLoss: 3.6329\tLR: 0.000010\n",
      "Training Epoch: 4 [2368/45000]\tLoss: 3.7043\tLR: 0.000010\n",
      "Training Epoch: 4 [2384/45000]\tLoss: 3.6396\tLR: 0.000010\n",
      "Training Epoch: 4 [2400/45000]\tLoss: 3.6719\tLR: 0.000010\n",
      "Training Epoch: 4 [2416/45000]\tLoss: 3.6789\tLR: 0.000010\n",
      "Training Epoch: 4 [2432/45000]\tLoss: 3.6832\tLR: 0.000010\n",
      "Training Epoch: 4 [2448/45000]\tLoss: 3.7024\tLR: 0.000010\n",
      "Training Epoch: 4 [2464/45000]\tLoss: 3.7025\tLR: 0.000010\n",
      "Training Epoch: 4 [2480/45000]\tLoss: 3.7173\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [2496/45000]\tLoss: 3.7203\tLR: 0.000010\n",
      "Training Epoch: 4 [2512/45000]\tLoss: 3.7841\tLR: 0.000010\n",
      "Training Epoch: 4 [2528/45000]\tLoss: 3.6185\tLR: 0.000010\n",
      "Training Epoch: 4 [2544/45000]\tLoss: 3.7274\tLR: 0.000010\n",
      "Training Epoch: 4 [2560/45000]\tLoss: 3.6092\tLR: 0.000010\n",
      "Training Epoch: 4 [2576/45000]\tLoss: 3.6648\tLR: 0.000010\n",
      "Training Epoch: 4 [2592/45000]\tLoss: 3.7788\tLR: 0.000010\n",
      "Training Epoch: 4 [2608/45000]\tLoss: 3.5929\tLR: 0.000010\n",
      "Training Epoch: 4 [2624/45000]\tLoss: 3.7052\tLR: 0.000010\n",
      "Training Epoch: 4 [2640/45000]\tLoss: 3.7127\tLR: 0.000010\n",
      "Training Epoch: 4 [2656/45000]\tLoss: 3.6452\tLR: 0.000010\n",
      "Training Epoch: 4 [2672/45000]\tLoss: 3.7191\tLR: 0.000010\n",
      "Training Epoch: 4 [2688/45000]\tLoss: 3.6321\tLR: 0.000010\n",
      "Training Epoch: 4 [2704/45000]\tLoss: 3.6686\tLR: 0.000010\n",
      "Training Epoch: 4 [2720/45000]\tLoss: 3.7346\tLR: 0.000010\n",
      "Training Epoch: 4 [2736/45000]\tLoss: 3.7448\tLR: 0.000010\n",
      "Training Epoch: 4 [2752/45000]\tLoss: 3.7178\tLR: 0.000010\n",
      "Training Epoch: 4 [2768/45000]\tLoss: 3.6391\tLR: 0.000010\n",
      "Training Epoch: 4 [2784/45000]\tLoss: 3.7661\tLR: 0.000010\n",
      "Training Epoch: 4 [2800/45000]\tLoss: 3.5258\tLR: 0.000010\n",
      "Training Epoch: 4 [2816/45000]\tLoss: 3.8082\tLR: 0.000010\n",
      "Training Epoch: 4 [2832/45000]\tLoss: 3.8657\tLR: 0.000010\n",
      "Training Epoch: 4 [2848/45000]\tLoss: 3.6640\tLR: 0.000010\n",
      "Training Epoch: 4 [2864/45000]\tLoss: 3.8026\tLR: 0.000010\n",
      "Training Epoch: 4 [2880/45000]\tLoss: 3.6728\tLR: 0.000010\n",
      "Training Epoch: 4 [2896/45000]\tLoss: 3.7696\tLR: 0.000010\n",
      "Training Epoch: 4 [2912/45000]\tLoss: 3.6971\tLR: 0.000010\n",
      "Training Epoch: 4 [2928/45000]\tLoss: 3.7219\tLR: 0.000010\n",
      "Training Epoch: 4 [2944/45000]\tLoss: 3.7034\tLR: 0.000010\n",
      "Training Epoch: 4 [2960/45000]\tLoss: 3.7535\tLR: 0.000010\n",
      "Training Epoch: 4 [2976/45000]\tLoss: 3.5955\tLR: 0.000010\n",
      "Training Epoch: 4 [2992/45000]\tLoss: 3.6794\tLR: 0.000010\n",
      "Training Epoch: 4 [3008/45000]\tLoss: 3.6855\tLR: 0.000010\n",
      "Training Epoch: 4 [3024/45000]\tLoss: 3.7019\tLR: 0.000010\n",
      "Training Epoch: 4 [3040/45000]\tLoss: 3.7013\tLR: 0.000010\n",
      "Training Epoch: 4 [3056/45000]\tLoss: 3.6956\tLR: 0.000010\n",
      "Training Epoch: 4 [3072/45000]\tLoss: 3.6675\tLR: 0.000010\n",
      "Training Epoch: 4 [3088/45000]\tLoss: 3.7417\tLR: 0.000010\n",
      "Training Epoch: 4 [3104/45000]\tLoss: 3.6951\tLR: 0.000010\n",
      "Training Epoch: 4 [3120/45000]\tLoss: 3.7055\tLR: 0.000010\n",
      "Training Epoch: 4 [3136/45000]\tLoss: 3.6883\tLR: 0.000010\n",
      "Training Epoch: 4 [3152/45000]\tLoss: 3.6328\tLR: 0.000010\n",
      "Training Epoch: 4 [3168/45000]\tLoss: 3.7305\tLR: 0.000010\n",
      "Training Epoch: 4 [3184/45000]\tLoss: 3.6435\tLR: 0.000010\n",
      "Training Epoch: 4 [3200/45000]\tLoss: 3.7130\tLR: 0.000010\n",
      "Training Epoch: 4 [3216/45000]\tLoss: 3.7669\tLR: 0.000010\n",
      "Training Epoch: 4 [3232/45000]\tLoss: 3.6660\tLR: 0.000010\n",
      "Training Epoch: 4 [3248/45000]\tLoss: 3.6659\tLR: 0.000010\n",
      "Training Epoch: 4 [3264/45000]\tLoss: 3.7363\tLR: 0.000010\n",
      "Training Epoch: 4 [3280/45000]\tLoss: 3.7650\tLR: 0.000010\n",
      "Training Epoch: 4 [3296/45000]\tLoss: 3.5670\tLR: 0.000010\n",
      "Training Epoch: 4 [3312/45000]\tLoss: 3.7478\tLR: 0.000010\n",
      "Training Epoch: 4 [3328/45000]\tLoss: 3.6147\tLR: 0.000010\n",
      "Training Epoch: 4 [3344/45000]\tLoss: 3.7079\tLR: 0.000010\n",
      "Training Epoch: 4 [3360/45000]\tLoss: 3.6459\tLR: 0.000010\n",
      "Training Epoch: 4 [3376/45000]\tLoss: 3.6380\tLR: 0.000010\n",
      "Training Epoch: 4 [3392/45000]\tLoss: 3.8254\tLR: 0.000010\n",
      "Training Epoch: 4 [3408/45000]\tLoss: 3.6232\tLR: 0.000010\n",
      "Training Epoch: 4 [3424/45000]\tLoss: 3.6644\tLR: 0.000010\n",
      "Training Epoch: 4 [3440/45000]\tLoss: 3.6077\tLR: 0.000010\n",
      "Training Epoch: 4 [3456/45000]\tLoss: 3.6900\tLR: 0.000010\n",
      "Training Epoch: 4 [3472/45000]\tLoss: 3.6875\tLR: 0.000010\n",
      "Training Epoch: 4 [3488/45000]\tLoss: 3.6470\tLR: 0.000010\n",
      "Training Epoch: 4 [3504/45000]\tLoss: 3.6734\tLR: 0.000010\n",
      "Training Epoch: 4 [3520/45000]\tLoss: 3.5833\tLR: 0.000010\n",
      "Training Epoch: 4 [3536/45000]\tLoss: 3.7315\tLR: 0.000010\n",
      "Training Epoch: 4 [3552/45000]\tLoss: 3.7162\tLR: 0.000010\n",
      "Training Epoch: 4 [3568/45000]\tLoss: 3.6743\tLR: 0.000010\n",
      "Training Epoch: 4 [3584/45000]\tLoss: 3.7340\tLR: 0.000010\n",
      "Training Epoch: 4 [3600/45000]\tLoss: 3.6392\tLR: 0.000010\n",
      "Training Epoch: 4 [3616/45000]\tLoss: 3.8180\tLR: 0.000010\n",
      "Training Epoch: 4 [3632/45000]\tLoss: 3.6801\tLR: 0.000010\n",
      "Training Epoch: 4 [3648/45000]\tLoss: 3.7555\tLR: 0.000010\n",
      "Training Epoch: 4 [3664/45000]\tLoss: 3.7100\tLR: 0.000010\n",
      "Training Epoch: 4 [3680/45000]\tLoss: 3.7828\tLR: 0.000010\n",
      "Training Epoch: 4 [3696/45000]\tLoss: 3.5801\tLR: 0.000010\n",
      "Training Epoch: 4 [3712/45000]\tLoss: 3.6161\tLR: 0.000010\n",
      "Training Epoch: 4 [3728/45000]\tLoss: 3.7226\tLR: 0.000010\n",
      "Training Epoch: 4 [3744/45000]\tLoss: 3.6003\tLR: 0.000010\n",
      "Training Epoch: 4 [3760/45000]\tLoss: 3.7477\tLR: 0.000010\n",
      "Training Epoch: 4 [3776/45000]\tLoss: 3.5657\tLR: 0.000010\n",
      "Training Epoch: 4 [3792/45000]\tLoss: 3.7116\tLR: 0.000010\n",
      "Training Epoch: 4 [3808/45000]\tLoss: 3.7236\tLR: 0.000010\n",
      "Training Epoch: 4 [3824/45000]\tLoss: 3.6746\tLR: 0.000010\n",
      "Training Epoch: 4 [3840/45000]\tLoss: 3.6704\tLR: 0.000010\n",
      "Training Epoch: 4 [3856/45000]\tLoss: 3.6577\tLR: 0.000010\n",
      "Training Epoch: 4 [3872/45000]\tLoss: 3.6780\tLR: 0.000010\n",
      "Training Epoch: 4 [3888/45000]\tLoss: 3.7182\tLR: 0.000010\n",
      "Training Epoch: 4 [3904/45000]\tLoss: 3.6499\tLR: 0.000010\n",
      "Training Epoch: 4 [3920/45000]\tLoss: 3.6957\tLR: 0.000010\n",
      "Training Epoch: 4 [3936/45000]\tLoss: 3.6586\tLR: 0.000010\n",
      "Training Epoch: 4 [3952/45000]\tLoss: 3.6820\tLR: 0.000010\n",
      "Training Epoch: 4 [3968/45000]\tLoss: 3.6620\tLR: 0.000010\n",
      "Training Epoch: 4 [3984/45000]\tLoss: 3.7323\tLR: 0.000010\n",
      "Training Epoch: 4 [4000/45000]\tLoss: 3.6383\tLR: 0.000010\n",
      "Training Epoch: 4 [4016/45000]\tLoss: 3.7020\tLR: 0.000010\n",
      "Training Epoch: 4 [4032/45000]\tLoss: 3.7269\tLR: 0.000010\n",
      "Training Epoch: 4 [4048/45000]\tLoss: 3.5852\tLR: 0.000010\n",
      "Training Epoch: 4 [4064/45000]\tLoss: 3.5668\tLR: 0.000010\n",
      "Training Epoch: 4 [4080/45000]\tLoss: 3.6461\tLR: 0.000010\n",
      "Training Epoch: 4 [4096/45000]\tLoss: 3.6098\tLR: 0.000010\n",
      "Training Epoch: 4 [4112/45000]\tLoss: 3.7037\tLR: 0.000010\n",
      "Training Epoch: 4 [4128/45000]\tLoss: 3.7592\tLR: 0.000010\n",
      "Training Epoch: 4 [4144/45000]\tLoss: 3.6070\tLR: 0.000010\n",
      "Training Epoch: 4 [4160/45000]\tLoss: 3.6338\tLR: 0.000010\n",
      "Training Epoch: 4 [4176/45000]\tLoss: 3.6155\tLR: 0.000010\n",
      "Training Epoch: 4 [4192/45000]\tLoss: 3.7721\tLR: 0.000010\n",
      "Training Epoch: 4 [4208/45000]\tLoss: 3.6727\tLR: 0.000010\n",
      "Training Epoch: 4 [4224/45000]\tLoss: 3.7934\tLR: 0.000010\n",
      "Training Epoch: 4 [4240/45000]\tLoss: 3.7055\tLR: 0.000010\n",
      "Training Epoch: 4 [4256/45000]\tLoss: 3.6822\tLR: 0.000010\n",
      "Training Epoch: 4 [4272/45000]\tLoss: 3.6346\tLR: 0.000010\n",
      "Training Epoch: 4 [4288/45000]\tLoss: 3.6833\tLR: 0.000010\n",
      "Training Epoch: 4 [4304/45000]\tLoss: 3.6904\tLR: 0.000010\n",
      "Training Epoch: 4 [4320/45000]\tLoss: 3.6472\tLR: 0.000010\n",
      "Training Epoch: 4 [4336/45000]\tLoss: 3.6312\tLR: 0.000010\n",
      "Training Epoch: 4 [4352/45000]\tLoss: 3.6772\tLR: 0.000010\n",
      "Training Epoch: 4 [4368/45000]\tLoss: 3.7225\tLR: 0.000010\n",
      "Training Epoch: 4 [4384/45000]\tLoss: 3.7176\tLR: 0.000010\n",
      "Training Epoch: 4 [4400/45000]\tLoss: 3.5931\tLR: 0.000010\n",
      "Training Epoch: 4 [4416/45000]\tLoss: 3.6320\tLR: 0.000010\n",
      "Training Epoch: 4 [4432/45000]\tLoss: 3.6640\tLR: 0.000010\n",
      "Training Epoch: 4 [4448/45000]\tLoss: 3.7100\tLR: 0.000010\n",
      "Training Epoch: 4 [4464/45000]\tLoss: 3.7717\tLR: 0.000010\n",
      "Training Epoch: 4 [4480/45000]\tLoss: 3.7024\tLR: 0.000010\n",
      "Training Epoch: 4 [4496/45000]\tLoss: 3.7972\tLR: 0.000010\n",
      "Training Epoch: 4 [4512/45000]\tLoss: 3.7577\tLR: 0.000010\n",
      "Training Epoch: 4 [4528/45000]\tLoss: 3.7021\tLR: 0.000010\n",
      "Training Epoch: 4 [4544/45000]\tLoss: 3.5985\tLR: 0.000010\n",
      "Training Epoch: 4 [4560/45000]\tLoss: 3.7093\tLR: 0.000010\n",
      "Training Epoch: 4 [4576/45000]\tLoss: 3.6174\tLR: 0.000010\n",
      "Training Epoch: 4 [4592/45000]\tLoss: 3.6993\tLR: 0.000010\n",
      "Training Epoch: 4 [4608/45000]\tLoss: 3.6266\tLR: 0.000010\n",
      "Training Epoch: 4 [4624/45000]\tLoss: 3.6635\tLR: 0.000010\n",
      "Training Epoch: 4 [4640/45000]\tLoss: 3.6790\tLR: 0.000010\n",
      "Training Epoch: 4 [4656/45000]\tLoss: 3.6588\tLR: 0.000010\n",
      "Training Epoch: 4 [4672/45000]\tLoss: 3.7314\tLR: 0.000010\n",
      "Training Epoch: 4 [4688/45000]\tLoss: 3.7543\tLR: 0.000010\n",
      "Training Epoch: 4 [4704/45000]\tLoss: 3.6488\tLR: 0.000010\n",
      "Training Epoch: 4 [4720/45000]\tLoss: 3.4986\tLR: 0.000010\n",
      "Training Epoch: 4 [4736/45000]\tLoss: 3.7725\tLR: 0.000010\n",
      "Training Epoch: 4 [4752/45000]\tLoss: 3.6663\tLR: 0.000010\n",
      "Training Epoch: 4 [4768/45000]\tLoss: 3.5934\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [4784/45000]\tLoss: 3.6461\tLR: 0.000010\n",
      "Training Epoch: 4 [4800/45000]\tLoss: 3.6705\tLR: 0.000010\n",
      "Training Epoch: 4 [4816/45000]\tLoss: 3.6478\tLR: 0.000010\n",
      "Training Epoch: 4 [4832/45000]\tLoss: 3.6119\tLR: 0.000010\n",
      "Training Epoch: 4 [4848/45000]\tLoss: 3.5988\tLR: 0.000010\n",
      "Training Epoch: 4 [4864/45000]\tLoss: 3.6522\tLR: 0.000010\n",
      "Training Epoch: 4 [4880/45000]\tLoss: 3.6537\tLR: 0.000010\n",
      "Training Epoch: 4 [4896/45000]\tLoss: 3.7595\tLR: 0.000010\n",
      "Training Epoch: 4 [4912/45000]\tLoss: 3.7255\tLR: 0.000010\n",
      "Training Epoch: 4 [4928/45000]\tLoss: 3.6051\tLR: 0.000010\n",
      "Training Epoch: 4 [4944/45000]\tLoss: 3.6431\tLR: 0.000010\n",
      "Training Epoch: 4 [4960/45000]\tLoss: 3.7119\tLR: 0.000010\n",
      "Training Epoch: 4 [4976/45000]\tLoss: 3.6998\tLR: 0.000010\n",
      "Training Epoch: 4 [4992/45000]\tLoss: 3.5907\tLR: 0.000010\n",
      "Training Epoch: 4 [5008/45000]\tLoss: 3.7713\tLR: 0.000010\n",
      "Training Epoch: 4 [5024/45000]\tLoss: 3.6881\tLR: 0.000010\n",
      "Training Epoch: 4 [5040/45000]\tLoss: 3.6138\tLR: 0.000010\n",
      "Training Epoch: 4 [5056/45000]\tLoss: 3.7174\tLR: 0.000010\n",
      "Training Epoch: 4 [5072/45000]\tLoss: 3.6537\tLR: 0.000010\n",
      "Training Epoch: 4 [5088/45000]\tLoss: 3.7028\tLR: 0.000010\n",
      "Training Epoch: 4 [5104/45000]\tLoss: 3.6700\tLR: 0.000010\n",
      "Training Epoch: 4 [5120/45000]\tLoss: 3.6539\tLR: 0.000010\n",
      "Training Epoch: 4 [5136/45000]\tLoss: 3.6701\tLR: 0.000010\n",
      "Training Epoch: 4 [5152/45000]\tLoss: 3.6563\tLR: 0.000010\n",
      "Training Epoch: 4 [5168/45000]\tLoss: 3.8070\tLR: 0.000010\n",
      "Training Epoch: 4 [5184/45000]\tLoss: 3.7159\tLR: 0.000010\n",
      "Training Epoch: 4 [5200/45000]\tLoss: 3.6137\tLR: 0.000010\n",
      "Training Epoch: 4 [5216/45000]\tLoss: 3.7892\tLR: 0.000010\n",
      "Training Epoch: 4 [5232/45000]\tLoss: 3.8191\tLR: 0.000010\n",
      "Training Epoch: 4 [5248/45000]\tLoss: 3.7269\tLR: 0.000010\n",
      "Training Epoch: 4 [5264/45000]\tLoss: 3.6990\tLR: 0.000010\n",
      "Training Epoch: 4 [5280/45000]\tLoss: 3.5320\tLR: 0.000010\n",
      "Training Epoch: 4 [5296/45000]\tLoss: 3.5785\tLR: 0.000010\n",
      "Training Epoch: 4 [5312/45000]\tLoss: 3.7727\tLR: 0.000010\n",
      "Training Epoch: 4 [5328/45000]\tLoss: 3.7256\tLR: 0.000010\n",
      "Training Epoch: 4 [5344/45000]\tLoss: 3.6394\tLR: 0.000010\n",
      "Training Epoch: 4 [5360/45000]\tLoss: 3.6359\tLR: 0.000010\n",
      "Training Epoch: 4 [5376/45000]\tLoss: 3.5649\tLR: 0.000010\n",
      "Training Epoch: 4 [5392/45000]\tLoss: 3.7006\tLR: 0.000010\n",
      "Training Epoch: 4 [5408/45000]\tLoss: 3.6888\tLR: 0.000010\n",
      "Training Epoch: 4 [5424/45000]\tLoss: 3.7420\tLR: 0.000010\n",
      "Training Epoch: 4 [5440/45000]\tLoss: 3.6817\tLR: 0.000010\n",
      "Training Epoch: 4 [5456/45000]\tLoss: 3.6229\tLR: 0.000010\n",
      "Training Epoch: 4 [5472/45000]\tLoss: 3.6309\tLR: 0.000010\n",
      "Training Epoch: 4 [5488/45000]\tLoss: 3.6275\tLR: 0.000010\n",
      "Training Epoch: 4 [5504/45000]\tLoss: 3.6541\tLR: 0.000010\n",
      "Training Epoch: 4 [5520/45000]\tLoss: 3.6955\tLR: 0.000010\n",
      "Training Epoch: 4 [5536/45000]\tLoss: 3.7539\tLR: 0.000010\n",
      "Training Epoch: 4 [5552/45000]\tLoss: 3.7136\tLR: 0.000010\n",
      "Training Epoch: 4 [5568/45000]\tLoss: 3.6223\tLR: 0.000010\n",
      "Training Epoch: 4 [5584/45000]\tLoss: 3.7094\tLR: 0.000010\n",
      "Training Epoch: 4 [5600/45000]\tLoss: 3.7342\tLR: 0.000010\n",
      "Training Epoch: 4 [5616/45000]\tLoss: 3.6468\tLR: 0.000010\n",
      "Training Epoch: 4 [5632/45000]\tLoss: 3.5852\tLR: 0.000010\n",
      "Training Epoch: 4 [5648/45000]\tLoss: 3.6466\tLR: 0.000010\n",
      "Training Epoch: 4 [5664/45000]\tLoss: 3.7075\tLR: 0.000010\n",
      "Training Epoch: 4 [5680/45000]\tLoss: 3.5712\tLR: 0.000010\n",
      "Training Epoch: 4 [5696/45000]\tLoss: 3.6382\tLR: 0.000010\n",
      "Training Epoch: 4 [5712/45000]\tLoss: 3.6516\tLR: 0.000010\n",
      "Training Epoch: 4 [5728/45000]\tLoss: 3.6601\tLR: 0.000010\n",
      "Training Epoch: 4 [5744/45000]\tLoss: 3.7285\tLR: 0.000010\n",
      "Training Epoch: 4 [5760/45000]\tLoss: 3.6724\tLR: 0.000010\n",
      "Training Epoch: 4 [5776/45000]\tLoss: 3.7782\tLR: 0.000010\n",
      "Training Epoch: 4 [5792/45000]\tLoss: 3.7113\tLR: 0.000010\n",
      "Training Epoch: 4 [5808/45000]\tLoss: 3.5385\tLR: 0.000010\n",
      "Training Epoch: 4 [5824/45000]\tLoss: 3.6966\tLR: 0.000010\n",
      "Training Epoch: 4 [5840/45000]\tLoss: 3.6730\tLR: 0.000010\n",
      "Training Epoch: 4 [5856/45000]\tLoss: 3.7088\tLR: 0.000010\n",
      "Training Epoch: 4 [5872/45000]\tLoss: 3.6119\tLR: 0.000010\n",
      "Training Epoch: 4 [5888/45000]\tLoss: 3.7889\tLR: 0.000010\n",
      "Training Epoch: 4 [5904/45000]\tLoss: 3.7306\tLR: 0.000010\n",
      "Training Epoch: 4 [5920/45000]\tLoss: 3.7070\tLR: 0.000010\n",
      "Training Epoch: 4 [5936/45000]\tLoss: 3.6594\tLR: 0.000010\n",
      "Training Epoch: 4 [5952/45000]\tLoss: 3.6161\tLR: 0.000010\n",
      "Training Epoch: 4 [5968/45000]\tLoss: 3.7339\tLR: 0.000010\n",
      "Training Epoch: 4 [5984/45000]\tLoss: 3.7394\tLR: 0.000010\n",
      "Training Epoch: 4 [6000/45000]\tLoss: 3.6458\tLR: 0.000010\n",
      "Training Epoch: 4 [6016/45000]\tLoss: 3.7386\tLR: 0.000010\n",
      "Training Epoch: 4 [6032/45000]\tLoss: 3.5938\tLR: 0.000010\n",
      "Training Epoch: 4 [6048/45000]\tLoss: 3.7540\tLR: 0.000010\n",
      "Training Epoch: 4 [6064/45000]\tLoss: 3.6932\tLR: 0.000010\n",
      "Training Epoch: 4 [6080/45000]\tLoss: 3.7432\tLR: 0.000010\n",
      "Training Epoch: 4 [6096/45000]\tLoss: 3.6532\tLR: 0.000010\n",
      "Training Epoch: 4 [6112/45000]\tLoss: 3.6140\tLR: 0.000010\n",
      "Training Epoch: 4 [6128/45000]\tLoss: 3.6891\tLR: 0.000010\n",
      "Training Epoch: 4 [6144/45000]\tLoss: 3.6529\tLR: 0.000010\n",
      "Training Epoch: 4 [6160/45000]\tLoss: 3.6272\tLR: 0.000010\n",
      "Training Epoch: 4 [6176/45000]\tLoss: 3.6716\tLR: 0.000010\n",
      "Training Epoch: 4 [6192/45000]\tLoss: 3.6424\tLR: 0.000010\n",
      "Training Epoch: 4 [6208/45000]\tLoss: 3.6703\tLR: 0.000010\n",
      "Training Epoch: 4 [6224/45000]\tLoss: 3.6495\tLR: 0.000010\n",
      "Training Epoch: 4 [6240/45000]\tLoss: 3.6583\tLR: 0.000010\n",
      "Training Epoch: 4 [6256/45000]\tLoss: 3.7373\tLR: 0.000010\n",
      "Training Epoch: 4 [6272/45000]\tLoss: 3.6455\tLR: 0.000010\n",
      "Training Epoch: 4 [6288/45000]\tLoss: 3.5683\tLR: 0.000010\n",
      "Training Epoch: 4 [6304/45000]\tLoss: 3.6156\tLR: 0.000010\n",
      "Training Epoch: 4 [6320/45000]\tLoss: 3.6234\tLR: 0.000010\n",
      "Training Epoch: 4 [6336/45000]\tLoss: 3.7425\tLR: 0.000010\n",
      "Training Epoch: 4 [6352/45000]\tLoss: 3.6716\tLR: 0.000010\n",
      "Training Epoch: 4 [6368/45000]\tLoss: 3.7692\tLR: 0.000010\n",
      "Training Epoch: 4 [6384/45000]\tLoss: 3.6310\tLR: 0.000010\n",
      "Training Epoch: 4 [6400/45000]\tLoss: 3.6854\tLR: 0.000010\n",
      "Training Epoch: 4 [6416/45000]\tLoss: 3.8080\tLR: 0.000010\n",
      "Training Epoch: 4 [6432/45000]\tLoss: 3.6580\tLR: 0.000010\n",
      "Training Epoch: 4 [6448/45000]\tLoss: 3.6226\tLR: 0.000010\n",
      "Training Epoch: 4 [6464/45000]\tLoss: 3.7182\tLR: 0.000010\n",
      "Training Epoch: 4 [6480/45000]\tLoss: 3.7506\tLR: 0.000010\n",
      "Training Epoch: 4 [6496/45000]\tLoss: 3.6927\tLR: 0.000010\n",
      "Training Epoch: 4 [6512/45000]\tLoss: 3.6051\tLR: 0.000010\n",
      "Training Epoch: 4 [6528/45000]\tLoss: 3.6597\tLR: 0.000010\n",
      "Training Epoch: 4 [6544/45000]\tLoss: 3.7487\tLR: 0.000010\n",
      "Training Epoch: 4 [6560/45000]\tLoss: 3.7026\tLR: 0.000010\n",
      "Training Epoch: 4 [6576/45000]\tLoss: 3.6093\tLR: 0.000010\n",
      "Training Epoch: 4 [6592/45000]\tLoss: 3.5850\tLR: 0.000010\n",
      "Training Epoch: 4 [6608/45000]\tLoss: 3.6738\tLR: 0.000010\n",
      "Training Epoch: 4 [6624/45000]\tLoss: 3.6341\tLR: 0.000010\n",
      "Training Epoch: 4 [6640/45000]\tLoss: 3.7292\tLR: 0.000010\n",
      "Training Epoch: 4 [6656/45000]\tLoss: 3.7005\tLR: 0.000010\n",
      "Training Epoch: 4 [6672/45000]\tLoss: 3.6909\tLR: 0.000010\n",
      "Training Epoch: 4 [6688/45000]\tLoss: 3.5753\tLR: 0.000010\n",
      "Training Epoch: 4 [6704/45000]\tLoss: 3.5974\tLR: 0.000010\n",
      "Training Epoch: 4 [6720/45000]\tLoss: 3.6784\tLR: 0.000010\n",
      "Training Epoch: 4 [6736/45000]\tLoss: 3.7740\tLR: 0.000010\n",
      "Training Epoch: 4 [6752/45000]\tLoss: 3.6563\tLR: 0.000010\n",
      "Training Epoch: 4 [6768/45000]\tLoss: 3.5865\tLR: 0.000010\n",
      "Training Epoch: 4 [6784/45000]\tLoss: 3.7904\tLR: 0.000010\n",
      "Training Epoch: 4 [6800/45000]\tLoss: 3.6689\tLR: 0.000010\n",
      "Training Epoch: 4 [6816/45000]\tLoss: 3.6713\tLR: 0.000010\n",
      "Training Epoch: 4 [6832/45000]\tLoss: 3.5945\tLR: 0.000010\n",
      "Training Epoch: 4 [6848/45000]\tLoss: 3.8263\tLR: 0.000010\n",
      "Training Epoch: 4 [6864/45000]\tLoss: 3.7413\tLR: 0.000010\n",
      "Training Epoch: 4 [6880/45000]\tLoss: 3.7049\tLR: 0.000010\n",
      "Training Epoch: 4 [6896/45000]\tLoss: 3.6499\tLR: 0.000010\n",
      "Training Epoch: 4 [6912/45000]\tLoss: 3.5661\tLR: 0.000010\n",
      "Training Epoch: 4 [6928/45000]\tLoss: 3.8458\tLR: 0.000010\n",
      "Training Epoch: 4 [6944/45000]\tLoss: 3.6899\tLR: 0.000010\n",
      "Training Epoch: 4 [6960/45000]\tLoss: 3.6687\tLR: 0.000010\n",
      "Training Epoch: 4 [6976/45000]\tLoss: 3.6192\tLR: 0.000010\n",
      "Training Epoch: 4 [6992/45000]\tLoss: 3.6891\tLR: 0.000010\n",
      "Training Epoch: 4 [7008/45000]\tLoss: 3.7505\tLR: 0.000010\n",
      "Training Epoch: 4 [7024/45000]\tLoss: 3.6582\tLR: 0.000010\n",
      "Training Epoch: 4 [7040/45000]\tLoss: 3.6191\tLR: 0.000010\n",
      "Training Epoch: 4 [7056/45000]\tLoss: 3.6295\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [7072/45000]\tLoss: 3.6102\tLR: 0.000010\n",
      "Training Epoch: 4 [7088/45000]\tLoss: 3.7610\tLR: 0.000010\n",
      "Training Epoch: 4 [7104/45000]\tLoss: 3.6525\tLR: 0.000010\n",
      "Training Epoch: 4 [7120/45000]\tLoss: 3.7064\tLR: 0.000010\n",
      "Training Epoch: 4 [7136/45000]\tLoss: 3.7652\tLR: 0.000010\n",
      "Training Epoch: 4 [7152/45000]\tLoss: 3.6965\tLR: 0.000010\n",
      "Training Epoch: 4 [7168/45000]\tLoss: 3.5742\tLR: 0.000010\n",
      "Training Epoch: 4 [7184/45000]\tLoss: 3.6909\tLR: 0.000010\n",
      "Training Epoch: 4 [7200/45000]\tLoss: 3.6864\tLR: 0.000010\n",
      "Training Epoch: 4 [7216/45000]\tLoss: 3.6874\tLR: 0.000010\n",
      "Training Epoch: 4 [7232/45000]\tLoss: 3.6457\tLR: 0.000010\n",
      "Training Epoch: 4 [7248/45000]\tLoss: 3.7340\tLR: 0.000010\n",
      "Training Epoch: 4 [7264/45000]\tLoss: 3.7059\tLR: 0.000010\n",
      "Training Epoch: 4 [7280/45000]\tLoss: 3.6823\tLR: 0.000010\n",
      "Training Epoch: 4 [7296/45000]\tLoss: 3.7601\tLR: 0.000010\n",
      "Training Epoch: 4 [7312/45000]\tLoss: 3.8305\tLR: 0.000010\n",
      "Training Epoch: 4 [7328/45000]\tLoss: 3.6664\tLR: 0.000010\n",
      "Training Epoch: 4 [7344/45000]\tLoss: 3.6224\tLR: 0.000010\n",
      "Training Epoch: 4 [7360/45000]\tLoss: 3.5611\tLR: 0.000010\n",
      "Training Epoch: 4 [7376/45000]\tLoss: 3.5600\tLR: 0.000010\n",
      "Training Epoch: 4 [7392/45000]\tLoss: 3.6521\tLR: 0.000010\n",
      "Training Epoch: 4 [7408/45000]\tLoss: 3.7175\tLR: 0.000010\n",
      "Training Epoch: 4 [7424/45000]\tLoss: 3.6190\tLR: 0.000010\n",
      "Training Epoch: 4 [7440/45000]\tLoss: 3.7105\tLR: 0.000010\n",
      "Training Epoch: 4 [7456/45000]\tLoss: 3.6662\tLR: 0.000010\n",
      "Training Epoch: 4 [7472/45000]\tLoss: 3.6254\tLR: 0.000010\n",
      "Training Epoch: 4 [7488/45000]\tLoss: 3.8272\tLR: 0.000010\n",
      "Training Epoch: 4 [7504/45000]\tLoss: 3.6232\tLR: 0.000010\n",
      "Training Epoch: 4 [7520/45000]\tLoss: 3.6977\tLR: 0.000010\n",
      "Training Epoch: 4 [7536/45000]\tLoss: 3.7011\tLR: 0.000010\n",
      "Training Epoch: 4 [7552/45000]\tLoss: 3.7732\tLR: 0.000010\n",
      "Training Epoch: 4 [7568/45000]\tLoss: 3.6901\tLR: 0.000010\n",
      "Training Epoch: 4 [7584/45000]\tLoss: 3.7289\tLR: 0.000010\n",
      "Training Epoch: 4 [7600/45000]\tLoss: 3.6283\tLR: 0.000010\n",
      "Training Epoch: 4 [7616/45000]\tLoss: 3.6538\tLR: 0.000010\n",
      "Training Epoch: 4 [7632/45000]\tLoss: 3.5912\tLR: 0.000010\n",
      "Training Epoch: 4 [7648/45000]\tLoss: 3.6744\tLR: 0.000010\n",
      "Training Epoch: 4 [7664/45000]\tLoss: 3.6276\tLR: 0.000010\n",
      "Training Epoch: 4 [7680/45000]\tLoss: 3.6477\tLR: 0.000010\n",
      "Training Epoch: 4 [7696/45000]\tLoss: 3.6430\tLR: 0.000010\n",
      "Training Epoch: 4 [7712/45000]\tLoss: 3.6608\tLR: 0.000010\n",
      "Training Epoch: 4 [7728/45000]\tLoss: 3.6677\tLR: 0.000010\n",
      "Training Epoch: 4 [7744/45000]\tLoss: 3.6497\tLR: 0.000010\n",
      "Training Epoch: 4 [7760/45000]\tLoss: 3.6404\tLR: 0.000010\n",
      "Training Epoch: 4 [7776/45000]\tLoss: 3.8012\tLR: 0.000010\n",
      "Training Epoch: 4 [7792/45000]\tLoss: 3.6360\tLR: 0.000010\n",
      "Training Epoch: 4 [7808/45000]\tLoss: 3.6152\tLR: 0.000010\n",
      "Training Epoch: 4 [7824/45000]\tLoss: 3.7486\tLR: 0.000010\n",
      "Training Epoch: 4 [7840/45000]\tLoss: 3.6709\tLR: 0.000010\n",
      "Training Epoch: 4 [7856/45000]\tLoss: 3.7440\tLR: 0.000010\n",
      "Training Epoch: 4 [7872/45000]\tLoss: 3.7003\tLR: 0.000010\n",
      "Training Epoch: 4 [7888/45000]\tLoss: 3.6184\tLR: 0.000010\n",
      "Training Epoch: 4 [7904/45000]\tLoss: 3.6337\tLR: 0.000010\n",
      "Training Epoch: 4 [7920/45000]\tLoss: 3.6780\tLR: 0.000010\n",
      "Training Epoch: 4 [7936/45000]\tLoss: 3.6940\tLR: 0.000010\n",
      "Training Epoch: 4 [7952/45000]\tLoss: 3.5442\tLR: 0.000010\n",
      "Training Epoch: 4 [7968/45000]\tLoss: 3.6776\tLR: 0.000010\n",
      "Training Epoch: 4 [7984/45000]\tLoss: 3.6094\tLR: 0.000010\n",
      "Training Epoch: 4 [8000/45000]\tLoss: 3.6681\tLR: 0.000010\n",
      "Training Epoch: 4 [8016/45000]\tLoss: 3.5511\tLR: 0.000010\n",
      "Training Epoch: 4 [8032/45000]\tLoss: 3.8542\tLR: 0.000010\n",
      "Training Epoch: 4 [8048/45000]\tLoss: 3.6497\tLR: 0.000010\n",
      "Training Epoch: 4 [8064/45000]\tLoss: 3.7470\tLR: 0.000010\n",
      "Training Epoch: 4 [8080/45000]\tLoss: 3.6731\tLR: 0.000010\n",
      "Training Epoch: 4 [8096/45000]\tLoss: 3.5710\tLR: 0.000010\n",
      "Training Epoch: 4 [8112/45000]\tLoss: 3.6875\tLR: 0.000010\n",
      "Training Epoch: 4 [8128/45000]\tLoss: 3.5714\tLR: 0.000010\n",
      "Training Epoch: 4 [8144/45000]\tLoss: 3.6019\tLR: 0.000010\n",
      "Training Epoch: 4 [8160/45000]\tLoss: 3.6663\tLR: 0.000010\n",
      "Training Epoch: 4 [8176/45000]\tLoss: 3.6924\tLR: 0.000010\n",
      "Training Epoch: 4 [8192/45000]\tLoss: 3.6354\tLR: 0.000010\n",
      "Training Epoch: 4 [8208/45000]\tLoss: 3.7868\tLR: 0.000010\n",
      "Training Epoch: 4 [8224/45000]\tLoss: 3.6881\tLR: 0.000010\n",
      "Training Epoch: 4 [8240/45000]\tLoss: 3.6849\tLR: 0.000010\n",
      "Training Epoch: 4 [8256/45000]\tLoss: 3.7835\tLR: 0.000010\n",
      "Training Epoch: 4 [8272/45000]\tLoss: 3.6726\tLR: 0.000010\n",
      "Training Epoch: 4 [8288/45000]\tLoss: 3.6376\tLR: 0.000010\n",
      "Training Epoch: 4 [8304/45000]\tLoss: 3.6176\tLR: 0.000010\n",
      "Training Epoch: 4 [8320/45000]\tLoss: 3.6889\tLR: 0.000010\n",
      "Training Epoch: 4 [8336/45000]\tLoss: 3.6573\tLR: 0.000010\n",
      "Training Epoch: 4 [8352/45000]\tLoss: 3.7122\tLR: 0.000010\n",
      "Training Epoch: 4 [8368/45000]\tLoss: 3.5713\tLR: 0.000010\n",
      "Training Epoch: 4 [8384/45000]\tLoss: 3.6566\tLR: 0.000010\n",
      "Training Epoch: 4 [8400/45000]\tLoss: 3.6874\tLR: 0.000010\n",
      "Training Epoch: 4 [8416/45000]\tLoss: 3.8348\tLR: 0.000010\n",
      "Training Epoch: 4 [8432/45000]\tLoss: 3.7921\tLR: 0.000010\n",
      "Training Epoch: 4 [8448/45000]\tLoss: 3.6452\tLR: 0.000010\n",
      "Training Epoch: 4 [8464/45000]\tLoss: 3.7662\tLR: 0.000010\n",
      "Training Epoch: 4 [8480/45000]\tLoss: 3.7387\tLR: 0.000010\n",
      "Training Epoch: 4 [8496/45000]\tLoss: 3.7298\tLR: 0.000010\n",
      "Training Epoch: 4 [8512/45000]\tLoss: 3.7097\tLR: 0.000010\n",
      "Training Epoch: 4 [8528/45000]\tLoss: 3.5939\tLR: 0.000010\n",
      "Training Epoch: 4 [8544/45000]\tLoss: 3.6715\tLR: 0.000010\n",
      "Training Epoch: 4 [8560/45000]\tLoss: 3.6780\tLR: 0.000010\n",
      "Training Epoch: 4 [8576/45000]\tLoss: 3.6893\tLR: 0.000010\n",
      "Training Epoch: 4 [8592/45000]\tLoss: 3.7365\tLR: 0.000010\n",
      "Training Epoch: 4 [8608/45000]\tLoss: 3.6484\tLR: 0.000010\n",
      "Training Epoch: 4 [8624/45000]\tLoss: 3.7417\tLR: 0.000010\n",
      "Training Epoch: 4 [8640/45000]\tLoss: 3.6946\tLR: 0.000010\n",
      "Training Epoch: 4 [8656/45000]\tLoss: 3.8128\tLR: 0.000010\n",
      "Training Epoch: 4 [8672/45000]\tLoss: 3.6159\tLR: 0.000010\n",
      "Training Epoch: 4 [8688/45000]\tLoss: 3.6203\tLR: 0.000010\n",
      "Training Epoch: 4 [8704/45000]\tLoss: 3.6587\tLR: 0.000010\n",
      "Training Epoch: 4 [8720/45000]\tLoss: 3.5159\tLR: 0.000010\n",
      "Training Epoch: 4 [8736/45000]\tLoss: 3.7024\tLR: 0.000010\n",
      "Training Epoch: 4 [8752/45000]\tLoss: 3.6261\tLR: 0.000010\n",
      "Training Epoch: 4 [8768/45000]\tLoss: 3.7925\tLR: 0.000010\n",
      "Training Epoch: 4 [8784/45000]\tLoss: 3.8189\tLR: 0.000010\n",
      "Training Epoch: 4 [8800/45000]\tLoss: 3.7271\tLR: 0.000010\n",
      "Training Epoch: 4 [8816/45000]\tLoss: 3.6372\tLR: 0.000010\n",
      "Training Epoch: 4 [8832/45000]\tLoss: 3.6506\tLR: 0.000010\n",
      "Training Epoch: 4 [8848/45000]\tLoss: 3.7246\tLR: 0.000010\n",
      "Training Epoch: 4 [8864/45000]\tLoss: 3.6853\tLR: 0.000010\n",
      "Training Epoch: 4 [8880/45000]\tLoss: 3.5833\tLR: 0.000010\n",
      "Training Epoch: 4 [8896/45000]\tLoss: 3.6207\tLR: 0.000010\n",
      "Training Epoch: 4 [8912/45000]\tLoss: 3.7856\tLR: 0.000010\n",
      "Training Epoch: 4 [8928/45000]\tLoss: 3.5779\tLR: 0.000010\n",
      "Training Epoch: 4 [8944/45000]\tLoss: 3.6356\tLR: 0.000010\n",
      "Training Epoch: 4 [8960/45000]\tLoss: 3.6532\tLR: 0.000010\n",
      "Training Epoch: 4 [8976/45000]\tLoss: 3.7223\tLR: 0.000010\n",
      "Training Epoch: 4 [8992/45000]\tLoss: 3.5854\tLR: 0.000010\n",
      "Training Epoch: 4 [9008/45000]\tLoss: 3.7023\tLR: 0.000010\n",
      "Training Epoch: 4 [9024/45000]\tLoss: 3.5803\tLR: 0.000010\n",
      "Training Epoch: 4 [9040/45000]\tLoss: 3.7253\tLR: 0.000010\n",
      "Training Epoch: 4 [9056/45000]\tLoss: 3.8150\tLR: 0.000010\n",
      "Training Epoch: 4 [9072/45000]\tLoss: 3.6980\tLR: 0.000010\n",
      "Training Epoch: 4 [9088/45000]\tLoss: 3.7207\tLR: 0.000010\n",
      "Training Epoch: 4 [9104/45000]\tLoss: 3.5412\tLR: 0.000010\n",
      "Training Epoch: 4 [9120/45000]\tLoss: 3.6216\tLR: 0.000010\n",
      "Training Epoch: 4 [9136/45000]\tLoss: 3.6850\tLR: 0.000010\n",
      "Training Epoch: 4 [9152/45000]\tLoss: 3.8580\tLR: 0.000010\n",
      "Training Epoch: 4 [9168/45000]\tLoss: 3.6314\tLR: 0.000010\n",
      "Training Epoch: 4 [9184/45000]\tLoss: 3.7061\tLR: 0.000010\n",
      "Training Epoch: 4 [9200/45000]\tLoss: 3.5389\tLR: 0.000010\n",
      "Training Epoch: 4 [9216/45000]\tLoss: 3.7806\tLR: 0.000010\n",
      "Training Epoch: 4 [9232/45000]\tLoss: 3.6739\tLR: 0.000010\n",
      "Training Epoch: 4 [9248/45000]\tLoss: 3.6141\tLR: 0.000010\n",
      "Training Epoch: 4 [9264/45000]\tLoss: 3.5265\tLR: 0.000010\n",
      "Training Epoch: 4 [9280/45000]\tLoss: 3.6307\tLR: 0.000010\n",
      "Training Epoch: 4 [9296/45000]\tLoss: 3.7172\tLR: 0.000010\n",
      "Training Epoch: 4 [9312/45000]\tLoss: 3.7737\tLR: 0.000010\n",
      "Training Epoch: 4 [9328/45000]\tLoss: 3.5396\tLR: 0.000010\n",
      "Training Epoch: 4 [9344/45000]\tLoss: 3.7073\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [9360/45000]\tLoss: 3.8737\tLR: 0.000010\n",
      "Training Epoch: 4 [9376/45000]\tLoss: 3.5858\tLR: 0.000010\n",
      "Training Epoch: 4 [9392/45000]\tLoss: 3.7144\tLR: 0.000010\n",
      "Training Epoch: 4 [9408/45000]\tLoss: 3.6266\tLR: 0.000010\n",
      "Training Epoch: 4 [9424/45000]\tLoss: 3.8175\tLR: 0.000010\n",
      "Training Epoch: 4 [9440/45000]\tLoss: 3.5918\tLR: 0.000010\n",
      "Training Epoch: 4 [9456/45000]\tLoss: 3.7167\tLR: 0.000010\n",
      "Training Epoch: 4 [9472/45000]\tLoss: 3.5964\tLR: 0.000010\n",
      "Training Epoch: 4 [9488/45000]\tLoss: 3.6782\tLR: 0.000010\n",
      "Training Epoch: 4 [9504/45000]\tLoss: 3.6973\tLR: 0.000010\n",
      "Training Epoch: 4 [9520/45000]\tLoss: 3.6940\tLR: 0.000010\n",
      "Training Epoch: 4 [9536/45000]\tLoss: 3.6417\tLR: 0.000010\n",
      "Training Epoch: 4 [9552/45000]\tLoss: 3.6700\tLR: 0.000010\n",
      "Training Epoch: 4 [9568/45000]\tLoss: 3.6931\tLR: 0.000010\n",
      "Training Epoch: 4 [9584/45000]\tLoss: 3.7130\tLR: 0.000010\n",
      "Training Epoch: 4 [9600/45000]\tLoss: 3.7122\tLR: 0.000010\n",
      "Training Epoch: 4 [9616/45000]\tLoss: 3.6922\tLR: 0.000010\n",
      "Training Epoch: 4 [9632/45000]\tLoss: 3.5656\tLR: 0.000010\n",
      "Training Epoch: 4 [9648/45000]\tLoss: 3.6269\tLR: 0.000010\n",
      "Training Epoch: 4 [9664/45000]\tLoss: 3.5780\tLR: 0.000010\n",
      "Training Epoch: 4 [9680/45000]\tLoss: 3.5358\tLR: 0.000010\n",
      "Training Epoch: 4 [9696/45000]\tLoss: 3.5954\tLR: 0.000010\n",
      "Training Epoch: 4 [9712/45000]\tLoss: 3.7880\tLR: 0.000010\n",
      "Training Epoch: 4 [9728/45000]\tLoss: 3.6415\tLR: 0.000010\n",
      "Training Epoch: 4 [9744/45000]\tLoss: 3.6343\tLR: 0.000010\n",
      "Training Epoch: 4 [9760/45000]\tLoss: 3.7360\tLR: 0.000010\n",
      "Training Epoch: 4 [9776/45000]\tLoss: 3.7578\tLR: 0.000010\n",
      "Training Epoch: 4 [9792/45000]\tLoss: 3.8586\tLR: 0.000010\n",
      "Training Epoch: 4 [9808/45000]\tLoss: 3.5013\tLR: 0.000010\n",
      "Training Epoch: 4 [9824/45000]\tLoss: 3.6747\tLR: 0.000010\n",
      "Training Epoch: 4 [9840/45000]\tLoss: 3.6799\tLR: 0.000010\n",
      "Training Epoch: 4 [9856/45000]\tLoss: 3.6475\tLR: 0.000010\n",
      "Training Epoch: 4 [9872/45000]\tLoss: 3.6345\tLR: 0.000010\n",
      "Training Epoch: 4 [9888/45000]\tLoss: 3.6262\tLR: 0.000010\n",
      "Training Epoch: 4 [9904/45000]\tLoss: 3.6495\tLR: 0.000010\n",
      "Training Epoch: 4 [9920/45000]\tLoss: 3.6800\tLR: 0.000010\n",
      "Training Epoch: 4 [9936/45000]\tLoss: 3.6696\tLR: 0.000010\n",
      "Training Epoch: 4 [9952/45000]\tLoss: 3.6695\tLR: 0.000010\n",
      "Training Epoch: 4 [9968/45000]\tLoss: 3.7089\tLR: 0.000010\n",
      "Training Epoch: 4 [9984/45000]\tLoss: 3.6458\tLR: 0.000010\n",
      "Training Epoch: 4 [10000/45000]\tLoss: 3.6318\tLR: 0.000010\n",
      "Training Epoch: 4 [10016/45000]\tLoss: 3.6293\tLR: 0.000010\n",
      "Training Epoch: 4 [10032/45000]\tLoss: 3.7324\tLR: 0.000010\n",
      "Training Epoch: 4 [10048/45000]\tLoss: 3.7619\tLR: 0.000010\n",
      "Training Epoch: 4 [10064/45000]\tLoss: 3.7548\tLR: 0.000010\n",
      "Training Epoch: 4 [10080/45000]\tLoss: 3.6559\tLR: 0.000010\n",
      "Training Epoch: 4 [10096/45000]\tLoss: 3.6266\tLR: 0.000010\n",
      "Training Epoch: 4 [10112/45000]\tLoss: 3.6398\tLR: 0.000010\n",
      "Training Epoch: 4 [10128/45000]\tLoss: 3.5984\tLR: 0.000010\n",
      "Training Epoch: 4 [10144/45000]\tLoss: 3.7667\tLR: 0.000010\n",
      "Training Epoch: 4 [10160/45000]\tLoss: 3.6956\tLR: 0.000010\n",
      "Training Epoch: 4 [10176/45000]\tLoss: 3.6518\tLR: 0.000010\n",
      "Training Epoch: 4 [10192/45000]\tLoss: 3.6360\tLR: 0.000010\n",
      "Training Epoch: 4 [10208/45000]\tLoss: 3.6773\tLR: 0.000010\n",
      "Training Epoch: 4 [10224/45000]\tLoss: 3.6362\tLR: 0.000010\n",
      "Training Epoch: 4 [10240/45000]\tLoss: 3.7395\tLR: 0.000010\n",
      "Training Epoch: 4 [10256/45000]\tLoss: 3.7279\tLR: 0.000010\n",
      "Training Epoch: 4 [10272/45000]\tLoss: 3.6457\tLR: 0.000010\n",
      "Training Epoch: 4 [10288/45000]\tLoss: 3.5959\tLR: 0.000010\n",
      "Training Epoch: 4 [10304/45000]\tLoss: 3.7166\tLR: 0.000010\n",
      "Training Epoch: 4 [10320/45000]\tLoss: 3.6681\tLR: 0.000010\n",
      "Training Epoch: 4 [10336/45000]\tLoss: 3.7159\tLR: 0.000010\n",
      "Training Epoch: 4 [10352/45000]\tLoss: 3.6821\tLR: 0.000010\n",
      "Training Epoch: 4 [10368/45000]\tLoss: 3.6446\tLR: 0.000010\n",
      "Training Epoch: 4 [10384/45000]\tLoss: 3.7477\tLR: 0.000010\n",
      "Training Epoch: 4 [10400/45000]\tLoss: 3.5344\tLR: 0.000010\n",
      "Training Epoch: 4 [10416/45000]\tLoss: 3.6313\tLR: 0.000010\n",
      "Training Epoch: 4 [10432/45000]\tLoss: 3.6800\tLR: 0.000010\n",
      "Training Epoch: 4 [10448/45000]\tLoss: 3.7242\tLR: 0.000010\n",
      "Training Epoch: 4 [10464/45000]\tLoss: 3.5905\tLR: 0.000010\n",
      "Training Epoch: 4 [10480/45000]\tLoss: 3.7026\tLR: 0.000010\n",
      "Training Epoch: 4 [10496/45000]\tLoss: 3.6771\tLR: 0.000010\n",
      "Training Epoch: 4 [10512/45000]\tLoss: 3.6654\tLR: 0.000010\n",
      "Training Epoch: 4 [10528/45000]\tLoss: 3.7269\tLR: 0.000010\n",
      "Training Epoch: 4 [10544/45000]\tLoss: 3.6285\tLR: 0.000010\n",
      "Training Epoch: 4 [10560/45000]\tLoss: 3.6084\tLR: 0.000010\n",
      "Training Epoch: 4 [10576/45000]\tLoss: 3.6382\tLR: 0.000010\n",
      "Training Epoch: 4 [10592/45000]\tLoss: 3.9659\tLR: 0.000010\n",
      "Training Epoch: 4 [10608/45000]\tLoss: 3.6434\tLR: 0.000010\n",
      "Training Epoch: 4 [10624/45000]\tLoss: 3.6095\tLR: 0.000010\n",
      "Training Epoch: 4 [10640/45000]\tLoss: 3.6880\tLR: 0.000010\n",
      "Training Epoch: 4 [10656/45000]\tLoss: 3.5755\tLR: 0.000010\n",
      "Training Epoch: 4 [10672/45000]\tLoss: 3.6752\tLR: 0.000010\n",
      "Training Epoch: 4 [10688/45000]\tLoss: 3.7320\tLR: 0.000010\n",
      "Training Epoch: 4 [10704/45000]\tLoss: 3.6526\tLR: 0.000010\n",
      "Training Epoch: 4 [10720/45000]\tLoss: 3.6290\tLR: 0.000010\n",
      "Training Epoch: 4 [10736/45000]\tLoss: 3.6045\tLR: 0.000010\n",
      "Training Epoch: 4 [10752/45000]\tLoss: 3.6410\tLR: 0.000010\n",
      "Training Epoch: 4 [10768/45000]\tLoss: 3.6648\tLR: 0.000010\n",
      "Training Epoch: 4 [10784/45000]\tLoss: 3.6674\tLR: 0.000010\n",
      "Training Epoch: 4 [10800/45000]\tLoss: 3.7770\tLR: 0.000010\n",
      "Training Epoch: 4 [10816/45000]\tLoss: 3.6634\tLR: 0.000010\n",
      "Training Epoch: 4 [10832/45000]\tLoss: 3.6374\tLR: 0.000010\n",
      "Training Epoch: 4 [10848/45000]\tLoss: 3.7745\tLR: 0.000010\n",
      "Training Epoch: 4 [10864/45000]\tLoss: 3.6384\tLR: 0.000010\n",
      "Training Epoch: 4 [10880/45000]\tLoss: 3.7255\tLR: 0.000010\n",
      "Training Epoch: 4 [10896/45000]\tLoss: 3.7347\tLR: 0.000010\n",
      "Training Epoch: 4 [10912/45000]\tLoss: 3.7123\tLR: 0.000010\n",
      "Training Epoch: 4 [10928/45000]\tLoss: 3.6325\tLR: 0.000010\n",
      "Training Epoch: 4 [10944/45000]\tLoss: 3.6996\tLR: 0.000010\n",
      "Training Epoch: 4 [10960/45000]\tLoss: 3.7774\tLR: 0.000010\n",
      "Training Epoch: 4 [10976/45000]\tLoss: 3.6446\tLR: 0.000010\n",
      "Training Epoch: 4 [10992/45000]\tLoss: 3.7221\tLR: 0.000010\n",
      "Training Epoch: 4 [11008/45000]\tLoss: 3.7612\tLR: 0.000010\n",
      "Training Epoch: 4 [11024/45000]\tLoss: 3.5887\tLR: 0.000010\n",
      "Training Epoch: 4 [11040/45000]\tLoss: 3.7190\tLR: 0.000010\n",
      "Training Epoch: 4 [11056/45000]\tLoss: 3.7072\tLR: 0.000010\n",
      "Training Epoch: 4 [11072/45000]\tLoss: 3.5900\tLR: 0.000010\n",
      "Training Epoch: 4 [11088/45000]\tLoss: 3.7148\tLR: 0.000010\n",
      "Training Epoch: 4 [11104/45000]\tLoss: 3.6496\tLR: 0.000010\n",
      "Training Epoch: 4 [11120/45000]\tLoss: 3.7499\tLR: 0.000010\n",
      "Training Epoch: 4 [11136/45000]\tLoss: 3.6782\tLR: 0.000010\n",
      "Training Epoch: 4 [11152/45000]\tLoss: 3.5939\tLR: 0.000010\n",
      "Training Epoch: 4 [11168/45000]\tLoss: 3.6865\tLR: 0.000010\n",
      "Training Epoch: 4 [11184/45000]\tLoss: 3.7043\tLR: 0.000010\n",
      "Training Epoch: 4 [11200/45000]\tLoss: 3.6657\tLR: 0.000010\n",
      "Training Epoch: 4 [11216/45000]\tLoss: 3.6332\tLR: 0.000010\n",
      "Training Epoch: 4 [11232/45000]\tLoss: 3.5585\tLR: 0.000010\n",
      "Training Epoch: 4 [11248/45000]\tLoss: 3.6713\tLR: 0.000010\n",
      "Training Epoch: 4 [11264/45000]\tLoss: 3.6581\tLR: 0.000010\n",
      "Training Epoch: 4 [11280/45000]\tLoss: 3.7539\tLR: 0.000010\n",
      "Training Epoch: 4 [11296/45000]\tLoss: 3.6651\tLR: 0.000010\n",
      "Training Epoch: 4 [11312/45000]\tLoss: 3.6610\tLR: 0.000010\n",
      "Training Epoch: 4 [11328/45000]\tLoss: 3.7508\tLR: 0.000010\n",
      "Training Epoch: 4 [11344/45000]\tLoss: 3.7135\tLR: 0.000010\n",
      "Training Epoch: 4 [11360/45000]\tLoss: 3.6410\tLR: 0.000010\n",
      "Training Epoch: 4 [11376/45000]\tLoss: 3.6527\tLR: 0.000010\n",
      "Training Epoch: 4 [11392/45000]\tLoss: 3.6363\tLR: 0.000010\n",
      "Training Epoch: 4 [11408/45000]\tLoss: 3.6858\tLR: 0.000010\n",
      "Training Epoch: 4 [11424/45000]\tLoss: 3.7249\tLR: 0.000010\n",
      "Training Epoch: 4 [11440/45000]\tLoss: 3.6885\tLR: 0.000010\n",
      "Training Epoch: 4 [11456/45000]\tLoss: 3.5745\tLR: 0.000010\n",
      "Training Epoch: 4 [11472/45000]\tLoss: 3.7069\tLR: 0.000010\n",
      "Training Epoch: 4 [11488/45000]\tLoss: 3.6307\tLR: 0.000010\n",
      "Training Epoch: 4 [11504/45000]\tLoss: 3.7019\tLR: 0.000010\n",
      "Training Epoch: 4 [11520/45000]\tLoss: 3.6073\tLR: 0.000010\n",
      "Training Epoch: 4 [11536/45000]\tLoss: 3.7062\tLR: 0.000010\n",
      "Training Epoch: 4 [11552/45000]\tLoss: 3.6874\tLR: 0.000010\n",
      "Training Epoch: 4 [11568/45000]\tLoss: 3.8305\tLR: 0.000010\n",
      "Training Epoch: 4 [11584/45000]\tLoss: 3.6156\tLR: 0.000010\n",
      "Training Epoch: 4 [11600/45000]\tLoss: 3.6123\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [11616/45000]\tLoss: 3.5647\tLR: 0.000010\n",
      "Training Epoch: 4 [11632/45000]\tLoss: 3.7377\tLR: 0.000010\n",
      "Training Epoch: 4 [11648/45000]\tLoss: 3.6566\tLR: 0.000010\n",
      "Training Epoch: 4 [11664/45000]\tLoss: 3.7021\tLR: 0.000010\n",
      "Training Epoch: 4 [11680/45000]\tLoss: 3.6878\tLR: 0.000010\n",
      "Training Epoch: 4 [11696/45000]\tLoss: 3.6829\tLR: 0.000010\n",
      "Training Epoch: 4 [11712/45000]\tLoss: 3.7298\tLR: 0.000010\n",
      "Training Epoch: 4 [11728/45000]\tLoss: 3.6547\tLR: 0.000010\n",
      "Training Epoch: 4 [11744/45000]\tLoss: 3.7251\tLR: 0.000010\n",
      "Training Epoch: 4 [11760/45000]\tLoss: 3.6283\tLR: 0.000010\n",
      "Training Epoch: 4 [11776/45000]\tLoss: 3.5879\tLR: 0.000010\n",
      "Training Epoch: 4 [11792/45000]\tLoss: 3.7075\tLR: 0.000010\n",
      "Training Epoch: 4 [11808/45000]\tLoss: 3.5891\tLR: 0.000010\n",
      "Training Epoch: 4 [11824/45000]\tLoss: 3.5918\tLR: 0.000010\n",
      "Training Epoch: 4 [11840/45000]\tLoss: 3.6155\tLR: 0.000010\n",
      "Training Epoch: 4 [11856/45000]\tLoss: 3.6251\tLR: 0.000010\n",
      "Training Epoch: 4 [11872/45000]\tLoss: 3.6726\tLR: 0.000010\n",
      "Training Epoch: 4 [11888/45000]\tLoss: 3.7489\tLR: 0.000010\n",
      "Training Epoch: 4 [11904/45000]\tLoss: 3.5884\tLR: 0.000010\n",
      "Training Epoch: 4 [11920/45000]\tLoss: 3.6799\tLR: 0.000010\n",
      "Training Epoch: 4 [11936/45000]\tLoss: 3.5379\tLR: 0.000010\n",
      "Training Epoch: 4 [11952/45000]\tLoss: 3.6849\tLR: 0.000010\n",
      "Training Epoch: 4 [11968/45000]\tLoss: 3.6759\tLR: 0.000010\n",
      "Training Epoch: 4 [11984/45000]\tLoss: 3.7818\tLR: 0.000010\n",
      "Training Epoch: 4 [12000/45000]\tLoss: 3.6435\tLR: 0.000010\n",
      "Training Epoch: 4 [12016/45000]\tLoss: 3.5780\tLR: 0.000010\n",
      "Training Epoch: 4 [12032/45000]\tLoss: 3.6876\tLR: 0.000010\n",
      "Training Epoch: 4 [12048/45000]\tLoss: 3.8153\tLR: 0.000010\n",
      "Training Epoch: 4 [12064/45000]\tLoss: 3.6707\tLR: 0.000010\n",
      "Training Epoch: 4 [12080/45000]\tLoss: 3.7424\tLR: 0.000010\n",
      "Training Epoch: 4 [12096/45000]\tLoss: 3.7672\tLR: 0.000010\n",
      "Training Epoch: 4 [12112/45000]\tLoss: 3.7236\tLR: 0.000010\n",
      "Training Epoch: 4 [12128/45000]\tLoss: 3.7294\tLR: 0.000010\n",
      "Training Epoch: 4 [12144/45000]\tLoss: 3.7068\tLR: 0.000010\n",
      "Training Epoch: 4 [12160/45000]\tLoss: 3.7105\tLR: 0.000010\n",
      "Training Epoch: 4 [12176/45000]\tLoss: 3.6851\tLR: 0.000010\n",
      "Training Epoch: 4 [12192/45000]\tLoss: 3.7047\tLR: 0.000010\n",
      "Training Epoch: 4 [12208/45000]\tLoss: 3.5793\tLR: 0.000010\n",
      "Training Epoch: 4 [12224/45000]\tLoss: 3.6770\tLR: 0.000010\n",
      "Training Epoch: 4 [12240/45000]\tLoss: 3.6159\tLR: 0.000010\n",
      "Training Epoch: 4 [12256/45000]\tLoss: 3.6627\tLR: 0.000010\n",
      "Training Epoch: 4 [12272/45000]\tLoss: 3.7176\tLR: 0.000010\n",
      "Training Epoch: 4 [12288/45000]\tLoss: 3.6548\tLR: 0.000010\n",
      "Training Epoch: 4 [12304/45000]\tLoss: 3.7058\tLR: 0.000010\n",
      "Training Epoch: 4 [12320/45000]\tLoss: 3.5800\tLR: 0.000010\n",
      "Training Epoch: 4 [12336/45000]\tLoss: 3.6806\tLR: 0.000010\n",
      "Training Epoch: 4 [12352/45000]\tLoss: 3.6409\tLR: 0.000010\n",
      "Training Epoch: 4 [12368/45000]\tLoss: 3.6698\tLR: 0.000010\n",
      "Training Epoch: 4 [12384/45000]\tLoss: 3.8033\tLR: 0.000010\n",
      "Training Epoch: 4 [12400/45000]\tLoss: 3.6360\tLR: 0.000010\n",
      "Training Epoch: 4 [12416/45000]\tLoss: 3.6126\tLR: 0.000010\n",
      "Training Epoch: 4 [12432/45000]\tLoss: 3.6714\tLR: 0.000010\n",
      "Training Epoch: 4 [12448/45000]\tLoss: 3.6665\tLR: 0.000010\n",
      "Training Epoch: 4 [12464/45000]\tLoss: 3.7257\tLR: 0.000010\n",
      "Training Epoch: 4 [12480/45000]\tLoss: 3.8089\tLR: 0.000010\n",
      "Training Epoch: 4 [12496/45000]\tLoss: 3.5487\tLR: 0.000010\n",
      "Training Epoch: 4 [12512/45000]\tLoss: 3.5992\tLR: 0.000010\n",
      "Training Epoch: 4 [12528/45000]\tLoss: 3.6921\tLR: 0.000010\n",
      "Training Epoch: 4 [12544/45000]\tLoss: 3.7049\tLR: 0.000010\n",
      "Training Epoch: 4 [12560/45000]\tLoss: 3.8101\tLR: 0.000010\n",
      "Training Epoch: 4 [12576/45000]\tLoss: 3.6484\tLR: 0.000010\n",
      "Training Epoch: 4 [12592/45000]\tLoss: 3.6850\tLR: 0.000010\n",
      "Training Epoch: 4 [12608/45000]\tLoss: 3.7125\tLR: 0.000010\n",
      "Training Epoch: 4 [12624/45000]\tLoss: 3.5606\tLR: 0.000010\n",
      "Training Epoch: 4 [12640/45000]\tLoss: 3.6770\tLR: 0.000010\n",
      "Training Epoch: 4 [12656/45000]\tLoss: 3.6103\tLR: 0.000010\n",
      "Training Epoch: 4 [12672/45000]\tLoss: 3.7586\tLR: 0.000010\n",
      "Training Epoch: 4 [12688/45000]\tLoss: 3.5076\tLR: 0.000010\n",
      "Training Epoch: 4 [12704/45000]\tLoss: 3.7471\tLR: 0.000010\n",
      "Training Epoch: 4 [12720/45000]\tLoss: 3.6168\tLR: 0.000010\n",
      "Training Epoch: 4 [12736/45000]\tLoss: 3.7242\tLR: 0.000010\n",
      "Training Epoch: 4 [12752/45000]\tLoss: 3.6630\tLR: 0.000010\n",
      "Training Epoch: 4 [12768/45000]\tLoss: 3.5766\tLR: 0.000010\n",
      "Training Epoch: 4 [12784/45000]\tLoss: 3.6461\tLR: 0.000010\n",
      "Training Epoch: 4 [12800/45000]\tLoss: 3.6966\tLR: 0.000010\n",
      "Training Epoch: 4 [12816/45000]\tLoss: 3.5929\tLR: 0.000010\n",
      "Training Epoch: 4 [12832/45000]\tLoss: 3.7120\tLR: 0.000010\n",
      "Training Epoch: 4 [12848/45000]\tLoss: 3.5844\tLR: 0.000010\n",
      "Training Epoch: 4 [12864/45000]\tLoss: 3.6189\tLR: 0.000010\n",
      "Training Epoch: 4 [12880/45000]\tLoss: 3.5055\tLR: 0.000010\n",
      "Training Epoch: 4 [12896/45000]\tLoss: 3.7075\tLR: 0.000010\n",
      "Training Epoch: 4 [12912/45000]\tLoss: 3.6906\tLR: 0.000010\n",
      "Training Epoch: 4 [12928/45000]\tLoss: 3.8350\tLR: 0.000010\n",
      "Training Epoch: 4 [12944/45000]\tLoss: 3.6211\tLR: 0.000010\n",
      "Training Epoch: 4 [12960/45000]\tLoss: 3.7979\tLR: 0.000010\n",
      "Training Epoch: 4 [12976/45000]\tLoss: 3.7093\tLR: 0.000010\n",
      "Training Epoch: 4 [12992/45000]\tLoss: 3.7358\tLR: 0.000010\n",
      "Training Epoch: 4 [13008/45000]\tLoss: 3.7520\tLR: 0.000010\n",
      "Training Epoch: 4 [13024/45000]\tLoss: 3.6187\tLR: 0.000010\n",
      "Training Epoch: 4 [13040/45000]\tLoss: 3.6414\tLR: 0.000010\n",
      "Training Epoch: 4 [13056/45000]\tLoss: 3.6801\tLR: 0.000010\n",
      "Training Epoch: 4 [13072/45000]\tLoss: 3.6768\tLR: 0.000010\n",
      "Training Epoch: 4 [13088/45000]\tLoss: 3.7138\tLR: 0.000010\n",
      "Training Epoch: 4 [13104/45000]\tLoss: 3.6013\tLR: 0.000010\n",
      "Training Epoch: 4 [13120/45000]\tLoss: 3.6646\tLR: 0.000010\n",
      "Training Epoch: 4 [13136/45000]\tLoss: 3.7166\tLR: 0.000010\n",
      "Training Epoch: 4 [13152/45000]\tLoss: 3.7669\tLR: 0.000010\n",
      "Training Epoch: 4 [13168/45000]\tLoss: 3.6566\tLR: 0.000010\n",
      "Training Epoch: 4 [13184/45000]\tLoss: 3.6736\tLR: 0.000010\n",
      "Training Epoch: 4 [13200/45000]\tLoss: 3.5851\tLR: 0.000010\n",
      "Training Epoch: 4 [13216/45000]\tLoss: 3.6688\tLR: 0.000010\n",
      "Training Epoch: 4 [13232/45000]\tLoss: 3.6349\tLR: 0.000010\n",
      "Training Epoch: 4 [13248/45000]\tLoss: 3.6618\tLR: 0.000010\n",
      "Training Epoch: 4 [13264/45000]\tLoss: 3.6740\tLR: 0.000010\n",
      "Training Epoch: 4 [13280/45000]\tLoss: 3.6038\tLR: 0.000010\n",
      "Training Epoch: 4 [13296/45000]\tLoss: 3.6837\tLR: 0.000010\n",
      "Training Epoch: 4 [13312/45000]\tLoss: 3.6810\tLR: 0.000010\n",
      "Training Epoch: 4 [13328/45000]\tLoss: 3.6888\tLR: 0.000010\n",
      "Training Epoch: 4 [13344/45000]\tLoss: 3.7425\tLR: 0.000010\n",
      "Training Epoch: 4 [13360/45000]\tLoss: 3.7425\tLR: 0.000010\n",
      "Training Epoch: 4 [13376/45000]\tLoss: 3.7001\tLR: 0.000010\n",
      "Training Epoch: 4 [13392/45000]\tLoss: 3.7227\tLR: 0.000010\n",
      "Training Epoch: 4 [13408/45000]\tLoss: 3.6605\tLR: 0.000010\n",
      "Training Epoch: 4 [13424/45000]\tLoss: 3.7110\tLR: 0.000010\n",
      "Training Epoch: 4 [13440/45000]\tLoss: 3.6344\tLR: 0.000010\n",
      "Training Epoch: 4 [13456/45000]\tLoss: 3.6431\tLR: 0.000010\n",
      "Training Epoch: 4 [13472/45000]\tLoss: 3.6089\tLR: 0.000010\n",
      "Training Epoch: 4 [13488/45000]\tLoss: 3.6088\tLR: 0.000010\n",
      "Training Epoch: 4 [13504/45000]\tLoss: 3.7171\tLR: 0.000010\n",
      "Training Epoch: 4 [13520/45000]\tLoss: 3.6914\tLR: 0.000010\n",
      "Training Epoch: 4 [13536/45000]\tLoss: 3.6353\tLR: 0.000010\n",
      "Training Epoch: 4 [13552/45000]\tLoss: 3.6251\tLR: 0.000010\n",
      "Training Epoch: 4 [13568/45000]\tLoss: 3.6241\tLR: 0.000010\n",
      "Training Epoch: 4 [13584/45000]\tLoss: 3.6881\tLR: 0.000010\n",
      "Training Epoch: 4 [13600/45000]\tLoss: 3.7043\tLR: 0.000010\n",
      "Training Epoch: 4 [13616/45000]\tLoss: 3.7404\tLR: 0.000010\n",
      "Training Epoch: 4 [13632/45000]\tLoss: 3.6498\tLR: 0.000010\n",
      "Training Epoch: 4 [13648/45000]\tLoss: 3.6757\tLR: 0.000010\n",
      "Training Epoch: 4 [13664/45000]\tLoss: 3.7949\tLR: 0.000010\n",
      "Training Epoch: 4 [13680/45000]\tLoss: 3.5979\tLR: 0.000010\n",
      "Training Epoch: 4 [13696/45000]\tLoss: 3.6409\tLR: 0.000010\n",
      "Training Epoch: 4 [13712/45000]\tLoss: 3.6885\tLR: 0.000010\n",
      "Training Epoch: 4 [13728/45000]\tLoss: 3.7418\tLR: 0.000010\n",
      "Training Epoch: 4 [13744/45000]\tLoss: 3.5526\tLR: 0.000010\n",
      "Training Epoch: 4 [13760/45000]\tLoss: 3.6286\tLR: 0.000010\n",
      "Training Epoch: 4 [13776/45000]\tLoss: 3.6134\tLR: 0.000010\n",
      "Training Epoch: 4 [13792/45000]\tLoss: 3.7480\tLR: 0.000010\n",
      "Training Epoch: 4 [13808/45000]\tLoss: 3.5965\tLR: 0.000010\n",
      "Training Epoch: 4 [13824/45000]\tLoss: 3.6442\tLR: 0.000010\n",
      "Training Epoch: 4 [13840/45000]\tLoss: 3.6419\tLR: 0.000010\n",
      "Training Epoch: 4 [13856/45000]\tLoss: 3.6380\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [13872/45000]\tLoss: 3.6838\tLR: 0.000010\n",
      "Training Epoch: 4 [13888/45000]\tLoss: 3.6680\tLR: 0.000010\n",
      "Training Epoch: 4 [13904/45000]\tLoss: 3.7033\tLR: 0.000010\n",
      "Training Epoch: 4 [13920/45000]\tLoss: 3.7135\tLR: 0.000010\n",
      "Training Epoch: 4 [13936/45000]\tLoss: 3.6806\tLR: 0.000010\n",
      "Training Epoch: 4 [13952/45000]\tLoss: 3.6801\tLR: 0.000010\n",
      "Training Epoch: 4 [13968/45000]\tLoss: 3.7145\tLR: 0.000010\n",
      "Training Epoch: 4 [13984/45000]\tLoss: 3.7549\tLR: 0.000010\n",
      "Training Epoch: 4 [14000/45000]\tLoss: 3.5946\tLR: 0.000010\n",
      "Training Epoch: 4 [14016/45000]\tLoss: 3.6540\tLR: 0.000010\n",
      "Training Epoch: 4 [14032/45000]\tLoss: 3.7245\tLR: 0.000010\n",
      "Training Epoch: 4 [14048/45000]\tLoss: 3.6931\tLR: 0.000010\n",
      "Training Epoch: 4 [14064/45000]\tLoss: 3.7269\tLR: 0.000010\n",
      "Training Epoch: 4 [14080/45000]\tLoss: 3.7290\tLR: 0.000010\n",
      "Training Epoch: 4 [14096/45000]\tLoss: 3.6497\tLR: 0.000010\n",
      "Training Epoch: 4 [14112/45000]\tLoss: 3.6567\tLR: 0.000010\n",
      "Training Epoch: 4 [14128/45000]\tLoss: 3.6990\tLR: 0.000010\n",
      "Training Epoch: 4 [14144/45000]\tLoss: 3.5227\tLR: 0.000010\n",
      "Training Epoch: 4 [14160/45000]\tLoss: 3.5724\tLR: 0.000010\n",
      "Training Epoch: 4 [14176/45000]\tLoss: 3.6903\tLR: 0.000010\n",
      "Training Epoch: 4 [14192/45000]\tLoss: 3.5518\tLR: 0.000010\n",
      "Training Epoch: 4 [14208/45000]\tLoss: 3.6977\tLR: 0.000010\n",
      "Training Epoch: 4 [14224/45000]\tLoss: 3.6025\tLR: 0.000010\n",
      "Training Epoch: 4 [14240/45000]\tLoss: 3.6637\tLR: 0.000010\n",
      "Training Epoch: 4 [14256/45000]\tLoss: 3.6663\tLR: 0.000010\n",
      "Training Epoch: 4 [14272/45000]\tLoss: 3.6435\tLR: 0.000010\n",
      "Training Epoch: 4 [14288/45000]\tLoss: 3.7292\tLR: 0.000010\n",
      "Training Epoch: 4 [14304/45000]\tLoss: 3.6263\tLR: 0.000010\n",
      "Training Epoch: 4 [14320/45000]\tLoss: 3.5892\tLR: 0.000010\n",
      "Training Epoch: 4 [14336/45000]\tLoss: 3.6726\tLR: 0.000010\n",
      "Training Epoch: 4 [14352/45000]\tLoss: 3.6646\tLR: 0.000010\n",
      "Training Epoch: 4 [14368/45000]\tLoss: 3.6564\tLR: 0.000010\n",
      "Training Epoch: 4 [14384/45000]\tLoss: 3.6500\tLR: 0.000010\n",
      "Training Epoch: 4 [14400/45000]\tLoss: 3.6219\tLR: 0.000010\n",
      "Training Epoch: 4 [14416/45000]\tLoss: 3.6887\tLR: 0.000010\n",
      "Training Epoch: 4 [14432/45000]\tLoss: 3.6958\tLR: 0.000010\n",
      "Training Epoch: 4 [14448/45000]\tLoss: 3.7491\tLR: 0.000010\n",
      "Training Epoch: 4 [14464/45000]\tLoss: 3.6693\tLR: 0.000010\n",
      "Training Epoch: 4 [14480/45000]\tLoss: 3.6667\tLR: 0.000010\n",
      "Training Epoch: 4 [14496/45000]\tLoss: 3.5817\tLR: 0.000010\n",
      "Training Epoch: 4 [14512/45000]\tLoss: 3.7170\tLR: 0.000010\n",
      "Training Epoch: 4 [14528/45000]\tLoss: 3.6701\tLR: 0.000010\n",
      "Training Epoch: 4 [14544/45000]\tLoss: 3.6723\tLR: 0.000010\n",
      "Training Epoch: 4 [14560/45000]\tLoss: 3.6075\tLR: 0.000010\n",
      "Training Epoch: 4 [14576/45000]\tLoss: 3.7793\tLR: 0.000010\n",
      "Training Epoch: 4 [14592/45000]\tLoss: 3.6759\tLR: 0.000010\n",
      "Training Epoch: 4 [14608/45000]\tLoss: 3.7430\tLR: 0.000010\n",
      "Training Epoch: 4 [14624/45000]\tLoss: 3.6541\tLR: 0.000010\n",
      "Training Epoch: 4 [14640/45000]\tLoss: 3.6446\tLR: 0.000010\n",
      "Training Epoch: 4 [14656/45000]\tLoss: 3.6827\tLR: 0.000010\n",
      "Training Epoch: 4 [14672/45000]\tLoss: 3.6416\tLR: 0.000010\n",
      "Training Epoch: 4 [14688/45000]\tLoss: 3.6443\tLR: 0.000010\n",
      "Training Epoch: 4 [14704/45000]\tLoss: 3.7191\tLR: 0.000010\n",
      "Training Epoch: 4 [14720/45000]\tLoss: 3.7045\tLR: 0.000010\n",
      "Training Epoch: 4 [14736/45000]\tLoss: 3.5953\tLR: 0.000010\n",
      "Training Epoch: 4 [14752/45000]\tLoss: 3.6434\tLR: 0.000010\n",
      "Training Epoch: 4 [14768/45000]\tLoss: 3.5429\tLR: 0.000010\n",
      "Training Epoch: 4 [14784/45000]\tLoss: 3.6532\tLR: 0.000010\n",
      "Training Epoch: 4 [14800/45000]\tLoss: 3.6266\tLR: 0.000010\n",
      "Training Epoch: 4 [14816/45000]\tLoss: 3.6926\tLR: 0.000010\n",
      "Training Epoch: 4 [14832/45000]\tLoss: 3.6587\tLR: 0.000010\n",
      "Training Epoch: 4 [14848/45000]\tLoss: 3.6162\tLR: 0.000010\n",
      "Training Epoch: 4 [14864/45000]\tLoss: 3.7567\tLR: 0.000010\n",
      "Training Epoch: 4 [14880/45000]\tLoss: 3.6332\tLR: 0.000010\n",
      "Training Epoch: 4 [14896/45000]\tLoss: 3.7606\tLR: 0.000010\n",
      "Training Epoch: 4 [14912/45000]\tLoss: 3.5749\tLR: 0.000010\n",
      "Training Epoch: 4 [14928/45000]\tLoss: 3.6671\tLR: 0.000010\n",
      "Training Epoch: 4 [14944/45000]\tLoss: 3.6818\tLR: 0.000010\n",
      "Training Epoch: 4 [14960/45000]\tLoss: 3.6647\tLR: 0.000010\n",
      "Training Epoch: 4 [14976/45000]\tLoss: 3.7390\tLR: 0.000010\n",
      "Training Epoch: 4 [14992/45000]\tLoss: 3.5476\tLR: 0.000010\n",
      "Training Epoch: 4 [15008/45000]\tLoss: 3.7559\tLR: 0.000010\n",
      "Training Epoch: 4 [15024/45000]\tLoss: 3.7221\tLR: 0.000010\n",
      "Training Epoch: 4 [15040/45000]\tLoss: 3.6825\tLR: 0.000010\n",
      "Training Epoch: 4 [15056/45000]\tLoss: 3.6957\tLR: 0.000010\n",
      "Training Epoch: 4 [15072/45000]\tLoss: 3.6334\tLR: 0.000010\n",
      "Training Epoch: 4 [15088/45000]\tLoss: 3.6143\tLR: 0.000010\n",
      "Training Epoch: 4 [15104/45000]\tLoss: 3.6065\tLR: 0.000010\n",
      "Training Epoch: 4 [15120/45000]\tLoss: 3.6161\tLR: 0.000010\n",
      "Training Epoch: 4 [15136/45000]\tLoss: 3.6441\tLR: 0.000010\n",
      "Training Epoch: 4 [15152/45000]\tLoss: 3.6568\tLR: 0.000010\n",
      "Training Epoch: 4 [15168/45000]\tLoss: 3.6192\tLR: 0.000010\n",
      "Training Epoch: 4 [15184/45000]\tLoss: 3.7238\tLR: 0.000010\n",
      "Training Epoch: 4 [15200/45000]\tLoss: 3.6037\tLR: 0.000010\n",
      "Training Epoch: 4 [15216/45000]\tLoss: 3.7133\tLR: 0.000010\n",
      "Training Epoch: 4 [15232/45000]\tLoss: 3.6053\tLR: 0.000010\n",
      "Training Epoch: 4 [15248/45000]\tLoss: 3.6864\tLR: 0.000010\n",
      "Training Epoch: 4 [15264/45000]\tLoss: 3.5055\tLR: 0.000010\n",
      "Training Epoch: 4 [15280/45000]\tLoss: 3.6497\tLR: 0.000010\n",
      "Training Epoch: 4 [15296/45000]\tLoss: 3.6539\tLR: 0.000010\n",
      "Training Epoch: 4 [15312/45000]\tLoss: 3.6284\tLR: 0.000010\n",
      "Training Epoch: 4 [15328/45000]\tLoss: 3.7574\tLR: 0.000010\n",
      "Training Epoch: 4 [15344/45000]\tLoss: 3.6533\tLR: 0.000010\n",
      "Training Epoch: 4 [15360/45000]\tLoss: 3.7380\tLR: 0.000010\n",
      "Training Epoch: 4 [15376/45000]\tLoss: 3.5909\tLR: 0.000010\n",
      "Training Epoch: 4 [15392/45000]\tLoss: 3.7278\tLR: 0.000010\n",
      "Training Epoch: 4 [15408/45000]\tLoss: 3.7476\tLR: 0.000010\n",
      "Training Epoch: 4 [15424/45000]\tLoss: 3.6154\tLR: 0.000010\n",
      "Training Epoch: 4 [15440/45000]\tLoss: 3.6884\tLR: 0.000010\n",
      "Training Epoch: 4 [15456/45000]\tLoss: 3.7061\tLR: 0.000010\n",
      "Training Epoch: 4 [15472/45000]\tLoss: 3.5637\tLR: 0.000010\n",
      "Training Epoch: 4 [15488/45000]\tLoss: 3.6971\tLR: 0.000010\n",
      "Training Epoch: 4 [15504/45000]\tLoss: 3.6620\tLR: 0.000010\n",
      "Training Epoch: 4 [15520/45000]\tLoss: 3.7054\tLR: 0.000010\n",
      "Training Epoch: 4 [15536/45000]\tLoss: 3.6083\tLR: 0.000010\n",
      "Training Epoch: 4 [15552/45000]\tLoss: 3.6569\tLR: 0.000010\n",
      "Training Epoch: 4 [15568/45000]\tLoss: 3.5856\tLR: 0.000010\n",
      "Training Epoch: 4 [15584/45000]\tLoss: 3.6016\tLR: 0.000010\n",
      "Training Epoch: 4 [15600/45000]\tLoss: 3.6517\tLR: 0.000010\n",
      "Training Epoch: 4 [15616/45000]\tLoss: 3.7423\tLR: 0.000010\n",
      "Training Epoch: 4 [15632/45000]\tLoss: 3.6621\tLR: 0.000010\n",
      "Training Epoch: 4 [15648/45000]\tLoss: 3.5754\tLR: 0.000010\n",
      "Training Epoch: 4 [15664/45000]\tLoss: 3.6402\tLR: 0.000010\n",
      "Training Epoch: 4 [15680/45000]\tLoss: 3.6216\tLR: 0.000010\n",
      "Training Epoch: 4 [15696/45000]\tLoss: 3.6119\tLR: 0.000010\n",
      "Training Epoch: 4 [15712/45000]\tLoss: 3.7125\tLR: 0.000010\n",
      "Training Epoch: 4 [15728/45000]\tLoss: 3.7313\tLR: 0.000010\n",
      "Training Epoch: 4 [15744/45000]\tLoss: 3.6886\tLR: 0.000010\n",
      "Training Epoch: 4 [15760/45000]\tLoss: 3.7780\tLR: 0.000010\n",
      "Training Epoch: 4 [15776/45000]\tLoss: 3.5778\tLR: 0.000010\n",
      "Training Epoch: 4 [15792/45000]\tLoss: 3.7383\tLR: 0.000010\n",
      "Training Epoch: 4 [15808/45000]\tLoss: 3.6508\tLR: 0.000010\n",
      "Training Epoch: 4 [15824/45000]\tLoss: 3.6524\tLR: 0.000010\n",
      "Training Epoch: 4 [15840/45000]\tLoss: 3.7173\tLR: 0.000010\n",
      "Training Epoch: 4 [15856/45000]\tLoss: 3.5175\tLR: 0.000010\n",
      "Training Epoch: 4 [15872/45000]\tLoss: 3.7263\tLR: 0.000010\n",
      "Training Epoch: 4 [15888/45000]\tLoss: 3.7298\tLR: 0.000010\n",
      "Training Epoch: 4 [15904/45000]\tLoss: 3.6401\tLR: 0.000010\n",
      "Training Epoch: 4 [15920/45000]\tLoss: 3.7779\tLR: 0.000010\n",
      "Training Epoch: 4 [15936/45000]\tLoss: 3.6719\tLR: 0.000010\n",
      "Training Epoch: 4 [15952/45000]\tLoss: 3.5885\tLR: 0.000010\n",
      "Training Epoch: 4 [15968/45000]\tLoss: 3.7016\tLR: 0.000010\n",
      "Training Epoch: 4 [15984/45000]\tLoss: 3.5863\tLR: 0.000010\n",
      "Training Epoch: 4 [16000/45000]\tLoss: 3.6750\tLR: 0.000010\n",
      "Training Epoch: 4 [16016/45000]\tLoss: 3.7421\tLR: 0.000010\n",
      "Training Epoch: 4 [16032/45000]\tLoss: 3.6218\tLR: 0.000010\n",
      "Training Epoch: 4 [16048/45000]\tLoss: 3.6151\tLR: 0.000010\n",
      "Training Epoch: 4 [16064/45000]\tLoss: 3.6274\tLR: 0.000010\n",
      "Training Epoch: 4 [16080/45000]\tLoss: 3.5695\tLR: 0.000010\n",
      "Training Epoch: 4 [16096/45000]\tLoss: 3.7300\tLR: 0.000010\n",
      "Training Epoch: 4 [16112/45000]\tLoss: 3.5808\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [16128/45000]\tLoss: 3.7073\tLR: 0.000010\n",
      "Training Epoch: 4 [16144/45000]\tLoss: 3.6157\tLR: 0.000010\n",
      "Training Epoch: 4 [16160/45000]\tLoss: 3.5346\tLR: 0.000010\n",
      "Training Epoch: 4 [16176/45000]\tLoss: 3.6857\tLR: 0.000010\n",
      "Training Epoch: 4 [16192/45000]\tLoss: 3.6616\tLR: 0.000010\n",
      "Training Epoch: 4 [16208/45000]\tLoss: 3.6948\tLR: 0.000010\n",
      "Training Epoch: 4 [16224/45000]\tLoss: 3.7256\tLR: 0.000010\n",
      "Training Epoch: 4 [16240/45000]\tLoss: 3.6542\tLR: 0.000010\n",
      "Training Epoch: 4 [16256/45000]\tLoss: 3.6915\tLR: 0.000010\n",
      "Training Epoch: 4 [16272/45000]\tLoss: 3.6760\tLR: 0.000010\n",
      "Training Epoch: 4 [16288/45000]\tLoss: 3.7227\tLR: 0.000010\n",
      "Training Epoch: 4 [16304/45000]\tLoss: 3.6881\tLR: 0.000010\n",
      "Training Epoch: 4 [16320/45000]\tLoss: 3.5529\tLR: 0.000010\n",
      "Training Epoch: 4 [16336/45000]\tLoss: 3.6810\tLR: 0.000010\n",
      "Training Epoch: 4 [16352/45000]\tLoss: 3.5795\tLR: 0.000010\n",
      "Training Epoch: 4 [16368/45000]\tLoss: 3.7299\tLR: 0.000010\n",
      "Training Epoch: 4 [16384/45000]\tLoss: 3.7027\tLR: 0.000010\n",
      "Training Epoch: 4 [16400/45000]\tLoss: 3.7309\tLR: 0.000010\n",
      "Training Epoch: 4 [16416/45000]\tLoss: 3.6519\tLR: 0.000010\n",
      "Training Epoch: 4 [16432/45000]\tLoss: 3.5645\tLR: 0.000010\n",
      "Training Epoch: 4 [16448/45000]\tLoss: 3.5703\tLR: 0.000010\n",
      "Training Epoch: 4 [16464/45000]\tLoss: 3.5937\tLR: 0.000010\n",
      "Training Epoch: 4 [16480/45000]\tLoss: 3.7490\tLR: 0.000010\n",
      "Training Epoch: 4 [16496/45000]\tLoss: 3.6630\tLR: 0.000010\n",
      "Training Epoch: 4 [16512/45000]\tLoss: 3.6769\tLR: 0.000010\n",
      "Training Epoch: 4 [16528/45000]\tLoss: 3.6781\tLR: 0.000010\n",
      "Training Epoch: 4 [16544/45000]\tLoss: 3.5728\tLR: 0.000010\n",
      "Training Epoch: 4 [16560/45000]\tLoss: 3.6331\tLR: 0.000010\n",
      "Training Epoch: 4 [16576/45000]\tLoss: 3.6075\tLR: 0.000010\n",
      "Training Epoch: 4 [16592/45000]\tLoss: 3.7782\tLR: 0.000010\n",
      "Training Epoch: 4 [16608/45000]\tLoss: 3.7742\tLR: 0.000010\n",
      "Training Epoch: 4 [16624/45000]\tLoss: 3.7404\tLR: 0.000010\n",
      "Training Epoch: 4 [16640/45000]\tLoss: 3.6984\tLR: 0.000010\n",
      "Training Epoch: 4 [16656/45000]\tLoss: 3.6318\tLR: 0.000010\n",
      "Training Epoch: 4 [16672/45000]\tLoss: 3.6545\tLR: 0.000010\n",
      "Training Epoch: 4 [16688/45000]\tLoss: 3.6879\tLR: 0.000010\n",
      "Training Epoch: 4 [16704/45000]\tLoss: 3.7178\tLR: 0.000010\n",
      "Training Epoch: 4 [16720/45000]\tLoss: 3.6705\tLR: 0.000010\n",
      "Training Epoch: 4 [16736/45000]\tLoss: 3.6063\tLR: 0.000010\n",
      "Training Epoch: 4 [16752/45000]\tLoss: 3.6021\tLR: 0.000010\n",
      "Training Epoch: 4 [16768/45000]\tLoss: 3.6077\tLR: 0.000010\n",
      "Training Epoch: 4 [16784/45000]\tLoss: 3.6651\tLR: 0.000010\n",
      "Training Epoch: 4 [16800/45000]\tLoss: 3.6882\tLR: 0.000010\n",
      "Training Epoch: 4 [16816/45000]\tLoss: 3.7013\tLR: 0.000010\n",
      "Training Epoch: 4 [16832/45000]\tLoss: 3.6394\tLR: 0.000010\n",
      "Training Epoch: 4 [16848/45000]\tLoss: 3.7534\tLR: 0.000010\n",
      "Training Epoch: 4 [16864/45000]\tLoss: 3.6355\tLR: 0.000010\n",
      "Training Epoch: 4 [16880/45000]\tLoss: 3.6666\tLR: 0.000010\n",
      "Training Epoch: 4 [16896/45000]\tLoss: 3.5567\tLR: 0.000010\n",
      "Training Epoch: 4 [16912/45000]\tLoss: 3.6896\tLR: 0.000010\n",
      "Training Epoch: 4 [16928/45000]\tLoss: 3.6133\tLR: 0.000010\n",
      "Training Epoch: 4 [16944/45000]\tLoss: 3.6005\tLR: 0.000010\n",
      "Training Epoch: 4 [16960/45000]\tLoss: 3.6399\tLR: 0.000010\n",
      "Training Epoch: 4 [16976/45000]\tLoss: 3.5837\tLR: 0.000010\n",
      "Training Epoch: 4 [16992/45000]\tLoss: 3.5886\tLR: 0.000010\n",
      "Training Epoch: 4 [17008/45000]\tLoss: 3.6652\tLR: 0.000010\n",
      "Training Epoch: 4 [17024/45000]\tLoss: 3.7406\tLR: 0.000010\n",
      "Training Epoch: 4 [17040/45000]\tLoss: 3.5992\tLR: 0.000010\n",
      "Training Epoch: 4 [17056/45000]\tLoss: 3.5774\tLR: 0.000010\n",
      "Training Epoch: 4 [17072/45000]\tLoss: 3.5805\tLR: 0.000010\n",
      "Training Epoch: 4 [17088/45000]\tLoss: 3.6607\tLR: 0.000010\n",
      "Training Epoch: 4 [17104/45000]\tLoss: 3.7092\tLR: 0.000010\n",
      "Training Epoch: 4 [17120/45000]\tLoss: 3.6490\tLR: 0.000010\n",
      "Training Epoch: 4 [17136/45000]\tLoss: 3.6245\tLR: 0.000010\n",
      "Training Epoch: 4 [17152/45000]\tLoss: 3.6594\tLR: 0.000010\n",
      "Training Epoch: 4 [17168/45000]\tLoss: 3.5491\tLR: 0.000010\n",
      "Training Epoch: 4 [17184/45000]\tLoss: 3.6676\tLR: 0.000010\n",
      "Training Epoch: 4 [17200/45000]\tLoss: 3.7085\tLR: 0.000010\n",
      "Training Epoch: 4 [17216/45000]\tLoss: 3.6071\tLR: 0.000010\n",
      "Training Epoch: 4 [17232/45000]\tLoss: 3.7537\tLR: 0.000010\n",
      "Training Epoch: 4 [17248/45000]\tLoss: 3.6996\tLR: 0.000010\n",
      "Training Epoch: 4 [17264/45000]\tLoss: 3.5845\tLR: 0.000010\n",
      "Training Epoch: 4 [17280/45000]\tLoss: 3.6113\tLR: 0.000010\n",
      "Training Epoch: 4 [17296/45000]\tLoss: 3.7341\tLR: 0.000010\n",
      "Training Epoch: 4 [17312/45000]\tLoss: 3.5298\tLR: 0.000010\n",
      "Training Epoch: 4 [17328/45000]\tLoss: 3.6363\tLR: 0.000010\n",
      "Training Epoch: 4 [17344/45000]\tLoss: 3.7252\tLR: 0.000010\n",
      "Training Epoch: 4 [17360/45000]\tLoss: 3.5549\tLR: 0.000010\n",
      "Training Epoch: 4 [17376/45000]\tLoss: 3.7471\tLR: 0.000010\n",
      "Training Epoch: 4 [17392/45000]\tLoss: 3.7070\tLR: 0.000010\n",
      "Training Epoch: 4 [17408/45000]\tLoss: 3.8241\tLR: 0.000010\n",
      "Training Epoch: 4 [17424/45000]\tLoss: 3.6653\tLR: 0.000010\n",
      "Training Epoch: 4 [17440/45000]\tLoss: 3.6968\tLR: 0.000010\n",
      "Training Epoch: 4 [17456/45000]\tLoss: 3.6374\tLR: 0.000010\n",
      "Training Epoch: 4 [17472/45000]\tLoss: 3.6582\tLR: 0.000010\n",
      "Training Epoch: 4 [17488/45000]\tLoss: 3.6764\tLR: 0.000010\n",
      "Training Epoch: 4 [17504/45000]\tLoss: 3.5709\tLR: 0.000010\n",
      "Training Epoch: 4 [17520/45000]\tLoss: 3.7182\tLR: 0.000010\n",
      "Training Epoch: 4 [17536/45000]\tLoss: 3.6576\tLR: 0.000010\n",
      "Training Epoch: 4 [17552/45000]\tLoss: 3.6898\tLR: 0.000010\n",
      "Training Epoch: 4 [17568/45000]\tLoss: 3.7193\tLR: 0.000010\n",
      "Training Epoch: 4 [17584/45000]\tLoss: 3.5895\tLR: 0.000010\n",
      "Training Epoch: 4 [17600/45000]\tLoss: 3.5584\tLR: 0.000010\n",
      "Training Epoch: 4 [17616/45000]\tLoss: 3.7101\tLR: 0.000010\n",
      "Training Epoch: 4 [17632/45000]\tLoss: 3.6905\tLR: 0.000010\n",
      "Training Epoch: 4 [17648/45000]\tLoss: 3.7072\tLR: 0.000010\n",
      "Training Epoch: 4 [17664/45000]\tLoss: 3.6555\tLR: 0.000010\n",
      "Training Epoch: 4 [17680/45000]\tLoss: 3.7564\tLR: 0.000010\n",
      "Training Epoch: 4 [17696/45000]\tLoss: 3.5749\tLR: 0.000010\n",
      "Training Epoch: 4 [17712/45000]\tLoss: 3.6858\tLR: 0.000010\n",
      "Training Epoch: 4 [17728/45000]\tLoss: 3.7132\tLR: 0.000010\n",
      "Training Epoch: 4 [17744/45000]\tLoss: 3.5865\tLR: 0.000010\n",
      "Training Epoch: 4 [17760/45000]\tLoss: 3.7543\tLR: 0.000010\n",
      "Training Epoch: 4 [17776/45000]\tLoss: 3.6253\tLR: 0.000010\n",
      "Training Epoch: 4 [17792/45000]\tLoss: 3.6843\tLR: 0.000010\n",
      "Training Epoch: 4 [17808/45000]\tLoss: 3.5331\tLR: 0.000010\n",
      "Training Epoch: 4 [17824/45000]\tLoss: 3.6954\tLR: 0.000010\n",
      "Training Epoch: 4 [17840/45000]\tLoss: 3.6324\tLR: 0.000010\n",
      "Training Epoch: 4 [17856/45000]\tLoss: 3.6861\tLR: 0.000010\n",
      "Training Epoch: 4 [17872/45000]\tLoss: 3.5202\tLR: 0.000010\n",
      "Training Epoch: 4 [17888/45000]\tLoss: 3.5235\tLR: 0.000010\n",
      "Training Epoch: 4 [17904/45000]\tLoss: 3.5505\tLR: 0.000010\n",
      "Training Epoch: 4 [17920/45000]\tLoss: 3.7130\tLR: 0.000010\n",
      "Training Epoch: 4 [17936/45000]\tLoss: 3.6375\tLR: 0.000010\n",
      "Training Epoch: 4 [17952/45000]\tLoss: 3.6254\tLR: 0.000010\n",
      "Training Epoch: 4 [17968/45000]\tLoss: 3.6372\tLR: 0.000010\n",
      "Training Epoch: 4 [17984/45000]\tLoss: 3.6941\tLR: 0.000010\n",
      "Training Epoch: 4 [18000/45000]\tLoss: 3.6482\tLR: 0.000010\n",
      "Training Epoch: 4 [18016/45000]\tLoss: 3.5696\tLR: 0.000010\n",
      "Training Epoch: 4 [18032/45000]\tLoss: 3.5791\tLR: 0.000010\n",
      "Training Epoch: 4 [18048/45000]\tLoss: 3.6420\tLR: 0.000010\n",
      "Training Epoch: 4 [18064/45000]\tLoss: 3.6961\tLR: 0.000010\n",
      "Training Epoch: 4 [18080/45000]\tLoss: 3.6595\tLR: 0.000010\n",
      "Training Epoch: 4 [18096/45000]\tLoss: 3.6815\tLR: 0.000010\n",
      "Training Epoch: 4 [18112/45000]\tLoss: 3.5110\tLR: 0.000010\n",
      "Training Epoch: 4 [18128/45000]\tLoss: 3.6572\tLR: 0.000010\n",
      "Training Epoch: 4 [18144/45000]\tLoss: 3.6937\tLR: 0.000010\n",
      "Training Epoch: 4 [18160/45000]\tLoss: 3.6861\tLR: 0.000010\n",
      "Training Epoch: 4 [18176/45000]\tLoss: 3.7474\tLR: 0.000010\n",
      "Training Epoch: 4 [18192/45000]\tLoss: 3.6123\tLR: 0.000010\n",
      "Training Epoch: 4 [18208/45000]\tLoss: 3.7056\tLR: 0.000010\n",
      "Training Epoch: 4 [18224/45000]\tLoss: 3.7857\tLR: 0.000010\n",
      "Training Epoch: 4 [18240/45000]\tLoss: 3.7970\tLR: 0.000010\n",
      "Training Epoch: 4 [18256/45000]\tLoss: 3.5687\tLR: 0.000010\n",
      "Training Epoch: 4 [18272/45000]\tLoss: 3.6568\tLR: 0.000010\n",
      "Training Epoch: 4 [18288/45000]\tLoss: 3.6971\tLR: 0.000010\n",
      "Training Epoch: 4 [18304/45000]\tLoss: 3.6329\tLR: 0.000010\n",
      "Training Epoch: 4 [18320/45000]\tLoss: 3.7000\tLR: 0.000010\n",
      "Training Epoch: 4 [18336/45000]\tLoss: 3.6838\tLR: 0.000010\n",
      "Training Epoch: 4 [18352/45000]\tLoss: 3.5522\tLR: 0.000010\n",
      "Training Epoch: 4 [18368/45000]\tLoss: 3.6326\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [18384/45000]\tLoss: 3.6769\tLR: 0.000010\n",
      "Training Epoch: 4 [18400/45000]\tLoss: 3.6800\tLR: 0.000010\n",
      "Training Epoch: 4 [18416/45000]\tLoss: 3.6939\tLR: 0.000010\n",
      "Training Epoch: 4 [18432/45000]\tLoss: 3.6234\tLR: 0.000010\n",
      "Training Epoch: 4 [18448/45000]\tLoss: 3.6274\tLR: 0.000010\n",
      "Training Epoch: 4 [18464/45000]\tLoss: 3.7050\tLR: 0.000010\n",
      "Training Epoch: 4 [18480/45000]\tLoss: 3.6541\tLR: 0.000010\n",
      "Training Epoch: 4 [18496/45000]\tLoss: 3.8463\tLR: 0.000010\n",
      "Training Epoch: 4 [18512/45000]\tLoss: 3.7140\tLR: 0.000010\n",
      "Training Epoch: 4 [18528/45000]\tLoss: 3.6746\tLR: 0.000010\n",
      "Training Epoch: 4 [18544/45000]\tLoss: 3.6932\tLR: 0.000010\n",
      "Training Epoch: 4 [18560/45000]\tLoss: 3.5737\tLR: 0.000010\n",
      "Training Epoch: 4 [18576/45000]\tLoss: 3.7059\tLR: 0.000010\n",
      "Training Epoch: 4 [18592/45000]\tLoss: 3.6888\tLR: 0.000010\n",
      "Training Epoch: 4 [18608/45000]\tLoss: 3.7048\tLR: 0.000010\n",
      "Training Epoch: 4 [18624/45000]\tLoss: 3.6931\tLR: 0.000010\n",
      "Training Epoch: 4 [18640/45000]\tLoss: 3.6698\tLR: 0.000010\n",
      "Training Epoch: 4 [18656/45000]\tLoss: 3.6156\tLR: 0.000010\n",
      "Training Epoch: 4 [18672/45000]\tLoss: 3.6061\tLR: 0.000010\n",
      "Training Epoch: 4 [18688/45000]\tLoss: 3.5552\tLR: 0.000010\n",
      "Training Epoch: 4 [18704/45000]\tLoss: 3.7627\tLR: 0.000010\n",
      "Training Epoch: 4 [18720/45000]\tLoss: 3.6839\tLR: 0.000010\n",
      "Training Epoch: 4 [18736/45000]\tLoss: 3.6618\tLR: 0.000010\n",
      "Training Epoch: 4 [18752/45000]\tLoss: 3.6235\tLR: 0.000010\n",
      "Training Epoch: 4 [18768/45000]\tLoss: 3.6902\tLR: 0.000010\n",
      "Training Epoch: 4 [18784/45000]\tLoss: 3.6809\tLR: 0.000010\n",
      "Training Epoch: 4 [18800/45000]\tLoss: 3.7372\tLR: 0.000010\n",
      "Training Epoch: 4 [18816/45000]\tLoss: 3.7745\tLR: 0.000010\n",
      "Training Epoch: 4 [18832/45000]\tLoss: 3.6990\tLR: 0.000010\n",
      "Training Epoch: 4 [18848/45000]\tLoss: 3.7148\tLR: 0.000010\n",
      "Training Epoch: 4 [18864/45000]\tLoss: 3.7749\tLR: 0.000010\n",
      "Training Epoch: 4 [18880/45000]\tLoss: 3.6198\tLR: 0.000010\n",
      "Training Epoch: 4 [18896/45000]\tLoss: 3.6402\tLR: 0.000010\n",
      "Training Epoch: 4 [18912/45000]\tLoss: 3.6369\tLR: 0.000010\n",
      "Training Epoch: 4 [18928/45000]\tLoss: 3.6616\tLR: 0.000010\n",
      "Training Epoch: 4 [18944/45000]\tLoss: 3.6078\tLR: 0.000010\n",
      "Training Epoch: 4 [18960/45000]\tLoss: 3.6367\tLR: 0.000010\n",
      "Training Epoch: 4 [18976/45000]\tLoss: 3.6529\tLR: 0.000010\n",
      "Training Epoch: 4 [18992/45000]\tLoss: 3.5791\tLR: 0.000010\n",
      "Training Epoch: 4 [19008/45000]\tLoss: 3.7110\tLR: 0.000010\n",
      "Training Epoch: 4 [19024/45000]\tLoss: 3.6176\tLR: 0.000010\n",
      "Training Epoch: 4 [19040/45000]\tLoss: 3.6083\tLR: 0.000010\n",
      "Training Epoch: 4 [19056/45000]\tLoss: 3.7079\tLR: 0.000010\n",
      "Training Epoch: 4 [19072/45000]\tLoss: 3.6916\tLR: 0.000010\n",
      "Training Epoch: 4 [19088/45000]\tLoss: 3.5435\tLR: 0.000010\n",
      "Training Epoch: 4 [19104/45000]\tLoss: 3.5726\tLR: 0.000010\n",
      "Training Epoch: 4 [19120/45000]\tLoss: 3.6915\tLR: 0.000010\n",
      "Training Epoch: 4 [19136/45000]\tLoss: 3.6337\tLR: 0.000010\n",
      "Training Epoch: 4 [19152/45000]\tLoss: 3.6139\tLR: 0.000010\n",
      "Training Epoch: 4 [19168/45000]\tLoss: 3.6539\tLR: 0.000010\n",
      "Training Epoch: 4 [19184/45000]\tLoss: 3.6044\tLR: 0.000010\n",
      "Training Epoch: 4 [19200/45000]\tLoss: 3.7473\tLR: 0.000010\n",
      "Training Epoch: 4 [19216/45000]\tLoss: 3.7431\tLR: 0.000010\n",
      "Training Epoch: 4 [19232/45000]\tLoss: 3.5707\tLR: 0.000010\n",
      "Training Epoch: 4 [19248/45000]\tLoss: 3.6146\tLR: 0.000010\n",
      "Training Epoch: 4 [19264/45000]\tLoss: 3.7493\tLR: 0.000010\n",
      "Training Epoch: 4 [19280/45000]\tLoss: 3.6647\tLR: 0.000010\n",
      "Training Epoch: 4 [19296/45000]\tLoss: 3.6616\tLR: 0.000010\n",
      "Training Epoch: 4 [19312/45000]\tLoss: 3.6973\tLR: 0.000010\n",
      "Training Epoch: 4 [19328/45000]\tLoss: 3.6030\tLR: 0.000010\n",
      "Training Epoch: 4 [19344/45000]\tLoss: 3.7410\tLR: 0.000010\n",
      "Training Epoch: 4 [19360/45000]\tLoss: 3.6534\tLR: 0.000010\n",
      "Training Epoch: 4 [19376/45000]\tLoss: 3.6232\tLR: 0.000010\n",
      "Training Epoch: 4 [19392/45000]\tLoss: 3.7739\tLR: 0.000010\n",
      "Training Epoch: 4 [19408/45000]\tLoss: 3.6052\tLR: 0.000010\n",
      "Training Epoch: 4 [19424/45000]\tLoss: 3.6475\tLR: 0.000010\n",
      "Training Epoch: 4 [19440/45000]\tLoss: 3.6397\tLR: 0.000010\n",
      "Training Epoch: 4 [19456/45000]\tLoss: 3.7078\tLR: 0.000010\n",
      "Training Epoch: 4 [19472/45000]\tLoss: 3.6797\tLR: 0.000010\n",
      "Training Epoch: 4 [19488/45000]\tLoss: 3.7114\tLR: 0.000010\n",
      "Training Epoch: 4 [19504/45000]\tLoss: 3.6030\tLR: 0.000010\n",
      "Training Epoch: 4 [19520/45000]\tLoss: 3.7089\tLR: 0.000010\n",
      "Training Epoch: 4 [19536/45000]\tLoss: 3.6866\tLR: 0.000010\n",
      "Training Epoch: 4 [19552/45000]\tLoss: 3.6300\tLR: 0.000010\n",
      "Training Epoch: 4 [19568/45000]\tLoss: 3.7153\tLR: 0.000010\n",
      "Training Epoch: 4 [19584/45000]\tLoss: 3.7292\tLR: 0.000010\n",
      "Training Epoch: 4 [19600/45000]\tLoss: 3.5656\tLR: 0.000010\n",
      "Training Epoch: 4 [19616/45000]\tLoss: 3.5562\tLR: 0.000010\n",
      "Training Epoch: 4 [19632/45000]\tLoss: 3.6379\tLR: 0.000010\n",
      "Training Epoch: 4 [19648/45000]\tLoss: 3.6962\tLR: 0.000010\n",
      "Training Epoch: 4 [19664/45000]\tLoss: 3.6175\tLR: 0.000010\n",
      "Training Epoch: 4 [19680/45000]\tLoss: 3.6610\tLR: 0.000010\n",
      "Training Epoch: 4 [19696/45000]\tLoss: 3.7440\tLR: 0.000010\n",
      "Training Epoch: 4 [19712/45000]\tLoss: 3.6298\tLR: 0.000010\n",
      "Training Epoch: 4 [19728/45000]\tLoss: 3.7074\tLR: 0.000010\n",
      "Training Epoch: 4 [19744/45000]\tLoss: 3.6717\tLR: 0.000010\n",
      "Training Epoch: 4 [19760/45000]\tLoss: 3.7296\tLR: 0.000010\n",
      "Training Epoch: 4 [19776/45000]\tLoss: 3.7177\tLR: 0.000010\n",
      "Training Epoch: 4 [19792/45000]\tLoss: 3.6575\tLR: 0.000010\n",
      "Training Epoch: 4 [19808/45000]\tLoss: 3.6505\tLR: 0.000010\n",
      "Training Epoch: 4 [19824/45000]\tLoss: 3.6622\tLR: 0.000010\n",
      "Training Epoch: 4 [19840/45000]\tLoss: 3.6823\tLR: 0.000010\n",
      "Training Epoch: 4 [19856/45000]\tLoss: 3.6113\tLR: 0.000010\n",
      "Training Epoch: 4 [19872/45000]\tLoss: 3.6359\tLR: 0.000010\n",
      "Training Epoch: 4 [19888/45000]\tLoss: 3.6554\tLR: 0.000010\n",
      "Training Epoch: 4 [19904/45000]\tLoss: 3.6966\tLR: 0.000010\n",
      "Training Epoch: 4 [19920/45000]\tLoss: 3.5716\tLR: 0.000010\n",
      "Training Epoch: 4 [19936/45000]\tLoss: 3.6275\tLR: 0.000010\n",
      "Training Epoch: 4 [19952/45000]\tLoss: 3.6610\tLR: 0.000010\n",
      "Training Epoch: 4 [19968/45000]\tLoss: 3.6611\tLR: 0.000010\n",
      "Training Epoch: 4 [19984/45000]\tLoss: 3.6877\tLR: 0.000010\n",
      "Training Epoch: 4 [20000/45000]\tLoss: 3.7660\tLR: 0.000010\n",
      "Training Epoch: 4 [20016/45000]\tLoss: 3.6303\tLR: 0.000010\n",
      "Training Epoch: 4 [20032/45000]\tLoss: 3.7399\tLR: 0.000010\n",
      "Training Epoch: 4 [20048/45000]\tLoss: 3.7050\tLR: 0.000010\n",
      "Training Epoch: 4 [20064/45000]\tLoss: 3.6999\tLR: 0.000010\n",
      "Training Epoch: 4 [20080/45000]\tLoss: 3.6519\tLR: 0.000010\n",
      "Training Epoch: 4 [20096/45000]\tLoss: 3.7999\tLR: 0.000010\n",
      "Training Epoch: 4 [20112/45000]\tLoss: 3.5959\tLR: 0.000010\n",
      "Training Epoch: 4 [20128/45000]\tLoss: 3.6835\tLR: 0.000010\n",
      "Training Epoch: 4 [20144/45000]\tLoss: 3.5857\tLR: 0.000010\n",
      "Training Epoch: 4 [20160/45000]\tLoss: 3.6562\tLR: 0.000010\n",
      "Training Epoch: 4 [20176/45000]\tLoss: 3.6483\tLR: 0.000010\n",
      "Training Epoch: 4 [20192/45000]\tLoss: 3.6048\tLR: 0.000010\n",
      "Training Epoch: 4 [20208/45000]\tLoss: 3.6060\tLR: 0.000010\n",
      "Training Epoch: 4 [20224/45000]\tLoss: 3.5839\tLR: 0.000010\n",
      "Training Epoch: 4 [20240/45000]\tLoss: 3.6238\tLR: 0.000010\n",
      "Training Epoch: 4 [20256/45000]\tLoss: 3.5786\tLR: 0.000010\n",
      "Training Epoch: 4 [20272/45000]\tLoss: 3.5907\tLR: 0.000010\n",
      "Training Epoch: 4 [20288/45000]\tLoss: 3.6782\tLR: 0.000010\n",
      "Training Epoch: 4 [20304/45000]\tLoss: 3.6169\tLR: 0.000010\n",
      "Training Epoch: 4 [20320/45000]\tLoss: 3.5587\tLR: 0.000010\n",
      "Training Epoch: 4 [20336/45000]\tLoss: 3.5769\tLR: 0.000010\n",
      "Training Epoch: 4 [20352/45000]\tLoss: 3.6219\tLR: 0.000010\n",
      "Training Epoch: 4 [20368/45000]\tLoss: 3.6818\tLR: 0.000010\n",
      "Training Epoch: 4 [20384/45000]\tLoss: 3.6341\tLR: 0.000010\n",
      "Training Epoch: 4 [20400/45000]\tLoss: 3.6260\tLR: 0.000010\n",
      "Training Epoch: 4 [20416/45000]\tLoss: 3.7026\tLR: 0.000010\n",
      "Training Epoch: 4 [20432/45000]\tLoss: 3.7495\tLR: 0.000010\n",
      "Training Epoch: 4 [20448/45000]\tLoss: 3.6837\tLR: 0.000010\n",
      "Training Epoch: 4 [20464/45000]\tLoss: 3.7207\tLR: 0.000010\n",
      "Training Epoch: 4 [20480/45000]\tLoss: 3.7053\tLR: 0.000010\n",
      "Training Epoch: 4 [20496/45000]\tLoss: 3.7649\tLR: 0.000010\n",
      "Training Epoch: 4 [20512/45000]\tLoss: 3.6880\tLR: 0.000010\n",
      "Training Epoch: 4 [20528/45000]\tLoss: 3.6171\tLR: 0.000010\n",
      "Training Epoch: 4 [20544/45000]\tLoss: 3.6305\tLR: 0.000010\n",
      "Training Epoch: 4 [20560/45000]\tLoss: 3.5535\tLR: 0.000010\n",
      "Training Epoch: 4 [20576/45000]\tLoss: 3.6638\tLR: 0.000010\n",
      "Training Epoch: 4 [20592/45000]\tLoss: 3.7182\tLR: 0.000010\n",
      "Training Epoch: 4 [20608/45000]\tLoss: 3.6750\tLR: 0.000010\n",
      "Training Epoch: 4 [20624/45000]\tLoss: 3.7780\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [20640/45000]\tLoss: 3.6378\tLR: 0.000010\n",
      "Training Epoch: 4 [20656/45000]\tLoss: 3.6568\tLR: 0.000010\n",
      "Training Epoch: 4 [20672/45000]\tLoss: 3.6425\tLR: 0.000010\n",
      "Training Epoch: 4 [20688/45000]\tLoss: 3.6904\tLR: 0.000010\n",
      "Training Epoch: 4 [20704/45000]\tLoss: 3.6271\tLR: 0.000010\n",
      "Training Epoch: 4 [20720/45000]\tLoss: 3.6568\tLR: 0.000010\n",
      "Training Epoch: 4 [20736/45000]\tLoss: 3.7443\tLR: 0.000010\n",
      "Training Epoch: 4 [20752/45000]\tLoss: 3.7807\tLR: 0.000010\n",
      "Training Epoch: 4 [20768/45000]\tLoss: 3.7259\tLR: 0.000010\n",
      "Training Epoch: 4 [20784/45000]\tLoss: 3.6771\tLR: 0.000010\n",
      "Training Epoch: 4 [20800/45000]\tLoss: 3.6852\tLR: 0.000010\n",
      "Training Epoch: 4 [20816/45000]\tLoss: 3.7244\tLR: 0.000010\n",
      "Training Epoch: 4 [20832/45000]\tLoss: 3.7387\tLR: 0.000010\n",
      "Training Epoch: 4 [20848/45000]\tLoss: 3.5895\tLR: 0.000010\n",
      "Training Epoch: 4 [20864/45000]\tLoss: 3.5685\tLR: 0.000010\n",
      "Training Epoch: 4 [20880/45000]\tLoss: 3.5613\tLR: 0.000010\n",
      "Training Epoch: 4 [20896/45000]\tLoss: 3.5995\tLR: 0.000010\n",
      "Training Epoch: 4 [20912/45000]\tLoss: 3.7191\tLR: 0.000010\n",
      "Training Epoch: 4 [20928/45000]\tLoss: 3.7706\tLR: 0.000010\n",
      "Training Epoch: 4 [20944/45000]\tLoss: 3.5921\tLR: 0.000010\n",
      "Training Epoch: 4 [20960/45000]\tLoss: 3.6382\tLR: 0.000010\n",
      "Training Epoch: 4 [20976/45000]\tLoss: 3.5658\tLR: 0.000010\n",
      "Training Epoch: 4 [20992/45000]\tLoss: 3.6845\tLR: 0.000010\n",
      "Training Epoch: 4 [21008/45000]\tLoss: 3.6625\tLR: 0.000010\n",
      "Training Epoch: 4 [21024/45000]\tLoss: 3.8084\tLR: 0.000010\n",
      "Training Epoch: 4 [21040/45000]\tLoss: 3.6607\tLR: 0.000010\n",
      "Training Epoch: 4 [21056/45000]\tLoss: 3.5407\tLR: 0.000010\n",
      "Training Epoch: 4 [21072/45000]\tLoss: 3.7863\tLR: 0.000010\n",
      "Training Epoch: 4 [21088/45000]\tLoss: 3.7140\tLR: 0.000010\n",
      "Training Epoch: 4 [21104/45000]\tLoss: 3.8393\tLR: 0.000010\n",
      "Training Epoch: 4 [21120/45000]\tLoss: 3.5284\tLR: 0.000010\n",
      "Training Epoch: 4 [21136/45000]\tLoss: 3.5938\tLR: 0.000010\n",
      "Training Epoch: 4 [21152/45000]\tLoss: 3.7139\tLR: 0.000010\n",
      "Training Epoch: 4 [21168/45000]\tLoss: 3.6793\tLR: 0.000010\n",
      "Training Epoch: 4 [21184/45000]\tLoss: 3.6036\tLR: 0.000010\n",
      "Training Epoch: 4 [21200/45000]\tLoss: 3.7060\tLR: 0.000010\n",
      "Training Epoch: 4 [21216/45000]\tLoss: 3.6122\tLR: 0.000010\n",
      "Training Epoch: 4 [21232/45000]\tLoss: 3.5998\tLR: 0.000010\n",
      "Training Epoch: 4 [21248/45000]\tLoss: 3.6784\tLR: 0.000010\n",
      "Training Epoch: 4 [21264/45000]\tLoss: 3.7023\tLR: 0.000010\n",
      "Training Epoch: 4 [21280/45000]\tLoss: 3.6221\tLR: 0.000010\n",
      "Training Epoch: 4 [21296/45000]\tLoss: 3.6551\tLR: 0.000010\n",
      "Training Epoch: 4 [21312/45000]\tLoss: 3.6211\tLR: 0.000010\n",
      "Training Epoch: 4 [21328/45000]\tLoss: 3.6891\tLR: 0.000010\n",
      "Training Epoch: 4 [21344/45000]\tLoss: 3.7007\tLR: 0.000010\n",
      "Training Epoch: 4 [21360/45000]\tLoss: 3.6980\tLR: 0.000010\n",
      "Training Epoch: 4 [21376/45000]\tLoss: 3.6977\tLR: 0.000010\n",
      "Training Epoch: 4 [21392/45000]\tLoss: 3.6073\tLR: 0.000010\n",
      "Training Epoch: 4 [21408/45000]\tLoss: 3.6417\tLR: 0.000010\n",
      "Training Epoch: 4 [21424/45000]\tLoss: 3.7780\tLR: 0.000010\n",
      "Training Epoch: 4 [21440/45000]\tLoss: 3.5932\tLR: 0.000010\n",
      "Training Epoch: 4 [21456/45000]\tLoss: 3.5963\tLR: 0.000010\n",
      "Training Epoch: 4 [21472/45000]\tLoss: 3.7410\tLR: 0.000010\n",
      "Training Epoch: 4 [21488/45000]\tLoss: 3.5925\tLR: 0.000010\n",
      "Training Epoch: 4 [21504/45000]\tLoss: 3.5872\tLR: 0.000010\n",
      "Training Epoch: 4 [21520/45000]\tLoss: 3.7368\tLR: 0.000010\n",
      "Training Epoch: 4 [21536/45000]\tLoss: 3.6679\tLR: 0.000010\n",
      "Training Epoch: 4 [21552/45000]\tLoss: 3.6993\tLR: 0.000010\n",
      "Training Epoch: 4 [21568/45000]\tLoss: 3.6004\tLR: 0.000010\n",
      "Training Epoch: 4 [21584/45000]\tLoss: 3.6973\tLR: 0.000010\n",
      "Training Epoch: 4 [21600/45000]\tLoss: 3.7103\tLR: 0.000010\n",
      "Training Epoch: 4 [21616/45000]\tLoss: 3.6891\tLR: 0.000010\n",
      "Training Epoch: 4 [21632/45000]\tLoss: 3.6556\tLR: 0.000010\n",
      "Training Epoch: 4 [21648/45000]\tLoss: 3.7079\tLR: 0.000010\n",
      "Training Epoch: 4 [21664/45000]\tLoss: 3.6737\tLR: 0.000010\n",
      "Training Epoch: 4 [21680/45000]\tLoss: 3.6922\tLR: 0.000010\n",
      "Training Epoch: 4 [21696/45000]\tLoss: 3.6737\tLR: 0.000010\n",
      "Training Epoch: 4 [21712/45000]\tLoss: 3.7305\tLR: 0.000010\n",
      "Training Epoch: 4 [21728/45000]\tLoss: 3.6959\tLR: 0.000010\n",
      "Training Epoch: 4 [21744/45000]\tLoss: 3.5675\tLR: 0.000010\n",
      "Training Epoch: 4 [21760/45000]\tLoss: 3.6453\tLR: 0.000010\n",
      "Training Epoch: 4 [21776/45000]\tLoss: 3.6735\tLR: 0.000010\n",
      "Training Epoch: 4 [21792/45000]\tLoss: 3.6740\tLR: 0.000010\n",
      "Training Epoch: 4 [21808/45000]\tLoss: 3.7726\tLR: 0.000010\n",
      "Training Epoch: 4 [21824/45000]\tLoss: 3.7235\tLR: 0.000010\n",
      "Training Epoch: 4 [21840/45000]\tLoss: 3.7255\tLR: 0.000010\n",
      "Training Epoch: 4 [21856/45000]\tLoss: 3.6176\tLR: 0.000010\n",
      "Training Epoch: 4 [21872/45000]\tLoss: 3.6586\tLR: 0.000010\n",
      "Training Epoch: 4 [21888/45000]\tLoss: 3.6147\tLR: 0.000010\n",
      "Training Epoch: 4 [21904/45000]\tLoss: 3.7565\tLR: 0.000010\n",
      "Training Epoch: 4 [21920/45000]\tLoss: 3.7010\tLR: 0.000010\n",
      "Training Epoch: 4 [21936/45000]\tLoss: 3.6457\tLR: 0.000010\n",
      "Training Epoch: 4 [21952/45000]\tLoss: 3.6872\tLR: 0.000010\n",
      "Training Epoch: 4 [21968/45000]\tLoss: 3.5627\tLR: 0.000010\n",
      "Training Epoch: 4 [21984/45000]\tLoss: 3.6195\tLR: 0.000010\n",
      "Training Epoch: 4 [22000/45000]\tLoss: 3.6803\tLR: 0.000010\n",
      "Training Epoch: 4 [22016/45000]\tLoss: 3.7243\tLR: 0.000010\n",
      "Training Epoch: 4 [22032/45000]\tLoss: 3.6192\tLR: 0.000010\n",
      "Training Epoch: 4 [22048/45000]\tLoss: 3.7940\tLR: 0.000010\n",
      "Training Epoch: 4 [22064/45000]\tLoss: 3.7618\tLR: 0.000010\n",
      "Training Epoch: 4 [22080/45000]\tLoss: 3.7207\tLR: 0.000010\n",
      "Training Epoch: 4 [22096/45000]\tLoss: 3.7362\tLR: 0.000010\n",
      "Training Epoch: 4 [22112/45000]\tLoss: 3.6473\tLR: 0.000010\n",
      "Training Epoch: 4 [22128/45000]\tLoss: 3.6884\tLR: 0.000010\n",
      "Training Epoch: 4 [22144/45000]\tLoss: 3.6204\tLR: 0.000010\n",
      "Training Epoch: 4 [22160/45000]\tLoss: 3.6116\tLR: 0.000010\n",
      "Training Epoch: 4 [22176/45000]\tLoss: 3.5775\tLR: 0.000010\n",
      "Training Epoch: 4 [22192/45000]\tLoss: 3.7275\tLR: 0.000010\n",
      "Training Epoch: 4 [22208/45000]\tLoss: 3.7357\tLR: 0.000010\n",
      "Training Epoch: 4 [22224/45000]\tLoss: 3.5581\tLR: 0.000010\n",
      "Training Epoch: 4 [22240/45000]\tLoss: 3.7981\tLR: 0.000010\n",
      "Training Epoch: 4 [22256/45000]\tLoss: 3.6387\tLR: 0.000010\n",
      "Training Epoch: 4 [22272/45000]\tLoss: 3.5880\tLR: 0.000010\n",
      "Training Epoch: 4 [22288/45000]\tLoss: 3.6146\tLR: 0.000010\n",
      "Training Epoch: 4 [22304/45000]\tLoss: 3.6336\tLR: 0.000010\n",
      "Training Epoch: 4 [22320/45000]\tLoss: 3.7025\tLR: 0.000010\n",
      "Training Epoch: 4 [22336/45000]\tLoss: 3.5911\tLR: 0.000010\n",
      "Training Epoch: 4 [22352/45000]\tLoss: 3.5516\tLR: 0.000010\n",
      "Training Epoch: 4 [22368/45000]\tLoss: 3.6766\tLR: 0.000010\n",
      "Training Epoch: 4 [22384/45000]\tLoss: 3.6523\tLR: 0.000010\n",
      "Training Epoch: 4 [22400/45000]\tLoss: 3.6321\tLR: 0.000010\n",
      "Training Epoch: 4 [22416/45000]\tLoss: 3.7258\tLR: 0.000010\n",
      "Training Epoch: 4 [22432/45000]\tLoss: 3.6909\tLR: 0.000010\n",
      "Training Epoch: 4 [22448/45000]\tLoss: 3.6788\tLR: 0.000010\n",
      "Training Epoch: 4 [22464/45000]\tLoss: 3.6715\tLR: 0.000010\n",
      "Training Epoch: 4 [22480/45000]\tLoss: 3.5641\tLR: 0.000010\n",
      "Training Epoch: 4 [22496/45000]\tLoss: 3.6075\tLR: 0.000010\n",
      "Training Epoch: 4 [22512/45000]\tLoss: 3.6755\tLR: 0.000010\n",
      "Training Epoch: 4 [22528/45000]\tLoss: 3.7287\tLR: 0.000010\n",
      "Training Epoch: 4 [22544/45000]\tLoss: 3.7771\tLR: 0.000010\n",
      "Training Epoch: 4 [22560/45000]\tLoss: 3.6249\tLR: 0.000010\n",
      "Training Epoch: 4 [22576/45000]\tLoss: 3.7587\tLR: 0.000010\n",
      "Training Epoch: 4 [22592/45000]\tLoss: 3.5899\tLR: 0.000010\n",
      "Training Epoch: 4 [22608/45000]\tLoss: 3.6775\tLR: 0.000010\n",
      "Training Epoch: 4 [22624/45000]\tLoss: 3.5184\tLR: 0.000010\n",
      "Training Epoch: 4 [22640/45000]\tLoss: 3.7062\tLR: 0.000010\n",
      "Training Epoch: 4 [22656/45000]\tLoss: 3.6946\tLR: 0.000010\n",
      "Training Epoch: 4 [22672/45000]\tLoss: 3.6436\tLR: 0.000010\n",
      "Training Epoch: 4 [22688/45000]\tLoss: 3.6177\tLR: 0.000010\n",
      "Training Epoch: 4 [22704/45000]\tLoss: 3.7693\tLR: 0.000010\n",
      "Training Epoch: 4 [22720/45000]\tLoss: 3.6698\tLR: 0.000010\n",
      "Training Epoch: 4 [22736/45000]\tLoss: 3.6143\tLR: 0.000010\n",
      "Training Epoch: 4 [22752/45000]\tLoss: 3.6825\tLR: 0.000010\n",
      "Training Epoch: 4 [22768/45000]\tLoss: 3.6497\tLR: 0.000010\n",
      "Training Epoch: 4 [22784/45000]\tLoss: 3.6289\tLR: 0.000010\n",
      "Training Epoch: 4 [22800/45000]\tLoss: 3.6505\tLR: 0.000010\n",
      "Training Epoch: 4 [22816/45000]\tLoss: 3.5616\tLR: 0.000010\n",
      "Training Epoch: 4 [22832/45000]\tLoss: 3.7564\tLR: 0.000010\n",
      "Training Epoch: 4 [22848/45000]\tLoss: 3.7911\tLR: 0.000010\n",
      "Training Epoch: 4 [22864/45000]\tLoss: 3.6992\tLR: 0.000010\n",
      "Training Epoch: 4 [22880/45000]\tLoss: 3.6448\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [22896/45000]\tLoss: 3.6565\tLR: 0.000010\n",
      "Training Epoch: 4 [22912/45000]\tLoss: 3.8545\tLR: 0.000010\n",
      "Training Epoch: 4 [22928/45000]\tLoss: 3.6343\tLR: 0.000010\n",
      "Training Epoch: 4 [22944/45000]\tLoss: 3.7510\tLR: 0.000010\n",
      "Training Epoch: 4 [22960/45000]\tLoss: 3.6963\tLR: 0.000010\n",
      "Training Epoch: 4 [22976/45000]\tLoss: 3.6702\tLR: 0.000010\n",
      "Training Epoch: 4 [22992/45000]\tLoss: 3.6414\tLR: 0.000010\n",
      "Training Epoch: 4 [23008/45000]\tLoss: 3.5717\tLR: 0.000010\n",
      "Training Epoch: 4 [23024/45000]\tLoss: 3.7259\tLR: 0.000010\n",
      "Training Epoch: 4 [23040/45000]\tLoss: 3.6621\tLR: 0.000010\n",
      "Training Epoch: 4 [23056/45000]\tLoss: 3.5829\tLR: 0.000010\n",
      "Training Epoch: 4 [23072/45000]\tLoss: 3.5924\tLR: 0.000010\n",
      "Training Epoch: 4 [23088/45000]\tLoss: 3.7413\tLR: 0.000010\n",
      "Training Epoch: 4 [23104/45000]\tLoss: 3.6944\tLR: 0.000010\n",
      "Training Epoch: 4 [23120/45000]\tLoss: 3.6388\tLR: 0.000010\n",
      "Training Epoch: 4 [23136/45000]\tLoss: 3.7282\tLR: 0.000010\n",
      "Training Epoch: 4 [23152/45000]\tLoss: 3.7085\tLR: 0.000010\n",
      "Training Epoch: 4 [23168/45000]\tLoss: 3.6305\tLR: 0.000010\n",
      "Training Epoch: 4 [23184/45000]\tLoss: 3.6278\tLR: 0.000010\n",
      "Training Epoch: 4 [23200/45000]\tLoss: 3.6892\tLR: 0.000010\n",
      "Training Epoch: 4 [23216/45000]\tLoss: 3.6771\tLR: 0.000010\n",
      "Training Epoch: 4 [23232/45000]\tLoss: 3.6511\tLR: 0.000010\n",
      "Training Epoch: 4 [23248/45000]\tLoss: 3.6483\tLR: 0.000010\n",
      "Training Epoch: 4 [23264/45000]\tLoss: 3.6955\tLR: 0.000010\n",
      "Training Epoch: 4 [23280/45000]\tLoss: 3.6413\tLR: 0.000010\n",
      "Training Epoch: 4 [23296/45000]\tLoss: 3.6793\tLR: 0.000010\n",
      "Training Epoch: 4 [23312/45000]\tLoss: 3.5627\tLR: 0.000010\n",
      "Training Epoch: 4 [23328/45000]\tLoss: 3.7611\tLR: 0.000010\n",
      "Training Epoch: 4 [23344/45000]\tLoss: 3.6119\tLR: 0.000010\n",
      "Training Epoch: 4 [23360/45000]\tLoss: 3.6178\tLR: 0.000010\n",
      "Training Epoch: 4 [23376/45000]\tLoss: 3.6736\tLR: 0.000010\n",
      "Training Epoch: 4 [23392/45000]\tLoss: 3.5524\tLR: 0.000010\n",
      "Training Epoch: 4 [23408/45000]\tLoss: 3.7146\tLR: 0.000010\n",
      "Training Epoch: 4 [23424/45000]\tLoss: 3.6073\tLR: 0.000010\n",
      "Training Epoch: 4 [23440/45000]\tLoss: 3.7610\tLR: 0.000010\n",
      "Training Epoch: 4 [23456/45000]\tLoss: 3.5376\tLR: 0.000010\n",
      "Training Epoch: 4 [23472/45000]\tLoss: 3.6471\tLR: 0.000010\n",
      "Training Epoch: 4 [23488/45000]\tLoss: 3.6662\tLR: 0.000010\n",
      "Training Epoch: 4 [23504/45000]\tLoss: 3.6383\tLR: 0.000010\n",
      "Training Epoch: 4 [23520/45000]\tLoss: 3.5176\tLR: 0.000010\n",
      "Training Epoch: 4 [23536/45000]\tLoss: 3.5631\tLR: 0.000010\n",
      "Training Epoch: 4 [23552/45000]\tLoss: 3.6036\tLR: 0.000010\n",
      "Training Epoch: 4 [23568/45000]\tLoss: 3.6280\tLR: 0.000010\n",
      "Training Epoch: 4 [23584/45000]\tLoss: 3.6780\tLR: 0.000010\n",
      "Training Epoch: 4 [23600/45000]\tLoss: 3.7431\tLR: 0.000010\n",
      "Training Epoch: 4 [23616/45000]\tLoss: 3.5947\tLR: 0.000010\n",
      "Training Epoch: 4 [23632/45000]\tLoss: 3.6518\tLR: 0.000010\n",
      "Training Epoch: 4 [23648/45000]\tLoss: 3.6830\tLR: 0.000010\n",
      "Training Epoch: 4 [23664/45000]\tLoss: 3.6366\tLR: 0.000010\n",
      "Training Epoch: 4 [23680/45000]\tLoss: 3.6385\tLR: 0.000010\n",
      "Training Epoch: 4 [23696/45000]\tLoss: 3.8309\tLR: 0.000010\n",
      "Training Epoch: 4 [23712/45000]\tLoss: 3.6648\tLR: 0.000010\n",
      "Training Epoch: 4 [23728/45000]\tLoss: 3.6786\tLR: 0.000010\n",
      "Training Epoch: 4 [23744/45000]\tLoss: 3.6685\tLR: 0.000010\n",
      "Training Epoch: 4 [23760/45000]\tLoss: 3.6662\tLR: 0.000010\n",
      "Training Epoch: 4 [23776/45000]\tLoss: 3.6893\tLR: 0.000010\n",
      "Training Epoch: 4 [23792/45000]\tLoss: 3.6906\tLR: 0.000010\n",
      "Training Epoch: 4 [23808/45000]\tLoss: 3.6818\tLR: 0.000010\n",
      "Training Epoch: 4 [23824/45000]\tLoss: 3.6850\tLR: 0.000010\n",
      "Training Epoch: 4 [23840/45000]\tLoss: 3.6493\tLR: 0.000010\n",
      "Training Epoch: 4 [23856/45000]\tLoss: 3.7065\tLR: 0.000010\n",
      "Training Epoch: 4 [23872/45000]\tLoss: 3.5813\tLR: 0.000010\n",
      "Training Epoch: 4 [23888/45000]\tLoss: 3.7348\tLR: 0.000010\n",
      "Training Epoch: 4 [23904/45000]\tLoss: 3.7501\tLR: 0.000010\n",
      "Training Epoch: 4 [23920/45000]\tLoss: 3.7161\tLR: 0.000010\n",
      "Training Epoch: 4 [23936/45000]\tLoss: 3.6649\tLR: 0.000010\n",
      "Training Epoch: 4 [23952/45000]\tLoss: 3.6337\tLR: 0.000010\n",
      "Training Epoch: 4 [23968/45000]\tLoss: 3.6997\tLR: 0.000010\n",
      "Training Epoch: 4 [23984/45000]\tLoss: 3.6227\tLR: 0.000010\n",
      "Training Epoch: 4 [24000/45000]\tLoss: 3.7122\tLR: 0.000010\n",
      "Training Epoch: 4 [24016/45000]\tLoss: 3.7299\tLR: 0.000010\n",
      "Training Epoch: 4 [24032/45000]\tLoss: 3.6425\tLR: 0.000010\n",
      "Training Epoch: 4 [24048/45000]\tLoss: 3.8369\tLR: 0.000010\n",
      "Training Epoch: 4 [24064/45000]\tLoss: 3.6528\tLR: 0.000010\n",
      "Training Epoch: 4 [24080/45000]\tLoss: 3.6338\tLR: 0.000010\n",
      "Training Epoch: 4 [24096/45000]\tLoss: 3.5842\tLR: 0.000010\n",
      "Training Epoch: 4 [24112/45000]\tLoss: 3.6704\tLR: 0.000010\n",
      "Training Epoch: 4 [24128/45000]\tLoss: 3.7675\tLR: 0.000010\n",
      "Training Epoch: 4 [24144/45000]\tLoss: 3.6835\tLR: 0.000010\n",
      "Training Epoch: 4 [24160/45000]\tLoss: 3.7118\tLR: 0.000010\n",
      "Training Epoch: 4 [24176/45000]\tLoss: 3.6646\tLR: 0.000010\n",
      "Training Epoch: 4 [24192/45000]\tLoss: 3.6565\tLR: 0.000010\n",
      "Training Epoch: 4 [24208/45000]\tLoss: 3.6178\tLR: 0.000010\n",
      "Training Epoch: 4 [24224/45000]\tLoss: 3.6236\tLR: 0.000010\n",
      "Training Epoch: 4 [24240/45000]\tLoss: 3.6216\tLR: 0.000010\n",
      "Training Epoch: 4 [24256/45000]\tLoss: 3.6648\tLR: 0.000010\n",
      "Training Epoch: 4 [24272/45000]\tLoss: 3.6401\tLR: 0.000010\n",
      "Training Epoch: 4 [24288/45000]\tLoss: 3.5933\tLR: 0.000010\n",
      "Training Epoch: 4 [24304/45000]\tLoss: 3.7057\tLR: 0.000010\n",
      "Training Epoch: 4 [24320/45000]\tLoss: 3.8041\tLR: 0.000010\n",
      "Training Epoch: 4 [24336/45000]\tLoss: 3.5932\tLR: 0.000010\n",
      "Training Epoch: 4 [24352/45000]\tLoss: 3.5895\tLR: 0.000010\n",
      "Training Epoch: 4 [24368/45000]\tLoss: 3.6299\tLR: 0.000010\n",
      "Training Epoch: 4 [24384/45000]\tLoss: 3.6431\tLR: 0.000010\n",
      "Training Epoch: 4 [24400/45000]\tLoss: 3.6240\tLR: 0.000010\n",
      "Training Epoch: 4 [24416/45000]\tLoss: 3.6358\tLR: 0.000010\n",
      "Training Epoch: 4 [24432/45000]\tLoss: 3.6695\tLR: 0.000010\n",
      "Training Epoch: 4 [24448/45000]\tLoss: 3.6434\tLR: 0.000010\n",
      "Training Epoch: 4 [24464/45000]\tLoss: 3.6656\tLR: 0.000010\n",
      "Training Epoch: 4 [24480/45000]\tLoss: 3.6587\tLR: 0.000010\n",
      "Training Epoch: 4 [24496/45000]\tLoss: 3.6102\tLR: 0.000010\n",
      "Training Epoch: 4 [24512/45000]\tLoss: 3.6679\tLR: 0.000010\n",
      "Training Epoch: 4 [24528/45000]\tLoss: 3.5886\tLR: 0.000010\n",
      "Training Epoch: 4 [24544/45000]\tLoss: 3.8352\tLR: 0.000010\n",
      "Training Epoch: 4 [24560/45000]\tLoss: 3.5495\tLR: 0.000010\n",
      "Training Epoch: 4 [24576/45000]\tLoss: 3.6069\tLR: 0.000010\n",
      "Training Epoch: 4 [24592/45000]\tLoss: 3.7242\tLR: 0.000010\n",
      "Training Epoch: 4 [24608/45000]\tLoss: 3.7268\tLR: 0.000010\n",
      "Training Epoch: 4 [24624/45000]\tLoss: 3.7275\tLR: 0.000010\n",
      "Training Epoch: 4 [24640/45000]\tLoss: 3.6108\tLR: 0.000010\n",
      "Training Epoch: 4 [24656/45000]\tLoss: 3.6194\tLR: 0.000010\n",
      "Training Epoch: 4 [24672/45000]\tLoss: 3.6631\tLR: 0.000010\n",
      "Training Epoch: 4 [24688/45000]\tLoss: 3.6208\tLR: 0.000010\n",
      "Training Epoch: 4 [24704/45000]\tLoss: 3.7064\tLR: 0.000010\n",
      "Training Epoch: 4 [24720/45000]\tLoss: 3.6372\tLR: 0.000010\n",
      "Training Epoch: 4 [24736/45000]\tLoss: 3.4776\tLR: 0.000010\n",
      "Training Epoch: 4 [24752/45000]\tLoss: 3.7055\tLR: 0.000010\n",
      "Training Epoch: 4 [24768/45000]\tLoss: 3.6579\tLR: 0.000010\n",
      "Training Epoch: 4 [24784/45000]\tLoss: 3.6062\tLR: 0.000010\n",
      "Training Epoch: 4 [24800/45000]\tLoss: 3.6102\tLR: 0.000010\n",
      "Training Epoch: 4 [24816/45000]\tLoss: 3.7851\tLR: 0.000010\n",
      "Training Epoch: 4 [24832/45000]\tLoss: 3.6854\tLR: 0.000010\n",
      "Training Epoch: 4 [24848/45000]\tLoss: 3.6598\tLR: 0.000010\n",
      "Training Epoch: 4 [24864/45000]\tLoss: 3.6583\tLR: 0.000010\n",
      "Training Epoch: 4 [24880/45000]\tLoss: 3.6423\tLR: 0.000010\n",
      "Training Epoch: 4 [24896/45000]\tLoss: 3.6326\tLR: 0.000010\n",
      "Training Epoch: 4 [24912/45000]\tLoss: 3.5493\tLR: 0.000010\n",
      "Training Epoch: 4 [24928/45000]\tLoss: 3.8242\tLR: 0.000010\n",
      "Training Epoch: 4 [24944/45000]\tLoss: 3.6599\tLR: 0.000010\n",
      "Training Epoch: 4 [24960/45000]\tLoss: 3.7387\tLR: 0.000010\n",
      "Training Epoch: 4 [24976/45000]\tLoss: 3.6031\tLR: 0.000010\n",
      "Training Epoch: 4 [24992/45000]\tLoss: 3.7588\tLR: 0.000010\n",
      "Training Epoch: 4 [25008/45000]\tLoss: 3.7700\tLR: 0.000010\n",
      "Training Epoch: 4 [25024/45000]\tLoss: 3.5801\tLR: 0.000010\n",
      "Training Epoch: 4 [25040/45000]\tLoss: 3.6001\tLR: 0.000010\n",
      "Training Epoch: 4 [25056/45000]\tLoss: 3.6713\tLR: 0.000010\n",
      "Training Epoch: 4 [25072/45000]\tLoss: 3.7024\tLR: 0.000010\n",
      "Training Epoch: 4 [25088/45000]\tLoss: 3.5514\tLR: 0.000010\n",
      "Training Epoch: 4 [25104/45000]\tLoss: 3.6513\tLR: 0.000010\n",
      "Training Epoch: 4 [25120/45000]\tLoss: 3.6075\tLR: 0.000010\n",
      "Training Epoch: 4 [25136/45000]\tLoss: 3.5797\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [25152/45000]\tLoss: 3.6512\tLR: 0.000010\n",
      "Training Epoch: 4 [25168/45000]\tLoss: 3.7014\tLR: 0.000010\n",
      "Training Epoch: 4 [25184/45000]\tLoss: 3.6927\tLR: 0.000010\n",
      "Training Epoch: 4 [25200/45000]\tLoss: 3.5697\tLR: 0.000010\n",
      "Training Epoch: 4 [25216/45000]\tLoss: 3.6571\tLR: 0.000010\n",
      "Training Epoch: 4 [25232/45000]\tLoss: 3.6872\tLR: 0.000010\n",
      "Training Epoch: 4 [25248/45000]\tLoss: 3.6715\tLR: 0.000010\n",
      "Training Epoch: 4 [25264/45000]\tLoss: 3.7245\tLR: 0.000010\n",
      "Training Epoch: 4 [25280/45000]\tLoss: 3.6119\tLR: 0.000010\n",
      "Training Epoch: 4 [25296/45000]\tLoss: 3.8456\tLR: 0.000010\n",
      "Training Epoch: 4 [25312/45000]\tLoss: 3.6722\tLR: 0.000010\n",
      "Training Epoch: 4 [25328/45000]\tLoss: 3.7164\tLR: 0.000010\n",
      "Training Epoch: 4 [25344/45000]\tLoss: 3.6624\tLR: 0.000010\n",
      "Training Epoch: 4 [25360/45000]\tLoss: 3.6887\tLR: 0.000010\n",
      "Training Epoch: 4 [25376/45000]\tLoss: 3.7513\tLR: 0.000010\n",
      "Training Epoch: 4 [25392/45000]\tLoss: 3.6558\tLR: 0.000010\n",
      "Training Epoch: 4 [25408/45000]\tLoss: 3.6612\tLR: 0.000010\n",
      "Training Epoch: 4 [25424/45000]\tLoss: 3.6857\tLR: 0.000010\n",
      "Training Epoch: 4 [25440/45000]\tLoss: 3.6852\tLR: 0.000010\n",
      "Training Epoch: 4 [25456/45000]\tLoss: 3.6881\tLR: 0.000010\n",
      "Training Epoch: 4 [25472/45000]\tLoss: 3.7004\tLR: 0.000010\n",
      "Training Epoch: 4 [25488/45000]\tLoss: 3.6700\tLR: 0.000010\n",
      "Training Epoch: 4 [25504/45000]\tLoss: 3.6512\tLR: 0.000010\n",
      "Training Epoch: 4 [25520/45000]\tLoss: 3.7910\tLR: 0.000010\n",
      "Training Epoch: 4 [25536/45000]\tLoss: 3.7874\tLR: 0.000010\n",
      "Training Epoch: 4 [25552/45000]\tLoss: 3.8110\tLR: 0.000010\n",
      "Training Epoch: 4 [25568/45000]\tLoss: 3.6679\tLR: 0.000010\n",
      "Training Epoch: 4 [25584/45000]\tLoss: 3.6212\tLR: 0.000010\n",
      "Training Epoch: 4 [25600/45000]\tLoss: 3.6685\tLR: 0.000010\n",
      "Training Epoch: 4 [25616/45000]\tLoss: 3.6784\tLR: 0.000010\n",
      "Training Epoch: 4 [25632/45000]\tLoss: 3.7105\tLR: 0.000010\n",
      "Training Epoch: 4 [25648/45000]\tLoss: 3.5882\tLR: 0.000010\n",
      "Training Epoch: 4 [25664/45000]\tLoss: 3.6479\tLR: 0.000010\n",
      "Training Epoch: 4 [25680/45000]\tLoss: 3.6238\tLR: 0.000010\n",
      "Training Epoch: 4 [25696/45000]\tLoss: 3.5708\tLR: 0.000010\n",
      "Training Epoch: 4 [25712/45000]\tLoss: 3.6130\tLR: 0.000010\n",
      "Training Epoch: 4 [25728/45000]\tLoss: 3.6810\tLR: 0.000010\n",
      "Training Epoch: 4 [25744/45000]\tLoss: 3.6990\tLR: 0.000010\n",
      "Training Epoch: 4 [25760/45000]\tLoss: 3.7823\tLR: 0.000010\n",
      "Training Epoch: 4 [25776/45000]\tLoss: 3.6386\tLR: 0.000010\n",
      "Training Epoch: 4 [25792/45000]\tLoss: 3.7149\tLR: 0.000010\n",
      "Training Epoch: 4 [25808/45000]\tLoss: 3.7681\tLR: 0.000010\n",
      "Training Epoch: 4 [25824/45000]\tLoss: 3.7215\tLR: 0.000010\n",
      "Training Epoch: 4 [25840/45000]\tLoss: 3.6935\tLR: 0.000010\n",
      "Training Epoch: 4 [25856/45000]\tLoss: 3.6870\tLR: 0.000010\n",
      "Training Epoch: 4 [25872/45000]\tLoss: 3.7203\tLR: 0.000010\n",
      "Training Epoch: 4 [25888/45000]\tLoss: 3.7217\tLR: 0.000010\n",
      "Training Epoch: 4 [25904/45000]\tLoss: 3.7255\tLR: 0.000010\n",
      "Training Epoch: 4 [25920/45000]\tLoss: 3.8052\tLR: 0.000010\n",
      "Training Epoch: 4 [25936/45000]\tLoss: 3.6858\tLR: 0.000010\n",
      "Training Epoch: 4 [25952/45000]\tLoss: 3.6208\tLR: 0.000010\n",
      "Training Epoch: 4 [25968/45000]\tLoss: 3.5566\tLR: 0.000010\n",
      "Training Epoch: 4 [25984/45000]\tLoss: 3.5833\tLR: 0.000010\n",
      "Training Epoch: 4 [26000/45000]\tLoss: 3.7763\tLR: 0.000010\n",
      "Training Epoch: 4 [26016/45000]\tLoss: 3.6515\tLR: 0.000010\n",
      "Training Epoch: 4 [26032/45000]\tLoss: 3.6676\tLR: 0.000010\n",
      "Training Epoch: 4 [26048/45000]\tLoss: 3.7388\tLR: 0.000010\n",
      "Training Epoch: 4 [26064/45000]\tLoss: 3.7508\tLR: 0.000010\n",
      "Training Epoch: 4 [26080/45000]\tLoss: 3.7020\tLR: 0.000010\n",
      "Training Epoch: 4 [26096/45000]\tLoss: 3.6047\tLR: 0.000010\n",
      "Training Epoch: 4 [26112/45000]\tLoss: 3.7566\tLR: 0.000010\n",
      "Training Epoch: 4 [26128/45000]\tLoss: 3.6731\tLR: 0.000010\n",
      "Training Epoch: 4 [26144/45000]\tLoss: 3.7488\tLR: 0.000010\n",
      "Training Epoch: 4 [26160/45000]\tLoss: 3.6034\tLR: 0.000010\n",
      "Training Epoch: 4 [26176/45000]\tLoss: 3.6701\tLR: 0.000010\n",
      "Training Epoch: 4 [26192/45000]\tLoss: 3.7225\tLR: 0.000010\n",
      "Training Epoch: 4 [26208/45000]\tLoss: 3.7226\tLR: 0.000010\n",
      "Training Epoch: 4 [26224/45000]\tLoss: 3.6796\tLR: 0.000010\n",
      "Training Epoch: 4 [26240/45000]\tLoss: 3.7507\tLR: 0.000010\n",
      "Training Epoch: 4 [26256/45000]\tLoss: 3.6933\tLR: 0.000010\n",
      "Training Epoch: 4 [26272/45000]\tLoss: 3.5786\tLR: 0.000010\n",
      "Training Epoch: 4 [26288/45000]\tLoss: 3.6689\tLR: 0.000010\n",
      "Training Epoch: 4 [26304/45000]\tLoss: 3.6979\tLR: 0.000010\n",
      "Training Epoch: 4 [26320/45000]\tLoss: 3.7059\tLR: 0.000010\n",
      "Training Epoch: 4 [26336/45000]\tLoss: 3.5994\tLR: 0.000010\n",
      "Training Epoch: 4 [26352/45000]\tLoss: 3.6875\tLR: 0.000010\n",
      "Training Epoch: 4 [26368/45000]\tLoss: 3.6042\tLR: 0.000010\n",
      "Training Epoch: 4 [26384/45000]\tLoss: 3.7565\tLR: 0.000010\n",
      "Training Epoch: 4 [26400/45000]\tLoss: 3.6211\tLR: 0.000010\n",
      "Training Epoch: 4 [26416/45000]\tLoss: 3.7043\tLR: 0.000010\n",
      "Training Epoch: 4 [26432/45000]\tLoss: 3.6691\tLR: 0.000010\n",
      "Training Epoch: 4 [26448/45000]\tLoss: 3.5878\tLR: 0.000010\n",
      "Training Epoch: 4 [26464/45000]\tLoss: 3.7015\tLR: 0.000010\n",
      "Training Epoch: 4 [26480/45000]\tLoss: 3.5655\tLR: 0.000010\n",
      "Training Epoch: 4 [26496/45000]\tLoss: 3.7007\tLR: 0.000010\n",
      "Training Epoch: 4 [26512/45000]\tLoss: 3.6731\tLR: 0.000010\n",
      "Training Epoch: 4 [26528/45000]\tLoss: 3.6794\tLR: 0.000010\n",
      "Training Epoch: 4 [26544/45000]\tLoss: 3.6745\tLR: 0.000010\n",
      "Training Epoch: 4 [26560/45000]\tLoss: 3.6909\tLR: 0.000010\n",
      "Training Epoch: 4 [26576/45000]\tLoss: 3.6036\tLR: 0.000010\n",
      "Training Epoch: 4 [26592/45000]\tLoss: 3.6686\tLR: 0.000010\n",
      "Training Epoch: 4 [26608/45000]\tLoss: 3.7621\tLR: 0.000010\n",
      "Training Epoch: 4 [26624/45000]\tLoss: 3.6784\tLR: 0.000010\n",
      "Training Epoch: 4 [26640/45000]\tLoss: 3.5821\tLR: 0.000010\n",
      "Training Epoch: 4 [26656/45000]\tLoss: 3.7068\tLR: 0.000010\n",
      "Training Epoch: 4 [26672/45000]\tLoss: 3.7096\tLR: 0.000010\n",
      "Training Epoch: 4 [26688/45000]\tLoss: 3.6018\tLR: 0.000010\n",
      "Training Epoch: 4 [26704/45000]\tLoss: 3.6405\tLR: 0.000010\n",
      "Training Epoch: 4 [26720/45000]\tLoss: 3.7789\tLR: 0.000010\n",
      "Training Epoch: 4 [26736/45000]\tLoss: 3.6672\tLR: 0.000010\n",
      "Training Epoch: 4 [26752/45000]\tLoss: 3.6782\tLR: 0.000010\n",
      "Training Epoch: 4 [26768/45000]\tLoss: 3.7449\tLR: 0.000010\n",
      "Training Epoch: 4 [26784/45000]\tLoss: 3.6276\tLR: 0.000010\n",
      "Training Epoch: 4 [26800/45000]\tLoss: 3.6242\tLR: 0.000010\n",
      "Training Epoch: 4 [26816/45000]\tLoss: 3.7635\tLR: 0.000010\n",
      "Training Epoch: 4 [26832/45000]\tLoss: 3.5624\tLR: 0.000010\n",
      "Training Epoch: 4 [26848/45000]\tLoss: 3.5542\tLR: 0.000010\n",
      "Training Epoch: 4 [26864/45000]\tLoss: 3.7047\tLR: 0.000010\n",
      "Training Epoch: 4 [26880/45000]\tLoss: 3.5877\tLR: 0.000010\n",
      "Training Epoch: 4 [26896/45000]\tLoss: 3.6804\tLR: 0.000010\n",
      "Training Epoch: 4 [26912/45000]\tLoss: 3.6809\tLR: 0.000010\n",
      "Training Epoch: 4 [26928/45000]\tLoss: 3.7004\tLR: 0.000010\n",
      "Training Epoch: 4 [26944/45000]\tLoss: 3.7908\tLR: 0.000010\n",
      "Training Epoch: 4 [26960/45000]\tLoss: 3.6937\tLR: 0.000010\n",
      "Training Epoch: 4 [26976/45000]\tLoss: 3.6283\tLR: 0.000010\n",
      "Training Epoch: 4 [26992/45000]\tLoss: 3.5491\tLR: 0.000010\n",
      "Training Epoch: 4 [27008/45000]\tLoss: 3.7048\tLR: 0.000010\n",
      "Training Epoch: 4 [27024/45000]\tLoss: 3.8056\tLR: 0.000010\n",
      "Training Epoch: 4 [27040/45000]\tLoss: 3.6452\tLR: 0.000010\n",
      "Training Epoch: 4 [27056/45000]\tLoss: 3.5973\tLR: 0.000010\n",
      "Training Epoch: 4 [27072/45000]\tLoss: 3.6813\tLR: 0.000010\n",
      "Training Epoch: 4 [27088/45000]\tLoss: 3.6545\tLR: 0.000010\n",
      "Training Epoch: 4 [27104/45000]\tLoss: 3.7036\tLR: 0.000010\n",
      "Training Epoch: 4 [27120/45000]\tLoss: 3.6825\tLR: 0.000010\n",
      "Training Epoch: 4 [27136/45000]\tLoss: 3.6903\tLR: 0.000010\n",
      "Training Epoch: 4 [27152/45000]\tLoss: 3.6243\tLR: 0.000010\n",
      "Training Epoch: 4 [27168/45000]\tLoss: 3.6662\tLR: 0.000010\n",
      "Training Epoch: 4 [27184/45000]\tLoss: 3.6061\tLR: 0.000010\n",
      "Training Epoch: 4 [27200/45000]\tLoss: 3.4844\tLR: 0.000010\n",
      "Training Epoch: 4 [27216/45000]\tLoss: 3.5754\tLR: 0.000010\n",
      "Training Epoch: 4 [27232/45000]\tLoss: 3.6897\tLR: 0.000010\n",
      "Training Epoch: 4 [27248/45000]\tLoss: 3.6229\tLR: 0.000010\n",
      "Training Epoch: 4 [27264/45000]\tLoss: 3.7214\tLR: 0.000010\n",
      "Training Epoch: 4 [27280/45000]\tLoss: 3.6733\tLR: 0.000010\n",
      "Training Epoch: 4 [27296/45000]\tLoss: 3.6259\tLR: 0.000010\n",
      "Training Epoch: 4 [27312/45000]\tLoss: 3.5493\tLR: 0.000010\n",
      "Training Epoch: 4 [27328/45000]\tLoss: 3.6590\tLR: 0.000010\n",
      "Training Epoch: 4 [27344/45000]\tLoss: 3.6017\tLR: 0.000010\n",
      "Training Epoch: 4 [27360/45000]\tLoss: 3.6082\tLR: 0.000010\n",
      "Training Epoch: 4 [27376/45000]\tLoss: 3.5481\tLR: 0.000010\n",
      "Training Epoch: 4 [27392/45000]\tLoss: 3.6067\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [27408/45000]\tLoss: 3.6408\tLR: 0.000010\n",
      "Training Epoch: 4 [27424/45000]\tLoss: 3.6551\tLR: 0.000010\n",
      "Training Epoch: 4 [27440/45000]\tLoss: 3.5897\tLR: 0.000010\n",
      "Training Epoch: 4 [27456/45000]\tLoss: 3.6560\tLR: 0.000010\n",
      "Training Epoch: 4 [27472/45000]\tLoss: 3.7512\tLR: 0.000010\n",
      "Training Epoch: 4 [27488/45000]\tLoss: 3.6171\tLR: 0.000010\n",
      "Training Epoch: 4 [27504/45000]\tLoss: 3.5608\tLR: 0.000010\n",
      "Training Epoch: 4 [27520/45000]\tLoss: 3.6338\tLR: 0.000010\n",
      "Training Epoch: 4 [27536/45000]\tLoss: 3.6447\tLR: 0.000010\n",
      "Training Epoch: 4 [27552/45000]\tLoss: 3.6417\tLR: 0.000010\n",
      "Training Epoch: 4 [27568/45000]\tLoss: 3.6073\tLR: 0.000010\n",
      "Training Epoch: 4 [27584/45000]\tLoss: 3.7557\tLR: 0.000010\n",
      "Training Epoch: 4 [27600/45000]\tLoss: 3.6336\tLR: 0.000010\n",
      "Training Epoch: 4 [27616/45000]\tLoss: 3.6778\tLR: 0.000010\n",
      "Training Epoch: 4 [27632/45000]\tLoss: 3.6044\tLR: 0.000010\n",
      "Training Epoch: 4 [27648/45000]\tLoss: 3.5715\tLR: 0.000010\n",
      "Training Epoch: 4 [27664/45000]\tLoss: 3.7358\tLR: 0.000010\n",
      "Training Epoch: 4 [27680/45000]\tLoss: 3.6675\tLR: 0.000010\n",
      "Training Epoch: 4 [27696/45000]\tLoss: 3.6618\tLR: 0.000010\n",
      "Training Epoch: 4 [27712/45000]\tLoss: 3.8028\tLR: 0.000010\n",
      "Training Epoch: 4 [27728/45000]\tLoss: 3.5846\tLR: 0.000010\n",
      "Training Epoch: 4 [27744/45000]\tLoss: 3.6379\tLR: 0.000010\n",
      "Training Epoch: 4 [27760/45000]\tLoss: 3.7247\tLR: 0.000010\n",
      "Training Epoch: 4 [27776/45000]\tLoss: 3.6897\tLR: 0.000010\n",
      "Training Epoch: 4 [27792/45000]\tLoss: 3.7412\tLR: 0.000010\n",
      "Training Epoch: 4 [27808/45000]\tLoss: 3.5933\tLR: 0.000010\n",
      "Training Epoch: 4 [27824/45000]\tLoss: 3.6379\tLR: 0.000010\n",
      "Training Epoch: 4 [27840/45000]\tLoss: 3.7633\tLR: 0.000010\n",
      "Training Epoch: 4 [27856/45000]\tLoss: 3.5616\tLR: 0.000010\n",
      "Training Epoch: 4 [27872/45000]\tLoss: 3.5834\tLR: 0.000010\n",
      "Training Epoch: 4 [27888/45000]\tLoss: 3.6135\tLR: 0.000010\n",
      "Training Epoch: 4 [27904/45000]\tLoss: 3.8826\tLR: 0.000010\n",
      "Training Epoch: 4 [27920/45000]\tLoss: 3.5929\tLR: 0.000010\n",
      "Training Epoch: 4 [27936/45000]\tLoss: 3.7308\tLR: 0.000010\n",
      "Training Epoch: 4 [27952/45000]\tLoss: 3.6417\tLR: 0.000010\n",
      "Training Epoch: 4 [27968/45000]\tLoss: 3.6797\tLR: 0.000010\n",
      "Training Epoch: 4 [27984/45000]\tLoss: 3.5585\tLR: 0.000010\n",
      "Training Epoch: 4 [28000/45000]\tLoss: 3.6997\tLR: 0.000010\n",
      "Training Epoch: 4 [28016/45000]\tLoss: 3.6904\tLR: 0.000010\n",
      "Training Epoch: 4 [28032/45000]\tLoss: 3.7282\tLR: 0.000010\n",
      "Training Epoch: 4 [28048/45000]\tLoss: 3.7088\tLR: 0.000010\n",
      "Training Epoch: 4 [28064/45000]\tLoss: 3.6277\tLR: 0.000010\n",
      "Training Epoch: 4 [28080/45000]\tLoss: 3.7670\tLR: 0.000010\n",
      "Training Epoch: 4 [28096/45000]\tLoss: 3.5826\tLR: 0.000010\n",
      "Training Epoch: 4 [28112/45000]\tLoss: 3.6964\tLR: 0.000010\n",
      "Training Epoch: 4 [28128/45000]\tLoss: 3.6395\tLR: 0.000010\n",
      "Training Epoch: 4 [28144/45000]\tLoss: 3.5772\tLR: 0.000010\n",
      "Training Epoch: 4 [28160/45000]\tLoss: 3.4972\tLR: 0.000010\n",
      "Training Epoch: 4 [28176/45000]\tLoss: 3.7430\tLR: 0.000010\n",
      "Training Epoch: 4 [28192/45000]\tLoss: 3.6876\tLR: 0.000010\n",
      "Training Epoch: 4 [28208/45000]\tLoss: 3.6389\tLR: 0.000010\n",
      "Training Epoch: 4 [28224/45000]\tLoss: 3.7350\tLR: 0.000010\n",
      "Training Epoch: 4 [28240/45000]\tLoss: 3.7030\tLR: 0.000010\n",
      "Training Epoch: 4 [28256/45000]\tLoss: 3.6616\tLR: 0.000010\n",
      "Training Epoch: 4 [28272/45000]\tLoss: 3.7662\tLR: 0.000010\n",
      "Training Epoch: 4 [28288/45000]\tLoss: 3.7394\tLR: 0.000010\n",
      "Training Epoch: 4 [28304/45000]\tLoss: 3.7247\tLR: 0.000010\n",
      "Training Epoch: 4 [28320/45000]\tLoss: 3.5994\tLR: 0.000010\n",
      "Training Epoch: 4 [28336/45000]\tLoss: 3.6639\tLR: 0.000010\n",
      "Training Epoch: 4 [28352/45000]\tLoss: 3.5444\tLR: 0.000010\n",
      "Training Epoch: 4 [28368/45000]\tLoss: 3.7251\tLR: 0.000010\n",
      "Training Epoch: 4 [28384/45000]\tLoss: 3.6673\tLR: 0.000010\n",
      "Training Epoch: 4 [28400/45000]\tLoss: 3.5111\tLR: 0.000010\n",
      "Training Epoch: 4 [28416/45000]\tLoss: 3.6617\tLR: 0.000010\n",
      "Training Epoch: 4 [28432/45000]\tLoss: 3.5349\tLR: 0.000010\n",
      "Training Epoch: 4 [28448/45000]\tLoss: 3.6208\tLR: 0.000010\n",
      "Training Epoch: 4 [28464/45000]\tLoss: 3.5702\tLR: 0.000010\n",
      "Training Epoch: 4 [28480/45000]\tLoss: 3.6913\tLR: 0.000010\n",
      "Training Epoch: 4 [28496/45000]\tLoss: 3.7098\tLR: 0.000010\n",
      "Training Epoch: 4 [28512/45000]\tLoss: 3.5495\tLR: 0.000010\n",
      "Training Epoch: 4 [28528/45000]\tLoss: 3.6430\tLR: 0.000010\n",
      "Training Epoch: 4 [28544/45000]\tLoss: 3.5406\tLR: 0.000010\n",
      "Training Epoch: 4 [28560/45000]\tLoss: 3.5876\tLR: 0.000010\n",
      "Training Epoch: 4 [28576/45000]\tLoss: 3.7019\tLR: 0.000010\n",
      "Training Epoch: 4 [28592/45000]\tLoss: 3.6191\tLR: 0.000010\n",
      "Training Epoch: 4 [28608/45000]\tLoss: 3.5594\tLR: 0.000010\n",
      "Training Epoch: 4 [28624/45000]\tLoss: 3.6704\tLR: 0.000010\n",
      "Training Epoch: 4 [28640/45000]\tLoss: 3.6704\tLR: 0.000010\n",
      "Training Epoch: 4 [28656/45000]\tLoss: 3.6452\tLR: 0.000010\n",
      "Training Epoch: 4 [28672/45000]\tLoss: 3.7178\tLR: 0.000010\n",
      "Training Epoch: 4 [28688/45000]\tLoss: 3.6000\tLR: 0.000010\n",
      "Training Epoch: 4 [28704/45000]\tLoss: 3.7327\tLR: 0.000010\n",
      "Training Epoch: 4 [28720/45000]\tLoss: 3.6132\tLR: 0.000010\n",
      "Training Epoch: 4 [28736/45000]\tLoss: 3.6010\tLR: 0.000010\n",
      "Training Epoch: 4 [28752/45000]\tLoss: 3.6700\tLR: 0.000010\n",
      "Training Epoch: 4 [28768/45000]\tLoss: 3.5825\tLR: 0.000010\n",
      "Training Epoch: 4 [28784/45000]\tLoss: 3.5516\tLR: 0.000010\n",
      "Training Epoch: 4 [28800/45000]\tLoss: 3.6821\tLR: 0.000010\n",
      "Training Epoch: 4 [28816/45000]\tLoss: 3.6587\tLR: 0.000010\n",
      "Training Epoch: 4 [28832/45000]\tLoss: 3.7839\tLR: 0.000010\n",
      "Training Epoch: 4 [28848/45000]\tLoss: 3.6172\tLR: 0.000010\n",
      "Training Epoch: 4 [28864/45000]\tLoss: 3.6249\tLR: 0.000010\n",
      "Training Epoch: 4 [28880/45000]\tLoss: 3.5535\tLR: 0.000010\n",
      "Training Epoch: 4 [28896/45000]\tLoss: 3.6541\tLR: 0.000010\n",
      "Training Epoch: 4 [28912/45000]\tLoss: 3.6739\tLR: 0.000010\n",
      "Training Epoch: 4 [28928/45000]\tLoss: 3.6878\tLR: 0.000010\n",
      "Training Epoch: 4 [28944/45000]\tLoss: 3.6770\tLR: 0.000010\n",
      "Training Epoch: 4 [28960/45000]\tLoss: 3.6020\tLR: 0.000010\n",
      "Training Epoch: 4 [28976/45000]\tLoss: 3.6272\tLR: 0.000010\n",
      "Training Epoch: 4 [28992/45000]\tLoss: 3.6689\tLR: 0.000010\n",
      "Training Epoch: 4 [29008/45000]\tLoss: 3.6119\tLR: 0.000010\n",
      "Training Epoch: 4 [29024/45000]\tLoss: 3.7217\tLR: 0.000010\n",
      "Training Epoch: 4 [29040/45000]\tLoss: 3.7328\tLR: 0.000010\n",
      "Training Epoch: 4 [29056/45000]\tLoss: 3.6195\tLR: 0.000010\n",
      "Training Epoch: 4 [29072/45000]\tLoss: 3.7135\tLR: 0.000010\n",
      "Training Epoch: 4 [29088/45000]\tLoss: 3.6075\tLR: 0.000010\n",
      "Training Epoch: 4 [29104/45000]\tLoss: 3.6503\tLR: 0.000010\n",
      "Training Epoch: 4 [29120/45000]\tLoss: 3.6413\tLR: 0.000010\n",
      "Training Epoch: 4 [29136/45000]\tLoss: 3.7046\tLR: 0.000010\n",
      "Training Epoch: 4 [29152/45000]\tLoss: 3.6549\tLR: 0.000010\n",
      "Training Epoch: 4 [29168/45000]\tLoss: 3.6893\tLR: 0.000010\n",
      "Training Epoch: 4 [29184/45000]\tLoss: 3.6431\tLR: 0.000010\n",
      "Training Epoch: 4 [29200/45000]\tLoss: 3.6290\tLR: 0.000010\n",
      "Training Epoch: 4 [29216/45000]\tLoss: 3.6662\tLR: 0.000010\n",
      "Training Epoch: 4 [29232/45000]\tLoss: 3.6845\tLR: 0.000010\n",
      "Training Epoch: 4 [29248/45000]\tLoss: 3.7120\tLR: 0.000010\n",
      "Training Epoch: 4 [29264/45000]\tLoss: 3.5737\tLR: 0.000010\n",
      "Training Epoch: 4 [29280/45000]\tLoss: 3.6561\tLR: 0.000010\n",
      "Training Epoch: 4 [29296/45000]\tLoss: 3.7341\tLR: 0.000010\n",
      "Training Epoch: 4 [29312/45000]\tLoss: 3.6776\tLR: 0.000010\n",
      "Training Epoch: 4 [29328/45000]\tLoss: 3.6186\tLR: 0.000010\n",
      "Training Epoch: 4 [29344/45000]\tLoss: 3.5778\tLR: 0.000010\n",
      "Training Epoch: 4 [29360/45000]\tLoss: 3.8512\tLR: 0.000010\n",
      "Training Epoch: 4 [29376/45000]\tLoss: 3.5508\tLR: 0.000010\n",
      "Training Epoch: 4 [29392/45000]\tLoss: 3.5961\tLR: 0.000010\n",
      "Training Epoch: 4 [29408/45000]\tLoss: 3.7656\tLR: 0.000010\n",
      "Training Epoch: 4 [29424/45000]\tLoss: 3.6204\tLR: 0.000010\n",
      "Training Epoch: 4 [29440/45000]\tLoss: 3.6380\tLR: 0.000010\n",
      "Training Epoch: 4 [29456/45000]\tLoss: 3.5665\tLR: 0.000010\n",
      "Training Epoch: 4 [29472/45000]\tLoss: 3.6866\tLR: 0.000010\n",
      "Training Epoch: 4 [29488/45000]\tLoss: 3.6023\tLR: 0.000010\n",
      "Training Epoch: 4 [29504/45000]\tLoss: 3.5190\tLR: 0.000010\n",
      "Training Epoch: 4 [29520/45000]\tLoss: 3.6433\tLR: 0.000010\n",
      "Training Epoch: 4 [29536/45000]\tLoss: 3.6181\tLR: 0.000010\n",
      "Training Epoch: 4 [29552/45000]\tLoss: 3.6059\tLR: 0.000010\n",
      "Training Epoch: 4 [29568/45000]\tLoss: 3.5330\tLR: 0.000010\n",
      "Training Epoch: 4 [29584/45000]\tLoss: 3.6681\tLR: 0.000010\n",
      "Training Epoch: 4 [29600/45000]\tLoss: 3.5926\tLR: 0.000010\n",
      "Training Epoch: 4 [29616/45000]\tLoss: 3.6923\tLR: 0.000010\n",
      "Training Epoch: 4 [29632/45000]\tLoss: 3.5195\tLR: 0.000010\n",
      "Training Epoch: 4 [29648/45000]\tLoss: 3.5996\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [29664/45000]\tLoss: 3.5867\tLR: 0.000010\n",
      "Training Epoch: 4 [29680/45000]\tLoss: 3.6257\tLR: 0.000010\n",
      "Training Epoch: 4 [29696/45000]\tLoss: 3.7016\tLR: 0.000010\n",
      "Training Epoch: 4 [29712/45000]\tLoss: 3.5844\tLR: 0.000010\n",
      "Training Epoch: 4 [29728/45000]\tLoss: 3.6996\tLR: 0.000010\n",
      "Training Epoch: 4 [29744/45000]\tLoss: 3.8009\tLR: 0.000010\n",
      "Training Epoch: 4 [29760/45000]\tLoss: 3.6129\tLR: 0.000010\n",
      "Training Epoch: 4 [29776/45000]\tLoss: 3.7852\tLR: 0.000010\n",
      "Training Epoch: 4 [29792/45000]\tLoss: 3.5717\tLR: 0.000010\n",
      "Training Epoch: 4 [29808/45000]\tLoss: 3.6505\tLR: 0.000010\n",
      "Training Epoch: 4 [29824/45000]\tLoss: 3.6044\tLR: 0.000010\n",
      "Training Epoch: 4 [29840/45000]\tLoss: 3.7597\tLR: 0.000010\n",
      "Training Epoch: 4 [29856/45000]\tLoss: 3.6531\tLR: 0.000010\n",
      "Training Epoch: 4 [29872/45000]\tLoss: 3.7052\tLR: 0.000010\n",
      "Training Epoch: 4 [29888/45000]\tLoss: 3.6640\tLR: 0.000010\n",
      "Training Epoch: 4 [29904/45000]\tLoss: 3.7363\tLR: 0.000010\n",
      "Training Epoch: 4 [29920/45000]\tLoss: 3.5840\tLR: 0.000010\n",
      "Training Epoch: 4 [29936/45000]\tLoss: 3.7068\tLR: 0.000010\n",
      "Training Epoch: 4 [29952/45000]\tLoss: 3.5881\tLR: 0.000010\n",
      "Training Epoch: 4 [29968/45000]\tLoss: 3.7059\tLR: 0.000010\n",
      "Training Epoch: 4 [29984/45000]\tLoss: 3.6000\tLR: 0.000010\n",
      "Training Epoch: 4 [30000/45000]\tLoss: 3.6377\tLR: 0.000010\n",
      "Training Epoch: 4 [30016/45000]\tLoss: 3.8210\tLR: 0.000010\n",
      "Training Epoch: 4 [30032/45000]\tLoss: 3.5349\tLR: 0.000010\n",
      "Training Epoch: 4 [30048/45000]\tLoss: 3.6383\tLR: 0.000010\n",
      "Training Epoch: 4 [30064/45000]\tLoss: 3.6317\tLR: 0.000010\n",
      "Training Epoch: 4 [30080/45000]\tLoss: 3.6034\tLR: 0.000010\n",
      "Training Epoch: 4 [30096/45000]\tLoss: 3.6310\tLR: 0.000010\n",
      "Training Epoch: 4 [30112/45000]\tLoss: 3.5723\tLR: 0.000010\n",
      "Training Epoch: 4 [30128/45000]\tLoss: 3.6674\tLR: 0.000010\n",
      "Training Epoch: 4 [30144/45000]\tLoss: 3.6542\tLR: 0.000010\n",
      "Training Epoch: 4 [30160/45000]\tLoss: 3.5679\tLR: 0.000010\n",
      "Training Epoch: 4 [30176/45000]\tLoss: 3.7421\tLR: 0.000010\n",
      "Training Epoch: 4 [30192/45000]\tLoss: 3.6524\tLR: 0.000010\n",
      "Training Epoch: 4 [30208/45000]\tLoss: 3.6379\tLR: 0.000010\n",
      "Training Epoch: 4 [30224/45000]\tLoss: 3.6509\tLR: 0.000010\n",
      "Training Epoch: 4 [30240/45000]\tLoss: 3.6280\tLR: 0.000010\n",
      "Training Epoch: 4 [30256/45000]\tLoss: 3.7330\tLR: 0.000010\n",
      "Training Epoch: 4 [30272/45000]\tLoss: 3.7275\tLR: 0.000010\n",
      "Training Epoch: 4 [30288/45000]\tLoss: 3.7173\tLR: 0.000010\n",
      "Training Epoch: 4 [30304/45000]\tLoss: 3.6282\tLR: 0.000010\n",
      "Training Epoch: 4 [30320/45000]\tLoss: 3.5857\tLR: 0.000010\n",
      "Training Epoch: 4 [30336/45000]\tLoss: 3.6157\tLR: 0.000010\n",
      "Training Epoch: 4 [30352/45000]\tLoss: 3.6352\tLR: 0.000010\n",
      "Training Epoch: 4 [30368/45000]\tLoss: 3.7317\tLR: 0.000010\n",
      "Training Epoch: 4 [30384/45000]\tLoss: 3.6248\tLR: 0.000010\n",
      "Training Epoch: 4 [30400/45000]\tLoss: 3.7392\tLR: 0.000010\n",
      "Training Epoch: 4 [30416/45000]\tLoss: 3.7295\tLR: 0.000010\n",
      "Training Epoch: 4 [30432/45000]\tLoss: 3.5656\tLR: 0.000010\n",
      "Training Epoch: 4 [30448/45000]\tLoss: 3.5713\tLR: 0.000010\n",
      "Training Epoch: 4 [30464/45000]\tLoss: 3.6085\tLR: 0.000010\n",
      "Training Epoch: 4 [30480/45000]\tLoss: 3.6698\tLR: 0.000010\n",
      "Training Epoch: 4 [30496/45000]\tLoss: 3.5683\tLR: 0.000010\n",
      "Training Epoch: 4 [30512/45000]\tLoss: 3.5465\tLR: 0.000010\n",
      "Training Epoch: 4 [30528/45000]\tLoss: 3.6544\tLR: 0.000010\n",
      "Training Epoch: 4 [30544/45000]\tLoss: 3.6229\tLR: 0.000010\n",
      "Training Epoch: 4 [30560/45000]\tLoss: 3.6641\tLR: 0.000010\n",
      "Training Epoch: 4 [30576/45000]\tLoss: 3.6699\tLR: 0.000010\n",
      "Training Epoch: 4 [30592/45000]\tLoss: 3.4875\tLR: 0.000010\n",
      "Training Epoch: 4 [30608/45000]\tLoss: 3.7065\tLR: 0.000010\n",
      "Training Epoch: 4 [30624/45000]\tLoss: 3.7640\tLR: 0.000010\n",
      "Training Epoch: 4 [30640/45000]\tLoss: 3.6246\tLR: 0.000010\n",
      "Training Epoch: 4 [30656/45000]\tLoss: 3.6694\tLR: 0.000010\n",
      "Training Epoch: 4 [30672/45000]\tLoss: 3.6851\tLR: 0.000010\n",
      "Training Epoch: 4 [30688/45000]\tLoss: 3.6627\tLR: 0.000010\n",
      "Training Epoch: 4 [30704/45000]\tLoss: 3.7263\tLR: 0.000010\n",
      "Training Epoch: 4 [30720/45000]\tLoss: 3.6474\tLR: 0.000010\n",
      "Training Epoch: 4 [30736/45000]\tLoss: 3.5562\tLR: 0.000010\n",
      "Training Epoch: 4 [30752/45000]\tLoss: 3.6301\tLR: 0.000010\n",
      "Training Epoch: 4 [30768/45000]\tLoss: 3.7319\tLR: 0.000010\n",
      "Training Epoch: 4 [30784/45000]\tLoss: 3.6081\tLR: 0.000010\n",
      "Training Epoch: 4 [30800/45000]\tLoss: 3.6729\tLR: 0.000010\n",
      "Training Epoch: 4 [30816/45000]\tLoss: 3.7499\tLR: 0.000010\n",
      "Training Epoch: 4 [30832/45000]\tLoss: 3.6459\tLR: 0.000010\n",
      "Training Epoch: 4 [30848/45000]\tLoss: 3.5880\tLR: 0.000010\n",
      "Training Epoch: 4 [30864/45000]\tLoss: 3.6967\tLR: 0.000010\n",
      "Training Epoch: 4 [30880/45000]\tLoss: 3.6026\tLR: 0.000010\n",
      "Training Epoch: 4 [30896/45000]\tLoss: 3.5854\tLR: 0.000010\n",
      "Training Epoch: 4 [30912/45000]\tLoss: 3.6511\tLR: 0.000010\n",
      "Training Epoch: 4 [30928/45000]\tLoss: 3.7469\tLR: 0.000010\n",
      "Training Epoch: 4 [30944/45000]\tLoss: 3.6008\tLR: 0.000010\n",
      "Training Epoch: 4 [30960/45000]\tLoss: 3.8038\tLR: 0.000010\n",
      "Training Epoch: 4 [30976/45000]\tLoss: 3.5614\tLR: 0.000010\n",
      "Training Epoch: 4 [30992/45000]\tLoss: 3.5903\tLR: 0.000010\n",
      "Training Epoch: 4 [31008/45000]\tLoss: 3.5836\tLR: 0.000010\n",
      "Training Epoch: 4 [31024/45000]\tLoss: 3.7059\tLR: 0.000010\n",
      "Training Epoch: 4 [31040/45000]\tLoss: 3.7074\tLR: 0.000010\n",
      "Training Epoch: 4 [31056/45000]\tLoss: 3.7478\tLR: 0.000010\n",
      "Training Epoch: 4 [31072/45000]\tLoss: 3.5957\tLR: 0.000010\n",
      "Training Epoch: 4 [31088/45000]\tLoss: 3.6949\tLR: 0.000010\n",
      "Training Epoch: 4 [31104/45000]\tLoss: 3.7643\tLR: 0.000010\n",
      "Training Epoch: 4 [31120/45000]\tLoss: 3.5383\tLR: 0.000010\n",
      "Training Epoch: 4 [31136/45000]\tLoss: 3.6953\tLR: 0.000010\n",
      "Training Epoch: 4 [31152/45000]\tLoss: 3.5514\tLR: 0.000010\n",
      "Training Epoch: 4 [31168/45000]\tLoss: 3.8103\tLR: 0.000010\n",
      "Training Epoch: 4 [31184/45000]\tLoss: 3.6689\tLR: 0.000010\n",
      "Training Epoch: 4 [31200/45000]\tLoss: 3.6018\tLR: 0.000010\n",
      "Training Epoch: 4 [31216/45000]\tLoss: 3.7960\tLR: 0.000010\n",
      "Training Epoch: 4 [31232/45000]\tLoss: 3.6867\tLR: 0.000010\n",
      "Training Epoch: 4 [31248/45000]\tLoss: 3.7986\tLR: 0.000010\n",
      "Training Epoch: 4 [31264/45000]\tLoss: 3.5483\tLR: 0.000010\n",
      "Training Epoch: 4 [31280/45000]\tLoss: 3.5970\tLR: 0.000010\n",
      "Training Epoch: 4 [31296/45000]\tLoss: 3.6460\tLR: 0.000010\n",
      "Training Epoch: 4 [31312/45000]\tLoss: 3.6189\tLR: 0.000010\n",
      "Training Epoch: 4 [31328/45000]\tLoss: 3.5988\tLR: 0.000010\n",
      "Training Epoch: 4 [31344/45000]\tLoss: 3.6053\tLR: 0.000010\n",
      "Training Epoch: 4 [31360/45000]\tLoss: 3.7116\tLR: 0.000010\n",
      "Training Epoch: 4 [31376/45000]\tLoss: 3.6849\tLR: 0.000010\n",
      "Training Epoch: 4 [31392/45000]\tLoss: 3.6438\tLR: 0.000010\n",
      "Training Epoch: 4 [31408/45000]\tLoss: 3.6777\tLR: 0.000010\n",
      "Training Epoch: 4 [31424/45000]\tLoss: 3.6464\tLR: 0.000010\n",
      "Training Epoch: 4 [31440/45000]\tLoss: 3.7274\tLR: 0.000010\n",
      "Training Epoch: 4 [31456/45000]\tLoss: 3.7567\tLR: 0.000010\n",
      "Training Epoch: 4 [31472/45000]\tLoss: 3.6997\tLR: 0.000010\n",
      "Training Epoch: 4 [31488/45000]\tLoss: 3.6551\tLR: 0.000010\n",
      "Training Epoch: 4 [31504/45000]\tLoss: 3.6171\tLR: 0.000010\n",
      "Training Epoch: 4 [31520/45000]\tLoss: 3.6880\tLR: 0.000010\n",
      "Training Epoch: 4 [31536/45000]\tLoss: 3.6213\tLR: 0.000010\n",
      "Training Epoch: 4 [31552/45000]\tLoss: 3.7103\tLR: 0.000010\n",
      "Training Epoch: 4 [31568/45000]\tLoss: 3.5575\tLR: 0.000010\n",
      "Training Epoch: 4 [31584/45000]\tLoss: 3.5685\tLR: 0.000010\n",
      "Training Epoch: 4 [31600/45000]\tLoss: 3.6808\tLR: 0.000010\n",
      "Training Epoch: 4 [31616/45000]\tLoss: 3.5919\tLR: 0.000010\n",
      "Training Epoch: 4 [31632/45000]\tLoss: 3.6323\tLR: 0.000010\n",
      "Training Epoch: 4 [31648/45000]\tLoss: 3.6528\tLR: 0.000010\n",
      "Training Epoch: 4 [31664/45000]\tLoss: 3.6211\tLR: 0.000010\n",
      "Training Epoch: 4 [31680/45000]\tLoss: 3.7186\tLR: 0.000010\n",
      "Training Epoch: 4 [31696/45000]\tLoss: 3.7787\tLR: 0.000010\n",
      "Training Epoch: 4 [31712/45000]\tLoss: 3.5388\tLR: 0.000010\n",
      "Training Epoch: 4 [31728/45000]\tLoss: 3.6834\tLR: 0.000010\n",
      "Training Epoch: 4 [31744/45000]\tLoss: 3.6041\tLR: 0.000010\n",
      "Training Epoch: 4 [31760/45000]\tLoss: 3.7182\tLR: 0.000010\n",
      "Training Epoch: 4 [31776/45000]\tLoss: 3.6855\tLR: 0.000010\n",
      "Training Epoch: 4 [31792/45000]\tLoss: 3.6434\tLR: 0.000010\n",
      "Training Epoch: 4 [31808/45000]\tLoss: 3.6331\tLR: 0.000010\n",
      "Training Epoch: 4 [31824/45000]\tLoss: 3.5993\tLR: 0.000010\n",
      "Training Epoch: 4 [31840/45000]\tLoss: 3.6784\tLR: 0.000010\n",
      "Training Epoch: 4 [31856/45000]\tLoss: 3.6320\tLR: 0.000010\n",
      "Training Epoch: 4 [31872/45000]\tLoss: 3.6732\tLR: 0.000010\n",
      "Training Epoch: 4 [31888/45000]\tLoss: 3.6691\tLR: 0.000010\n",
      "Training Epoch: 4 [31904/45000]\tLoss: 3.5258\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [31920/45000]\tLoss: 3.5567\tLR: 0.000010\n",
      "Training Epoch: 4 [31936/45000]\tLoss: 3.7604\tLR: 0.000010\n",
      "Training Epoch: 4 [31952/45000]\tLoss: 3.6253\tLR: 0.000010\n",
      "Training Epoch: 4 [31968/45000]\tLoss: 3.6471\tLR: 0.000010\n",
      "Training Epoch: 4 [31984/45000]\tLoss: 3.5613\tLR: 0.000010\n",
      "Training Epoch: 4 [32000/45000]\tLoss: 3.7140\tLR: 0.000010\n",
      "Training Epoch: 4 [32016/45000]\tLoss: 3.7000\tLR: 0.000010\n",
      "Training Epoch: 4 [32032/45000]\tLoss: 3.6947\tLR: 0.000010\n",
      "Training Epoch: 4 [32048/45000]\tLoss: 3.6694\tLR: 0.000010\n",
      "Training Epoch: 4 [32064/45000]\tLoss: 3.6002\tLR: 0.000010\n",
      "Training Epoch: 4 [32080/45000]\tLoss: 3.7063\tLR: 0.000010\n",
      "Training Epoch: 4 [32096/45000]\tLoss: 3.5664\tLR: 0.000010\n",
      "Training Epoch: 4 [32112/45000]\tLoss: 3.6845\tLR: 0.000010\n",
      "Training Epoch: 4 [32128/45000]\tLoss: 3.5983\tLR: 0.000010\n",
      "Training Epoch: 4 [32144/45000]\tLoss: 3.7861\tLR: 0.000010\n",
      "Training Epoch: 4 [32160/45000]\tLoss: 3.5519\tLR: 0.000010\n",
      "Training Epoch: 4 [32176/45000]\tLoss: 3.5597\tLR: 0.000010\n",
      "Training Epoch: 4 [32192/45000]\tLoss: 3.7755\tLR: 0.000010\n",
      "Training Epoch: 4 [32208/45000]\tLoss: 3.5846\tLR: 0.000010\n",
      "Training Epoch: 4 [32224/45000]\tLoss: 3.7265\tLR: 0.000010\n",
      "Training Epoch: 4 [32240/45000]\tLoss: 3.6591\tLR: 0.000010\n",
      "Training Epoch: 4 [32256/45000]\tLoss: 3.6948\tLR: 0.000010\n",
      "Training Epoch: 4 [32272/45000]\tLoss: 3.6733\tLR: 0.000010\n",
      "Training Epoch: 4 [32288/45000]\tLoss: 3.5991\tLR: 0.000010\n",
      "Training Epoch: 4 [32304/45000]\tLoss: 3.6122\tLR: 0.000010\n",
      "Training Epoch: 4 [32320/45000]\tLoss: 3.6839\tLR: 0.000010\n",
      "Training Epoch: 4 [32336/45000]\tLoss: 3.6696\tLR: 0.000010\n",
      "Training Epoch: 4 [32352/45000]\tLoss: 3.6393\tLR: 0.000010\n",
      "Training Epoch: 4 [32368/45000]\tLoss: 3.5445\tLR: 0.000010\n",
      "Training Epoch: 4 [32384/45000]\tLoss: 3.6300\tLR: 0.000010\n",
      "Training Epoch: 4 [32400/45000]\tLoss: 3.5994\tLR: 0.000010\n",
      "Training Epoch: 4 [32416/45000]\tLoss: 3.6563\tLR: 0.000010\n",
      "Training Epoch: 4 [32432/45000]\tLoss: 3.6077\tLR: 0.000010\n",
      "Training Epoch: 4 [32448/45000]\tLoss: 3.7174\tLR: 0.000010\n",
      "Training Epoch: 4 [32464/45000]\tLoss: 3.5869\tLR: 0.000010\n",
      "Training Epoch: 4 [32480/45000]\tLoss: 3.6524\tLR: 0.000010\n",
      "Training Epoch: 4 [32496/45000]\tLoss: 3.5939\tLR: 0.000010\n",
      "Training Epoch: 4 [32512/45000]\tLoss: 3.6630\tLR: 0.000010\n",
      "Training Epoch: 4 [32528/45000]\tLoss: 3.6604\tLR: 0.000010\n",
      "Training Epoch: 4 [32544/45000]\tLoss: 3.5966\tLR: 0.000010\n",
      "Training Epoch: 4 [32560/45000]\tLoss: 3.5658\tLR: 0.000010\n",
      "Training Epoch: 4 [32576/45000]\tLoss: 3.6227\tLR: 0.000010\n",
      "Training Epoch: 4 [32592/45000]\tLoss: 3.7179\tLR: 0.000010\n",
      "Training Epoch: 4 [32608/45000]\tLoss: 3.6732\tLR: 0.000010\n",
      "Training Epoch: 4 [32624/45000]\tLoss: 3.6629\tLR: 0.000010\n",
      "Training Epoch: 4 [32640/45000]\tLoss: 3.6545\tLR: 0.000010\n",
      "Training Epoch: 4 [32656/45000]\tLoss: 3.7039\tLR: 0.000010\n",
      "Training Epoch: 4 [32672/45000]\tLoss: 3.6943\tLR: 0.000010\n",
      "Training Epoch: 4 [32688/45000]\tLoss: 3.6351\tLR: 0.000010\n",
      "Training Epoch: 4 [32704/45000]\tLoss: 3.5882\tLR: 0.000010\n",
      "Training Epoch: 4 [32720/45000]\tLoss: 3.6985\tLR: 0.000010\n",
      "Training Epoch: 4 [32736/45000]\tLoss: 3.6646\tLR: 0.000010\n",
      "Training Epoch: 4 [32752/45000]\tLoss: 3.6886\tLR: 0.000010\n",
      "Training Epoch: 4 [32768/45000]\tLoss: 3.6719\tLR: 0.000010\n",
      "Training Epoch: 4 [32784/45000]\tLoss: 3.6644\tLR: 0.000010\n",
      "Training Epoch: 4 [32800/45000]\tLoss: 3.6334\tLR: 0.000010\n",
      "Training Epoch: 4 [32816/45000]\tLoss: 3.5684\tLR: 0.000010\n",
      "Training Epoch: 4 [32832/45000]\tLoss: 3.7167\tLR: 0.000010\n",
      "Training Epoch: 4 [32848/45000]\tLoss: 3.7013\tLR: 0.000010\n",
      "Training Epoch: 4 [32864/45000]\tLoss: 3.6813\tLR: 0.000010\n",
      "Training Epoch: 4 [32880/45000]\tLoss: 3.7797\tLR: 0.000010\n",
      "Training Epoch: 4 [32896/45000]\tLoss: 3.7485\tLR: 0.000010\n",
      "Training Epoch: 4 [32912/45000]\tLoss: 3.5640\tLR: 0.000010\n",
      "Training Epoch: 4 [32928/45000]\tLoss: 3.6998\tLR: 0.000010\n",
      "Training Epoch: 4 [32944/45000]\tLoss: 3.5967\tLR: 0.000010\n",
      "Training Epoch: 4 [32960/45000]\tLoss: 3.6175\tLR: 0.000010\n",
      "Training Epoch: 4 [32976/45000]\tLoss: 3.5236\tLR: 0.000010\n",
      "Training Epoch: 4 [32992/45000]\tLoss: 3.6967\tLR: 0.000010\n",
      "Training Epoch: 4 [33008/45000]\tLoss: 3.6355\tLR: 0.000010\n",
      "Training Epoch: 4 [33024/45000]\tLoss: 3.6313\tLR: 0.000010\n",
      "Training Epoch: 4 [33040/45000]\tLoss: 3.6381\tLR: 0.000010\n",
      "Training Epoch: 4 [33056/45000]\tLoss: 3.6231\tLR: 0.000010\n",
      "Training Epoch: 4 [33072/45000]\tLoss: 3.6238\tLR: 0.000010\n",
      "Training Epoch: 4 [33088/45000]\tLoss: 3.5969\tLR: 0.000010\n",
      "Training Epoch: 4 [33104/45000]\tLoss: 3.6268\tLR: 0.000010\n",
      "Training Epoch: 4 [33120/45000]\tLoss: 3.5894\tLR: 0.000010\n",
      "Training Epoch: 4 [33136/45000]\tLoss: 3.7729\tLR: 0.000010\n",
      "Training Epoch: 4 [33152/45000]\tLoss: 3.6072\tLR: 0.000010\n",
      "Training Epoch: 4 [33168/45000]\tLoss: 3.6146\tLR: 0.000010\n",
      "Training Epoch: 4 [33184/45000]\tLoss: 3.5522\tLR: 0.000010\n",
      "Training Epoch: 4 [33200/45000]\tLoss: 3.7401\tLR: 0.000010\n",
      "Training Epoch: 4 [33216/45000]\tLoss: 3.6894\tLR: 0.000010\n",
      "Training Epoch: 4 [33232/45000]\tLoss: 3.5374\tLR: 0.000010\n",
      "Training Epoch: 4 [33248/45000]\tLoss: 3.4887\tLR: 0.000010\n",
      "Training Epoch: 4 [33264/45000]\tLoss: 3.6322\tLR: 0.000010\n",
      "Training Epoch: 4 [33280/45000]\tLoss: 3.6354\tLR: 0.000010\n",
      "Training Epoch: 4 [33296/45000]\tLoss: 3.6063\tLR: 0.000010\n",
      "Training Epoch: 4 [33312/45000]\tLoss: 3.5315\tLR: 0.000010\n",
      "Training Epoch: 4 [33328/45000]\tLoss: 3.6899\tLR: 0.000010\n",
      "Training Epoch: 4 [33344/45000]\tLoss: 3.5510\tLR: 0.000010\n",
      "Training Epoch: 4 [33360/45000]\tLoss: 3.6441\tLR: 0.000010\n",
      "Training Epoch: 4 [33376/45000]\tLoss: 3.7222\tLR: 0.000010\n",
      "Training Epoch: 4 [33392/45000]\tLoss: 3.7612\tLR: 0.000010\n",
      "Training Epoch: 4 [33408/45000]\tLoss: 3.7173\tLR: 0.000010\n",
      "Training Epoch: 4 [33424/45000]\tLoss: 3.6180\tLR: 0.000010\n",
      "Training Epoch: 4 [33440/45000]\tLoss: 3.5961\tLR: 0.000010\n",
      "Training Epoch: 4 [33456/45000]\tLoss: 3.7134\tLR: 0.000010\n",
      "Training Epoch: 4 [33472/45000]\tLoss: 3.6453\tLR: 0.000010\n",
      "Training Epoch: 4 [33488/45000]\tLoss: 3.6513\tLR: 0.000010\n",
      "Training Epoch: 4 [33504/45000]\tLoss: 3.5729\tLR: 0.000010\n",
      "Training Epoch: 4 [33520/45000]\tLoss: 3.7342\tLR: 0.000010\n",
      "Training Epoch: 4 [33536/45000]\tLoss: 3.6762\tLR: 0.000010\n",
      "Training Epoch: 4 [33552/45000]\tLoss: 3.6836\tLR: 0.000010\n",
      "Training Epoch: 4 [33568/45000]\tLoss: 3.6245\tLR: 0.000010\n",
      "Training Epoch: 4 [33584/45000]\tLoss: 3.7094\tLR: 0.000010\n",
      "Training Epoch: 4 [33600/45000]\tLoss: 3.6049\tLR: 0.000010\n",
      "Training Epoch: 4 [33616/45000]\tLoss: 3.7248\tLR: 0.000010\n",
      "Training Epoch: 4 [33632/45000]\tLoss: 3.6610\tLR: 0.000010\n",
      "Training Epoch: 4 [33648/45000]\tLoss: 3.6391\tLR: 0.000010\n",
      "Training Epoch: 4 [33664/45000]\tLoss: 3.7833\tLR: 0.000010\n",
      "Training Epoch: 4 [33680/45000]\tLoss: 3.6464\tLR: 0.000010\n",
      "Training Epoch: 4 [33696/45000]\tLoss: 3.6871\tLR: 0.000010\n",
      "Training Epoch: 4 [33712/45000]\tLoss: 3.6806\tLR: 0.000010\n",
      "Training Epoch: 4 [33728/45000]\tLoss: 3.5720\tLR: 0.000010\n",
      "Training Epoch: 4 [33744/45000]\tLoss: 3.6695\tLR: 0.000010\n",
      "Training Epoch: 4 [33760/45000]\tLoss: 3.6329\tLR: 0.000010\n",
      "Training Epoch: 4 [33776/45000]\tLoss: 3.7085\tLR: 0.000010\n",
      "Training Epoch: 4 [33792/45000]\tLoss: 3.4841\tLR: 0.000010\n",
      "Training Epoch: 4 [33808/45000]\tLoss: 3.6694\tLR: 0.000010\n",
      "Training Epoch: 4 [33824/45000]\tLoss: 3.5449\tLR: 0.000010\n",
      "Training Epoch: 4 [33840/45000]\tLoss: 3.7339\tLR: 0.000010\n",
      "Training Epoch: 4 [33856/45000]\tLoss: 3.6813\tLR: 0.000010\n",
      "Training Epoch: 4 [33872/45000]\tLoss: 3.6202\tLR: 0.000010\n",
      "Training Epoch: 4 [33888/45000]\tLoss: 3.6845\tLR: 0.000010\n",
      "Training Epoch: 4 [33904/45000]\tLoss: 3.6539\tLR: 0.000010\n",
      "Training Epoch: 4 [33920/45000]\tLoss: 3.5607\tLR: 0.000010\n",
      "Training Epoch: 4 [33936/45000]\tLoss: 3.6787\tLR: 0.000010\n",
      "Training Epoch: 4 [33952/45000]\tLoss: 3.7590\tLR: 0.000010\n",
      "Training Epoch: 4 [33968/45000]\tLoss: 3.6791\tLR: 0.000010\n",
      "Training Epoch: 4 [33984/45000]\tLoss: 3.6190\tLR: 0.000010\n",
      "Training Epoch: 4 [34000/45000]\tLoss: 3.6182\tLR: 0.000010\n",
      "Training Epoch: 4 [34016/45000]\tLoss: 3.5649\tLR: 0.000010\n",
      "Training Epoch: 4 [34032/45000]\tLoss: 3.6773\tLR: 0.000010\n",
      "Training Epoch: 4 [34048/45000]\tLoss: 3.5860\tLR: 0.000010\n",
      "Training Epoch: 4 [34064/45000]\tLoss: 3.8008\tLR: 0.000010\n",
      "Training Epoch: 4 [34080/45000]\tLoss: 3.5539\tLR: 0.000010\n",
      "Training Epoch: 4 [34096/45000]\tLoss: 3.6830\tLR: 0.000010\n",
      "Training Epoch: 4 [34112/45000]\tLoss: 3.7815\tLR: 0.000010\n",
      "Training Epoch: 4 [34128/45000]\tLoss: 3.6988\tLR: 0.000010\n",
      "Training Epoch: 4 [34144/45000]\tLoss: 3.5498\tLR: 0.000010\n",
      "Training Epoch: 4 [34160/45000]\tLoss: 3.5980\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [34176/45000]\tLoss: 3.7490\tLR: 0.000010\n",
      "Training Epoch: 4 [34192/45000]\tLoss: 3.5882\tLR: 0.000010\n",
      "Training Epoch: 4 [34208/45000]\tLoss: 3.6206\tLR: 0.000010\n",
      "Training Epoch: 4 [34224/45000]\tLoss: 3.7200\tLR: 0.000010\n",
      "Training Epoch: 4 [34240/45000]\tLoss: 3.7397\tLR: 0.000010\n",
      "Training Epoch: 4 [34256/45000]\tLoss: 3.7402\tLR: 0.000010\n",
      "Training Epoch: 4 [34272/45000]\tLoss: 3.7429\tLR: 0.000010\n",
      "Training Epoch: 4 [34288/45000]\tLoss: 3.6668\tLR: 0.000010\n",
      "Training Epoch: 4 [34304/45000]\tLoss: 3.6595\tLR: 0.000010\n",
      "Training Epoch: 4 [34320/45000]\tLoss: 3.7643\tLR: 0.000010\n",
      "Training Epoch: 4 [34336/45000]\tLoss: 3.6078\tLR: 0.000010\n",
      "Training Epoch: 4 [34352/45000]\tLoss: 3.5500\tLR: 0.000010\n",
      "Training Epoch: 4 [34368/45000]\tLoss: 3.6627\tLR: 0.000010\n",
      "Training Epoch: 4 [34384/45000]\tLoss: 3.5203\tLR: 0.000010\n",
      "Training Epoch: 4 [34400/45000]\tLoss: 3.6439\tLR: 0.000010\n",
      "Training Epoch: 4 [34416/45000]\tLoss: 3.6416\tLR: 0.000010\n",
      "Training Epoch: 4 [34432/45000]\tLoss: 3.6617\tLR: 0.000010\n",
      "Training Epoch: 4 [34448/45000]\tLoss: 3.5812\tLR: 0.000010\n",
      "Training Epoch: 4 [34464/45000]\tLoss: 3.7479\tLR: 0.000010\n",
      "Training Epoch: 4 [34480/45000]\tLoss: 3.6340\tLR: 0.000010\n",
      "Training Epoch: 4 [34496/45000]\tLoss: 3.6591\tLR: 0.000010\n",
      "Training Epoch: 4 [34512/45000]\tLoss: 3.4832\tLR: 0.000010\n",
      "Training Epoch: 4 [34528/45000]\tLoss: 3.6272\tLR: 0.000010\n",
      "Training Epoch: 4 [34544/45000]\tLoss: 3.6483\tLR: 0.000010\n",
      "Training Epoch: 4 [34560/45000]\tLoss: 3.6420\tLR: 0.000010\n",
      "Training Epoch: 4 [34576/45000]\tLoss: 3.7161\tLR: 0.000010\n",
      "Training Epoch: 4 [34592/45000]\tLoss: 3.5706\tLR: 0.000010\n",
      "Training Epoch: 4 [34608/45000]\tLoss: 3.6904\tLR: 0.000010\n",
      "Training Epoch: 4 [34624/45000]\tLoss: 3.5811\tLR: 0.000010\n",
      "Training Epoch: 4 [34640/45000]\tLoss: 3.6964\tLR: 0.000010\n",
      "Training Epoch: 4 [34656/45000]\tLoss: 3.5970\tLR: 0.000010\n",
      "Training Epoch: 4 [34672/45000]\tLoss: 3.6573\tLR: 0.000010\n",
      "Training Epoch: 4 [34688/45000]\tLoss: 3.5141\tLR: 0.000010\n",
      "Training Epoch: 4 [34704/45000]\tLoss: 3.6418\tLR: 0.000010\n",
      "Training Epoch: 4 [34720/45000]\tLoss: 3.5490\tLR: 0.000010\n",
      "Training Epoch: 4 [34736/45000]\tLoss: 3.6144\tLR: 0.000010\n",
      "Training Epoch: 4 [34752/45000]\tLoss: 3.6819\tLR: 0.000010\n",
      "Training Epoch: 4 [34768/45000]\tLoss: 3.6034\tLR: 0.000010\n",
      "Training Epoch: 4 [34784/45000]\tLoss: 3.6181\tLR: 0.000010\n",
      "Training Epoch: 4 [34800/45000]\tLoss: 3.6349\tLR: 0.000010\n",
      "Training Epoch: 4 [34816/45000]\tLoss: 3.6154\tLR: 0.000010\n",
      "Training Epoch: 4 [34832/45000]\tLoss: 3.5459\tLR: 0.000010\n",
      "Training Epoch: 4 [34848/45000]\tLoss: 3.5801\tLR: 0.000010\n",
      "Training Epoch: 4 [34864/45000]\tLoss: 3.6923\tLR: 0.000010\n",
      "Training Epoch: 4 [34880/45000]\tLoss: 3.6066\tLR: 0.000010\n",
      "Training Epoch: 4 [34896/45000]\tLoss: 3.6348\tLR: 0.000010\n",
      "Training Epoch: 4 [34912/45000]\tLoss: 3.7168\tLR: 0.000010\n",
      "Training Epoch: 4 [34928/45000]\tLoss: 3.7020\tLR: 0.000010\n",
      "Training Epoch: 4 [34944/45000]\tLoss: 3.6209\tLR: 0.000010\n",
      "Training Epoch: 4 [34960/45000]\tLoss: 3.6217\tLR: 0.000010\n",
      "Training Epoch: 4 [34976/45000]\tLoss: 3.6603\tLR: 0.000010\n",
      "Training Epoch: 4 [34992/45000]\tLoss: 3.6135\tLR: 0.000010\n",
      "Training Epoch: 4 [35008/45000]\tLoss: 3.5154\tLR: 0.000010\n",
      "Training Epoch: 4 [35024/45000]\tLoss: 3.6085\tLR: 0.000010\n",
      "Training Epoch: 4 [35040/45000]\tLoss: 3.7881\tLR: 0.000010\n",
      "Training Epoch: 4 [35056/45000]\tLoss: 3.6129\tLR: 0.000010\n",
      "Training Epoch: 4 [35072/45000]\tLoss: 3.7228\tLR: 0.000010\n",
      "Training Epoch: 4 [35088/45000]\tLoss: 3.6975\tLR: 0.000010\n",
      "Training Epoch: 4 [35104/45000]\tLoss: 3.7017\tLR: 0.000010\n",
      "Training Epoch: 4 [35120/45000]\tLoss: 3.6153\tLR: 0.000010\n",
      "Training Epoch: 4 [35136/45000]\tLoss: 3.7500\tLR: 0.000010\n",
      "Training Epoch: 4 [35152/45000]\tLoss: 3.6749\tLR: 0.000010\n",
      "Training Epoch: 4 [35168/45000]\tLoss: 3.7053\tLR: 0.000010\n",
      "Training Epoch: 4 [35184/45000]\tLoss: 3.6186\tLR: 0.000010\n",
      "Training Epoch: 4 [35200/45000]\tLoss: 3.8553\tLR: 0.000010\n",
      "Training Epoch: 4 [35216/45000]\tLoss: 3.5792\tLR: 0.000010\n",
      "Training Epoch: 4 [35232/45000]\tLoss: 3.5918\tLR: 0.000010\n",
      "Training Epoch: 4 [35248/45000]\tLoss: 3.6415\tLR: 0.000010\n",
      "Training Epoch: 4 [35264/45000]\tLoss: 3.6676\tLR: 0.000010\n",
      "Training Epoch: 4 [35280/45000]\tLoss: 3.6430\tLR: 0.000010\n",
      "Training Epoch: 4 [35296/45000]\tLoss: 3.6542\tLR: 0.000010\n",
      "Training Epoch: 4 [35312/45000]\tLoss: 3.6503\tLR: 0.000010\n",
      "Training Epoch: 4 [35328/45000]\tLoss: 3.8556\tLR: 0.000010\n",
      "Training Epoch: 4 [35344/45000]\tLoss: 3.7530\tLR: 0.000010\n",
      "Training Epoch: 4 [35360/45000]\tLoss: 3.7080\tLR: 0.000010\n",
      "Training Epoch: 4 [35376/45000]\tLoss: 3.5798\tLR: 0.000010\n",
      "Training Epoch: 4 [35392/45000]\tLoss: 3.7337\tLR: 0.000010\n",
      "Training Epoch: 4 [35408/45000]\tLoss: 3.5934\tLR: 0.000010\n",
      "Training Epoch: 4 [35424/45000]\tLoss: 3.6456\tLR: 0.000010\n",
      "Training Epoch: 4 [35440/45000]\tLoss: 3.5892\tLR: 0.000010\n",
      "Training Epoch: 4 [35456/45000]\tLoss: 3.5103\tLR: 0.000010\n",
      "Training Epoch: 4 [35472/45000]\tLoss: 3.6758\tLR: 0.000010\n",
      "Training Epoch: 4 [35488/45000]\tLoss: 3.6615\tLR: 0.000010\n",
      "Training Epoch: 4 [35504/45000]\tLoss: 3.7292\tLR: 0.000010\n",
      "Training Epoch: 4 [35520/45000]\tLoss: 3.6999\tLR: 0.000010\n",
      "Training Epoch: 4 [35536/45000]\tLoss: 3.6493\tLR: 0.000010\n",
      "Training Epoch: 4 [35552/45000]\tLoss: 3.7291\tLR: 0.000010\n",
      "Training Epoch: 4 [35568/45000]\tLoss: 3.6515\tLR: 0.000010\n",
      "Training Epoch: 4 [35584/45000]\tLoss: 3.6800\tLR: 0.000010\n",
      "Training Epoch: 4 [35600/45000]\tLoss: 3.7617\tLR: 0.000010\n",
      "Training Epoch: 4 [35616/45000]\tLoss: 3.6435\tLR: 0.000010\n",
      "Training Epoch: 4 [35632/45000]\tLoss: 3.6218\tLR: 0.000010\n",
      "Training Epoch: 4 [35648/45000]\tLoss: 3.6254\tLR: 0.000010\n",
      "Training Epoch: 4 [35664/45000]\tLoss: 3.7337\tLR: 0.000010\n",
      "Training Epoch: 4 [35680/45000]\tLoss: 3.6885\tLR: 0.000010\n",
      "Training Epoch: 4 [35696/45000]\tLoss: 3.7204\tLR: 0.000010\n",
      "Training Epoch: 4 [35712/45000]\tLoss: 3.6311\tLR: 0.000010\n",
      "Training Epoch: 4 [35728/45000]\tLoss: 3.7441\tLR: 0.000010\n",
      "Training Epoch: 4 [35744/45000]\tLoss: 3.6692\tLR: 0.000010\n",
      "Training Epoch: 4 [35760/45000]\tLoss: 3.7056\tLR: 0.000010\n",
      "Training Epoch: 4 [35776/45000]\tLoss: 3.6883\tLR: 0.000010\n",
      "Training Epoch: 4 [35792/45000]\tLoss: 3.7977\tLR: 0.000010\n",
      "Training Epoch: 4 [35808/45000]\tLoss: 3.6217\tLR: 0.000010\n",
      "Training Epoch: 4 [35824/45000]\tLoss: 3.6117\tLR: 0.000010\n",
      "Training Epoch: 4 [35840/45000]\tLoss: 3.7689\tLR: 0.000010\n",
      "Training Epoch: 4 [35856/45000]\tLoss: 3.6114\tLR: 0.000010\n",
      "Training Epoch: 4 [35872/45000]\tLoss: 3.6997\tLR: 0.000010\n",
      "Training Epoch: 4 [35888/45000]\tLoss: 3.6884\tLR: 0.000010\n",
      "Training Epoch: 4 [35904/45000]\tLoss: 3.7347\tLR: 0.000010\n",
      "Training Epoch: 4 [35920/45000]\tLoss: 3.7059\tLR: 0.000010\n",
      "Training Epoch: 4 [35936/45000]\tLoss: 3.6943\tLR: 0.000010\n",
      "Training Epoch: 4 [35952/45000]\tLoss: 3.6684\tLR: 0.000010\n",
      "Training Epoch: 4 [35968/45000]\tLoss: 3.6506\tLR: 0.000010\n",
      "Training Epoch: 4 [35984/45000]\tLoss: 3.5927\tLR: 0.000010\n",
      "Training Epoch: 4 [36000/45000]\tLoss: 3.6624\tLR: 0.000010\n",
      "Training Epoch: 4 [36016/45000]\tLoss: 3.4757\tLR: 0.000010\n",
      "Training Epoch: 4 [36032/45000]\tLoss: 3.6661\tLR: 0.000010\n",
      "Training Epoch: 4 [36048/45000]\tLoss: 3.6668\tLR: 0.000010\n",
      "Training Epoch: 4 [36064/45000]\tLoss: 3.5860\tLR: 0.000010\n",
      "Training Epoch: 4 [36080/45000]\tLoss: 3.6051\tLR: 0.000010\n",
      "Training Epoch: 4 [36096/45000]\tLoss: 3.5145\tLR: 0.000010\n",
      "Training Epoch: 4 [36112/45000]\tLoss: 3.7477\tLR: 0.000010\n",
      "Training Epoch: 4 [36128/45000]\tLoss: 3.5967\tLR: 0.000010\n",
      "Training Epoch: 4 [36144/45000]\tLoss: 3.6276\tLR: 0.000010\n",
      "Training Epoch: 4 [36160/45000]\tLoss: 3.6465\tLR: 0.000010\n",
      "Training Epoch: 4 [36176/45000]\tLoss: 3.7201\tLR: 0.000010\n",
      "Training Epoch: 4 [36192/45000]\tLoss: 3.6040\tLR: 0.000010\n",
      "Training Epoch: 4 [36208/45000]\tLoss: 3.6623\tLR: 0.000010\n",
      "Training Epoch: 4 [36224/45000]\tLoss: 3.6720\tLR: 0.000010\n",
      "Training Epoch: 4 [36240/45000]\tLoss: 3.6364\tLR: 0.000010\n",
      "Training Epoch: 4 [36256/45000]\tLoss: 3.7107\tLR: 0.000010\n",
      "Training Epoch: 4 [36272/45000]\tLoss: 3.5931\tLR: 0.000010\n",
      "Training Epoch: 4 [36288/45000]\tLoss: 3.6017\tLR: 0.000010\n",
      "Training Epoch: 4 [36304/45000]\tLoss: 3.5377\tLR: 0.000010\n",
      "Training Epoch: 4 [36320/45000]\tLoss: 3.6293\tLR: 0.000010\n",
      "Training Epoch: 4 [36336/45000]\tLoss: 3.6412\tLR: 0.000010\n",
      "Training Epoch: 4 [36352/45000]\tLoss: 3.7835\tLR: 0.000010\n",
      "Training Epoch: 4 [36368/45000]\tLoss: 3.6561\tLR: 0.000010\n",
      "Training Epoch: 4 [36384/45000]\tLoss: 3.7005\tLR: 0.000010\n",
      "Training Epoch: 4 [36400/45000]\tLoss: 3.6799\tLR: 0.000010\n",
      "Training Epoch: 4 [36416/45000]\tLoss: 3.6492\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [36432/45000]\tLoss: 3.6121\tLR: 0.000010\n",
      "Training Epoch: 4 [36448/45000]\tLoss: 3.6565\tLR: 0.000010\n",
      "Training Epoch: 4 [36464/45000]\tLoss: 3.6080\tLR: 0.000010\n",
      "Training Epoch: 4 [36480/45000]\tLoss: 3.6155\tLR: 0.000010\n",
      "Training Epoch: 4 [36496/45000]\tLoss: 3.6582\tLR: 0.000010\n",
      "Training Epoch: 4 [36512/45000]\tLoss: 3.5336\tLR: 0.000010\n",
      "Training Epoch: 4 [36528/45000]\tLoss: 3.6482\tLR: 0.000010\n",
      "Training Epoch: 4 [36544/45000]\tLoss: 3.6633\tLR: 0.000010\n",
      "Training Epoch: 4 [36560/45000]\tLoss: 3.7239\tLR: 0.000010\n",
      "Training Epoch: 4 [36576/45000]\tLoss: 3.5990\tLR: 0.000010\n",
      "Training Epoch: 4 [36592/45000]\tLoss: 3.5868\tLR: 0.000010\n",
      "Training Epoch: 4 [36608/45000]\tLoss: 3.7005\tLR: 0.000010\n",
      "Training Epoch: 4 [36624/45000]\tLoss: 3.5950\tLR: 0.000010\n",
      "Training Epoch: 4 [36640/45000]\tLoss: 3.5823\tLR: 0.000010\n",
      "Training Epoch: 4 [36656/45000]\tLoss: 3.7219\tLR: 0.000010\n",
      "Training Epoch: 4 [36672/45000]\tLoss: 3.6640\tLR: 0.000010\n",
      "Training Epoch: 4 [36688/45000]\tLoss: 3.5328\tLR: 0.000010\n",
      "Training Epoch: 4 [36704/45000]\tLoss: 3.5546\tLR: 0.000010\n",
      "Training Epoch: 4 [36720/45000]\tLoss: 3.7530\tLR: 0.000010\n",
      "Training Epoch: 4 [36736/45000]\tLoss: 3.5492\tLR: 0.000010\n",
      "Training Epoch: 4 [36752/45000]\tLoss: 3.5968\tLR: 0.000010\n",
      "Training Epoch: 4 [36768/45000]\tLoss: 3.6020\tLR: 0.000010\n",
      "Training Epoch: 4 [36784/45000]\tLoss: 3.5553\tLR: 0.000010\n",
      "Training Epoch: 4 [36800/45000]\tLoss: 3.6273\tLR: 0.000010\n",
      "Training Epoch: 4 [36816/45000]\tLoss: 3.6721\tLR: 0.000010\n",
      "Training Epoch: 4 [36832/45000]\tLoss: 3.6868\tLR: 0.000010\n",
      "Training Epoch: 4 [36848/45000]\tLoss: 3.6515\tLR: 0.000010\n",
      "Training Epoch: 4 [36864/45000]\tLoss: 3.6698\tLR: 0.000010\n",
      "Training Epoch: 4 [36880/45000]\tLoss: 3.6430\tLR: 0.000010\n",
      "Training Epoch: 4 [36896/45000]\tLoss: 3.7734\tLR: 0.000010\n",
      "Training Epoch: 4 [36912/45000]\tLoss: 3.5987\tLR: 0.000010\n",
      "Training Epoch: 4 [36928/45000]\tLoss: 3.6248\tLR: 0.000010\n",
      "Training Epoch: 4 [36944/45000]\tLoss: 3.5834\tLR: 0.000010\n",
      "Training Epoch: 4 [36960/45000]\tLoss: 3.6422\tLR: 0.000010\n",
      "Training Epoch: 4 [36976/45000]\tLoss: 3.5516\tLR: 0.000010\n",
      "Training Epoch: 4 [36992/45000]\tLoss: 3.5760\tLR: 0.000010\n",
      "Training Epoch: 4 [37008/45000]\tLoss: 3.6141\tLR: 0.000010\n",
      "Training Epoch: 4 [37024/45000]\tLoss: 3.6396\tLR: 0.000010\n",
      "Training Epoch: 4 [37040/45000]\tLoss: 3.6384\tLR: 0.000010\n",
      "Training Epoch: 4 [37056/45000]\tLoss: 3.5713\tLR: 0.000010\n",
      "Training Epoch: 4 [37072/45000]\tLoss: 3.7162\tLR: 0.000010\n",
      "Training Epoch: 4 [37088/45000]\tLoss: 3.7326\tLR: 0.000010\n",
      "Training Epoch: 4 [37104/45000]\tLoss: 3.6020\tLR: 0.000010\n",
      "Training Epoch: 4 [37120/45000]\tLoss: 3.8039\tLR: 0.000010\n",
      "Training Epoch: 4 [37136/45000]\tLoss: 3.6135\tLR: 0.000010\n",
      "Training Epoch: 4 [37152/45000]\tLoss: 3.7058\tLR: 0.000010\n",
      "Training Epoch: 4 [37168/45000]\tLoss: 3.7504\tLR: 0.000010\n",
      "Training Epoch: 4 [37184/45000]\tLoss: 3.6081\tLR: 0.000010\n",
      "Training Epoch: 4 [37200/45000]\tLoss: 3.6969\tLR: 0.000010\n",
      "Training Epoch: 4 [37216/45000]\tLoss: 3.5680\tLR: 0.000010\n",
      "Training Epoch: 4 [37232/45000]\tLoss: 3.6042\tLR: 0.000010\n",
      "Training Epoch: 4 [37248/45000]\tLoss: 3.5978\tLR: 0.000010\n",
      "Training Epoch: 4 [37264/45000]\tLoss: 3.5931\tLR: 0.000010\n",
      "Training Epoch: 4 [37280/45000]\tLoss: 3.6174\tLR: 0.000010\n",
      "Training Epoch: 4 [37296/45000]\tLoss: 3.6162\tLR: 0.000010\n",
      "Training Epoch: 4 [37312/45000]\tLoss: 3.6241\tLR: 0.000010\n",
      "Training Epoch: 4 [37328/45000]\tLoss: 3.6315\tLR: 0.000010\n",
      "Training Epoch: 4 [37344/45000]\tLoss: 3.5921\tLR: 0.000010\n",
      "Training Epoch: 4 [37360/45000]\tLoss: 3.6757\tLR: 0.000010\n",
      "Training Epoch: 4 [37376/45000]\tLoss: 3.7139\tLR: 0.000010\n",
      "Training Epoch: 4 [37392/45000]\tLoss: 3.6400\tLR: 0.000010\n",
      "Training Epoch: 4 [37408/45000]\tLoss: 3.6034\tLR: 0.000010\n",
      "Training Epoch: 4 [37424/45000]\tLoss: 3.5997\tLR: 0.000010\n",
      "Training Epoch: 4 [37440/45000]\tLoss: 3.6460\tLR: 0.000010\n",
      "Training Epoch: 4 [37456/45000]\tLoss: 3.7184\tLR: 0.000010\n",
      "Training Epoch: 4 [37472/45000]\tLoss: 3.5892\tLR: 0.000010\n",
      "Training Epoch: 4 [37488/45000]\tLoss: 3.7243\tLR: 0.000010\n",
      "Training Epoch: 4 [37504/45000]\tLoss: 3.6082\tLR: 0.000010\n",
      "Training Epoch: 4 [37520/45000]\tLoss: 3.6331\tLR: 0.000010\n",
      "Training Epoch: 4 [37536/45000]\tLoss: 3.6640\tLR: 0.000010\n",
      "Training Epoch: 4 [37552/45000]\tLoss: 3.5254\tLR: 0.000010\n",
      "Training Epoch: 4 [37568/45000]\tLoss: 3.5833\tLR: 0.000010\n",
      "Training Epoch: 4 [37584/45000]\tLoss: 3.6180\tLR: 0.000010\n",
      "Training Epoch: 4 [37600/45000]\tLoss: 3.6384\tLR: 0.000010\n",
      "Training Epoch: 4 [37616/45000]\tLoss: 3.6944\tLR: 0.000010\n",
      "Training Epoch: 4 [37632/45000]\tLoss: 3.5744\tLR: 0.000010\n",
      "Training Epoch: 4 [37648/45000]\tLoss: 3.6487\tLR: 0.000010\n",
      "Training Epoch: 4 [37664/45000]\tLoss: 3.6215\tLR: 0.000010\n",
      "Training Epoch: 4 [37680/45000]\tLoss: 3.6783\tLR: 0.000010\n",
      "Training Epoch: 4 [37696/45000]\tLoss: 3.5797\tLR: 0.000010\n",
      "Training Epoch: 4 [37712/45000]\tLoss: 3.5748\tLR: 0.000010\n",
      "Training Epoch: 4 [37728/45000]\tLoss: 3.6446\tLR: 0.000010\n",
      "Training Epoch: 4 [37744/45000]\tLoss: 3.6414\tLR: 0.000010\n",
      "Training Epoch: 4 [37760/45000]\tLoss: 3.7397\tLR: 0.000010\n",
      "Training Epoch: 4 [37776/45000]\tLoss: 3.6018\tLR: 0.000010\n",
      "Training Epoch: 4 [37792/45000]\tLoss: 3.6959\tLR: 0.000010\n",
      "Training Epoch: 4 [37808/45000]\tLoss: 3.6563\tLR: 0.000010\n",
      "Training Epoch: 4 [37824/45000]\tLoss: 3.6071\tLR: 0.000010\n",
      "Training Epoch: 4 [37840/45000]\tLoss: 3.7505\tLR: 0.000010\n",
      "Training Epoch: 4 [37856/45000]\tLoss: 3.6819\tLR: 0.000010\n",
      "Training Epoch: 4 [37872/45000]\tLoss: 3.5857\tLR: 0.000010\n",
      "Training Epoch: 4 [37888/45000]\tLoss: 3.6964\tLR: 0.000010\n",
      "Training Epoch: 4 [37904/45000]\tLoss: 3.7110\tLR: 0.000010\n",
      "Training Epoch: 4 [37920/45000]\tLoss: 3.5929\tLR: 0.000010\n",
      "Training Epoch: 4 [37936/45000]\tLoss: 3.5727\tLR: 0.000010\n",
      "Training Epoch: 4 [37952/45000]\tLoss: 3.7039\tLR: 0.000010\n",
      "Training Epoch: 4 [37968/45000]\tLoss: 3.5323\tLR: 0.000010\n",
      "Training Epoch: 4 [37984/45000]\tLoss: 3.6147\tLR: 0.000010\n",
      "Training Epoch: 4 [38000/45000]\tLoss: 3.6414\tLR: 0.000010\n",
      "Training Epoch: 4 [38016/45000]\tLoss: 3.5498\tLR: 0.000010\n",
      "Training Epoch: 4 [38032/45000]\tLoss: 3.6282\tLR: 0.000010\n",
      "Training Epoch: 4 [38048/45000]\tLoss: 3.5791\tLR: 0.000010\n",
      "Training Epoch: 4 [38064/45000]\tLoss: 3.5780\tLR: 0.000010\n",
      "Training Epoch: 4 [38080/45000]\tLoss: 3.7400\tLR: 0.000010\n",
      "Training Epoch: 4 [38096/45000]\tLoss: 3.5728\tLR: 0.000010\n",
      "Training Epoch: 4 [38112/45000]\tLoss: 3.6653\tLR: 0.000010\n",
      "Training Epoch: 4 [38128/45000]\tLoss: 3.5500\tLR: 0.000010\n",
      "Training Epoch: 4 [38144/45000]\tLoss: 3.6203\tLR: 0.000010\n",
      "Training Epoch: 4 [38160/45000]\tLoss: 3.6639\tLR: 0.000010\n",
      "Training Epoch: 4 [38176/45000]\tLoss: 3.7196\tLR: 0.000010\n",
      "Training Epoch: 4 [38192/45000]\tLoss: 3.6499\tLR: 0.000010\n",
      "Training Epoch: 4 [38208/45000]\tLoss: 3.6461\tLR: 0.000010\n",
      "Training Epoch: 4 [38224/45000]\tLoss: 3.7068\tLR: 0.000010\n",
      "Training Epoch: 4 [38240/45000]\tLoss: 3.6831\tLR: 0.000010\n",
      "Training Epoch: 4 [38256/45000]\tLoss: 3.5825\tLR: 0.000010\n",
      "Training Epoch: 4 [38272/45000]\tLoss: 3.7767\tLR: 0.000010\n",
      "Training Epoch: 4 [38288/45000]\tLoss: 3.6161\tLR: 0.000010\n",
      "Training Epoch: 4 [38304/45000]\tLoss: 3.6489\tLR: 0.000010\n",
      "Training Epoch: 4 [38320/45000]\tLoss: 3.5715\tLR: 0.000010\n",
      "Training Epoch: 4 [38336/45000]\tLoss: 3.5913\tLR: 0.000010\n",
      "Training Epoch: 4 [38352/45000]\tLoss: 3.8105\tLR: 0.000010\n",
      "Training Epoch: 4 [38368/45000]\tLoss: 3.5746\tLR: 0.000010\n",
      "Training Epoch: 4 [38384/45000]\tLoss: 3.7508\tLR: 0.000010\n",
      "Training Epoch: 4 [38400/45000]\tLoss: 3.5165\tLR: 0.000010\n",
      "Training Epoch: 4 [38416/45000]\tLoss: 3.5735\tLR: 0.000010\n",
      "Training Epoch: 4 [38432/45000]\tLoss: 3.5483\tLR: 0.000010\n",
      "Training Epoch: 4 [38448/45000]\tLoss: 3.7074\tLR: 0.000010\n",
      "Training Epoch: 4 [38464/45000]\tLoss: 3.7443\tLR: 0.000010\n",
      "Training Epoch: 4 [38480/45000]\tLoss: 3.6787\tLR: 0.000010\n",
      "Training Epoch: 4 [38496/45000]\tLoss: 3.6062\tLR: 0.000010\n",
      "Training Epoch: 4 [38512/45000]\tLoss: 3.6091\tLR: 0.000010\n",
      "Training Epoch: 4 [38528/45000]\tLoss: 3.6065\tLR: 0.000010\n",
      "Training Epoch: 4 [38544/45000]\tLoss: 3.5603\tLR: 0.000010\n",
      "Training Epoch: 4 [38560/45000]\tLoss: 3.5830\tLR: 0.000010\n",
      "Training Epoch: 4 [38576/45000]\tLoss: 3.6144\tLR: 0.000010\n",
      "Training Epoch: 4 [38592/45000]\tLoss: 3.7139\tLR: 0.000010\n",
      "Training Epoch: 4 [38608/45000]\tLoss: 3.6750\tLR: 0.000010\n",
      "Training Epoch: 4 [38624/45000]\tLoss: 3.5679\tLR: 0.000010\n",
      "Training Epoch: 4 [38640/45000]\tLoss: 3.6941\tLR: 0.000010\n",
      "Training Epoch: 4 [38656/45000]\tLoss: 3.6305\tLR: 0.000010\n",
      "Training Epoch: 4 [38672/45000]\tLoss: 3.6878\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [38688/45000]\tLoss: 3.5965\tLR: 0.000010\n",
      "Training Epoch: 4 [38704/45000]\tLoss: 3.5967\tLR: 0.000010\n",
      "Training Epoch: 4 [38720/45000]\tLoss: 3.8167\tLR: 0.000010\n",
      "Training Epoch: 4 [38736/45000]\tLoss: 3.6772\tLR: 0.000010\n",
      "Training Epoch: 4 [38752/45000]\tLoss: 3.7833\tLR: 0.000010\n",
      "Training Epoch: 4 [38768/45000]\tLoss: 3.6187\tLR: 0.000010\n",
      "Training Epoch: 4 [38784/45000]\tLoss: 3.6650\tLR: 0.000010\n",
      "Training Epoch: 4 [38800/45000]\tLoss: 3.5564\tLR: 0.000010\n",
      "Training Epoch: 4 [38816/45000]\tLoss: 3.6235\tLR: 0.000010\n",
      "Training Epoch: 4 [38832/45000]\tLoss: 3.6854\tLR: 0.000010\n",
      "Training Epoch: 4 [38848/45000]\tLoss: 3.7709\tLR: 0.000010\n",
      "Training Epoch: 4 [38864/45000]\tLoss: 3.6426\tLR: 0.000010\n",
      "Training Epoch: 4 [38880/45000]\tLoss: 3.6967\tLR: 0.000010\n",
      "Training Epoch: 4 [38896/45000]\tLoss: 3.5979\tLR: 0.000010\n",
      "Training Epoch: 4 [38912/45000]\tLoss: 3.6781\tLR: 0.000010\n",
      "Training Epoch: 4 [38928/45000]\tLoss: 3.6869\tLR: 0.000010\n",
      "Training Epoch: 4 [38944/45000]\tLoss: 3.5959\tLR: 0.000010\n",
      "Training Epoch: 4 [38960/45000]\tLoss: 3.5743\tLR: 0.000010\n",
      "Training Epoch: 4 [38976/45000]\tLoss: 3.6647\tLR: 0.000010\n",
      "Training Epoch: 4 [38992/45000]\tLoss: 3.6616\tLR: 0.000010\n",
      "Training Epoch: 4 [39008/45000]\tLoss: 3.6712\tLR: 0.000010\n",
      "Training Epoch: 4 [39024/45000]\tLoss: 3.8551\tLR: 0.000010\n",
      "Training Epoch: 4 [39040/45000]\tLoss: 3.6094\tLR: 0.000010\n",
      "Training Epoch: 4 [39056/45000]\tLoss: 3.4705\tLR: 0.000010\n",
      "Training Epoch: 4 [39072/45000]\tLoss: 3.6769\tLR: 0.000010\n",
      "Training Epoch: 4 [39088/45000]\tLoss: 3.7470\tLR: 0.000010\n",
      "Training Epoch: 4 [39104/45000]\tLoss: 3.6260\tLR: 0.000010\n",
      "Training Epoch: 4 [39120/45000]\tLoss: 3.6438\tLR: 0.000010\n",
      "Training Epoch: 4 [39136/45000]\tLoss: 3.4861\tLR: 0.000010\n",
      "Training Epoch: 4 [39152/45000]\tLoss: 3.6204\tLR: 0.000010\n",
      "Training Epoch: 4 [39168/45000]\tLoss: 3.6422\tLR: 0.000010\n",
      "Training Epoch: 4 [39184/45000]\tLoss: 3.6323\tLR: 0.000010\n",
      "Training Epoch: 4 [39200/45000]\tLoss: 3.5691\tLR: 0.000010\n",
      "Training Epoch: 4 [39216/45000]\tLoss: 3.6854\tLR: 0.000010\n",
      "Training Epoch: 4 [39232/45000]\tLoss: 3.5563\tLR: 0.000010\n",
      "Training Epoch: 4 [39248/45000]\tLoss: 3.5934\tLR: 0.000010\n",
      "Training Epoch: 4 [39264/45000]\tLoss: 3.6467\tLR: 0.000010\n",
      "Training Epoch: 4 [39280/45000]\tLoss: 3.5257\tLR: 0.000010\n",
      "Training Epoch: 4 [39296/45000]\tLoss: 3.5999\tLR: 0.000010\n",
      "Training Epoch: 4 [39312/45000]\tLoss: 3.6199\tLR: 0.000010\n",
      "Training Epoch: 4 [39328/45000]\tLoss: 3.6233\tLR: 0.000010\n",
      "Training Epoch: 4 [39344/45000]\tLoss: 3.5580\tLR: 0.000010\n",
      "Training Epoch: 4 [39360/45000]\tLoss: 3.6485\tLR: 0.000010\n",
      "Training Epoch: 4 [39376/45000]\tLoss: 3.5981\tLR: 0.000010\n",
      "Training Epoch: 4 [39392/45000]\tLoss: 3.6251\tLR: 0.000010\n",
      "Training Epoch: 4 [39408/45000]\tLoss: 3.6655\tLR: 0.000010\n",
      "Training Epoch: 4 [39424/45000]\tLoss: 3.6026\tLR: 0.000010\n",
      "Training Epoch: 4 [39440/45000]\tLoss: 3.6016\tLR: 0.000010\n",
      "Training Epoch: 4 [39456/45000]\tLoss: 3.6675\tLR: 0.000010\n",
      "Training Epoch: 4 [39472/45000]\tLoss: 3.6369\tLR: 0.000010\n",
      "Training Epoch: 4 [39488/45000]\tLoss: 3.6907\tLR: 0.000010\n",
      "Training Epoch: 4 [39504/45000]\tLoss: 3.4997\tLR: 0.000010\n",
      "Training Epoch: 4 [39520/45000]\tLoss: 3.7350\tLR: 0.000010\n",
      "Training Epoch: 4 [39536/45000]\tLoss: 3.5923\tLR: 0.000010\n",
      "Training Epoch: 4 [39552/45000]\tLoss: 3.7217\tLR: 0.000010\n",
      "Training Epoch: 4 [39568/45000]\tLoss: 3.6587\tLR: 0.000010\n",
      "Training Epoch: 4 [39584/45000]\tLoss: 3.6075\tLR: 0.000010\n",
      "Training Epoch: 4 [39600/45000]\tLoss: 3.6702\tLR: 0.000010\n",
      "Training Epoch: 4 [39616/45000]\tLoss: 3.6610\tLR: 0.000010\n",
      "Training Epoch: 4 [39632/45000]\tLoss: 3.5943\tLR: 0.000010\n",
      "Training Epoch: 4 [39648/45000]\tLoss: 3.6874\tLR: 0.000010\n",
      "Training Epoch: 4 [39664/45000]\tLoss: 3.6055\tLR: 0.000010\n",
      "Training Epoch: 4 [39680/45000]\tLoss: 3.6497\tLR: 0.000010\n",
      "Training Epoch: 4 [39696/45000]\tLoss: 3.6709\tLR: 0.000010\n",
      "Training Epoch: 4 [39712/45000]\tLoss: 3.6823\tLR: 0.000010\n",
      "Training Epoch: 4 [39728/45000]\tLoss: 3.6768\tLR: 0.000010\n",
      "Training Epoch: 4 [39744/45000]\tLoss: 3.6325\tLR: 0.000010\n",
      "Training Epoch: 4 [39760/45000]\tLoss: 3.8827\tLR: 0.000010\n",
      "Training Epoch: 4 [39776/45000]\tLoss: 3.7140\tLR: 0.000010\n",
      "Training Epoch: 4 [39792/45000]\tLoss: 3.5185\tLR: 0.000010\n",
      "Training Epoch: 4 [39808/45000]\tLoss: 3.6942\tLR: 0.000010\n",
      "Training Epoch: 4 [39824/45000]\tLoss: 3.7026\tLR: 0.000010\n",
      "Training Epoch: 4 [39840/45000]\tLoss: 3.7243\tLR: 0.000010\n",
      "Training Epoch: 4 [39856/45000]\tLoss: 3.7009\tLR: 0.000010\n",
      "Training Epoch: 4 [39872/45000]\tLoss: 3.6189\tLR: 0.000010\n",
      "Training Epoch: 4 [39888/45000]\tLoss: 3.6287\tLR: 0.000010\n",
      "Training Epoch: 4 [39904/45000]\tLoss: 3.7495\tLR: 0.000010\n",
      "Training Epoch: 4 [39920/45000]\tLoss: 3.6422\tLR: 0.000010\n",
      "Training Epoch: 4 [39936/45000]\tLoss: 3.6083\tLR: 0.000010\n",
      "Training Epoch: 4 [39952/45000]\tLoss: 3.7202\tLR: 0.000010\n",
      "Training Epoch: 4 [39968/45000]\tLoss: 3.5544\tLR: 0.000010\n",
      "Training Epoch: 4 [39984/45000]\tLoss: 3.7166\tLR: 0.000010\n",
      "Training Epoch: 4 [40000/45000]\tLoss: 3.5288\tLR: 0.000010\n",
      "Training Epoch: 4 [40016/45000]\tLoss: 3.6476\tLR: 0.000010\n",
      "Training Epoch: 4 [40032/45000]\tLoss: 3.6069\tLR: 0.000010\n",
      "Training Epoch: 4 [40048/45000]\tLoss: 3.7996\tLR: 0.000010\n",
      "Training Epoch: 4 [40064/45000]\tLoss: 3.6242\tLR: 0.000010\n",
      "Training Epoch: 4 [40080/45000]\tLoss: 3.6377\tLR: 0.000010\n",
      "Training Epoch: 4 [40096/45000]\tLoss: 3.6750\tLR: 0.000010\n",
      "Training Epoch: 4 [40112/45000]\tLoss: 3.6604\tLR: 0.000010\n",
      "Training Epoch: 4 [40128/45000]\tLoss: 3.6240\tLR: 0.000010\n",
      "Training Epoch: 4 [40144/45000]\tLoss: 3.6234\tLR: 0.000010\n",
      "Training Epoch: 4 [40160/45000]\tLoss: 3.7899\tLR: 0.000010\n",
      "Training Epoch: 4 [40176/45000]\tLoss: 3.7433\tLR: 0.000010\n",
      "Training Epoch: 4 [40192/45000]\tLoss: 3.7595\tLR: 0.000010\n",
      "Training Epoch: 4 [40208/45000]\tLoss: 3.6676\tLR: 0.000010\n",
      "Training Epoch: 4 [40224/45000]\tLoss: 3.6847\tLR: 0.000010\n",
      "Training Epoch: 4 [40240/45000]\tLoss: 3.7387\tLR: 0.000010\n",
      "Training Epoch: 4 [40256/45000]\tLoss: 3.6772\tLR: 0.000010\n",
      "Training Epoch: 4 [40272/45000]\tLoss: 3.5975\tLR: 0.000010\n",
      "Training Epoch: 4 [40288/45000]\tLoss: 3.7856\tLR: 0.000010\n",
      "Training Epoch: 4 [40304/45000]\tLoss: 3.5791\tLR: 0.000010\n",
      "Training Epoch: 4 [40320/45000]\tLoss: 3.6966\tLR: 0.000010\n",
      "Training Epoch: 4 [40336/45000]\tLoss: 3.7015\tLR: 0.000010\n",
      "Training Epoch: 4 [40352/45000]\tLoss: 3.7246\tLR: 0.000010\n",
      "Training Epoch: 4 [40368/45000]\tLoss: 3.5550\tLR: 0.000010\n",
      "Training Epoch: 4 [40384/45000]\tLoss: 3.6221\tLR: 0.000010\n",
      "Training Epoch: 4 [40400/45000]\tLoss: 3.6842\tLR: 0.000010\n",
      "Training Epoch: 4 [40416/45000]\tLoss: 3.6179\tLR: 0.000010\n",
      "Training Epoch: 4 [40432/45000]\tLoss: 3.6877\tLR: 0.000010\n",
      "Training Epoch: 4 [40448/45000]\tLoss: 3.6636\tLR: 0.000010\n",
      "Training Epoch: 4 [40464/45000]\tLoss: 3.6716\tLR: 0.000010\n",
      "Training Epoch: 4 [40480/45000]\tLoss: 3.6681\tLR: 0.000010\n",
      "Training Epoch: 4 [40496/45000]\tLoss: 3.7440\tLR: 0.000010\n",
      "Training Epoch: 4 [40512/45000]\tLoss: 3.6890\tLR: 0.000010\n",
      "Training Epoch: 4 [40528/45000]\tLoss: 3.5917\tLR: 0.000010\n",
      "Training Epoch: 4 [40544/45000]\tLoss: 3.6343\tLR: 0.000010\n",
      "Training Epoch: 4 [40560/45000]\tLoss: 3.5947\tLR: 0.000010\n",
      "Training Epoch: 4 [40576/45000]\tLoss: 3.6942\tLR: 0.000010\n",
      "Training Epoch: 4 [40592/45000]\tLoss: 3.7058\tLR: 0.000010\n",
      "Training Epoch: 4 [40608/45000]\tLoss: 3.6267\tLR: 0.000010\n",
      "Training Epoch: 4 [40624/45000]\tLoss: 3.5822\tLR: 0.000010\n",
      "Training Epoch: 4 [40640/45000]\tLoss: 3.7326\tLR: 0.000010\n",
      "Training Epoch: 4 [40656/45000]\tLoss: 3.6562\tLR: 0.000010\n",
      "Training Epoch: 4 [40672/45000]\tLoss: 3.6879\tLR: 0.000010\n",
      "Training Epoch: 4 [40688/45000]\tLoss: 3.6515\tLR: 0.000010\n",
      "Training Epoch: 4 [40704/45000]\tLoss: 3.5726\tLR: 0.000010\n",
      "Training Epoch: 4 [40720/45000]\tLoss: 3.5704\tLR: 0.000010\n",
      "Training Epoch: 4 [40736/45000]\tLoss: 3.7482\tLR: 0.000010\n",
      "Training Epoch: 4 [40752/45000]\tLoss: 3.5949\tLR: 0.000010\n",
      "Training Epoch: 4 [40768/45000]\tLoss: 3.6345\tLR: 0.000010\n",
      "Training Epoch: 4 [40784/45000]\tLoss: 3.6994\tLR: 0.000010\n",
      "Training Epoch: 4 [40800/45000]\tLoss: 3.6824\tLR: 0.000010\n",
      "Training Epoch: 4 [40816/45000]\tLoss: 3.7594\tLR: 0.000010\n",
      "Training Epoch: 4 [40832/45000]\tLoss: 3.6331\tLR: 0.000010\n",
      "Training Epoch: 4 [40848/45000]\tLoss: 3.6067\tLR: 0.000010\n",
      "Training Epoch: 4 [40864/45000]\tLoss: 3.5751\tLR: 0.000010\n",
      "Training Epoch: 4 [40880/45000]\tLoss: 3.6634\tLR: 0.000010\n",
      "Training Epoch: 4 [40896/45000]\tLoss: 3.5244\tLR: 0.000010\n",
      "Training Epoch: 4 [40912/45000]\tLoss: 3.5726\tLR: 0.000010\n",
      "Training Epoch: 4 [40928/45000]\tLoss: 3.8024\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [40944/45000]\tLoss: 3.7549\tLR: 0.000010\n",
      "Training Epoch: 4 [40960/45000]\tLoss: 3.6601\tLR: 0.000010\n",
      "Training Epoch: 4 [40976/45000]\tLoss: 3.5937\tLR: 0.000010\n",
      "Training Epoch: 4 [40992/45000]\tLoss: 3.6361\tLR: 0.000010\n",
      "Training Epoch: 4 [41008/45000]\tLoss: 3.7111\tLR: 0.000010\n",
      "Training Epoch: 4 [41024/45000]\tLoss: 3.5865\tLR: 0.000010\n",
      "Training Epoch: 4 [41040/45000]\tLoss: 3.7664\tLR: 0.000010\n",
      "Training Epoch: 4 [41056/45000]\tLoss: 3.5734\tLR: 0.000010\n",
      "Training Epoch: 4 [41072/45000]\tLoss: 3.6465\tLR: 0.000010\n",
      "Training Epoch: 4 [41088/45000]\tLoss: 3.6991\tLR: 0.000010\n",
      "Training Epoch: 4 [41104/45000]\tLoss: 3.7551\tLR: 0.000010\n",
      "Training Epoch: 4 [41120/45000]\tLoss: 3.6931\tLR: 0.000010\n",
      "Training Epoch: 4 [41136/45000]\tLoss: 3.5857\tLR: 0.000010\n",
      "Training Epoch: 4 [41152/45000]\tLoss: 3.5575\tLR: 0.000010\n",
      "Training Epoch: 4 [41168/45000]\tLoss: 3.6465\tLR: 0.000010\n",
      "Training Epoch: 4 [41184/45000]\tLoss: 3.6016\tLR: 0.000010\n",
      "Training Epoch: 4 [41200/45000]\tLoss: 3.6221\tLR: 0.000010\n",
      "Training Epoch: 4 [41216/45000]\tLoss: 3.6111\tLR: 0.000010\n",
      "Training Epoch: 4 [41232/45000]\tLoss: 3.5831\tLR: 0.000010\n",
      "Training Epoch: 4 [41248/45000]\tLoss: 3.5220\tLR: 0.000010\n",
      "Training Epoch: 4 [41264/45000]\tLoss: 3.5991\tLR: 0.000010\n",
      "Training Epoch: 4 [41280/45000]\tLoss: 3.6143\tLR: 0.000010\n",
      "Training Epoch: 4 [41296/45000]\tLoss: 3.7674\tLR: 0.000010\n",
      "Training Epoch: 4 [41312/45000]\tLoss: 3.6160\tLR: 0.000010\n",
      "Training Epoch: 4 [41328/45000]\tLoss: 3.5827\tLR: 0.000010\n",
      "Training Epoch: 4 [41344/45000]\tLoss: 3.6666\tLR: 0.000010\n",
      "Training Epoch: 4 [41360/45000]\tLoss: 3.6284\tLR: 0.000010\n",
      "Training Epoch: 4 [41376/45000]\tLoss: 3.6204\tLR: 0.000010\n",
      "Training Epoch: 4 [41392/45000]\tLoss: 3.5936\tLR: 0.000010\n",
      "Training Epoch: 4 [41408/45000]\tLoss: 3.6114\tLR: 0.000010\n",
      "Training Epoch: 4 [41424/45000]\tLoss: 3.7683\tLR: 0.000010\n",
      "Training Epoch: 4 [41440/45000]\tLoss: 3.6064\tLR: 0.000010\n",
      "Training Epoch: 4 [41456/45000]\tLoss: 3.5856\tLR: 0.000010\n",
      "Training Epoch: 4 [41472/45000]\tLoss: 3.5682\tLR: 0.000010\n",
      "Training Epoch: 4 [41488/45000]\tLoss: 3.6528\tLR: 0.000010\n",
      "Training Epoch: 4 [41504/45000]\tLoss: 3.5986\tLR: 0.000010\n",
      "Training Epoch: 4 [41520/45000]\tLoss: 3.6309\tLR: 0.000010\n",
      "Training Epoch: 4 [41536/45000]\tLoss: 3.5634\tLR: 0.000010\n",
      "Training Epoch: 4 [41552/45000]\tLoss: 3.7335\tLR: 0.000010\n",
      "Training Epoch: 4 [41568/45000]\tLoss: 3.4954\tLR: 0.000010\n",
      "Training Epoch: 4 [41584/45000]\tLoss: 3.5387\tLR: 0.000010\n",
      "Training Epoch: 4 [41600/45000]\tLoss: 3.6765\tLR: 0.000010\n",
      "Training Epoch: 4 [41616/45000]\tLoss: 3.5361\tLR: 0.000010\n",
      "Training Epoch: 4 [41632/45000]\tLoss: 3.7030\tLR: 0.000010\n",
      "Training Epoch: 4 [41648/45000]\tLoss: 3.6239\tLR: 0.000010\n",
      "Training Epoch: 4 [41664/45000]\tLoss: 3.6608\tLR: 0.000010\n",
      "Training Epoch: 4 [41680/45000]\tLoss: 3.5771\tLR: 0.000010\n",
      "Training Epoch: 4 [41696/45000]\tLoss: 3.5984\tLR: 0.000010\n",
      "Training Epoch: 4 [41712/45000]\tLoss: 3.5976\tLR: 0.000010\n",
      "Training Epoch: 4 [41728/45000]\tLoss: 3.5612\tLR: 0.000010\n",
      "Training Epoch: 4 [41744/45000]\tLoss: 3.5848\tLR: 0.000010\n",
      "Training Epoch: 4 [41760/45000]\tLoss: 3.7221\tLR: 0.000010\n",
      "Training Epoch: 4 [41776/45000]\tLoss: 3.6558\tLR: 0.000010\n",
      "Training Epoch: 4 [41792/45000]\tLoss: 3.6277\tLR: 0.000010\n",
      "Training Epoch: 4 [41808/45000]\tLoss: 3.5945\tLR: 0.000010\n",
      "Training Epoch: 4 [41824/45000]\tLoss: 3.7634\tLR: 0.000010\n",
      "Training Epoch: 4 [41840/45000]\tLoss: 3.5921\tLR: 0.000010\n",
      "Training Epoch: 4 [41856/45000]\tLoss: 3.5577\tLR: 0.000010\n",
      "Training Epoch: 4 [41872/45000]\tLoss: 3.7559\tLR: 0.000010\n",
      "Training Epoch: 4 [41888/45000]\tLoss: 3.6904\tLR: 0.000010\n",
      "Training Epoch: 4 [41904/45000]\tLoss: 3.7119\tLR: 0.000010\n",
      "Training Epoch: 4 [41920/45000]\tLoss: 3.6925\tLR: 0.000010\n",
      "Training Epoch: 4 [41936/45000]\tLoss: 3.7045\tLR: 0.000010\n",
      "Training Epoch: 4 [41952/45000]\tLoss: 3.5895\tLR: 0.000010\n",
      "Training Epoch: 4 [41968/45000]\tLoss: 3.6801\tLR: 0.000010\n",
      "Training Epoch: 4 [41984/45000]\tLoss: 3.6218\tLR: 0.000010\n",
      "Training Epoch: 4 [42000/45000]\tLoss: 3.6239\tLR: 0.000010\n",
      "Training Epoch: 4 [42016/45000]\tLoss: 3.6250\tLR: 0.000010\n",
      "Training Epoch: 4 [42032/45000]\tLoss: 3.6956\tLR: 0.000010\n",
      "Training Epoch: 4 [42048/45000]\tLoss: 3.6615\tLR: 0.000010\n",
      "Training Epoch: 4 [42064/45000]\tLoss: 3.5231\tLR: 0.000010\n",
      "Training Epoch: 4 [42080/45000]\tLoss: 3.5733\tLR: 0.000010\n",
      "Training Epoch: 4 [42096/45000]\tLoss: 3.6571\tLR: 0.000010\n",
      "Training Epoch: 4 [42112/45000]\tLoss: 3.6204\tLR: 0.000010\n",
      "Training Epoch: 4 [42128/45000]\tLoss: 3.5673\tLR: 0.000010\n",
      "Training Epoch: 4 [42144/45000]\tLoss: 3.6682\tLR: 0.000010\n",
      "Training Epoch: 4 [42160/45000]\tLoss: 3.6837\tLR: 0.000010\n",
      "Training Epoch: 4 [42176/45000]\tLoss: 3.6478\tLR: 0.000010\n",
      "Training Epoch: 4 [42192/45000]\tLoss: 3.6696\tLR: 0.000010\n",
      "Training Epoch: 4 [42208/45000]\tLoss: 3.6048\tLR: 0.000010\n",
      "Training Epoch: 4 [42224/45000]\tLoss: 3.6842\tLR: 0.000010\n",
      "Training Epoch: 4 [42240/45000]\tLoss: 3.6337\tLR: 0.000010\n",
      "Training Epoch: 4 [42256/45000]\tLoss: 3.7023\tLR: 0.000010\n",
      "Training Epoch: 4 [42272/45000]\tLoss: 3.5733\tLR: 0.000010\n",
      "Training Epoch: 4 [42288/45000]\tLoss: 3.6843\tLR: 0.000010\n",
      "Training Epoch: 4 [42304/45000]\tLoss: 3.6405\tLR: 0.000010\n",
      "Training Epoch: 4 [42320/45000]\tLoss: 3.5450\tLR: 0.000010\n",
      "Training Epoch: 4 [42336/45000]\tLoss: 3.4667\tLR: 0.000010\n",
      "Training Epoch: 4 [42352/45000]\tLoss: 3.6246\tLR: 0.000010\n",
      "Training Epoch: 4 [42368/45000]\tLoss: 3.6390\tLR: 0.000010\n",
      "Training Epoch: 4 [42384/45000]\tLoss: 3.6819\tLR: 0.000010\n",
      "Training Epoch: 4 [42400/45000]\tLoss: 3.5710\tLR: 0.000010\n",
      "Training Epoch: 4 [42416/45000]\tLoss: 3.7047\tLR: 0.000010\n",
      "Training Epoch: 4 [42432/45000]\tLoss: 3.7475\tLR: 0.000010\n",
      "Training Epoch: 4 [42448/45000]\tLoss: 3.6076\tLR: 0.000010\n",
      "Training Epoch: 4 [42464/45000]\tLoss: 3.6200\tLR: 0.000010\n",
      "Training Epoch: 4 [42480/45000]\tLoss: 3.5343\tLR: 0.000010\n",
      "Training Epoch: 4 [42496/45000]\tLoss: 3.5561\tLR: 0.000010\n",
      "Training Epoch: 4 [42512/45000]\tLoss: 3.5738\tLR: 0.000010\n",
      "Training Epoch: 4 [42528/45000]\tLoss: 3.6928\tLR: 0.000010\n",
      "Training Epoch: 4 [42544/45000]\tLoss: 3.7093\tLR: 0.000010\n",
      "Training Epoch: 4 [42560/45000]\tLoss: 3.6340\tLR: 0.000010\n",
      "Training Epoch: 4 [42576/45000]\tLoss: 3.6904\tLR: 0.000010\n",
      "Training Epoch: 4 [42592/45000]\tLoss: 3.6432\tLR: 0.000010\n",
      "Training Epoch: 4 [42608/45000]\tLoss: 3.6011\tLR: 0.000010\n",
      "Training Epoch: 4 [42624/45000]\tLoss: 3.7107\tLR: 0.000010\n",
      "Training Epoch: 4 [42640/45000]\tLoss: 3.5571\tLR: 0.000010\n",
      "Training Epoch: 4 [42656/45000]\tLoss: 3.5512\tLR: 0.000010\n",
      "Training Epoch: 4 [42672/45000]\tLoss: 3.6575\tLR: 0.000010\n",
      "Training Epoch: 4 [42688/45000]\tLoss: 3.6513\tLR: 0.000010\n",
      "Training Epoch: 4 [42704/45000]\tLoss: 3.5399\tLR: 0.000010\n",
      "Training Epoch: 4 [42720/45000]\tLoss: 3.6713\tLR: 0.000010\n",
      "Training Epoch: 4 [42736/45000]\tLoss: 3.7304\tLR: 0.000010\n",
      "Training Epoch: 4 [42752/45000]\tLoss: 3.6096\tLR: 0.000010\n",
      "Training Epoch: 4 [42768/45000]\tLoss: 3.6034\tLR: 0.000010\n",
      "Training Epoch: 4 [42784/45000]\tLoss: 3.6620\tLR: 0.000010\n",
      "Training Epoch: 4 [42800/45000]\tLoss: 3.6173\tLR: 0.000010\n",
      "Training Epoch: 4 [42816/45000]\tLoss: 3.6496\tLR: 0.000010\n",
      "Training Epoch: 4 [42832/45000]\tLoss: 3.5603\tLR: 0.000010\n",
      "Training Epoch: 4 [42848/45000]\tLoss: 3.5579\tLR: 0.000010\n",
      "Training Epoch: 4 [42864/45000]\tLoss: 3.5718\tLR: 0.000010\n",
      "Training Epoch: 4 [42880/45000]\tLoss: 3.5489\tLR: 0.000010\n",
      "Training Epoch: 4 [42896/45000]\tLoss: 3.5780\tLR: 0.000010\n",
      "Training Epoch: 4 [42912/45000]\tLoss: 3.6656\tLR: 0.000010\n",
      "Training Epoch: 4 [42928/45000]\tLoss: 3.5591\tLR: 0.000010\n",
      "Training Epoch: 4 [42944/45000]\tLoss: 3.7099\tLR: 0.000010\n",
      "Training Epoch: 4 [42960/45000]\tLoss: 3.6439\tLR: 0.000010\n",
      "Training Epoch: 4 [42976/45000]\tLoss: 3.5898\tLR: 0.000010\n",
      "Training Epoch: 4 [42992/45000]\tLoss: 3.6894\tLR: 0.000010\n",
      "Training Epoch: 4 [43008/45000]\tLoss: 3.6823\tLR: 0.000010\n",
      "Training Epoch: 4 [43024/45000]\tLoss: 3.6237\tLR: 0.000010\n",
      "Training Epoch: 4 [43040/45000]\tLoss: 3.6530\tLR: 0.000010\n",
      "Training Epoch: 4 [43056/45000]\tLoss: 3.6420\tLR: 0.000010\n",
      "Training Epoch: 4 [43072/45000]\tLoss: 3.6782\tLR: 0.000010\n",
      "Training Epoch: 4 [43088/45000]\tLoss: 3.5903\tLR: 0.000010\n",
      "Training Epoch: 4 [43104/45000]\tLoss: 3.7033\tLR: 0.000010\n",
      "Training Epoch: 4 [43120/45000]\tLoss: 3.6162\tLR: 0.000010\n",
      "Training Epoch: 4 [43136/45000]\tLoss: 3.6201\tLR: 0.000010\n",
      "Training Epoch: 4 [43152/45000]\tLoss: 3.6096\tLR: 0.000010\n",
      "Training Epoch: 4 [43168/45000]\tLoss: 3.7745\tLR: 0.000010\n",
      "Training Epoch: 4 [43184/45000]\tLoss: 3.7703\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [43200/45000]\tLoss: 3.6196\tLR: 0.000010\n",
      "Training Epoch: 4 [43216/45000]\tLoss: 3.6788\tLR: 0.000010\n",
      "Training Epoch: 4 [43232/45000]\tLoss: 3.5974\tLR: 0.000010\n",
      "Training Epoch: 4 [43248/45000]\tLoss: 3.7266\tLR: 0.000010\n",
      "Training Epoch: 4 [43264/45000]\tLoss: 3.5325\tLR: 0.000010\n",
      "Training Epoch: 4 [43280/45000]\tLoss: 3.6071\tLR: 0.000010\n",
      "Training Epoch: 4 [43296/45000]\tLoss: 3.6099\tLR: 0.000010\n",
      "Training Epoch: 4 [43312/45000]\tLoss: 3.6819\tLR: 0.000010\n",
      "Training Epoch: 4 [43328/45000]\tLoss: 3.5482\tLR: 0.000010\n",
      "Training Epoch: 4 [43344/45000]\tLoss: 3.6988\tLR: 0.000010\n",
      "Training Epoch: 4 [43360/45000]\tLoss: 3.6416\tLR: 0.000010\n",
      "Training Epoch: 4 [43376/45000]\tLoss: 3.7232\tLR: 0.000010\n",
      "Training Epoch: 4 [43392/45000]\tLoss: 3.6898\tLR: 0.000010\n",
      "Training Epoch: 4 [43408/45000]\tLoss: 3.7506\tLR: 0.000010\n",
      "Training Epoch: 4 [43424/45000]\tLoss: 3.6851\tLR: 0.000010\n",
      "Training Epoch: 4 [43440/45000]\tLoss: 3.6609\tLR: 0.000010\n",
      "Training Epoch: 4 [43456/45000]\tLoss: 3.5607\tLR: 0.000010\n",
      "Training Epoch: 4 [43472/45000]\tLoss: 3.6124\tLR: 0.000010\n",
      "Training Epoch: 4 [43488/45000]\tLoss: 3.6342\tLR: 0.000010\n",
      "Training Epoch: 4 [43504/45000]\tLoss: 3.6413\tLR: 0.000010\n",
      "Training Epoch: 4 [43520/45000]\tLoss: 3.6697\tLR: 0.000010\n",
      "Training Epoch: 4 [43536/45000]\tLoss: 3.6544\tLR: 0.000010\n",
      "Training Epoch: 4 [43552/45000]\tLoss: 3.6468\tLR: 0.000010\n",
      "Training Epoch: 4 [43568/45000]\tLoss: 3.6187\tLR: 0.000010\n",
      "Training Epoch: 4 [43584/45000]\tLoss: 3.6447\tLR: 0.000010\n",
      "Training Epoch: 4 [43600/45000]\tLoss: 3.5605\tLR: 0.000010\n",
      "Training Epoch: 4 [43616/45000]\tLoss: 3.5981\tLR: 0.000010\n",
      "Training Epoch: 4 [43632/45000]\tLoss: 3.6391\tLR: 0.000010\n",
      "Training Epoch: 4 [43648/45000]\tLoss: 3.5836\tLR: 0.000010\n",
      "Training Epoch: 4 [43664/45000]\tLoss: 3.6887\tLR: 0.000010\n",
      "Training Epoch: 4 [43680/45000]\tLoss: 3.6281\tLR: 0.000010\n",
      "Training Epoch: 4 [43696/45000]\tLoss: 3.6529\tLR: 0.000010\n",
      "Training Epoch: 4 [43712/45000]\tLoss: 3.5912\tLR: 0.000010\n",
      "Training Epoch: 4 [43728/45000]\tLoss: 3.5860\tLR: 0.000010\n",
      "Training Epoch: 4 [43744/45000]\tLoss: 3.5810\tLR: 0.000010\n",
      "Training Epoch: 4 [43760/45000]\tLoss: 3.7495\tLR: 0.000010\n",
      "Training Epoch: 4 [43776/45000]\tLoss: 3.5530\tLR: 0.000010\n",
      "Training Epoch: 4 [43792/45000]\tLoss: 3.6350\tLR: 0.000010\n",
      "Training Epoch: 4 [43808/45000]\tLoss: 3.5812\tLR: 0.000010\n",
      "Training Epoch: 4 [43824/45000]\tLoss: 3.8040\tLR: 0.000010\n",
      "Training Epoch: 4 [43840/45000]\tLoss: 3.5951\tLR: 0.000010\n",
      "Training Epoch: 4 [43856/45000]\tLoss: 3.6277\tLR: 0.000010\n",
      "Training Epoch: 4 [43872/45000]\tLoss: 3.5344\tLR: 0.000010\n",
      "Training Epoch: 4 [43888/45000]\tLoss: 3.5782\tLR: 0.000010\n",
      "Training Epoch: 4 [43904/45000]\tLoss: 3.6464\tLR: 0.000010\n",
      "Training Epoch: 4 [43920/45000]\tLoss: 3.6250\tLR: 0.000010\n",
      "Training Epoch: 4 [43936/45000]\tLoss: 3.5691\tLR: 0.000010\n",
      "Training Epoch: 4 [43952/45000]\tLoss: 3.5514\tLR: 0.000010\n",
      "Training Epoch: 4 [43968/45000]\tLoss: 3.6404\tLR: 0.000010\n",
      "Training Epoch: 4 [43984/45000]\tLoss: 3.6122\tLR: 0.000010\n",
      "Training Epoch: 4 [44000/45000]\tLoss: 3.7258\tLR: 0.000010\n",
      "Training Epoch: 4 [44016/45000]\tLoss: 3.6619\tLR: 0.000010\n",
      "Training Epoch: 4 [44032/45000]\tLoss: 3.6732\tLR: 0.000010\n",
      "Training Epoch: 4 [44048/45000]\tLoss: 3.5370\tLR: 0.000010\n",
      "Training Epoch: 4 [44064/45000]\tLoss: 3.6467\tLR: 0.000010\n",
      "Training Epoch: 4 [44080/45000]\tLoss: 3.6895\tLR: 0.000010\n",
      "Training Epoch: 4 [44096/45000]\tLoss: 3.6092\tLR: 0.000010\n",
      "Training Epoch: 4 [44112/45000]\tLoss: 3.5957\tLR: 0.000010\n",
      "Training Epoch: 4 [44128/45000]\tLoss: 3.6077\tLR: 0.000010\n",
      "Training Epoch: 4 [44144/45000]\tLoss: 3.6339\tLR: 0.000010\n",
      "Training Epoch: 4 [44160/45000]\tLoss: 3.6410\tLR: 0.000010\n",
      "Training Epoch: 4 [44176/45000]\tLoss: 3.5726\tLR: 0.000010\n",
      "Training Epoch: 4 [44192/45000]\tLoss: 3.7147\tLR: 0.000010\n",
      "Training Epoch: 4 [44208/45000]\tLoss: 3.6289\tLR: 0.000010\n",
      "Training Epoch: 4 [44224/45000]\tLoss: 3.5528\tLR: 0.000010\n",
      "Training Epoch: 4 [44240/45000]\tLoss: 3.6516\tLR: 0.000010\n",
      "Training Epoch: 4 [44256/45000]\tLoss: 3.8009\tLR: 0.000010\n",
      "Training Epoch: 4 [44272/45000]\tLoss: 3.6987\tLR: 0.000010\n",
      "Training Epoch: 4 [44288/45000]\tLoss: 3.5032\tLR: 0.000010\n",
      "Training Epoch: 4 [44304/45000]\tLoss: 3.6628\tLR: 0.000010\n",
      "Training Epoch: 4 [44320/45000]\tLoss: 3.6059\tLR: 0.000010\n",
      "Training Epoch: 4 [44336/45000]\tLoss: 3.5621\tLR: 0.000010\n",
      "Training Epoch: 4 [44352/45000]\tLoss: 3.5115\tLR: 0.000010\n",
      "Training Epoch: 4 [44368/45000]\tLoss: 3.5391\tLR: 0.000010\n",
      "Training Epoch: 4 [44384/45000]\tLoss: 3.5905\tLR: 0.000010\n",
      "Training Epoch: 4 [44400/45000]\tLoss: 3.6208\tLR: 0.000010\n",
      "Training Epoch: 4 [44416/45000]\tLoss: 3.6131\tLR: 0.000010\n",
      "Training Epoch: 4 [44432/45000]\tLoss: 3.7002\tLR: 0.000010\n",
      "Training Epoch: 4 [44448/45000]\tLoss: 3.6383\tLR: 0.000010\n",
      "Training Epoch: 4 [44464/45000]\tLoss: 3.5127\tLR: 0.000010\n",
      "Training Epoch: 4 [44480/45000]\tLoss: 3.6744\tLR: 0.000010\n",
      "Training Epoch: 4 [44496/45000]\tLoss: 3.6434\tLR: 0.000010\n",
      "Training Epoch: 4 [44512/45000]\tLoss: 3.8095\tLR: 0.000010\n",
      "Training Epoch: 4 [44528/45000]\tLoss: 3.6238\tLR: 0.000010\n",
      "Training Epoch: 4 [44544/45000]\tLoss: 3.6222\tLR: 0.000010\n",
      "Training Epoch: 4 [44560/45000]\tLoss: 3.5983\tLR: 0.000010\n",
      "Training Epoch: 4 [44576/45000]\tLoss: 3.5591\tLR: 0.000010\n",
      "Training Epoch: 4 [44592/45000]\tLoss: 3.7239\tLR: 0.000010\n",
      "Training Epoch: 4 [44608/45000]\tLoss: 3.6606\tLR: 0.000010\n",
      "Training Epoch: 4 [44624/45000]\tLoss: 3.6160\tLR: 0.000010\n",
      "Training Epoch: 4 [44640/45000]\tLoss: 3.6193\tLR: 0.000010\n",
      "Training Epoch: 4 [44656/45000]\tLoss: 3.8261\tLR: 0.000010\n",
      "Training Epoch: 4 [44672/45000]\tLoss: 3.6494\tLR: 0.000010\n",
      "Training Epoch: 4 [44688/45000]\tLoss: 3.5607\tLR: 0.000010\n",
      "Training Epoch: 4 [44704/45000]\tLoss: 3.5433\tLR: 0.000010\n",
      "Training Epoch: 4 [44720/45000]\tLoss: 3.6877\tLR: 0.000010\n",
      "Training Epoch: 4 [44736/45000]\tLoss: 3.6539\tLR: 0.000010\n",
      "Training Epoch: 4 [44752/45000]\tLoss: 3.6192\tLR: 0.000010\n",
      "Training Epoch: 4 [44768/45000]\tLoss: 3.7092\tLR: 0.000010\n",
      "Training Epoch: 4 [44784/45000]\tLoss: 3.6422\tLR: 0.000010\n",
      "Training Epoch: 4 [44800/45000]\tLoss: 3.7308\tLR: 0.000010\n",
      "Training Epoch: 4 [44816/45000]\tLoss: 3.6195\tLR: 0.000010\n",
      "Training Epoch: 4 [44832/45000]\tLoss: 3.6859\tLR: 0.000010\n",
      "Training Epoch: 4 [44848/45000]\tLoss: 3.6001\tLR: 0.000010\n",
      "Training Epoch: 4 [44864/45000]\tLoss: 3.6170\tLR: 0.000010\n",
      "Training Epoch: 4 [44880/45000]\tLoss: 3.6610\tLR: 0.000010\n",
      "Training Epoch: 4 [44896/45000]\tLoss: 3.7276\tLR: 0.000010\n",
      "Training Epoch: 4 [44912/45000]\tLoss: 3.6497\tLR: 0.000010\n",
      "Training Epoch: 4 [44928/45000]\tLoss: 3.6529\tLR: 0.000010\n",
      "Training Epoch: 4 [44944/45000]\tLoss: 3.8011\tLR: 0.000010\n",
      "Training Epoch: 4 [44960/45000]\tLoss: 3.5858\tLR: 0.000010\n",
      "Training Epoch: 4 [44976/45000]\tLoss: 3.5503\tLR: 0.000010\n",
      "Training Epoch: 4 [44992/45000]\tLoss: 3.6291\tLR: 0.000010\n",
      "Training Epoch: 4 [45000/45000]\tLoss: 3.7886\tLR: 0.000010\n",
      "epoch 4 training time consumed: 172.48s\n",
      "Accuracy is 0.97340\n",
      "num_zeros / total_parameters ratio is  0.8847389576178974\n",
      "accuracy is  0.9734\n",
      "overall score is  0.9290694788089487\n",
      "Round 3/3:\n",
      "Training Epoch: 4 [16/45000]\tLoss: 3.5549\tLR: 0.000010\n",
      "Training Epoch: 4 [32/45000]\tLoss: 3.7277\tLR: 0.000010\n",
      "Training Epoch: 4 [48/45000]\tLoss: 3.7046\tLR: 0.000010\n",
      "Training Epoch: 4 [64/45000]\tLoss: 3.6142\tLR: 0.000010\n",
      "Training Epoch: 4 [80/45000]\tLoss: 3.5448\tLR: 0.000010\n",
      "Training Epoch: 4 [96/45000]\tLoss: 3.5483\tLR: 0.000010\n",
      "Training Epoch: 4 [112/45000]\tLoss: 3.7142\tLR: 0.000010\n",
      "Training Epoch: 4 [128/45000]\tLoss: 3.6700\tLR: 0.000010\n",
      "Training Epoch: 4 [144/45000]\tLoss: 3.7952\tLR: 0.000010\n",
      "Training Epoch: 4 [160/45000]\tLoss: 3.5857\tLR: 0.000010\n",
      "Training Epoch: 4 [176/45000]\tLoss: 3.6254\tLR: 0.000010\n",
      "Training Epoch: 4 [192/45000]\tLoss: 3.6524\tLR: 0.000010\n",
      "Training Epoch: 4 [208/45000]\tLoss: 3.6426\tLR: 0.000010\n",
      "Training Epoch: 4 [224/45000]\tLoss: 3.5442\tLR: 0.000010\n",
      "Training Epoch: 4 [240/45000]\tLoss: 3.6098\tLR: 0.000010\n",
      "Training Epoch: 4 [256/45000]\tLoss: 3.6087\tLR: 0.000010\n",
      "Training Epoch: 4 [272/45000]\tLoss: 3.7467\tLR: 0.000010\n",
      "Training Epoch: 4 [288/45000]\tLoss: 3.5973\tLR: 0.000010\n",
      "Training Epoch: 4 [304/45000]\tLoss: 3.5703\tLR: 0.000010\n",
      "Training Epoch: 4 [320/45000]\tLoss: 3.5628\tLR: 0.000010\n",
      "Training Epoch: 4 [336/45000]\tLoss: 3.6479\tLR: 0.000010\n",
      "Training Epoch: 4 [352/45000]\tLoss: 3.7147\tLR: 0.000010\n",
      "Training Epoch: 4 [368/45000]\tLoss: 3.6026\tLR: 0.000010\n",
      "Training Epoch: 4 [384/45000]\tLoss: 3.6492\tLR: 0.000010\n",
      "Training Epoch: 4 [400/45000]\tLoss: 3.5217\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [416/45000]\tLoss: 3.6102\tLR: 0.000010\n",
      "Training Epoch: 4 [432/45000]\tLoss: 3.6549\tLR: 0.000010\n",
      "Training Epoch: 4 [448/45000]\tLoss: 3.7231\tLR: 0.000010\n",
      "Training Epoch: 4 [464/45000]\tLoss: 3.6420\tLR: 0.000010\n",
      "Training Epoch: 4 [480/45000]\tLoss: 3.5172\tLR: 0.000010\n",
      "Training Epoch: 4 [496/45000]\tLoss: 3.7230\tLR: 0.000010\n",
      "Training Epoch: 4 [512/45000]\tLoss: 3.5608\tLR: 0.000010\n",
      "Training Epoch: 4 [528/45000]\tLoss: 3.6919\tLR: 0.000010\n",
      "Training Epoch: 4 [544/45000]\tLoss: 3.4741\tLR: 0.000010\n",
      "Training Epoch: 4 [560/45000]\tLoss: 3.5206\tLR: 0.000010\n",
      "Training Epoch: 4 [576/45000]\tLoss: 3.6205\tLR: 0.000010\n",
      "Training Epoch: 4 [592/45000]\tLoss: 3.6603\tLR: 0.000010\n",
      "Training Epoch: 4 [608/45000]\tLoss: 3.8029\tLR: 0.000010\n",
      "Training Epoch: 4 [624/45000]\tLoss: 3.5222\tLR: 0.000010\n",
      "Training Epoch: 4 [640/45000]\tLoss: 3.5419\tLR: 0.000010\n",
      "Training Epoch: 4 [656/45000]\tLoss: 3.6312\tLR: 0.000010\n",
      "Training Epoch: 4 [672/45000]\tLoss: 3.6447\tLR: 0.000010\n",
      "Training Epoch: 4 [688/45000]\tLoss: 3.6207\tLR: 0.000010\n",
      "Training Epoch: 4 [704/45000]\tLoss: 3.6111\tLR: 0.000010\n",
      "Training Epoch: 4 [720/45000]\tLoss: 3.5910\tLR: 0.000010\n",
      "Training Epoch: 4 [736/45000]\tLoss: 3.7064\tLR: 0.000010\n",
      "Training Epoch: 4 [752/45000]\tLoss: 3.6519\tLR: 0.000010\n",
      "Training Epoch: 4 [768/45000]\tLoss: 3.5941\tLR: 0.000010\n",
      "Training Epoch: 4 [784/45000]\tLoss: 3.6894\tLR: 0.000010\n",
      "Training Epoch: 4 [800/45000]\tLoss: 3.7189\tLR: 0.000010\n",
      "Training Epoch: 4 [816/45000]\tLoss: 3.6232\tLR: 0.000010\n",
      "Training Epoch: 4 [832/45000]\tLoss: 3.6808\tLR: 0.000010\n",
      "Training Epoch: 4 [848/45000]\tLoss: 3.6250\tLR: 0.000010\n",
      "Training Epoch: 4 [864/45000]\tLoss: 3.5287\tLR: 0.000010\n",
      "Training Epoch: 4 [880/45000]\tLoss: 3.6516\tLR: 0.000010\n",
      "Training Epoch: 4 [896/45000]\tLoss: 3.5709\tLR: 0.000010\n",
      "Training Epoch: 4 [912/45000]\tLoss: 3.5720\tLR: 0.000010\n",
      "Training Epoch: 4 [928/45000]\tLoss: 3.6836\tLR: 0.000010\n",
      "Training Epoch: 4 [944/45000]\tLoss: 3.6685\tLR: 0.000010\n",
      "Training Epoch: 4 [960/45000]\tLoss: 3.5944\tLR: 0.000010\n",
      "Training Epoch: 4 [976/45000]\tLoss: 3.6548\tLR: 0.000010\n",
      "Training Epoch: 4 [992/45000]\tLoss: 3.6500\tLR: 0.000010\n",
      "Training Epoch: 4 [1008/45000]\tLoss: 3.5988\tLR: 0.000010\n",
      "Training Epoch: 4 [1024/45000]\tLoss: 3.6135\tLR: 0.000010\n",
      "Training Epoch: 4 [1040/45000]\tLoss: 3.6000\tLR: 0.000010\n",
      "Training Epoch: 4 [1056/45000]\tLoss: 3.6099\tLR: 0.000010\n",
      "Training Epoch: 4 [1072/45000]\tLoss: 3.6387\tLR: 0.000010\n",
      "Training Epoch: 4 [1088/45000]\tLoss: 3.6100\tLR: 0.000010\n",
      "Training Epoch: 4 [1104/45000]\tLoss: 3.5032\tLR: 0.000010\n",
      "Training Epoch: 4 [1120/45000]\tLoss: 3.6702\tLR: 0.000010\n",
      "Training Epoch: 4 [1136/45000]\tLoss: 3.5558\tLR: 0.000010\n",
      "Training Epoch: 4 [1152/45000]\tLoss: 3.7254\tLR: 0.000010\n",
      "Training Epoch: 4 [1168/45000]\tLoss: 3.6138\tLR: 0.000010\n",
      "Training Epoch: 4 [1184/45000]\tLoss: 3.6602\tLR: 0.000010\n",
      "Training Epoch: 4 [1200/45000]\tLoss: 3.6177\tLR: 0.000010\n",
      "Training Epoch: 4 [1216/45000]\tLoss: 3.6552\tLR: 0.000010\n",
      "Training Epoch: 4 [1232/45000]\tLoss: 3.5269\tLR: 0.000010\n",
      "Training Epoch: 4 [1248/45000]\tLoss: 3.7150\tLR: 0.000010\n",
      "Training Epoch: 4 [1264/45000]\tLoss: 3.6709\tLR: 0.000010\n",
      "Training Epoch: 4 [1280/45000]\tLoss: 3.7625\tLR: 0.000010\n",
      "Training Epoch: 4 [1296/45000]\tLoss: 3.6730\tLR: 0.000010\n",
      "Training Epoch: 4 [1312/45000]\tLoss: 3.6992\tLR: 0.000010\n",
      "Training Epoch: 4 [1328/45000]\tLoss: 3.5744\tLR: 0.000010\n",
      "Training Epoch: 4 [1344/45000]\tLoss: 3.6011\tLR: 0.000010\n",
      "Training Epoch: 4 [1360/45000]\tLoss: 3.6603\tLR: 0.000010\n",
      "Training Epoch: 4 [1376/45000]\tLoss: 3.5726\tLR: 0.000010\n",
      "Training Epoch: 4 [1392/45000]\tLoss: 3.5244\tLR: 0.000010\n",
      "Training Epoch: 4 [1408/45000]\tLoss: 3.7060\tLR: 0.000010\n",
      "Training Epoch: 4 [1424/45000]\tLoss: 3.5776\tLR: 0.000010\n",
      "Training Epoch: 4 [1440/45000]\tLoss: 3.5189\tLR: 0.000010\n",
      "Training Epoch: 4 [1456/45000]\tLoss: 3.6450\tLR: 0.000010\n",
      "Training Epoch: 4 [1472/45000]\tLoss: 3.5123\tLR: 0.000010\n",
      "Training Epoch: 4 [1488/45000]\tLoss: 3.6050\tLR: 0.000010\n",
      "Training Epoch: 4 [1504/45000]\tLoss: 3.7149\tLR: 0.000010\n",
      "Training Epoch: 4 [1520/45000]\tLoss: 3.5790\tLR: 0.000010\n",
      "Training Epoch: 4 [1536/45000]\tLoss: 3.6052\tLR: 0.000010\n",
      "Training Epoch: 4 [1552/45000]\tLoss: 3.6544\tLR: 0.000010\n",
      "Training Epoch: 4 [1568/45000]\tLoss: 3.6714\tLR: 0.000010\n",
      "Training Epoch: 4 [1584/45000]\tLoss: 3.5670\tLR: 0.000010\n",
      "Training Epoch: 4 [1600/45000]\tLoss: 3.6513\tLR: 0.000010\n",
      "Training Epoch: 4 [1616/45000]\tLoss: 3.6283\tLR: 0.000010\n",
      "Training Epoch: 4 [1632/45000]\tLoss: 3.5461\tLR: 0.000010\n",
      "Training Epoch: 4 [1648/45000]\tLoss: 3.6702\tLR: 0.000010\n",
      "Training Epoch: 4 [1664/45000]\tLoss: 3.7470\tLR: 0.000010\n",
      "Training Epoch: 4 [1680/45000]\tLoss: 3.5648\tLR: 0.000010\n",
      "Training Epoch: 4 [1696/45000]\tLoss: 3.6521\tLR: 0.000010\n",
      "Training Epoch: 4 [1712/45000]\tLoss: 3.7272\tLR: 0.000010\n",
      "Training Epoch: 4 [1728/45000]\tLoss: 3.6684\tLR: 0.000010\n",
      "Training Epoch: 4 [1744/45000]\tLoss: 3.5389\tLR: 0.000010\n",
      "Training Epoch: 4 [1760/45000]\tLoss: 3.5380\tLR: 0.000010\n",
      "Training Epoch: 4 [1776/45000]\tLoss: 3.5460\tLR: 0.000010\n",
      "Training Epoch: 4 [1792/45000]\tLoss: 3.6455\tLR: 0.000010\n",
      "Training Epoch: 4 [1808/45000]\tLoss: 3.5992\tLR: 0.000010\n",
      "Training Epoch: 4 [1824/45000]\tLoss: 3.7388\tLR: 0.000010\n",
      "Training Epoch: 4 [1840/45000]\tLoss: 3.8038\tLR: 0.000010\n",
      "Training Epoch: 4 [1856/45000]\tLoss: 3.5758\tLR: 0.000010\n",
      "Training Epoch: 4 [1872/45000]\tLoss: 3.6342\tLR: 0.000010\n",
      "Training Epoch: 4 [1888/45000]\tLoss: 3.5457\tLR: 0.000010\n",
      "Training Epoch: 4 [1904/45000]\tLoss: 3.4848\tLR: 0.000010\n",
      "Training Epoch: 4 [1920/45000]\tLoss: 3.4782\tLR: 0.000010\n",
      "Training Epoch: 4 [1936/45000]\tLoss: 3.6145\tLR: 0.000010\n",
      "Training Epoch: 4 [1952/45000]\tLoss: 3.5956\tLR: 0.000010\n",
      "Training Epoch: 4 [1968/45000]\tLoss: 3.6698\tLR: 0.000010\n",
      "Training Epoch: 4 [1984/45000]\tLoss: 3.7385\tLR: 0.000010\n",
      "Training Epoch: 4 [2000/45000]\tLoss: 3.7110\tLR: 0.000010\n",
      "Training Epoch: 4 [2016/45000]\tLoss: 3.7311\tLR: 0.000010\n",
      "Training Epoch: 4 [2032/45000]\tLoss: 3.6197\tLR: 0.000010\n",
      "Training Epoch: 4 [2048/45000]\tLoss: 3.5512\tLR: 0.000010\n",
      "Training Epoch: 4 [2064/45000]\tLoss: 3.6012\tLR: 0.000010\n",
      "Training Epoch: 4 [2080/45000]\tLoss: 3.6251\tLR: 0.000010\n",
      "Training Epoch: 4 [2096/45000]\tLoss: 3.6768\tLR: 0.000010\n",
      "Training Epoch: 4 [2112/45000]\tLoss: 3.7910\tLR: 0.000010\n",
      "Training Epoch: 4 [2128/45000]\tLoss: 3.6200\tLR: 0.000010\n",
      "Training Epoch: 4 [2144/45000]\tLoss: 3.6121\tLR: 0.000010\n",
      "Training Epoch: 4 [2160/45000]\tLoss: 3.7174\tLR: 0.000010\n",
      "Training Epoch: 4 [2176/45000]\tLoss: 3.5887\tLR: 0.000010\n",
      "Training Epoch: 4 [2192/45000]\tLoss: 3.5839\tLR: 0.000010\n",
      "Training Epoch: 4 [2208/45000]\tLoss: 3.5177\tLR: 0.000010\n",
      "Training Epoch: 4 [2224/45000]\tLoss: 3.6259\tLR: 0.000010\n",
      "Training Epoch: 4 [2240/45000]\tLoss: 3.6595\tLR: 0.000010\n",
      "Training Epoch: 4 [2256/45000]\tLoss: 3.6118\tLR: 0.000010\n",
      "Training Epoch: 4 [2272/45000]\tLoss: 3.4652\tLR: 0.000010\n",
      "Training Epoch: 4 [2288/45000]\tLoss: 3.7104\tLR: 0.000010\n",
      "Training Epoch: 4 [2304/45000]\tLoss: 3.6146\tLR: 0.000010\n",
      "Training Epoch: 4 [2320/45000]\tLoss: 3.5430\tLR: 0.000010\n",
      "Training Epoch: 4 [2336/45000]\tLoss: 3.6612\tLR: 0.000010\n",
      "Training Epoch: 4 [2352/45000]\tLoss: 3.7429\tLR: 0.000010\n",
      "Training Epoch: 4 [2368/45000]\tLoss: 3.5640\tLR: 0.000010\n",
      "Training Epoch: 4 [2384/45000]\tLoss: 3.5820\tLR: 0.000010\n",
      "Training Epoch: 4 [2400/45000]\tLoss: 3.5824\tLR: 0.000010\n",
      "Training Epoch: 4 [2416/45000]\tLoss: 3.6634\tLR: 0.000010\n",
      "Training Epoch: 4 [2432/45000]\tLoss: 3.6163\tLR: 0.000010\n",
      "Training Epoch: 4 [2448/45000]\tLoss: 3.5747\tLR: 0.000010\n",
      "Training Epoch: 4 [2464/45000]\tLoss: 3.5185\tLR: 0.000010\n",
      "Training Epoch: 4 [2480/45000]\tLoss: 3.5811\tLR: 0.000010\n",
      "Training Epoch: 4 [2496/45000]\tLoss: 3.6636\tLR: 0.000010\n",
      "Training Epoch: 4 [2512/45000]\tLoss: 3.5487\tLR: 0.000010\n",
      "Training Epoch: 4 [2528/45000]\tLoss: 3.6644\tLR: 0.000010\n",
      "Training Epoch: 4 [2544/45000]\tLoss: 3.7571\tLR: 0.000010\n",
      "Training Epoch: 4 [2560/45000]\tLoss: 3.7008\tLR: 0.000010\n",
      "Training Epoch: 4 [2576/45000]\tLoss: 3.5863\tLR: 0.000010\n",
      "Training Epoch: 4 [2592/45000]\tLoss: 3.6478\tLR: 0.000010\n",
      "Training Epoch: 4 [2608/45000]\tLoss: 3.5538\tLR: 0.000010\n",
      "Training Epoch: 4 [2624/45000]\tLoss: 3.5981\tLR: 0.000010\n",
      "Training Epoch: 4 [2640/45000]\tLoss: 3.5707\tLR: 0.000010\n",
      "Training Epoch: 4 [2656/45000]\tLoss: 3.6657\tLR: 0.000010\n",
      "Training Epoch: 4 [2672/45000]\tLoss: 3.6662\tLR: 0.000010\n",
      "Training Epoch: 4 [2688/45000]\tLoss: 3.6267\tLR: 0.000010\n",
      "Training Epoch: 4 [2704/45000]\tLoss: 3.6329\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [2720/45000]\tLoss: 3.6049\tLR: 0.000010\n",
      "Training Epoch: 4 [2736/45000]\tLoss: 3.7162\tLR: 0.000010\n",
      "Training Epoch: 4 [2752/45000]\tLoss: 3.6685\tLR: 0.000010\n",
      "Training Epoch: 4 [2768/45000]\tLoss: 3.5953\tLR: 0.000010\n",
      "Training Epoch: 4 [2784/45000]\tLoss: 3.6733\tLR: 0.000010\n",
      "Training Epoch: 4 [2800/45000]\tLoss: 3.6124\tLR: 0.000010\n",
      "Training Epoch: 4 [2816/45000]\tLoss: 3.5986\tLR: 0.000010\n",
      "Training Epoch: 4 [2832/45000]\tLoss: 3.5937\tLR: 0.000010\n",
      "Training Epoch: 4 [2848/45000]\tLoss: 3.6999\tLR: 0.000010\n",
      "Training Epoch: 4 [2864/45000]\tLoss: 3.5540\tLR: 0.000010\n",
      "Training Epoch: 4 [2880/45000]\tLoss: 3.7339\tLR: 0.000010\n",
      "Training Epoch: 4 [2896/45000]\tLoss: 3.6779\tLR: 0.000010\n",
      "Training Epoch: 4 [2912/45000]\tLoss: 3.5656\tLR: 0.000010\n",
      "Training Epoch: 4 [2928/45000]\tLoss: 3.6373\tLR: 0.000010\n",
      "Training Epoch: 4 [2944/45000]\tLoss: 3.7663\tLR: 0.000010\n",
      "Training Epoch: 4 [2960/45000]\tLoss: 3.4757\tLR: 0.000010\n",
      "Training Epoch: 4 [2976/45000]\tLoss: 3.5873\tLR: 0.000010\n",
      "Training Epoch: 4 [2992/45000]\tLoss: 3.5959\tLR: 0.000010\n",
      "Training Epoch: 4 [3008/45000]\tLoss: 3.5998\tLR: 0.000010\n",
      "Training Epoch: 4 [3024/45000]\tLoss: 3.6721\tLR: 0.000010\n",
      "Training Epoch: 4 [3040/45000]\tLoss: 3.6019\tLR: 0.000010\n",
      "Training Epoch: 4 [3056/45000]\tLoss: 3.5327\tLR: 0.000010\n",
      "Training Epoch: 4 [3072/45000]\tLoss: 3.4707\tLR: 0.000010\n",
      "Training Epoch: 4 [3088/45000]\tLoss: 3.5223\tLR: 0.000010\n",
      "Training Epoch: 4 [3104/45000]\tLoss: 3.6240\tLR: 0.000010\n",
      "Training Epoch: 4 [3120/45000]\tLoss: 3.4300\tLR: 0.000010\n",
      "Training Epoch: 4 [3136/45000]\tLoss: 3.7068\tLR: 0.000010\n",
      "Training Epoch: 4 [3152/45000]\tLoss: 3.6184\tLR: 0.000010\n",
      "Training Epoch: 4 [3168/45000]\tLoss: 3.5750\tLR: 0.000010\n",
      "Training Epoch: 4 [3184/45000]\tLoss: 3.5796\tLR: 0.000010\n",
      "Training Epoch: 4 [3200/45000]\tLoss: 3.7488\tLR: 0.000010\n",
      "Training Epoch: 4 [3216/45000]\tLoss: 3.6622\tLR: 0.000010\n",
      "Training Epoch: 4 [3232/45000]\tLoss: 3.7036\tLR: 0.000010\n",
      "Training Epoch: 4 [3248/45000]\tLoss: 3.6383\tLR: 0.000010\n",
      "Training Epoch: 4 [3264/45000]\tLoss: 3.6004\tLR: 0.000010\n",
      "Training Epoch: 4 [3280/45000]\tLoss: 3.5175\tLR: 0.000010\n",
      "Training Epoch: 4 [3296/45000]\tLoss: 3.5966\tLR: 0.000010\n",
      "Training Epoch: 4 [3312/45000]\tLoss: 3.6904\tLR: 0.000010\n",
      "Training Epoch: 4 [3328/45000]\tLoss: 3.6622\tLR: 0.000010\n",
      "Training Epoch: 4 [3344/45000]\tLoss: 3.5489\tLR: 0.000010\n",
      "Training Epoch: 4 [3360/45000]\tLoss: 3.6402\tLR: 0.000010\n",
      "Training Epoch: 4 [3376/45000]\tLoss: 3.6277\tLR: 0.000010\n",
      "Training Epoch: 4 [3392/45000]\tLoss: 3.6393\tLR: 0.000010\n",
      "Training Epoch: 4 [3408/45000]\tLoss: 3.6528\tLR: 0.000010\n",
      "Training Epoch: 4 [3424/45000]\tLoss: 3.5324\tLR: 0.000010\n",
      "Training Epoch: 4 [3440/45000]\tLoss: 3.5512\tLR: 0.000010\n",
      "Training Epoch: 4 [3456/45000]\tLoss: 3.6175\tLR: 0.000010\n",
      "Training Epoch: 4 [3472/45000]\tLoss: 3.7111\tLR: 0.000010\n",
      "Training Epoch: 4 [3488/45000]\tLoss: 3.6932\tLR: 0.000010\n",
      "Training Epoch: 4 [3504/45000]\tLoss: 3.4864\tLR: 0.000010\n",
      "Training Epoch: 4 [3520/45000]\tLoss: 3.5605\tLR: 0.000010\n",
      "Training Epoch: 4 [3536/45000]\tLoss: 3.5541\tLR: 0.000010\n",
      "Training Epoch: 4 [3552/45000]\tLoss: 3.6575\tLR: 0.000010\n",
      "Training Epoch: 4 [3568/45000]\tLoss: 3.6253\tLR: 0.000010\n",
      "Training Epoch: 4 [3584/45000]\tLoss: 3.6447\tLR: 0.000010\n",
      "Training Epoch: 4 [3600/45000]\tLoss: 3.6627\tLR: 0.000010\n",
      "Training Epoch: 4 [3616/45000]\tLoss: 3.6410\tLR: 0.000010\n",
      "Training Epoch: 4 [3632/45000]\tLoss: 3.6617\tLR: 0.000010\n",
      "Training Epoch: 4 [3648/45000]\tLoss: 3.5929\tLR: 0.000010\n",
      "Training Epoch: 4 [3664/45000]\tLoss: 3.5801\tLR: 0.000010\n",
      "Training Epoch: 4 [3680/45000]\tLoss: 3.6344\tLR: 0.000010\n",
      "Training Epoch: 4 [3696/45000]\tLoss: 3.5458\tLR: 0.000010\n",
      "Training Epoch: 4 [3712/45000]\tLoss: 3.7344\tLR: 0.000010\n",
      "Training Epoch: 4 [3728/45000]\tLoss: 3.5826\tLR: 0.000010\n",
      "Training Epoch: 4 [3744/45000]\tLoss: 3.5177\tLR: 0.000010\n",
      "Training Epoch: 4 [3760/45000]\tLoss: 3.6363\tLR: 0.000010\n",
      "Training Epoch: 4 [3776/45000]\tLoss: 3.6573\tLR: 0.000010\n",
      "Training Epoch: 4 [3792/45000]\tLoss: 3.7078\tLR: 0.000010\n",
      "Training Epoch: 4 [3808/45000]\tLoss: 3.5624\tLR: 0.000010\n",
      "Training Epoch: 4 [3824/45000]\tLoss: 3.7009\tLR: 0.000010\n",
      "Training Epoch: 4 [3840/45000]\tLoss: 3.5758\tLR: 0.000010\n",
      "Training Epoch: 4 [3856/45000]\tLoss: 3.5690\tLR: 0.000010\n",
      "Training Epoch: 4 [3872/45000]\tLoss: 3.5836\tLR: 0.000010\n",
      "Training Epoch: 4 [3888/45000]\tLoss: 3.7991\tLR: 0.000010\n",
      "Training Epoch: 4 [3904/45000]\tLoss: 3.6960\tLR: 0.000010\n",
      "Training Epoch: 4 [3920/45000]\tLoss: 3.6168\tLR: 0.000010\n",
      "Training Epoch: 4 [3936/45000]\tLoss: 3.6706\tLR: 0.000010\n",
      "Training Epoch: 4 [3952/45000]\tLoss: 3.6098\tLR: 0.000010\n",
      "Training Epoch: 4 [3968/45000]\tLoss: 3.5984\tLR: 0.000010\n",
      "Training Epoch: 4 [3984/45000]\tLoss: 3.6477\tLR: 0.000010\n",
      "Training Epoch: 4 [4000/45000]\tLoss: 3.6493\tLR: 0.000010\n",
      "Training Epoch: 4 [4016/45000]\tLoss: 3.6139\tLR: 0.000010\n",
      "Training Epoch: 4 [4032/45000]\tLoss: 3.7686\tLR: 0.000010\n",
      "Training Epoch: 4 [4048/45000]\tLoss: 3.5899\tLR: 0.000010\n",
      "Training Epoch: 4 [4064/45000]\tLoss: 3.6877\tLR: 0.000010\n",
      "Training Epoch: 4 [4080/45000]\tLoss: 3.6537\tLR: 0.000010\n",
      "Training Epoch: 4 [4096/45000]\tLoss: 3.7037\tLR: 0.000010\n",
      "Training Epoch: 4 [4112/45000]\tLoss: 3.6423\tLR: 0.000010\n",
      "Training Epoch: 4 [4128/45000]\tLoss: 3.6220\tLR: 0.000010\n",
      "Training Epoch: 4 [4144/45000]\tLoss: 3.6765\tLR: 0.000010\n",
      "Training Epoch: 4 [4160/45000]\tLoss: 3.6312\tLR: 0.000010\n",
      "Training Epoch: 4 [4176/45000]\tLoss: 3.6067\tLR: 0.000010\n",
      "Training Epoch: 4 [4192/45000]\tLoss: 3.6668\tLR: 0.000010\n",
      "Training Epoch: 4 [4208/45000]\tLoss: 3.6486\tLR: 0.000010\n",
      "Training Epoch: 4 [4224/45000]\tLoss: 3.7007\tLR: 0.000010\n",
      "Training Epoch: 4 [4240/45000]\tLoss: 3.5536\tLR: 0.000010\n",
      "Training Epoch: 4 [4256/45000]\tLoss: 3.6797\tLR: 0.000010\n",
      "Training Epoch: 4 [4272/45000]\tLoss: 3.7045\tLR: 0.000010\n",
      "Training Epoch: 4 [4288/45000]\tLoss: 3.6009\tLR: 0.000010\n",
      "Training Epoch: 4 [4304/45000]\tLoss: 3.7396\tLR: 0.000010\n",
      "Training Epoch: 4 [4320/45000]\tLoss: 3.7086\tLR: 0.000010\n",
      "Training Epoch: 4 [4336/45000]\tLoss: 3.6567\tLR: 0.000010\n",
      "Training Epoch: 4 [4352/45000]\tLoss: 3.6482\tLR: 0.000010\n",
      "Training Epoch: 4 [4368/45000]\tLoss: 3.6184\tLR: 0.000010\n",
      "Training Epoch: 4 [4384/45000]\tLoss: 3.7874\tLR: 0.000010\n",
      "Training Epoch: 4 [4400/45000]\tLoss: 3.6759\tLR: 0.000010\n",
      "Training Epoch: 4 [4416/45000]\tLoss: 3.6819\tLR: 0.000010\n",
      "Training Epoch: 4 [4432/45000]\tLoss: 3.7138\tLR: 0.000010\n",
      "Training Epoch: 4 [4448/45000]\tLoss: 3.5632\tLR: 0.000010\n",
      "Training Epoch: 4 [4464/45000]\tLoss: 3.6587\tLR: 0.000010\n",
      "Training Epoch: 4 [4480/45000]\tLoss: 3.6143\tLR: 0.000010\n",
      "Training Epoch: 4 [4496/45000]\tLoss: 3.6286\tLR: 0.000010\n",
      "Training Epoch: 4 [4512/45000]\tLoss: 3.5402\tLR: 0.000010\n",
      "Training Epoch: 4 [4528/45000]\tLoss: 3.6462\tLR: 0.000010\n",
      "Training Epoch: 4 [4544/45000]\tLoss: 3.6669\tLR: 0.000010\n",
      "Training Epoch: 4 [4560/45000]\tLoss: 3.5519\tLR: 0.000010\n",
      "Training Epoch: 4 [4576/45000]\tLoss: 3.5589\tLR: 0.000010\n",
      "Training Epoch: 4 [4592/45000]\tLoss: 3.4920\tLR: 0.000010\n",
      "Training Epoch: 4 [4608/45000]\tLoss: 3.7670\tLR: 0.000010\n",
      "Training Epoch: 4 [4624/45000]\tLoss: 3.5397\tLR: 0.000010\n",
      "Training Epoch: 4 [4640/45000]\tLoss: 3.6004\tLR: 0.000010\n",
      "Training Epoch: 4 [4656/45000]\tLoss: 3.7381\tLR: 0.000010\n",
      "Training Epoch: 4 [4672/45000]\tLoss: 3.6972\tLR: 0.000010\n",
      "Training Epoch: 4 [4688/45000]\tLoss: 3.7156\tLR: 0.000010\n",
      "Training Epoch: 4 [4704/45000]\tLoss: 3.6067\tLR: 0.000010\n",
      "Training Epoch: 4 [4720/45000]\tLoss: 3.5376\tLR: 0.000010\n",
      "Training Epoch: 4 [4736/45000]\tLoss: 3.5751\tLR: 0.000010\n",
      "Training Epoch: 4 [4752/45000]\tLoss: 3.6686\tLR: 0.000010\n",
      "Training Epoch: 4 [4768/45000]\tLoss: 3.6887\tLR: 0.000010\n",
      "Training Epoch: 4 [4784/45000]\tLoss: 3.5721\tLR: 0.000010\n",
      "Training Epoch: 4 [4800/45000]\tLoss: 3.6171\tLR: 0.000010\n",
      "Training Epoch: 4 [4816/45000]\tLoss: 3.7494\tLR: 0.000010\n",
      "Training Epoch: 4 [4832/45000]\tLoss: 3.6790\tLR: 0.000010\n",
      "Training Epoch: 4 [4848/45000]\tLoss: 3.7079\tLR: 0.000010\n",
      "Training Epoch: 4 [4864/45000]\tLoss: 3.6174\tLR: 0.000010\n",
      "Training Epoch: 4 [4880/45000]\tLoss: 3.5761\tLR: 0.000010\n",
      "Training Epoch: 4 [4896/45000]\tLoss: 3.6532\tLR: 0.000010\n",
      "Training Epoch: 4 [4912/45000]\tLoss: 3.6129\tLR: 0.000010\n",
      "Training Epoch: 4 [4928/45000]\tLoss: 3.6729\tLR: 0.000010\n",
      "Training Epoch: 4 [4944/45000]\tLoss: 3.6050\tLR: 0.000010\n",
      "Training Epoch: 4 [4960/45000]\tLoss: 3.6035\tLR: 0.000010\n",
      "Training Epoch: 4 [4976/45000]\tLoss: 3.6059\tLR: 0.000010\n",
      "Training Epoch: 4 [4992/45000]\tLoss: 3.5909\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [5008/45000]\tLoss: 3.5932\tLR: 0.000010\n",
      "Training Epoch: 4 [5024/45000]\tLoss: 3.6081\tLR: 0.000010\n",
      "Training Epoch: 4 [5040/45000]\tLoss: 3.5628\tLR: 0.000010\n",
      "Training Epoch: 4 [5056/45000]\tLoss: 3.5835\tLR: 0.000010\n",
      "Training Epoch: 4 [5072/45000]\tLoss: 3.6234\tLR: 0.000010\n",
      "Training Epoch: 4 [5088/45000]\tLoss: 3.6891\tLR: 0.000010\n",
      "Training Epoch: 4 [5104/45000]\tLoss: 3.6434\tLR: 0.000010\n",
      "Training Epoch: 4 [5120/45000]\tLoss: 3.6215\tLR: 0.000010\n",
      "Training Epoch: 4 [5136/45000]\tLoss: 3.5206\tLR: 0.000010\n",
      "Training Epoch: 4 [5152/45000]\tLoss: 3.5840\tLR: 0.000010\n",
      "Training Epoch: 4 [5168/45000]\tLoss: 3.6183\tLR: 0.000010\n",
      "Training Epoch: 4 [5184/45000]\tLoss: 3.6868\tLR: 0.000010\n",
      "Training Epoch: 4 [5200/45000]\tLoss: 3.7291\tLR: 0.000010\n",
      "Training Epoch: 4 [5216/45000]\tLoss: 3.6173\tLR: 0.000010\n",
      "Training Epoch: 4 [5232/45000]\tLoss: 3.5919\tLR: 0.000010\n",
      "Training Epoch: 4 [5248/45000]\tLoss: 3.4815\tLR: 0.000010\n",
      "Training Epoch: 4 [5264/45000]\tLoss: 3.6841\tLR: 0.000010\n",
      "Training Epoch: 4 [5280/45000]\tLoss: 3.6266\tLR: 0.000010\n",
      "Training Epoch: 4 [5296/45000]\tLoss: 3.6625\tLR: 0.000010\n",
      "Training Epoch: 4 [5312/45000]\tLoss: 3.6004\tLR: 0.000010\n",
      "Training Epoch: 4 [5328/45000]\tLoss: 3.7277\tLR: 0.000010\n",
      "Training Epoch: 4 [5344/45000]\tLoss: 3.6383\tLR: 0.000010\n",
      "Training Epoch: 4 [5360/45000]\tLoss: 3.6573\tLR: 0.000010\n",
      "Training Epoch: 4 [5376/45000]\tLoss: 3.4761\tLR: 0.000010\n",
      "Training Epoch: 4 [5392/45000]\tLoss: 3.6824\tLR: 0.000010\n",
      "Training Epoch: 4 [5408/45000]\tLoss: 3.5285\tLR: 0.000010\n",
      "Training Epoch: 4 [5424/45000]\tLoss: 3.6721\tLR: 0.000010\n",
      "Training Epoch: 4 [5440/45000]\tLoss: 3.6075\tLR: 0.000010\n",
      "Training Epoch: 4 [5456/45000]\tLoss: 3.7726\tLR: 0.000010\n",
      "Training Epoch: 4 [5472/45000]\tLoss: 3.7129\tLR: 0.000010\n",
      "Training Epoch: 4 [5488/45000]\tLoss: 3.6189\tLR: 0.000010\n",
      "Training Epoch: 4 [5504/45000]\tLoss: 3.6088\tLR: 0.000010\n",
      "Training Epoch: 4 [5520/45000]\tLoss: 3.6627\tLR: 0.000010\n",
      "Training Epoch: 4 [5536/45000]\tLoss: 3.5428\tLR: 0.000010\n",
      "Training Epoch: 4 [5552/45000]\tLoss: 3.4840\tLR: 0.000010\n",
      "Training Epoch: 4 [5568/45000]\tLoss: 3.6541\tLR: 0.000010\n",
      "Training Epoch: 4 [5584/45000]\tLoss: 3.7184\tLR: 0.000010\n",
      "Training Epoch: 4 [5600/45000]\tLoss: 3.5330\tLR: 0.000010\n",
      "Training Epoch: 4 [5616/45000]\tLoss: 3.7298\tLR: 0.000010\n",
      "Training Epoch: 4 [5632/45000]\tLoss: 3.5942\tLR: 0.000010\n",
      "Training Epoch: 4 [5648/45000]\tLoss: 3.6094\tLR: 0.000010\n",
      "Training Epoch: 4 [5664/45000]\tLoss: 3.5761\tLR: 0.000010\n",
      "Training Epoch: 4 [5680/45000]\tLoss: 3.5412\tLR: 0.000010\n",
      "Training Epoch: 4 [5696/45000]\tLoss: 3.5302\tLR: 0.000010\n",
      "Training Epoch: 4 [5712/45000]\tLoss: 3.6303\tLR: 0.000010\n",
      "Training Epoch: 4 [5728/45000]\tLoss: 3.4838\tLR: 0.000010\n",
      "Training Epoch: 4 [5744/45000]\tLoss: 3.7383\tLR: 0.000010\n",
      "Training Epoch: 4 [5760/45000]\tLoss: 3.5560\tLR: 0.000010\n",
      "Training Epoch: 4 [5776/45000]\tLoss: 3.7034\tLR: 0.000010\n",
      "Training Epoch: 4 [5792/45000]\tLoss: 3.6048\tLR: 0.000010\n",
      "Training Epoch: 4 [5808/45000]\tLoss: 3.6047\tLR: 0.000010\n",
      "Training Epoch: 4 [5824/45000]\tLoss: 3.7122\tLR: 0.000010\n",
      "Training Epoch: 4 [5840/45000]\tLoss: 3.6864\tLR: 0.000010\n",
      "Training Epoch: 4 [5856/45000]\tLoss: 3.5841\tLR: 0.000010\n",
      "Training Epoch: 4 [5872/45000]\tLoss: 3.6750\tLR: 0.000010\n",
      "Training Epoch: 4 [5888/45000]\tLoss: 3.6077\tLR: 0.000010\n",
      "Training Epoch: 4 [5904/45000]\tLoss: 3.7025\tLR: 0.000010\n",
      "Training Epoch: 4 [5920/45000]\tLoss: 3.6443\tLR: 0.000010\n",
      "Training Epoch: 4 [5936/45000]\tLoss: 3.6303\tLR: 0.000010\n",
      "Training Epoch: 4 [5952/45000]\tLoss: 3.4686\tLR: 0.000010\n",
      "Training Epoch: 4 [5968/45000]\tLoss: 3.6277\tLR: 0.000010\n",
      "Training Epoch: 4 [5984/45000]\tLoss: 3.5474\tLR: 0.000010\n",
      "Training Epoch: 4 [6000/45000]\tLoss: 3.5638\tLR: 0.000010\n",
      "Training Epoch: 4 [6016/45000]\tLoss: 3.7012\tLR: 0.000010\n",
      "Training Epoch: 4 [6032/45000]\tLoss: 3.6274\tLR: 0.000010\n",
      "Training Epoch: 4 [6048/45000]\tLoss: 3.5801\tLR: 0.000010\n",
      "Training Epoch: 4 [6064/45000]\tLoss: 3.5967\tLR: 0.000010\n",
      "Training Epoch: 4 [6080/45000]\tLoss: 3.6053\tLR: 0.000010\n",
      "Training Epoch: 4 [6096/45000]\tLoss: 3.6228\tLR: 0.000010\n",
      "Training Epoch: 4 [6112/45000]\tLoss: 3.6408\tLR: 0.000010\n",
      "Training Epoch: 4 [6128/45000]\tLoss: 3.5707\tLR: 0.000010\n",
      "Training Epoch: 4 [6144/45000]\tLoss: 3.5540\tLR: 0.000010\n",
      "Training Epoch: 4 [6160/45000]\tLoss: 3.6309\tLR: 0.000010\n",
      "Training Epoch: 4 [6176/45000]\tLoss: 3.5705\tLR: 0.000010\n",
      "Training Epoch: 4 [6192/45000]\tLoss: 3.5194\tLR: 0.000010\n",
      "Training Epoch: 4 [6208/45000]\tLoss: 3.6754\tLR: 0.000010\n",
      "Training Epoch: 4 [6224/45000]\tLoss: 3.6669\tLR: 0.000010\n",
      "Training Epoch: 4 [6240/45000]\tLoss: 3.6870\tLR: 0.000010\n",
      "Training Epoch: 4 [6256/45000]\tLoss: 3.6272\tLR: 0.000010\n",
      "Training Epoch: 4 [6272/45000]\tLoss: 3.6574\tLR: 0.000010\n",
      "Training Epoch: 4 [6288/45000]\tLoss: 3.5523\tLR: 0.000010\n",
      "Training Epoch: 4 [6304/45000]\tLoss: 3.6043\tLR: 0.000010\n",
      "Training Epoch: 4 [6320/45000]\tLoss: 3.5487\tLR: 0.000010\n",
      "Training Epoch: 4 [6336/45000]\tLoss: 3.6310\tLR: 0.000010\n",
      "Training Epoch: 4 [6352/45000]\tLoss: 3.5694\tLR: 0.000010\n",
      "Training Epoch: 4 [6368/45000]\tLoss: 3.6550\tLR: 0.000010\n",
      "Training Epoch: 4 [6384/45000]\tLoss: 3.5375\tLR: 0.000010\n",
      "Training Epoch: 4 [6400/45000]\tLoss: 3.6571\tLR: 0.000010\n",
      "Training Epoch: 4 [6416/45000]\tLoss: 3.7239\tLR: 0.000010\n",
      "Training Epoch: 4 [6432/45000]\tLoss: 3.6655\tLR: 0.000010\n",
      "Training Epoch: 4 [6448/45000]\tLoss: 3.6942\tLR: 0.000010\n",
      "Training Epoch: 4 [6464/45000]\tLoss: 3.8059\tLR: 0.000010\n",
      "Training Epoch: 4 [6480/45000]\tLoss: 3.6301\tLR: 0.000010\n",
      "Training Epoch: 4 [6496/45000]\tLoss: 3.5852\tLR: 0.000010\n",
      "Training Epoch: 4 [6512/45000]\tLoss: 3.5930\tLR: 0.000010\n",
      "Training Epoch: 4 [6528/45000]\tLoss: 3.5808\tLR: 0.000010\n",
      "Training Epoch: 4 [6544/45000]\tLoss: 3.6308\tLR: 0.000010\n",
      "Training Epoch: 4 [6560/45000]\tLoss: 3.5678\tLR: 0.000010\n",
      "Training Epoch: 4 [6576/45000]\tLoss: 3.4310\tLR: 0.000010\n",
      "Training Epoch: 4 [6592/45000]\tLoss: 3.6099\tLR: 0.000010\n",
      "Training Epoch: 4 [6608/45000]\tLoss: 3.6220\tLR: 0.000010\n",
      "Training Epoch: 4 [6624/45000]\tLoss: 3.6012\tLR: 0.000010\n",
      "Training Epoch: 4 [6640/45000]\tLoss: 3.7236\tLR: 0.000010\n",
      "Training Epoch: 4 [6656/45000]\tLoss: 3.7168\tLR: 0.000010\n",
      "Training Epoch: 4 [6672/45000]\tLoss: 3.5553\tLR: 0.000010\n",
      "Training Epoch: 4 [6688/45000]\tLoss: 3.5975\tLR: 0.000010\n",
      "Training Epoch: 4 [6704/45000]\tLoss: 3.6656\tLR: 0.000010\n",
      "Training Epoch: 4 [6720/45000]\tLoss: 3.5680\tLR: 0.000010\n",
      "Training Epoch: 4 [6736/45000]\tLoss: 3.7264\tLR: 0.000010\n",
      "Training Epoch: 4 [6752/45000]\tLoss: 3.6181\tLR: 0.000010\n",
      "Training Epoch: 4 [6768/45000]\tLoss: 3.5804\tLR: 0.000010\n",
      "Training Epoch: 4 [6784/45000]\tLoss: 3.6391\tLR: 0.000010\n",
      "Training Epoch: 4 [6800/45000]\tLoss: 3.6102\tLR: 0.000010\n",
      "Training Epoch: 4 [6816/45000]\tLoss: 3.5088\tLR: 0.000010\n",
      "Training Epoch: 4 [6832/45000]\tLoss: 3.7001\tLR: 0.000010\n",
      "Training Epoch: 4 [6848/45000]\tLoss: 3.6793\tLR: 0.000010\n",
      "Training Epoch: 4 [6864/45000]\tLoss: 3.6443\tLR: 0.000010\n",
      "Training Epoch: 4 [6880/45000]\tLoss: 3.6064\tLR: 0.000010\n",
      "Training Epoch: 4 [6896/45000]\tLoss: 3.5825\tLR: 0.000010\n",
      "Training Epoch: 4 [6912/45000]\tLoss: 3.6345\tLR: 0.000010\n",
      "Training Epoch: 4 [6928/45000]\tLoss: 3.7293\tLR: 0.000010\n",
      "Training Epoch: 4 [6944/45000]\tLoss: 3.5463\tLR: 0.000010\n",
      "Training Epoch: 4 [6960/45000]\tLoss: 3.3844\tLR: 0.000010\n",
      "Training Epoch: 4 [6976/45000]\tLoss: 3.6252\tLR: 0.000010\n",
      "Training Epoch: 4 [6992/45000]\tLoss: 3.6953\tLR: 0.000010\n",
      "Training Epoch: 4 [7008/45000]\tLoss: 3.4823\tLR: 0.000010\n",
      "Training Epoch: 4 [7024/45000]\tLoss: 3.6918\tLR: 0.000010\n",
      "Training Epoch: 4 [7040/45000]\tLoss: 3.5865\tLR: 0.000010\n",
      "Training Epoch: 4 [7056/45000]\tLoss: 3.6341\tLR: 0.000010\n",
      "Training Epoch: 4 [7072/45000]\tLoss: 3.6247\tLR: 0.000010\n",
      "Training Epoch: 4 [7088/45000]\tLoss: 3.5768\tLR: 0.000010\n",
      "Training Epoch: 4 [7104/45000]\tLoss: 3.5325\tLR: 0.000010\n",
      "Training Epoch: 4 [7120/45000]\tLoss: 3.6094\tLR: 0.000010\n",
      "Training Epoch: 4 [7136/45000]\tLoss: 3.6043\tLR: 0.000010\n",
      "Training Epoch: 4 [7152/45000]\tLoss: 3.5526\tLR: 0.000010\n",
      "Training Epoch: 4 [7168/45000]\tLoss: 3.6399\tLR: 0.000010\n",
      "Training Epoch: 4 [7184/45000]\tLoss: 3.5937\tLR: 0.000010\n",
      "Training Epoch: 4 [7200/45000]\tLoss: 3.6036\tLR: 0.000010\n",
      "Training Epoch: 4 [7216/45000]\tLoss: 3.5451\tLR: 0.000010\n",
      "Training Epoch: 4 [7232/45000]\tLoss: 3.5579\tLR: 0.000010\n",
      "Training Epoch: 4 [7248/45000]\tLoss: 3.5644\tLR: 0.000010\n",
      "Training Epoch: 4 [7264/45000]\tLoss: 3.5340\tLR: 0.000010\n",
      "Training Epoch: 4 [7280/45000]\tLoss: 3.6954\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [7296/45000]\tLoss: 3.6792\tLR: 0.000010\n",
      "Training Epoch: 4 [7312/45000]\tLoss: 3.6696\tLR: 0.000010\n",
      "Training Epoch: 4 [7328/45000]\tLoss: 3.5796\tLR: 0.000010\n",
      "Training Epoch: 4 [7344/45000]\tLoss: 3.6813\tLR: 0.000010\n",
      "Training Epoch: 4 [7360/45000]\tLoss: 3.6378\tLR: 0.000010\n",
      "Training Epoch: 4 [7376/45000]\tLoss: 3.5310\tLR: 0.000010\n",
      "Training Epoch: 4 [7392/45000]\tLoss: 3.5830\tLR: 0.000010\n",
      "Training Epoch: 4 [7408/45000]\tLoss: 3.6092\tLR: 0.000010\n",
      "Training Epoch: 4 [7424/45000]\tLoss: 3.6396\tLR: 0.000010\n",
      "Training Epoch: 4 [7440/45000]\tLoss: 3.7168\tLR: 0.000010\n",
      "Training Epoch: 4 [7456/45000]\tLoss: 3.6135\tLR: 0.000010\n",
      "Training Epoch: 4 [7472/45000]\tLoss: 3.5903\tLR: 0.000010\n",
      "Training Epoch: 4 [7488/45000]\tLoss: 3.6368\tLR: 0.000010\n",
      "Training Epoch: 4 [7504/45000]\tLoss: 3.5870\tLR: 0.000010\n",
      "Training Epoch: 4 [7520/45000]\tLoss: 3.5282\tLR: 0.000010\n",
      "Training Epoch: 4 [7536/45000]\tLoss: 3.6193\tLR: 0.000010\n",
      "Training Epoch: 4 [7552/45000]\tLoss: 3.6273\tLR: 0.000010\n",
      "Training Epoch: 4 [7568/45000]\tLoss: 3.5456\tLR: 0.000010\n",
      "Training Epoch: 4 [7584/45000]\tLoss: 3.5708\tLR: 0.000010\n",
      "Training Epoch: 4 [7600/45000]\tLoss: 3.5425\tLR: 0.000010\n",
      "Training Epoch: 4 [7616/45000]\tLoss: 3.5804\tLR: 0.000010\n",
      "Training Epoch: 4 [7632/45000]\tLoss: 3.6159\tLR: 0.000010\n",
      "Training Epoch: 4 [7648/45000]\tLoss: 3.6849\tLR: 0.000010\n",
      "Training Epoch: 4 [7664/45000]\tLoss: 3.5950\tLR: 0.000010\n",
      "Training Epoch: 4 [7680/45000]\tLoss: 3.6431\tLR: 0.000010\n",
      "Training Epoch: 4 [7696/45000]\tLoss: 3.6234\tLR: 0.000010\n",
      "Training Epoch: 4 [7712/45000]\tLoss: 3.6196\tLR: 0.000010\n",
      "Training Epoch: 4 [7728/45000]\tLoss: 3.5839\tLR: 0.000010\n",
      "Training Epoch: 4 [7744/45000]\tLoss: 3.5708\tLR: 0.000010\n",
      "Training Epoch: 4 [7760/45000]\tLoss: 3.5410\tLR: 0.000010\n",
      "Training Epoch: 4 [7776/45000]\tLoss: 3.5622\tLR: 0.000010\n",
      "Training Epoch: 4 [7792/45000]\tLoss: 3.6107\tLR: 0.000010\n",
      "Training Epoch: 4 [7808/45000]\tLoss: 3.6376\tLR: 0.000010\n",
      "Training Epoch: 4 [7824/45000]\tLoss: 3.6705\tLR: 0.000010\n",
      "Training Epoch: 4 [7840/45000]\tLoss: 3.5585\tLR: 0.000010\n",
      "Training Epoch: 4 [7856/45000]\tLoss: 3.5883\tLR: 0.000010\n",
      "Training Epoch: 4 [7872/45000]\tLoss: 3.6714\tLR: 0.000010\n",
      "Training Epoch: 4 [7888/45000]\tLoss: 3.6135\tLR: 0.000010\n",
      "Training Epoch: 4 [7904/45000]\tLoss: 3.6276\tLR: 0.000010\n",
      "Training Epoch: 4 [7920/45000]\tLoss: 3.6703\tLR: 0.000010\n",
      "Training Epoch: 4 [7936/45000]\tLoss: 3.5879\tLR: 0.000010\n",
      "Training Epoch: 4 [7952/45000]\tLoss: 3.6219\tLR: 0.000010\n",
      "Training Epoch: 4 [7968/45000]\tLoss: 3.7310\tLR: 0.000010\n",
      "Training Epoch: 4 [7984/45000]\tLoss: 3.7344\tLR: 0.000010\n",
      "Training Epoch: 4 [8000/45000]\tLoss: 3.6977\tLR: 0.000010\n",
      "Training Epoch: 4 [8016/45000]\tLoss: 3.6609\tLR: 0.000010\n",
      "Training Epoch: 4 [8032/45000]\tLoss: 3.5985\tLR: 0.000010\n",
      "Training Epoch: 4 [8048/45000]\tLoss: 3.6659\tLR: 0.000010\n",
      "Training Epoch: 4 [8064/45000]\tLoss: 3.5702\tLR: 0.000010\n",
      "Training Epoch: 4 [8080/45000]\tLoss: 3.6865\tLR: 0.000010\n",
      "Training Epoch: 4 [8096/45000]\tLoss: 3.5647\tLR: 0.000010\n",
      "Training Epoch: 4 [8112/45000]\tLoss: 3.6935\tLR: 0.000010\n",
      "Training Epoch: 4 [8128/45000]\tLoss: 3.5598\tLR: 0.000010\n",
      "Training Epoch: 4 [8144/45000]\tLoss: 3.6204\tLR: 0.000010\n",
      "Training Epoch: 4 [8160/45000]\tLoss: 3.5390\tLR: 0.000010\n",
      "Training Epoch: 4 [8176/45000]\tLoss: 3.6702\tLR: 0.000010\n",
      "Training Epoch: 4 [8192/45000]\tLoss: 3.6952\tLR: 0.000010\n",
      "Training Epoch: 4 [8208/45000]\tLoss: 3.6013\tLR: 0.000010\n",
      "Training Epoch: 4 [8224/45000]\tLoss: 3.7247\tLR: 0.000010\n",
      "Training Epoch: 4 [8240/45000]\tLoss: 3.5450\tLR: 0.000010\n",
      "Training Epoch: 4 [8256/45000]\tLoss: 3.6415\tLR: 0.000010\n",
      "Training Epoch: 4 [8272/45000]\tLoss: 3.6500\tLR: 0.000010\n",
      "Training Epoch: 4 [8288/45000]\tLoss: 3.7010\tLR: 0.000010\n",
      "Training Epoch: 4 [8304/45000]\tLoss: 3.6318\tLR: 0.000010\n",
      "Training Epoch: 4 [8320/45000]\tLoss: 3.6296\tLR: 0.000010\n",
      "Training Epoch: 4 [8336/45000]\tLoss: 3.4571\tLR: 0.000010\n",
      "Training Epoch: 4 [8352/45000]\tLoss: 3.7992\tLR: 0.000010\n",
      "Training Epoch: 4 [8368/45000]\tLoss: 3.5685\tLR: 0.000010\n",
      "Training Epoch: 4 [8384/45000]\tLoss: 3.6479\tLR: 0.000010\n",
      "Training Epoch: 4 [8400/45000]\tLoss: 3.5615\tLR: 0.000010\n",
      "Training Epoch: 4 [8416/45000]\tLoss: 3.5644\tLR: 0.000010\n",
      "Training Epoch: 4 [8432/45000]\tLoss: 3.5772\tLR: 0.000010\n",
      "Training Epoch: 4 [8448/45000]\tLoss: 3.5900\tLR: 0.000010\n",
      "Training Epoch: 4 [8464/45000]\tLoss: 3.5932\tLR: 0.000010\n",
      "Training Epoch: 4 [8480/45000]\tLoss: 3.5964\tLR: 0.000010\n",
      "Training Epoch: 4 [8496/45000]\tLoss: 3.5741\tLR: 0.000010\n",
      "Training Epoch: 4 [8512/45000]\tLoss: 3.5710\tLR: 0.000010\n",
      "Training Epoch: 4 [8528/45000]\tLoss: 3.6129\tLR: 0.000010\n",
      "Training Epoch: 4 [8544/45000]\tLoss: 3.5609\tLR: 0.000010\n",
      "Training Epoch: 4 [8560/45000]\tLoss: 3.5655\tLR: 0.000010\n",
      "Training Epoch: 4 [8576/45000]\tLoss: 3.5269\tLR: 0.000010\n",
      "Training Epoch: 4 [8592/45000]\tLoss: 3.6387\tLR: 0.000010\n",
      "Training Epoch: 4 [8608/45000]\tLoss: 3.5492\tLR: 0.000010\n",
      "Training Epoch: 4 [8624/45000]\tLoss: 3.6202\tLR: 0.000010\n",
      "Training Epoch: 4 [8640/45000]\tLoss: 3.6847\tLR: 0.000010\n",
      "Training Epoch: 4 [8656/45000]\tLoss: 3.5681\tLR: 0.000010\n",
      "Training Epoch: 4 [8672/45000]\tLoss: 3.6893\tLR: 0.000010\n",
      "Training Epoch: 4 [8688/45000]\tLoss: 3.5372\tLR: 0.000010\n",
      "Training Epoch: 4 [8704/45000]\tLoss: 3.7289\tLR: 0.000010\n",
      "Training Epoch: 4 [8720/45000]\tLoss: 3.5703\tLR: 0.000010\n",
      "Training Epoch: 4 [8736/45000]\tLoss: 3.6529\tLR: 0.000010\n",
      "Training Epoch: 4 [8752/45000]\tLoss: 3.6134\tLR: 0.000010\n",
      "Training Epoch: 4 [8768/45000]\tLoss: 3.6533\tLR: 0.000010\n",
      "Training Epoch: 4 [8784/45000]\tLoss: 3.6119\tLR: 0.000010\n",
      "Training Epoch: 4 [8800/45000]\tLoss: 3.6441\tLR: 0.000010\n",
      "Training Epoch: 4 [8816/45000]\tLoss: 3.6208\tLR: 0.000010\n",
      "Training Epoch: 4 [8832/45000]\tLoss: 3.5183\tLR: 0.000010\n",
      "Training Epoch: 4 [8848/45000]\tLoss: 3.6685\tLR: 0.000010\n",
      "Training Epoch: 4 [8864/45000]\tLoss: 3.4386\tLR: 0.000010\n",
      "Training Epoch: 4 [8880/45000]\tLoss: 3.5994\tLR: 0.000010\n",
      "Training Epoch: 4 [8896/45000]\tLoss: 3.7471\tLR: 0.000010\n",
      "Training Epoch: 4 [8912/45000]\tLoss: 3.5840\tLR: 0.000010\n",
      "Training Epoch: 4 [8928/45000]\tLoss: 3.5511\tLR: 0.000010\n",
      "Training Epoch: 4 [8944/45000]\tLoss: 3.6546\tLR: 0.000010\n",
      "Training Epoch: 4 [8960/45000]\tLoss: 3.6259\tLR: 0.000010\n",
      "Training Epoch: 4 [8976/45000]\tLoss: 3.5727\tLR: 0.000010\n",
      "Training Epoch: 4 [8992/45000]\tLoss: 3.6814\tLR: 0.000010\n",
      "Training Epoch: 4 [9008/45000]\tLoss: 3.6439\tLR: 0.000010\n",
      "Training Epoch: 4 [9024/45000]\tLoss: 3.5126\tLR: 0.000010\n",
      "Training Epoch: 4 [9040/45000]\tLoss: 3.6664\tLR: 0.000010\n",
      "Training Epoch: 4 [9056/45000]\tLoss: 3.5477\tLR: 0.000010\n",
      "Training Epoch: 4 [9072/45000]\tLoss: 3.6605\tLR: 0.000010\n",
      "Training Epoch: 4 [9088/45000]\tLoss: 3.5788\tLR: 0.000010\n",
      "Training Epoch: 4 [9104/45000]\tLoss: 3.5969\tLR: 0.000010\n",
      "Training Epoch: 4 [9120/45000]\tLoss: 3.6111\tLR: 0.000010\n",
      "Training Epoch: 4 [9136/45000]\tLoss: 3.7287\tLR: 0.000010\n",
      "Training Epoch: 4 [9152/45000]\tLoss: 3.5517\tLR: 0.000010\n",
      "Training Epoch: 4 [9168/45000]\tLoss: 3.6903\tLR: 0.000010\n",
      "Training Epoch: 4 [9184/45000]\tLoss: 3.5535\tLR: 0.000010\n",
      "Training Epoch: 4 [9200/45000]\tLoss: 3.5334\tLR: 0.000010\n",
      "Training Epoch: 4 [9216/45000]\tLoss: 3.6116\tLR: 0.000010\n",
      "Training Epoch: 4 [9232/45000]\tLoss: 3.6828\tLR: 0.000010\n",
      "Training Epoch: 4 [9248/45000]\tLoss: 3.5560\tLR: 0.000010\n",
      "Training Epoch: 4 [9264/45000]\tLoss: 3.6142\tLR: 0.000010\n",
      "Training Epoch: 4 [9280/45000]\tLoss: 3.6996\tLR: 0.000010\n",
      "Training Epoch: 4 [9296/45000]\tLoss: 3.5505\tLR: 0.000010\n",
      "Training Epoch: 4 [9312/45000]\tLoss: 3.7232\tLR: 0.000010\n",
      "Training Epoch: 4 [9328/45000]\tLoss: 3.5948\tLR: 0.000010\n",
      "Training Epoch: 4 [9344/45000]\tLoss: 3.6675\tLR: 0.000010\n",
      "Training Epoch: 4 [9360/45000]\tLoss: 3.6504\tLR: 0.000010\n",
      "Training Epoch: 4 [9376/45000]\tLoss: 3.6254\tLR: 0.000010\n",
      "Training Epoch: 4 [9392/45000]\tLoss: 3.5644\tLR: 0.000010\n",
      "Training Epoch: 4 [9408/45000]\tLoss: 3.5717\tLR: 0.000010\n",
      "Training Epoch: 4 [9424/45000]\tLoss: 3.5739\tLR: 0.000010\n",
      "Training Epoch: 4 [9440/45000]\tLoss: 3.5511\tLR: 0.000010\n",
      "Training Epoch: 4 [9456/45000]\tLoss: 3.7318\tLR: 0.000010\n",
      "Training Epoch: 4 [9472/45000]\tLoss: 3.6956\tLR: 0.000010\n",
      "Training Epoch: 4 [9488/45000]\tLoss: 3.6405\tLR: 0.000010\n",
      "Training Epoch: 4 [9504/45000]\tLoss: 3.5201\tLR: 0.000010\n",
      "Training Epoch: 4 [9520/45000]\tLoss: 3.7432\tLR: 0.000010\n",
      "Training Epoch: 4 [9536/45000]\tLoss: 3.5510\tLR: 0.000010\n",
      "Training Epoch: 4 [9552/45000]\tLoss: 3.6413\tLR: 0.000010\n",
      "Training Epoch: 4 [9568/45000]\tLoss: 3.7519\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [9584/45000]\tLoss: 3.5010\tLR: 0.000010\n",
      "Training Epoch: 4 [9600/45000]\tLoss: 3.6076\tLR: 0.000010\n",
      "Training Epoch: 4 [9616/45000]\tLoss: 3.6961\tLR: 0.000010\n",
      "Training Epoch: 4 [9632/45000]\tLoss: 3.5765\tLR: 0.000010\n",
      "Training Epoch: 4 [9648/45000]\tLoss: 3.5337\tLR: 0.000010\n",
      "Training Epoch: 4 [9664/45000]\tLoss: 3.5690\tLR: 0.000010\n",
      "Training Epoch: 4 [9680/45000]\tLoss: 3.7156\tLR: 0.000010\n",
      "Training Epoch: 4 [9696/45000]\tLoss: 3.6670\tLR: 0.000010\n",
      "Training Epoch: 4 [9712/45000]\tLoss: 3.6919\tLR: 0.000010\n",
      "Training Epoch: 4 [9728/45000]\tLoss: 3.6120\tLR: 0.000010\n",
      "Training Epoch: 4 [9744/45000]\tLoss: 3.5616\tLR: 0.000010\n",
      "Training Epoch: 4 [9760/45000]\tLoss: 3.5282\tLR: 0.000010\n",
      "Training Epoch: 4 [9776/45000]\tLoss: 3.5084\tLR: 0.000010\n",
      "Training Epoch: 4 [9792/45000]\tLoss: 3.6745\tLR: 0.000010\n",
      "Training Epoch: 4 [9808/45000]\tLoss: 3.5599\tLR: 0.000010\n",
      "Training Epoch: 4 [9824/45000]\tLoss: 3.5368\tLR: 0.000010\n",
      "Training Epoch: 4 [9840/45000]\tLoss: 3.7045\tLR: 0.000010\n",
      "Training Epoch: 4 [9856/45000]\tLoss: 3.5938\tLR: 0.000010\n",
      "Training Epoch: 4 [9872/45000]\tLoss: 3.5761\tLR: 0.000010\n",
      "Training Epoch: 4 [9888/45000]\tLoss: 3.6389\tLR: 0.000010\n",
      "Training Epoch: 4 [9904/45000]\tLoss: 3.6769\tLR: 0.000010\n",
      "Training Epoch: 4 [9920/45000]\tLoss: 3.6724\tLR: 0.000010\n",
      "Training Epoch: 4 [9936/45000]\tLoss: 3.6455\tLR: 0.000010\n",
      "Training Epoch: 4 [9952/45000]\tLoss: 3.7319\tLR: 0.000010\n",
      "Training Epoch: 4 [9968/45000]\tLoss: 3.5535\tLR: 0.000010\n",
      "Training Epoch: 4 [9984/45000]\tLoss: 3.5952\tLR: 0.000010\n",
      "Training Epoch: 4 [10000/45000]\tLoss: 3.5697\tLR: 0.000010\n",
      "Training Epoch: 4 [10016/45000]\tLoss: 3.6923\tLR: 0.000010\n",
      "Training Epoch: 4 [10032/45000]\tLoss: 3.5702\tLR: 0.000010\n",
      "Training Epoch: 4 [10048/45000]\tLoss: 3.6688\tLR: 0.000010\n",
      "Training Epoch: 4 [10064/45000]\tLoss: 3.6217\tLR: 0.000010\n",
      "Training Epoch: 4 [10080/45000]\tLoss: 3.5931\tLR: 0.000010\n",
      "Training Epoch: 4 [10096/45000]\tLoss: 3.7013\tLR: 0.000010\n",
      "Training Epoch: 4 [10112/45000]\tLoss: 3.6383\tLR: 0.000010\n",
      "Training Epoch: 4 [10128/45000]\tLoss: 3.5901\tLR: 0.000010\n",
      "Training Epoch: 4 [10144/45000]\tLoss: 3.7403\tLR: 0.000010\n",
      "Training Epoch: 4 [10160/45000]\tLoss: 3.5343\tLR: 0.000010\n",
      "Training Epoch: 4 [10176/45000]\tLoss: 3.6376\tLR: 0.000010\n",
      "Training Epoch: 4 [10192/45000]\tLoss: 3.5371\tLR: 0.000010\n",
      "Training Epoch: 4 [10208/45000]\tLoss: 3.6537\tLR: 0.000010\n",
      "Training Epoch: 4 [10224/45000]\tLoss: 3.5983\tLR: 0.000010\n",
      "Training Epoch: 4 [10240/45000]\tLoss: 3.6111\tLR: 0.000010\n",
      "Training Epoch: 4 [10256/45000]\tLoss: 3.5067\tLR: 0.000010\n",
      "Training Epoch: 4 [10272/45000]\tLoss: 3.5145\tLR: 0.000010\n",
      "Training Epoch: 4 [10288/45000]\tLoss: 3.6681\tLR: 0.000010\n",
      "Training Epoch: 4 [10304/45000]\tLoss: 3.5567\tLR: 0.000010\n",
      "Training Epoch: 4 [10320/45000]\tLoss: 3.5719\tLR: 0.000010\n",
      "Training Epoch: 4 [10336/45000]\tLoss: 3.6902\tLR: 0.000010\n",
      "Training Epoch: 4 [10352/45000]\tLoss: 3.6717\tLR: 0.000010\n",
      "Training Epoch: 4 [10368/45000]\tLoss: 3.6153\tLR: 0.000010\n",
      "Training Epoch: 4 [10384/45000]\tLoss: 3.6669\tLR: 0.000010\n",
      "Training Epoch: 4 [10400/45000]\tLoss: 3.6530\tLR: 0.000010\n",
      "Training Epoch: 4 [10416/45000]\tLoss: 3.6018\tLR: 0.000010\n",
      "Training Epoch: 4 [10432/45000]\tLoss: 3.6480\tLR: 0.000010\n",
      "Training Epoch: 4 [10448/45000]\tLoss: 3.6593\tLR: 0.000010\n",
      "Training Epoch: 4 [10464/45000]\tLoss: 3.6531\tLR: 0.000010\n",
      "Training Epoch: 4 [10480/45000]\tLoss: 3.5436\tLR: 0.000010\n",
      "Training Epoch: 4 [10496/45000]\tLoss: 3.6590\tLR: 0.000010\n",
      "Training Epoch: 4 [10512/45000]\tLoss: 3.7055\tLR: 0.000010\n",
      "Training Epoch: 4 [10528/45000]\tLoss: 3.6631\tLR: 0.000010\n",
      "Training Epoch: 4 [10544/45000]\tLoss: 3.5429\tLR: 0.000010\n",
      "Training Epoch: 4 [10560/45000]\tLoss: 3.6963\tLR: 0.000010\n",
      "Training Epoch: 4 [10576/45000]\tLoss: 3.6403\tLR: 0.000010\n",
      "Training Epoch: 4 [10592/45000]\tLoss: 3.5619\tLR: 0.000010\n",
      "Training Epoch: 4 [10608/45000]\tLoss: 3.6305\tLR: 0.000010\n",
      "Training Epoch: 4 [10624/45000]\tLoss: 3.6028\tLR: 0.000010\n",
      "Training Epoch: 4 [10640/45000]\tLoss: 3.6048\tLR: 0.000010\n",
      "Training Epoch: 4 [10656/45000]\tLoss: 3.6052\tLR: 0.000010\n",
      "Training Epoch: 4 [10672/45000]\tLoss: 3.7124\tLR: 0.000010\n",
      "Training Epoch: 4 [10688/45000]\tLoss: 3.6413\tLR: 0.000010\n",
      "Training Epoch: 4 [10704/45000]\tLoss: 3.6783\tLR: 0.000010\n",
      "Training Epoch: 4 [10720/45000]\tLoss: 3.6577\tLR: 0.000010\n",
      "Training Epoch: 4 [10736/45000]\tLoss: 3.5425\tLR: 0.000010\n",
      "Training Epoch: 4 [10752/45000]\tLoss: 3.6210\tLR: 0.000010\n",
      "Training Epoch: 4 [10768/45000]\tLoss: 3.5948\tLR: 0.000010\n",
      "Training Epoch: 4 [10784/45000]\tLoss: 3.6677\tLR: 0.000010\n",
      "Training Epoch: 4 [10800/45000]\tLoss: 3.6400\tLR: 0.000010\n",
      "Training Epoch: 4 [10816/45000]\tLoss: 3.6315\tLR: 0.000010\n",
      "Training Epoch: 4 [10832/45000]\tLoss: 3.5848\tLR: 0.000010\n",
      "Training Epoch: 4 [10848/45000]\tLoss: 3.5837\tLR: 0.000010\n",
      "Training Epoch: 4 [10864/45000]\tLoss: 3.6719\tLR: 0.000010\n",
      "Training Epoch: 4 [10880/45000]\tLoss: 3.6431\tLR: 0.000010\n",
      "Training Epoch: 4 [10896/45000]\tLoss: 3.6021\tLR: 0.000010\n",
      "Training Epoch: 4 [10912/45000]\tLoss: 3.5904\tLR: 0.000010\n",
      "Training Epoch: 4 [10928/45000]\tLoss: 3.5543\tLR: 0.000010\n",
      "Training Epoch: 4 [10944/45000]\tLoss: 3.6312\tLR: 0.000010\n",
      "Training Epoch: 4 [10960/45000]\tLoss: 3.5742\tLR: 0.000010\n",
      "Training Epoch: 4 [10976/45000]\tLoss: 3.5638\tLR: 0.000010\n",
      "Training Epoch: 4 [10992/45000]\tLoss: 3.6493\tLR: 0.000010\n",
      "Training Epoch: 4 [11008/45000]\tLoss: 3.5677\tLR: 0.000010\n",
      "Training Epoch: 4 [11024/45000]\tLoss: 3.6100\tLR: 0.000010\n",
      "Training Epoch: 4 [11040/45000]\tLoss: 3.6666\tLR: 0.000010\n",
      "Training Epoch: 4 [11056/45000]\tLoss: 3.5606\tLR: 0.000010\n",
      "Training Epoch: 4 [11072/45000]\tLoss: 3.5887\tLR: 0.000010\n",
      "Training Epoch: 4 [11088/45000]\tLoss: 3.5626\tLR: 0.000010\n",
      "Training Epoch: 4 [11104/45000]\tLoss: 3.7327\tLR: 0.000010\n",
      "Training Epoch: 4 [11120/45000]\tLoss: 3.6791\tLR: 0.000010\n",
      "Training Epoch: 4 [11136/45000]\tLoss: 3.6483\tLR: 0.000010\n",
      "Training Epoch: 4 [11152/45000]\tLoss: 3.6702\tLR: 0.000010\n",
      "Training Epoch: 4 [11168/45000]\tLoss: 3.5847\tLR: 0.000010\n",
      "Training Epoch: 4 [11184/45000]\tLoss: 3.6074\tLR: 0.000010\n",
      "Training Epoch: 4 [11200/45000]\tLoss: 3.6309\tLR: 0.000010\n",
      "Training Epoch: 4 [11216/45000]\tLoss: 3.6596\tLR: 0.000010\n",
      "Training Epoch: 4 [11232/45000]\tLoss: 3.5708\tLR: 0.000010\n",
      "Training Epoch: 4 [11248/45000]\tLoss: 3.6234\tLR: 0.000010\n",
      "Training Epoch: 4 [11264/45000]\tLoss: 3.6214\tLR: 0.000010\n",
      "Training Epoch: 4 [11280/45000]\tLoss: 3.5036\tLR: 0.000010\n",
      "Training Epoch: 4 [11296/45000]\tLoss: 3.6381\tLR: 0.000010\n",
      "Training Epoch: 4 [11312/45000]\tLoss: 3.5898\tLR: 0.000010\n",
      "Training Epoch: 4 [11328/45000]\tLoss: 3.6700\tLR: 0.000010\n",
      "Training Epoch: 4 [11344/45000]\tLoss: 3.5530\tLR: 0.000010\n",
      "Training Epoch: 4 [11360/45000]\tLoss: 3.6955\tLR: 0.000010\n",
      "Training Epoch: 4 [11376/45000]\tLoss: 3.6495\tLR: 0.000010\n",
      "Training Epoch: 4 [11392/45000]\tLoss: 3.6275\tLR: 0.000010\n",
      "Training Epoch: 4 [11408/45000]\tLoss: 3.6665\tLR: 0.000010\n",
      "Training Epoch: 4 [11424/45000]\tLoss: 3.6695\tLR: 0.000010\n",
      "Training Epoch: 4 [11440/45000]\tLoss: 3.5509\tLR: 0.000010\n",
      "Training Epoch: 4 [11456/45000]\tLoss: 3.6320\tLR: 0.000010\n",
      "Training Epoch: 4 [11472/45000]\tLoss: 3.5431\tLR: 0.000010\n",
      "Training Epoch: 4 [11488/45000]\tLoss: 3.6742\tLR: 0.000010\n",
      "Training Epoch: 4 [11504/45000]\tLoss: 3.6506\tLR: 0.000010\n",
      "Training Epoch: 4 [11520/45000]\tLoss: 3.7191\tLR: 0.000010\n",
      "Training Epoch: 4 [11536/45000]\tLoss: 3.7236\tLR: 0.000010\n",
      "Training Epoch: 4 [11552/45000]\tLoss: 3.5120\tLR: 0.000010\n",
      "Training Epoch: 4 [11568/45000]\tLoss: 3.6047\tLR: 0.000010\n",
      "Training Epoch: 4 [11584/45000]\tLoss: 3.7003\tLR: 0.000010\n",
      "Training Epoch: 4 [11600/45000]\tLoss: 3.5361\tLR: 0.000010\n",
      "Training Epoch: 4 [11616/45000]\tLoss: 3.6537\tLR: 0.000010\n",
      "Training Epoch: 4 [11632/45000]\tLoss: 3.6388\tLR: 0.000010\n",
      "Training Epoch: 4 [11648/45000]\tLoss: 3.5863\tLR: 0.000010\n",
      "Training Epoch: 4 [11664/45000]\tLoss: 3.7372\tLR: 0.000010\n",
      "Training Epoch: 4 [11680/45000]\tLoss: 3.5636\tLR: 0.000010\n",
      "Training Epoch: 4 [11696/45000]\tLoss: 3.6116\tLR: 0.000010\n",
      "Training Epoch: 4 [11712/45000]\tLoss: 3.5541\tLR: 0.000010\n",
      "Training Epoch: 4 [11728/45000]\tLoss: 3.6274\tLR: 0.000010\n",
      "Training Epoch: 4 [11744/45000]\tLoss: 3.6225\tLR: 0.000010\n",
      "Training Epoch: 4 [11760/45000]\tLoss: 3.5967\tLR: 0.000010\n",
      "Training Epoch: 4 [11776/45000]\tLoss: 3.6867\tLR: 0.000010\n",
      "Training Epoch: 4 [11792/45000]\tLoss: 3.6040\tLR: 0.000010\n",
      "Training Epoch: 4 [11808/45000]\tLoss: 3.6453\tLR: 0.000010\n",
      "Training Epoch: 4 [11824/45000]\tLoss: 3.6445\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [11840/45000]\tLoss: 3.5636\tLR: 0.000010\n",
      "Training Epoch: 4 [11856/45000]\tLoss: 3.5639\tLR: 0.000010\n",
      "Training Epoch: 4 [11872/45000]\tLoss: 3.6283\tLR: 0.000010\n",
      "Training Epoch: 4 [11888/45000]\tLoss: 3.5977\tLR: 0.000010\n",
      "Training Epoch: 4 [11904/45000]\tLoss: 3.5370\tLR: 0.000010\n",
      "Training Epoch: 4 [11920/45000]\tLoss: 3.5509\tLR: 0.000010\n",
      "Training Epoch: 4 [11936/45000]\tLoss: 3.6915\tLR: 0.000010\n",
      "Training Epoch: 4 [11952/45000]\tLoss: 3.6360\tLR: 0.000010\n",
      "Training Epoch: 4 [11968/45000]\tLoss: 3.5826\tLR: 0.000010\n",
      "Training Epoch: 4 [11984/45000]\tLoss: 3.6305\tLR: 0.000010\n",
      "Training Epoch: 4 [12000/45000]\tLoss: 3.6533\tLR: 0.000010\n",
      "Training Epoch: 4 [12016/45000]\tLoss: 3.6630\tLR: 0.000010\n",
      "Training Epoch: 4 [12032/45000]\tLoss: 3.7059\tLR: 0.000010\n",
      "Training Epoch: 4 [12048/45000]\tLoss: 3.6514\tLR: 0.000010\n",
      "Training Epoch: 4 [12064/45000]\tLoss: 3.6383\tLR: 0.000010\n",
      "Training Epoch: 4 [12080/45000]\tLoss: 3.5956\tLR: 0.000010\n",
      "Training Epoch: 4 [12096/45000]\tLoss: 3.6511\tLR: 0.000010\n",
      "Training Epoch: 4 [12112/45000]\tLoss: 3.6440\tLR: 0.000010\n",
      "Training Epoch: 4 [12128/45000]\tLoss: 3.6124\tLR: 0.000010\n",
      "Training Epoch: 4 [12144/45000]\tLoss: 3.4906\tLR: 0.000010\n",
      "Training Epoch: 4 [12160/45000]\tLoss: 3.5974\tLR: 0.000010\n",
      "Training Epoch: 4 [12176/45000]\tLoss: 3.5757\tLR: 0.000010\n",
      "Training Epoch: 4 [12192/45000]\tLoss: 3.5916\tLR: 0.000010\n",
      "Training Epoch: 4 [12208/45000]\tLoss: 3.6138\tLR: 0.000010\n",
      "Training Epoch: 4 [12224/45000]\tLoss: 3.5912\tLR: 0.000010\n",
      "Training Epoch: 4 [12240/45000]\tLoss: 3.5641\tLR: 0.000010\n",
      "Training Epoch: 4 [12256/45000]\tLoss: 3.5873\tLR: 0.000010\n",
      "Training Epoch: 4 [12272/45000]\tLoss: 3.6529\tLR: 0.000010\n",
      "Training Epoch: 4 [12288/45000]\tLoss: 3.4440\tLR: 0.000010\n",
      "Training Epoch: 4 [12304/45000]\tLoss: 3.6691\tLR: 0.000010\n",
      "Training Epoch: 4 [12320/45000]\tLoss: 3.5108\tLR: 0.000010\n",
      "Training Epoch: 4 [12336/45000]\tLoss: 3.6563\tLR: 0.000010\n",
      "Training Epoch: 4 [12352/45000]\tLoss: 3.5949\tLR: 0.000010\n",
      "Training Epoch: 4 [12368/45000]\tLoss: 3.6771\tLR: 0.000010\n",
      "Training Epoch: 4 [12384/45000]\tLoss: 3.6584\tLR: 0.000010\n",
      "Training Epoch: 4 [12400/45000]\tLoss: 3.5668\tLR: 0.000010\n",
      "Training Epoch: 4 [12416/45000]\tLoss: 3.5235\tLR: 0.000010\n",
      "Training Epoch: 4 [12432/45000]\tLoss: 3.5305\tLR: 0.000010\n",
      "Training Epoch: 4 [12448/45000]\tLoss: 3.5064\tLR: 0.000010\n",
      "Training Epoch: 4 [12464/45000]\tLoss: 3.5439\tLR: 0.000010\n",
      "Training Epoch: 4 [12480/45000]\tLoss: 3.6142\tLR: 0.000010\n",
      "Training Epoch: 4 [12496/45000]\tLoss: 3.5402\tLR: 0.000010\n",
      "Training Epoch: 4 [12512/45000]\tLoss: 3.6378\tLR: 0.000010\n",
      "Training Epoch: 4 [12528/45000]\tLoss: 3.5997\tLR: 0.000010\n",
      "Training Epoch: 4 [12544/45000]\tLoss: 3.6903\tLR: 0.000010\n",
      "Training Epoch: 4 [12560/45000]\tLoss: 3.5478\tLR: 0.000010\n",
      "Training Epoch: 4 [12576/45000]\tLoss: 3.6348\tLR: 0.000010\n",
      "Training Epoch: 4 [12592/45000]\tLoss: 3.5856\tLR: 0.000010\n",
      "Training Epoch: 4 [12608/45000]\tLoss: 3.5626\tLR: 0.000010\n",
      "Training Epoch: 4 [12624/45000]\tLoss: 3.6158\tLR: 0.000010\n",
      "Training Epoch: 4 [12640/45000]\tLoss: 3.5869\tLR: 0.000010\n",
      "Training Epoch: 4 [12656/45000]\tLoss: 3.4706\tLR: 0.000010\n",
      "Training Epoch: 4 [12672/45000]\tLoss: 3.6807\tLR: 0.000010\n",
      "Training Epoch: 4 [12688/45000]\tLoss: 3.6374\tLR: 0.000010\n",
      "Training Epoch: 4 [12704/45000]\tLoss: 3.5402\tLR: 0.000010\n",
      "Training Epoch: 4 [12720/45000]\tLoss: 3.6697\tLR: 0.000010\n",
      "Training Epoch: 4 [12736/45000]\tLoss: 3.7232\tLR: 0.000010\n",
      "Training Epoch: 4 [12752/45000]\tLoss: 3.6179\tLR: 0.000010\n",
      "Training Epoch: 4 [12768/45000]\tLoss: 3.6786\tLR: 0.000010\n",
      "Training Epoch: 4 [12784/45000]\tLoss: 3.6207\tLR: 0.000010\n",
      "Training Epoch: 4 [12800/45000]\tLoss: 3.5909\tLR: 0.000010\n",
      "Training Epoch: 4 [12816/45000]\tLoss: 3.8746\tLR: 0.000010\n",
      "Training Epoch: 4 [12832/45000]\tLoss: 3.5681\tLR: 0.000010\n",
      "Training Epoch: 4 [12848/45000]\tLoss: 3.6475\tLR: 0.000010\n",
      "Training Epoch: 4 [12864/45000]\tLoss: 3.6273\tLR: 0.000010\n",
      "Training Epoch: 4 [12880/45000]\tLoss: 3.6883\tLR: 0.000010\n",
      "Training Epoch: 4 [12896/45000]\tLoss: 3.6380\tLR: 0.000010\n",
      "Training Epoch: 4 [12912/45000]\tLoss: 3.6128\tLR: 0.000010\n",
      "Training Epoch: 4 [12928/45000]\tLoss: 3.7095\tLR: 0.000010\n",
      "Training Epoch: 4 [12944/45000]\tLoss: 3.7555\tLR: 0.000010\n",
      "Training Epoch: 4 [12960/45000]\tLoss: 3.5867\tLR: 0.000010\n",
      "Training Epoch: 4 [12976/45000]\tLoss: 3.6200\tLR: 0.000010\n",
      "Training Epoch: 4 [12992/45000]\tLoss: 3.6208\tLR: 0.000010\n",
      "Training Epoch: 4 [13008/45000]\tLoss: 3.7204\tLR: 0.000010\n",
      "Training Epoch: 4 [13024/45000]\tLoss: 3.6042\tLR: 0.000010\n",
      "Training Epoch: 4 [13040/45000]\tLoss: 3.4959\tLR: 0.000010\n",
      "Training Epoch: 4 [13056/45000]\tLoss: 3.5467\tLR: 0.000010\n",
      "Training Epoch: 4 [13072/45000]\tLoss: 3.5661\tLR: 0.000010\n",
      "Training Epoch: 4 [13088/45000]\tLoss: 3.6032\tLR: 0.000010\n",
      "Training Epoch: 4 [13104/45000]\tLoss: 3.6389\tLR: 0.000010\n",
      "Training Epoch: 4 [13120/45000]\tLoss: 3.6782\tLR: 0.000010\n",
      "Training Epoch: 4 [13136/45000]\tLoss: 3.6315\tLR: 0.000010\n",
      "Training Epoch: 4 [13152/45000]\tLoss: 3.6382\tLR: 0.000010\n",
      "Training Epoch: 4 [13168/45000]\tLoss: 3.6960\tLR: 0.000010\n",
      "Training Epoch: 4 [13184/45000]\tLoss: 3.6191\tLR: 0.000010\n",
      "Training Epoch: 4 [13200/45000]\tLoss: 3.5830\tLR: 0.000010\n",
      "Training Epoch: 4 [13216/45000]\tLoss: 3.6380\tLR: 0.000010\n",
      "Training Epoch: 4 [13232/45000]\tLoss: 3.5615\tLR: 0.000010\n",
      "Training Epoch: 4 [13248/45000]\tLoss: 3.6272\tLR: 0.000010\n",
      "Training Epoch: 4 [13264/45000]\tLoss: 3.6597\tLR: 0.000010\n",
      "Training Epoch: 4 [13280/45000]\tLoss: 3.4812\tLR: 0.000010\n",
      "Training Epoch: 4 [13296/45000]\tLoss: 3.5925\tLR: 0.000010\n",
      "Training Epoch: 4 [13312/45000]\tLoss: 3.6273\tLR: 0.000010\n",
      "Training Epoch: 4 [13328/45000]\tLoss: 3.6065\tLR: 0.000010\n",
      "Training Epoch: 4 [13344/45000]\tLoss: 3.5906\tLR: 0.000010\n",
      "Training Epoch: 4 [13360/45000]\tLoss: 3.5930\tLR: 0.000010\n",
      "Training Epoch: 4 [13376/45000]\tLoss: 3.5784\tLR: 0.000010\n",
      "Training Epoch: 4 [13392/45000]\tLoss: 3.6099\tLR: 0.000010\n",
      "Training Epoch: 4 [13408/45000]\tLoss: 3.7632\tLR: 0.000010\n",
      "Training Epoch: 4 [13424/45000]\tLoss: 3.6005\tLR: 0.000010\n",
      "Training Epoch: 4 [13440/45000]\tLoss: 3.5568\tLR: 0.000010\n",
      "Training Epoch: 4 [13456/45000]\tLoss: 3.5570\tLR: 0.000010\n",
      "Training Epoch: 4 [13472/45000]\tLoss: 3.5612\tLR: 0.000010\n",
      "Training Epoch: 4 [13488/45000]\tLoss: 3.5307\tLR: 0.000010\n",
      "Training Epoch: 4 [13504/45000]\tLoss: 3.6091\tLR: 0.000010\n",
      "Training Epoch: 4 [13520/45000]\tLoss: 3.7343\tLR: 0.000010\n",
      "Training Epoch: 4 [13536/45000]\tLoss: 3.4762\tLR: 0.000010\n",
      "Training Epoch: 4 [13552/45000]\tLoss: 3.5434\tLR: 0.000010\n",
      "Training Epoch: 4 [13568/45000]\tLoss: 3.5978\tLR: 0.000010\n",
      "Training Epoch: 4 [13584/45000]\tLoss: 3.6744\tLR: 0.000010\n",
      "Training Epoch: 4 [13600/45000]\tLoss: 3.7230\tLR: 0.000010\n",
      "Training Epoch: 4 [13616/45000]\tLoss: 3.7318\tLR: 0.000010\n",
      "Training Epoch: 4 [13632/45000]\tLoss: 3.5312\tLR: 0.000010\n",
      "Training Epoch: 4 [13648/45000]\tLoss: 3.4582\tLR: 0.000010\n",
      "Training Epoch: 4 [13664/45000]\tLoss: 3.5982\tLR: 0.000010\n",
      "Training Epoch: 4 [13680/45000]\tLoss: 3.6271\tLR: 0.000010\n",
      "Training Epoch: 4 [13696/45000]\tLoss: 3.5397\tLR: 0.000010\n",
      "Training Epoch: 4 [13712/45000]\tLoss: 3.6420\tLR: 0.000010\n",
      "Training Epoch: 4 [13728/45000]\tLoss: 3.5795\tLR: 0.000010\n",
      "Training Epoch: 4 [13744/45000]\tLoss: 3.6353\tLR: 0.000010\n",
      "Training Epoch: 4 [13760/45000]\tLoss: 3.5904\tLR: 0.000010\n",
      "Training Epoch: 4 [13776/45000]\tLoss: 3.5525\tLR: 0.000010\n",
      "Training Epoch: 4 [13792/45000]\tLoss: 3.6323\tLR: 0.000010\n",
      "Training Epoch: 4 [13808/45000]\tLoss: 3.6515\tLR: 0.000010\n",
      "Training Epoch: 4 [13824/45000]\tLoss: 3.5975\tLR: 0.000010\n",
      "Training Epoch: 4 [13840/45000]\tLoss: 3.6475\tLR: 0.000010\n",
      "Training Epoch: 4 [13856/45000]\tLoss: 3.5596\tLR: 0.000010\n",
      "Training Epoch: 4 [13872/45000]\tLoss: 3.5883\tLR: 0.000010\n",
      "Training Epoch: 4 [13888/45000]\tLoss: 3.5320\tLR: 0.000010\n",
      "Training Epoch: 4 [13904/45000]\tLoss: 3.5146\tLR: 0.000010\n",
      "Training Epoch: 4 [13920/45000]\tLoss: 3.6357\tLR: 0.000010\n",
      "Training Epoch: 4 [13936/45000]\tLoss: 3.5587\tLR: 0.000010\n",
      "Training Epoch: 4 [13952/45000]\tLoss: 3.4936\tLR: 0.000010\n",
      "Training Epoch: 4 [13968/45000]\tLoss: 3.6162\tLR: 0.000010\n",
      "Training Epoch: 4 [13984/45000]\tLoss: 3.6447\tLR: 0.000010\n",
      "Training Epoch: 4 [14000/45000]\tLoss: 3.7113\tLR: 0.000010\n",
      "Training Epoch: 4 [14016/45000]\tLoss: 3.6618\tLR: 0.000010\n",
      "Training Epoch: 4 [14032/45000]\tLoss: 3.6885\tLR: 0.000010\n",
      "Training Epoch: 4 [14048/45000]\tLoss: 3.6157\tLR: 0.000010\n",
      "Training Epoch: 4 [14064/45000]\tLoss: 3.6895\tLR: 0.000010\n",
      "Training Epoch: 4 [14080/45000]\tLoss: 3.4574\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [14096/45000]\tLoss: 3.6509\tLR: 0.000010\n",
      "Training Epoch: 4 [14112/45000]\tLoss: 3.7034\tLR: 0.000010\n",
      "Training Epoch: 4 [14128/45000]\tLoss: 3.4396\tLR: 0.000010\n",
      "Training Epoch: 4 [14144/45000]\tLoss: 3.6808\tLR: 0.000010\n",
      "Training Epoch: 4 [14160/45000]\tLoss: 3.6442\tLR: 0.000010\n",
      "Training Epoch: 4 [14176/45000]\tLoss: 3.5470\tLR: 0.000010\n",
      "Training Epoch: 4 [14192/45000]\tLoss: 3.5451\tLR: 0.000010\n",
      "Training Epoch: 4 [14208/45000]\tLoss: 3.6213\tLR: 0.000010\n",
      "Training Epoch: 4 [14224/45000]\tLoss: 3.6902\tLR: 0.000010\n",
      "Training Epoch: 4 [14240/45000]\tLoss: 3.5559\tLR: 0.000010\n",
      "Training Epoch: 4 [14256/45000]\tLoss: 3.5381\tLR: 0.000010\n",
      "Training Epoch: 4 [14272/45000]\tLoss: 3.5106\tLR: 0.000010\n",
      "Training Epoch: 4 [14288/45000]\tLoss: 3.7346\tLR: 0.000010\n",
      "Training Epoch: 4 [14304/45000]\tLoss: 3.6751\tLR: 0.000010\n",
      "Training Epoch: 4 [14320/45000]\tLoss: 3.5996\tLR: 0.000010\n",
      "Training Epoch: 4 [14336/45000]\tLoss: 3.6544\tLR: 0.000010\n",
      "Training Epoch: 4 [14352/45000]\tLoss: 3.5336\tLR: 0.000010\n",
      "Training Epoch: 4 [14368/45000]\tLoss: 3.5278\tLR: 0.000010\n",
      "Training Epoch: 4 [14384/45000]\tLoss: 3.4836\tLR: 0.000010\n",
      "Training Epoch: 4 [14400/45000]\tLoss: 3.6983\tLR: 0.000010\n",
      "Training Epoch: 4 [14416/45000]\tLoss: 3.6555\tLR: 0.000010\n",
      "Training Epoch: 4 [14432/45000]\tLoss: 3.6487\tLR: 0.000010\n",
      "Training Epoch: 4 [14448/45000]\tLoss: 3.6866\tLR: 0.000010\n",
      "Training Epoch: 4 [14464/45000]\tLoss: 3.6878\tLR: 0.000010\n",
      "Training Epoch: 4 [14480/45000]\tLoss: 3.6941\tLR: 0.000010\n",
      "Training Epoch: 4 [14496/45000]\tLoss: 3.4540\tLR: 0.000010\n",
      "Training Epoch: 4 [14512/45000]\tLoss: 3.5549\tLR: 0.000010\n",
      "Training Epoch: 4 [14528/45000]\tLoss: 3.5850\tLR: 0.000010\n",
      "Training Epoch: 4 [14544/45000]\tLoss: 3.5303\tLR: 0.000010\n",
      "Training Epoch: 4 [14560/45000]\tLoss: 3.6431\tLR: 0.000010\n",
      "Training Epoch: 4 [14576/45000]\tLoss: 3.7285\tLR: 0.000010\n",
      "Training Epoch: 4 [14592/45000]\tLoss: 3.6110\tLR: 0.000010\n",
      "Training Epoch: 4 [14608/45000]\tLoss: 3.6139\tLR: 0.000010\n",
      "Training Epoch: 4 [14624/45000]\tLoss: 3.6252\tLR: 0.000010\n",
      "Training Epoch: 4 [14640/45000]\tLoss: 3.5966\tLR: 0.000010\n",
      "Training Epoch: 4 [14656/45000]\tLoss: 3.5612\tLR: 0.000010\n",
      "Training Epoch: 4 [14672/45000]\tLoss: 3.6296\tLR: 0.000010\n",
      "Training Epoch: 4 [14688/45000]\tLoss: 3.6454\tLR: 0.000010\n",
      "Training Epoch: 4 [14704/45000]\tLoss: 3.5435\tLR: 0.000010\n",
      "Training Epoch: 4 [14720/45000]\tLoss: 3.5671\tLR: 0.000010\n",
      "Training Epoch: 4 [14736/45000]\tLoss: 3.6505\tLR: 0.000010\n",
      "Training Epoch: 4 [14752/45000]\tLoss: 3.5589\tLR: 0.000010\n",
      "Training Epoch: 4 [14768/45000]\tLoss: 3.5345\tLR: 0.000010\n",
      "Training Epoch: 4 [14784/45000]\tLoss: 3.7121\tLR: 0.000010\n",
      "Training Epoch: 4 [14800/45000]\tLoss: 3.6152\tLR: 0.000010\n",
      "Training Epoch: 4 [14816/45000]\tLoss: 3.6004\tLR: 0.000010\n",
      "Training Epoch: 4 [14832/45000]\tLoss: 3.6829\tLR: 0.000010\n",
      "Training Epoch: 4 [14848/45000]\tLoss: 3.4311\tLR: 0.000010\n",
      "Training Epoch: 4 [14864/45000]\tLoss: 3.5812\tLR: 0.000010\n",
      "Training Epoch: 4 [14880/45000]\tLoss: 3.7398\tLR: 0.000010\n",
      "Training Epoch: 4 [14896/45000]\tLoss: 3.6018\tLR: 0.000010\n",
      "Training Epoch: 4 [14912/45000]\tLoss: 3.4740\tLR: 0.000010\n",
      "Training Epoch: 4 [14928/45000]\tLoss: 3.5583\tLR: 0.000010\n",
      "Training Epoch: 4 [14944/45000]\tLoss: 3.5129\tLR: 0.000010\n",
      "Training Epoch: 4 [14960/45000]\tLoss: 3.6235\tLR: 0.000010\n",
      "Training Epoch: 4 [14976/45000]\tLoss: 3.6208\tLR: 0.000010\n",
      "Training Epoch: 4 [14992/45000]\tLoss: 3.5364\tLR: 0.000010\n",
      "Training Epoch: 4 [15008/45000]\tLoss: 3.5851\tLR: 0.000010\n",
      "Training Epoch: 4 [15024/45000]\tLoss: 3.6035\tLR: 0.000010\n",
      "Training Epoch: 4 [15040/45000]\tLoss: 3.6177\tLR: 0.000010\n",
      "Training Epoch: 4 [15056/45000]\tLoss: 3.6296\tLR: 0.000010\n",
      "Training Epoch: 4 [15072/45000]\tLoss: 3.5372\tLR: 0.000010\n",
      "Training Epoch: 4 [15088/45000]\tLoss: 3.5453\tLR: 0.000010\n",
      "Training Epoch: 4 [15104/45000]\tLoss: 3.7539\tLR: 0.000010\n",
      "Training Epoch: 4 [15120/45000]\tLoss: 3.5664\tLR: 0.000010\n",
      "Training Epoch: 4 [15136/45000]\tLoss: 3.6032\tLR: 0.000010\n",
      "Training Epoch: 4 [15152/45000]\tLoss: 3.6595\tLR: 0.000010\n",
      "Training Epoch: 4 [15168/45000]\tLoss: 3.5829\tLR: 0.000010\n",
      "Training Epoch: 4 [15184/45000]\tLoss: 3.6429\tLR: 0.000010\n",
      "Training Epoch: 4 [15200/45000]\tLoss: 3.6048\tLR: 0.000010\n",
      "Training Epoch: 4 [15216/45000]\tLoss: 3.5197\tLR: 0.000010\n",
      "Training Epoch: 4 [15232/45000]\tLoss: 3.6691\tLR: 0.000010\n",
      "Training Epoch: 4 [15248/45000]\tLoss: 3.5179\tLR: 0.000010\n",
      "Training Epoch: 4 [15264/45000]\tLoss: 3.7108\tLR: 0.000010\n",
      "Training Epoch: 4 [15280/45000]\tLoss: 3.6122\tLR: 0.000010\n",
      "Training Epoch: 4 [15296/45000]\tLoss: 3.7481\tLR: 0.000010\n",
      "Training Epoch: 4 [15312/45000]\tLoss: 3.6132\tLR: 0.000010\n",
      "Training Epoch: 4 [15328/45000]\tLoss: 3.5517\tLR: 0.000010\n",
      "Training Epoch: 4 [15344/45000]\tLoss: 3.5619\tLR: 0.000010\n",
      "Training Epoch: 4 [15360/45000]\tLoss: 3.5817\tLR: 0.000010\n",
      "Training Epoch: 4 [15376/45000]\tLoss: 3.6098\tLR: 0.000010\n",
      "Training Epoch: 4 [15392/45000]\tLoss: 3.6627\tLR: 0.000010\n",
      "Training Epoch: 4 [15408/45000]\tLoss: 3.5857\tLR: 0.000010\n",
      "Training Epoch: 4 [15424/45000]\tLoss: 3.5921\tLR: 0.000010\n",
      "Training Epoch: 4 [15440/45000]\tLoss: 3.5836\tLR: 0.000010\n",
      "Training Epoch: 4 [15456/45000]\tLoss: 3.5460\tLR: 0.000010\n",
      "Training Epoch: 4 [15472/45000]\tLoss: 3.5440\tLR: 0.000010\n",
      "Training Epoch: 4 [15488/45000]\tLoss: 3.7470\tLR: 0.000010\n",
      "Training Epoch: 4 [15504/45000]\tLoss: 3.6560\tLR: 0.000010\n",
      "Training Epoch: 4 [15520/45000]\tLoss: 3.6908\tLR: 0.000010\n",
      "Training Epoch: 4 [15536/45000]\tLoss: 3.6392\tLR: 0.000010\n",
      "Training Epoch: 4 [15552/45000]\tLoss: 3.5800\tLR: 0.000010\n",
      "Training Epoch: 4 [15568/45000]\tLoss: 3.5566\tLR: 0.000010\n",
      "Training Epoch: 4 [15584/45000]\tLoss: 3.6561\tLR: 0.000010\n",
      "Training Epoch: 4 [15600/45000]\tLoss: 3.6062\tLR: 0.000010\n",
      "Training Epoch: 4 [15616/45000]\tLoss: 3.6259\tLR: 0.000010\n",
      "Training Epoch: 4 [15632/45000]\tLoss: 3.7072\tLR: 0.000010\n",
      "Training Epoch: 4 [15648/45000]\tLoss: 3.6928\tLR: 0.000010\n",
      "Training Epoch: 4 [15664/45000]\tLoss: 3.7247\tLR: 0.000010\n",
      "Training Epoch: 4 [15680/45000]\tLoss: 3.6216\tLR: 0.000010\n",
      "Training Epoch: 4 [15696/45000]\tLoss: 3.6390\tLR: 0.000010\n",
      "Training Epoch: 4 [15712/45000]\tLoss: 3.7424\tLR: 0.000010\n",
      "Training Epoch: 4 [15728/45000]\tLoss: 3.5634\tLR: 0.000010\n",
      "Training Epoch: 4 [15744/45000]\tLoss: 3.6757\tLR: 0.000010\n",
      "Training Epoch: 4 [15760/45000]\tLoss: 3.6311\tLR: 0.000010\n",
      "Training Epoch: 4 [15776/45000]\tLoss: 3.5487\tLR: 0.000010\n",
      "Training Epoch: 4 [15792/45000]\tLoss: 3.4867\tLR: 0.000010\n",
      "Training Epoch: 4 [15808/45000]\tLoss: 3.5323\tLR: 0.000010\n",
      "Training Epoch: 4 [15824/45000]\tLoss: 3.5128\tLR: 0.000010\n",
      "Training Epoch: 4 [15840/45000]\tLoss: 3.6901\tLR: 0.000010\n",
      "Training Epoch: 4 [15856/45000]\tLoss: 3.5429\tLR: 0.000010\n",
      "Training Epoch: 4 [15872/45000]\tLoss: 3.5837\tLR: 0.000010\n",
      "Training Epoch: 4 [15888/45000]\tLoss: 3.5889\tLR: 0.000010\n",
      "Training Epoch: 4 [15904/45000]\tLoss: 3.5368\tLR: 0.000010\n",
      "Training Epoch: 4 [15920/45000]\tLoss: 3.6400\tLR: 0.000010\n",
      "Training Epoch: 4 [15936/45000]\tLoss: 3.6771\tLR: 0.000010\n",
      "Training Epoch: 4 [15952/45000]\tLoss: 3.5651\tLR: 0.000010\n",
      "Training Epoch: 4 [15968/45000]\tLoss: 3.6965\tLR: 0.000010\n",
      "Training Epoch: 4 [15984/45000]\tLoss: 3.5886\tLR: 0.000010\n",
      "Training Epoch: 4 [16000/45000]\tLoss: 3.6317\tLR: 0.000010\n",
      "Training Epoch: 4 [16016/45000]\tLoss: 3.6377\tLR: 0.000010\n",
      "Training Epoch: 4 [16032/45000]\tLoss: 3.6323\tLR: 0.000010\n",
      "Training Epoch: 4 [16048/45000]\tLoss: 3.5629\tLR: 0.000010\n",
      "Training Epoch: 4 [16064/45000]\tLoss: 3.6040\tLR: 0.000010\n",
      "Training Epoch: 4 [16080/45000]\tLoss: 3.4655\tLR: 0.000010\n",
      "Training Epoch: 4 [16096/45000]\tLoss: 3.5688\tLR: 0.000010\n",
      "Training Epoch: 4 [16112/45000]\tLoss: 3.5854\tLR: 0.000010\n",
      "Training Epoch: 4 [16128/45000]\tLoss: 3.4958\tLR: 0.000010\n",
      "Training Epoch: 4 [16144/45000]\tLoss: 3.6262\tLR: 0.000010\n",
      "Training Epoch: 4 [16160/45000]\tLoss: 3.6578\tLR: 0.000010\n",
      "Training Epoch: 4 [16176/45000]\tLoss: 3.6248\tLR: 0.000010\n",
      "Training Epoch: 4 [16192/45000]\tLoss: 3.6450\tLR: 0.000010\n",
      "Training Epoch: 4 [16208/45000]\tLoss: 3.5771\tLR: 0.000010\n",
      "Training Epoch: 4 [16224/45000]\tLoss: 3.6270\tLR: 0.000010\n",
      "Training Epoch: 4 [16240/45000]\tLoss: 3.5275\tLR: 0.000010\n",
      "Training Epoch: 4 [16256/45000]\tLoss: 3.5961\tLR: 0.000010\n",
      "Training Epoch: 4 [16272/45000]\tLoss: 3.6356\tLR: 0.000010\n",
      "Training Epoch: 4 [16288/45000]\tLoss: 3.5548\tLR: 0.000010\n",
      "Training Epoch: 4 [16304/45000]\tLoss: 3.6353\tLR: 0.000010\n",
      "Training Epoch: 4 [16320/45000]\tLoss: 3.6685\tLR: 0.000010\n",
      "Training Epoch: 4 [16336/45000]\tLoss: 3.5419\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [16352/45000]\tLoss: 3.6533\tLR: 0.000010\n",
      "Training Epoch: 4 [16368/45000]\tLoss: 3.4932\tLR: 0.000010\n",
      "Training Epoch: 4 [16384/45000]\tLoss: 3.6360\tLR: 0.000010\n",
      "Training Epoch: 4 [16400/45000]\tLoss: 3.5771\tLR: 0.000010\n",
      "Training Epoch: 4 [16416/45000]\tLoss: 3.6159\tLR: 0.000010\n",
      "Training Epoch: 4 [16432/45000]\tLoss: 3.6013\tLR: 0.000010\n",
      "Training Epoch: 4 [16448/45000]\tLoss: 3.6210\tLR: 0.000010\n",
      "Training Epoch: 4 [16464/45000]\tLoss: 3.6304\tLR: 0.000010\n",
      "Training Epoch: 4 [16480/45000]\tLoss: 3.5548\tLR: 0.000010\n",
      "Training Epoch: 4 [16496/45000]\tLoss: 3.6653\tLR: 0.000010\n",
      "Training Epoch: 4 [16512/45000]\tLoss: 3.6710\tLR: 0.000010\n",
      "Training Epoch: 4 [16528/45000]\tLoss: 3.5782\tLR: 0.000010\n",
      "Training Epoch: 4 [16544/45000]\tLoss: 3.6175\tLR: 0.000010\n",
      "Training Epoch: 4 [16560/45000]\tLoss: 3.6043\tLR: 0.000010\n",
      "Training Epoch: 4 [16576/45000]\tLoss: 3.4807\tLR: 0.000010\n",
      "Training Epoch: 4 [16592/45000]\tLoss: 3.6217\tLR: 0.000010\n",
      "Training Epoch: 4 [16608/45000]\tLoss: 3.6380\tLR: 0.000010\n",
      "Training Epoch: 4 [16624/45000]\tLoss: 3.5690\tLR: 0.000010\n",
      "Training Epoch: 4 [16640/45000]\tLoss: 3.7099\tLR: 0.000010\n",
      "Training Epoch: 4 [16656/45000]\tLoss: 3.5981\tLR: 0.000010\n",
      "Training Epoch: 4 [16672/45000]\tLoss: 3.5172\tLR: 0.000010\n",
      "Training Epoch: 4 [16688/45000]\tLoss: 3.5889\tLR: 0.000010\n",
      "Training Epoch: 4 [16704/45000]\tLoss: 3.7355\tLR: 0.000010\n",
      "Training Epoch: 4 [16720/45000]\tLoss: 3.5642\tLR: 0.000010\n",
      "Training Epoch: 4 [16736/45000]\tLoss: 3.6946\tLR: 0.000010\n",
      "Training Epoch: 4 [16752/45000]\tLoss: 3.6221\tLR: 0.000010\n",
      "Training Epoch: 4 [16768/45000]\tLoss: 3.6014\tLR: 0.000010\n",
      "Training Epoch: 4 [16784/45000]\tLoss: 3.5562\tLR: 0.000010\n",
      "Training Epoch: 4 [16800/45000]\tLoss: 3.5429\tLR: 0.000010\n",
      "Training Epoch: 4 [16816/45000]\tLoss: 3.5809\tLR: 0.000010\n",
      "Training Epoch: 4 [16832/45000]\tLoss: 3.6231\tLR: 0.000010\n",
      "Training Epoch: 4 [16848/45000]\tLoss: 3.6326\tLR: 0.000010\n",
      "Training Epoch: 4 [16864/45000]\tLoss: 3.6146\tLR: 0.000010\n",
      "Training Epoch: 4 [16880/45000]\tLoss: 3.5390\tLR: 0.000010\n",
      "Training Epoch: 4 [16896/45000]\tLoss: 3.6782\tLR: 0.000010\n",
      "Training Epoch: 4 [16912/45000]\tLoss: 3.7180\tLR: 0.000010\n",
      "Training Epoch: 4 [16928/45000]\tLoss: 3.6732\tLR: 0.000010\n",
      "Training Epoch: 4 [16944/45000]\tLoss: 3.5684\tLR: 0.000010\n",
      "Training Epoch: 4 [16960/45000]\tLoss: 3.6488\tLR: 0.000010\n",
      "Training Epoch: 4 [16976/45000]\tLoss: 3.6669\tLR: 0.000010\n",
      "Training Epoch: 4 [16992/45000]\tLoss: 3.6414\tLR: 0.000010\n",
      "Training Epoch: 4 [17008/45000]\tLoss: 3.5333\tLR: 0.000010\n",
      "Training Epoch: 4 [17024/45000]\tLoss: 3.5720\tLR: 0.000010\n",
      "Training Epoch: 4 [17040/45000]\tLoss: 3.6161\tLR: 0.000010\n",
      "Training Epoch: 4 [17056/45000]\tLoss: 3.4075\tLR: 0.000010\n",
      "Training Epoch: 4 [17072/45000]\tLoss: 3.5997\tLR: 0.000010\n",
      "Training Epoch: 4 [17088/45000]\tLoss: 3.5246\tLR: 0.000010\n",
      "Training Epoch: 4 [17104/45000]\tLoss: 3.5640\tLR: 0.000010\n",
      "Training Epoch: 4 [17120/45000]\tLoss: 3.6068\tLR: 0.000010\n",
      "Training Epoch: 4 [17136/45000]\tLoss: 3.5706\tLR: 0.000010\n",
      "Training Epoch: 4 [17152/45000]\tLoss: 3.5493\tLR: 0.000010\n",
      "Training Epoch: 4 [17168/45000]\tLoss: 3.7354\tLR: 0.000010\n",
      "Training Epoch: 4 [17184/45000]\tLoss: 3.6898\tLR: 0.000010\n",
      "Training Epoch: 4 [17200/45000]\tLoss: 3.5839\tLR: 0.000010\n",
      "Training Epoch: 4 [17216/45000]\tLoss: 3.5915\tLR: 0.000010\n",
      "Training Epoch: 4 [17232/45000]\tLoss: 3.6008\tLR: 0.000010\n",
      "Training Epoch: 4 [17248/45000]\tLoss: 3.6382\tLR: 0.000010\n",
      "Training Epoch: 4 [17264/45000]\tLoss: 3.6382\tLR: 0.000010\n",
      "Training Epoch: 4 [17280/45000]\tLoss: 3.5867\tLR: 0.000010\n",
      "Training Epoch: 4 [17296/45000]\tLoss: 3.6135\tLR: 0.000010\n",
      "Training Epoch: 4 [17312/45000]\tLoss: 3.5925\tLR: 0.000010\n",
      "Training Epoch: 4 [17328/45000]\tLoss: 3.6265\tLR: 0.000010\n",
      "Training Epoch: 4 [17344/45000]\tLoss: 3.6434\tLR: 0.000010\n",
      "Training Epoch: 4 [17360/45000]\tLoss: 3.5246\tLR: 0.000010\n",
      "Training Epoch: 4 [17376/45000]\tLoss: 3.6031\tLR: 0.000010\n",
      "Training Epoch: 4 [17392/45000]\tLoss: 3.5707\tLR: 0.000010\n",
      "Training Epoch: 4 [17408/45000]\tLoss: 3.4777\tLR: 0.000010\n",
      "Training Epoch: 4 [17424/45000]\tLoss: 3.5930\tLR: 0.000010\n",
      "Training Epoch: 4 [17440/45000]\tLoss: 3.6544\tLR: 0.000010\n",
      "Training Epoch: 4 [17456/45000]\tLoss: 3.6245\tLR: 0.000010\n",
      "Training Epoch: 4 [17472/45000]\tLoss: 3.6708\tLR: 0.000010\n",
      "Training Epoch: 4 [17488/45000]\tLoss: 3.5970\tLR: 0.000010\n",
      "Training Epoch: 4 [17504/45000]\tLoss: 3.6738\tLR: 0.000010\n",
      "Training Epoch: 4 [17520/45000]\tLoss: 3.5242\tLR: 0.000010\n",
      "Training Epoch: 4 [17536/45000]\tLoss: 3.5882\tLR: 0.000010\n",
      "Training Epoch: 4 [17552/45000]\tLoss: 3.7357\tLR: 0.000010\n",
      "Training Epoch: 4 [17568/45000]\tLoss: 3.6226\tLR: 0.000010\n",
      "Training Epoch: 4 [17584/45000]\tLoss: 3.7123\tLR: 0.000010\n",
      "Training Epoch: 4 [17600/45000]\tLoss: 3.6736\tLR: 0.000010\n",
      "Training Epoch: 4 [17616/45000]\tLoss: 3.6488\tLR: 0.000010\n",
      "Training Epoch: 4 [17632/45000]\tLoss: 3.6665\tLR: 0.000010\n",
      "Training Epoch: 4 [17648/45000]\tLoss: 3.6394\tLR: 0.000010\n",
      "Training Epoch: 4 [17664/45000]\tLoss: 3.5888\tLR: 0.000010\n",
      "Training Epoch: 4 [17680/45000]\tLoss: 3.6368\tLR: 0.000010\n",
      "Training Epoch: 4 [17696/45000]\tLoss: 3.5284\tLR: 0.000010\n",
      "Training Epoch: 4 [17712/45000]\tLoss: 3.6290\tLR: 0.000010\n",
      "Training Epoch: 4 [17728/45000]\tLoss: 3.5113\tLR: 0.000010\n",
      "Training Epoch: 4 [17744/45000]\tLoss: 3.5453\tLR: 0.000010\n",
      "Training Epoch: 4 [17760/45000]\tLoss: 3.7344\tLR: 0.000010\n",
      "Training Epoch: 4 [17776/45000]\tLoss: 3.6282\tLR: 0.000010\n",
      "Training Epoch: 4 [17792/45000]\tLoss: 3.7515\tLR: 0.000010\n",
      "Training Epoch: 4 [17808/45000]\tLoss: 3.6837\tLR: 0.000010\n",
      "Training Epoch: 4 [17824/45000]\tLoss: 3.7021\tLR: 0.000010\n",
      "Training Epoch: 4 [17840/45000]\tLoss: 3.5781\tLR: 0.000010\n",
      "Training Epoch: 4 [17856/45000]\tLoss: 3.6136\tLR: 0.000010\n",
      "Training Epoch: 4 [17872/45000]\tLoss: 3.6311\tLR: 0.000010\n",
      "Training Epoch: 4 [17888/45000]\tLoss: 3.4479\tLR: 0.000010\n",
      "Training Epoch: 4 [17904/45000]\tLoss: 3.5548\tLR: 0.000010\n",
      "Training Epoch: 4 [17920/45000]\tLoss: 3.5372\tLR: 0.000010\n",
      "Training Epoch: 4 [17936/45000]\tLoss: 3.7870\tLR: 0.000010\n",
      "Training Epoch: 4 [17952/45000]\tLoss: 3.5047\tLR: 0.000010\n",
      "Training Epoch: 4 [17968/45000]\tLoss: 3.5818\tLR: 0.000010\n",
      "Training Epoch: 4 [17984/45000]\tLoss: 3.7572\tLR: 0.000010\n",
      "Training Epoch: 4 [18000/45000]\tLoss: 3.6519\tLR: 0.000010\n",
      "Training Epoch: 4 [18016/45000]\tLoss: 3.6545\tLR: 0.000010\n",
      "Training Epoch: 4 [18032/45000]\tLoss: 3.6604\tLR: 0.000010\n",
      "Training Epoch: 4 [18048/45000]\tLoss: 3.7498\tLR: 0.000010\n",
      "Training Epoch: 4 [18064/45000]\tLoss: 3.6263\tLR: 0.000010\n",
      "Training Epoch: 4 [18080/45000]\tLoss: 3.6718\tLR: 0.000010\n",
      "Training Epoch: 4 [18096/45000]\tLoss: 3.6243\tLR: 0.000010\n",
      "Training Epoch: 4 [18112/45000]\tLoss: 3.6404\tLR: 0.000010\n",
      "Training Epoch: 4 [18128/45000]\tLoss: 3.5620\tLR: 0.000010\n",
      "Training Epoch: 4 [18144/45000]\tLoss: 3.5100\tLR: 0.000010\n",
      "Training Epoch: 4 [18160/45000]\tLoss: 3.4801\tLR: 0.000010\n",
      "Training Epoch: 4 [18176/45000]\tLoss: 3.7250\tLR: 0.000010\n",
      "Training Epoch: 4 [18192/45000]\tLoss: 3.5750\tLR: 0.000010\n",
      "Training Epoch: 4 [18208/45000]\tLoss: 3.7228\tLR: 0.000010\n",
      "Training Epoch: 4 [18224/45000]\tLoss: 3.5541\tLR: 0.000010\n",
      "Training Epoch: 4 [18240/45000]\tLoss: 3.7216\tLR: 0.000010\n",
      "Training Epoch: 4 [18256/45000]\tLoss: 3.5346\tLR: 0.000010\n",
      "Training Epoch: 4 [18272/45000]\tLoss: 3.4888\tLR: 0.000010\n",
      "Training Epoch: 4 [18288/45000]\tLoss: 3.7112\tLR: 0.000010\n",
      "Training Epoch: 4 [18304/45000]\tLoss: 3.5977\tLR: 0.000010\n",
      "Training Epoch: 4 [18320/45000]\tLoss: 3.6618\tLR: 0.000010\n",
      "Training Epoch: 4 [18336/45000]\tLoss: 3.7420\tLR: 0.000010\n",
      "Training Epoch: 4 [18352/45000]\tLoss: 3.6234\tLR: 0.000010\n",
      "Training Epoch: 4 [18368/45000]\tLoss: 3.5992\tLR: 0.000010\n",
      "Training Epoch: 4 [18384/45000]\tLoss: 3.6091\tLR: 0.000010\n",
      "Training Epoch: 4 [18400/45000]\tLoss: 3.6035\tLR: 0.000010\n",
      "Training Epoch: 4 [18416/45000]\tLoss: 3.7018\tLR: 0.000010\n",
      "Training Epoch: 4 [18432/45000]\tLoss: 3.6351\tLR: 0.000010\n",
      "Training Epoch: 4 [18448/45000]\tLoss: 3.6438\tLR: 0.000010\n",
      "Training Epoch: 4 [18464/45000]\tLoss: 3.5638\tLR: 0.000010\n",
      "Training Epoch: 4 [18480/45000]\tLoss: 3.5725\tLR: 0.000010\n",
      "Training Epoch: 4 [18496/45000]\tLoss: 3.7443\tLR: 0.000010\n",
      "Training Epoch: 4 [18512/45000]\tLoss: 3.6567\tLR: 0.000010\n",
      "Training Epoch: 4 [18528/45000]\tLoss: 3.5761\tLR: 0.000010\n",
      "Training Epoch: 4 [18544/45000]\tLoss: 3.6196\tLR: 0.000010\n",
      "Training Epoch: 4 [18560/45000]\tLoss: 3.8022\tLR: 0.000010\n",
      "Training Epoch: 4 [18576/45000]\tLoss: 3.6044\tLR: 0.000010\n",
      "Training Epoch: 4 [18592/45000]\tLoss: 3.6442\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [18608/45000]\tLoss: 3.6712\tLR: 0.000010\n",
      "Training Epoch: 4 [18624/45000]\tLoss: 3.6532\tLR: 0.000010\n",
      "Training Epoch: 4 [18640/45000]\tLoss: 3.7525\tLR: 0.000010\n",
      "Training Epoch: 4 [18656/45000]\tLoss: 3.5855\tLR: 0.000010\n",
      "Training Epoch: 4 [18672/45000]\tLoss: 3.6264\tLR: 0.000010\n",
      "Training Epoch: 4 [18688/45000]\tLoss: 3.7197\tLR: 0.000010\n",
      "Training Epoch: 4 [18704/45000]\tLoss: 3.6783\tLR: 0.000010\n",
      "Training Epoch: 4 [18720/45000]\tLoss: 3.5861\tLR: 0.000010\n",
      "Training Epoch: 4 [18736/45000]\tLoss: 3.6998\tLR: 0.000010\n",
      "Training Epoch: 4 [18752/45000]\tLoss: 3.6523\tLR: 0.000010\n",
      "Training Epoch: 4 [18768/45000]\tLoss: 3.6395\tLR: 0.000010\n",
      "Training Epoch: 4 [18784/45000]\tLoss: 3.7043\tLR: 0.000010\n",
      "Training Epoch: 4 [18800/45000]\tLoss: 3.6168\tLR: 0.000010\n",
      "Training Epoch: 4 [18816/45000]\tLoss: 3.6545\tLR: 0.000010\n",
      "Training Epoch: 4 [18832/45000]\tLoss: 3.5535\tLR: 0.000010\n",
      "Training Epoch: 4 [18848/45000]\tLoss: 3.6670\tLR: 0.000010\n",
      "Training Epoch: 4 [18864/45000]\tLoss: 3.6030\tLR: 0.000010\n",
      "Training Epoch: 4 [18880/45000]\tLoss: 3.6237\tLR: 0.000010\n",
      "Training Epoch: 4 [18896/45000]\tLoss: 3.5686\tLR: 0.000010\n",
      "Training Epoch: 4 [18912/45000]\tLoss: 3.5371\tLR: 0.000010\n",
      "Training Epoch: 4 [18928/45000]\tLoss: 3.5782\tLR: 0.000010\n",
      "Training Epoch: 4 [18944/45000]\tLoss: 3.6860\tLR: 0.000010\n",
      "Training Epoch: 4 [18960/45000]\tLoss: 3.7301\tLR: 0.000010\n",
      "Training Epoch: 4 [18976/45000]\tLoss: 3.5559\tLR: 0.000010\n",
      "Training Epoch: 4 [18992/45000]\tLoss: 3.7426\tLR: 0.000010\n",
      "Training Epoch: 4 [19008/45000]\tLoss: 3.5720\tLR: 0.000010\n",
      "Training Epoch: 4 [19024/45000]\tLoss: 3.5586\tLR: 0.000010\n",
      "Training Epoch: 4 [19040/45000]\tLoss: 3.6763\tLR: 0.000010\n",
      "Training Epoch: 4 [19056/45000]\tLoss: 3.6798\tLR: 0.000010\n",
      "Training Epoch: 4 [19072/45000]\tLoss: 3.5695\tLR: 0.000010\n",
      "Training Epoch: 4 [19088/45000]\tLoss: 3.7183\tLR: 0.000010\n",
      "Training Epoch: 4 [19104/45000]\tLoss: 3.6246\tLR: 0.000010\n",
      "Training Epoch: 4 [19120/45000]\tLoss: 3.4729\tLR: 0.000010\n",
      "Training Epoch: 4 [19136/45000]\tLoss: 3.5976\tLR: 0.000010\n",
      "Training Epoch: 4 [19152/45000]\tLoss: 3.5395\tLR: 0.000010\n",
      "Training Epoch: 4 [19168/45000]\tLoss: 3.3932\tLR: 0.000010\n",
      "Training Epoch: 4 [19184/45000]\tLoss: 3.5053\tLR: 0.000010\n",
      "Training Epoch: 4 [19200/45000]\tLoss: 3.5991\tLR: 0.000010\n",
      "Training Epoch: 4 [19216/45000]\tLoss: 3.7987\tLR: 0.000010\n",
      "Training Epoch: 4 [19232/45000]\tLoss: 3.5869\tLR: 0.000010\n",
      "Training Epoch: 4 [19248/45000]\tLoss: 3.5870\tLR: 0.000010\n",
      "Training Epoch: 4 [19264/45000]\tLoss: 3.6201\tLR: 0.000010\n",
      "Training Epoch: 4 [19280/45000]\tLoss: 3.5481\tLR: 0.000010\n",
      "Training Epoch: 4 [19296/45000]\tLoss: 3.5429\tLR: 0.000010\n",
      "Training Epoch: 4 [19312/45000]\tLoss: 3.6258\tLR: 0.000010\n",
      "Training Epoch: 4 [19328/45000]\tLoss: 3.6479\tLR: 0.000010\n",
      "Training Epoch: 4 [19344/45000]\tLoss: 3.5943\tLR: 0.000010\n",
      "Training Epoch: 4 [19360/45000]\tLoss: 3.5276\tLR: 0.000010\n",
      "Training Epoch: 4 [19376/45000]\tLoss: 3.6243\tLR: 0.000010\n",
      "Training Epoch: 4 [19392/45000]\tLoss: 3.6725\tLR: 0.000010\n",
      "Training Epoch: 4 [19408/45000]\tLoss: 3.6637\tLR: 0.000010\n",
      "Training Epoch: 4 [19424/45000]\tLoss: 3.6971\tLR: 0.000010\n",
      "Training Epoch: 4 [19440/45000]\tLoss: 3.6363\tLR: 0.000010\n",
      "Training Epoch: 4 [19456/45000]\tLoss: 3.4586\tLR: 0.000010\n",
      "Training Epoch: 4 [19472/45000]\tLoss: 3.7161\tLR: 0.000010\n",
      "Training Epoch: 4 [19488/45000]\tLoss: 3.5968\tLR: 0.000010\n",
      "Training Epoch: 4 [19504/45000]\tLoss: 3.6352\tLR: 0.000010\n",
      "Training Epoch: 4 [19520/45000]\tLoss: 3.5887\tLR: 0.000010\n",
      "Training Epoch: 4 [19536/45000]\tLoss: 3.6796\tLR: 0.000010\n",
      "Training Epoch: 4 [19552/45000]\tLoss: 3.6315\tLR: 0.000010\n",
      "Training Epoch: 4 [19568/45000]\tLoss: 3.6217\tLR: 0.000010\n",
      "Training Epoch: 4 [19584/45000]\tLoss: 3.5532\tLR: 0.000010\n",
      "Training Epoch: 4 [19600/45000]\tLoss: 3.5866\tLR: 0.000010\n",
      "Training Epoch: 4 [19616/45000]\tLoss: 3.5818\tLR: 0.000010\n",
      "Training Epoch: 4 [19632/45000]\tLoss: 3.7208\tLR: 0.000010\n",
      "Training Epoch: 4 [19648/45000]\tLoss: 3.5528\tLR: 0.000010\n",
      "Training Epoch: 4 [19664/45000]\tLoss: 3.6548\tLR: 0.000010\n",
      "Training Epoch: 4 [19680/45000]\tLoss: 3.5429\tLR: 0.000010\n",
      "Training Epoch: 4 [19696/45000]\tLoss: 3.7080\tLR: 0.000010\n",
      "Training Epoch: 4 [19712/45000]\tLoss: 3.6318\tLR: 0.000010\n",
      "Training Epoch: 4 [19728/45000]\tLoss: 3.5496\tLR: 0.000010\n",
      "Training Epoch: 4 [19744/45000]\tLoss: 3.6181\tLR: 0.000010\n",
      "Training Epoch: 4 [19760/45000]\tLoss: 3.6899\tLR: 0.000010\n",
      "Training Epoch: 4 [19776/45000]\tLoss: 3.7324\tLR: 0.000010\n",
      "Training Epoch: 4 [19792/45000]\tLoss: 3.6390\tLR: 0.000010\n",
      "Training Epoch: 4 [19808/45000]\tLoss: 3.6513\tLR: 0.000010\n",
      "Training Epoch: 4 [19824/45000]\tLoss: 3.6030\tLR: 0.000010\n",
      "Training Epoch: 4 [19840/45000]\tLoss: 3.6392\tLR: 0.000010\n",
      "Training Epoch: 4 [19856/45000]\tLoss: 3.6214\tLR: 0.000010\n",
      "Training Epoch: 4 [19872/45000]\tLoss: 3.7232\tLR: 0.000010\n",
      "Training Epoch: 4 [19888/45000]\tLoss: 3.5701\tLR: 0.000010\n",
      "Training Epoch: 4 [19904/45000]\tLoss: 3.5811\tLR: 0.000010\n",
      "Training Epoch: 4 [19920/45000]\tLoss: 3.6180\tLR: 0.000010\n",
      "Training Epoch: 4 [19936/45000]\tLoss: 3.6198\tLR: 0.000010\n",
      "Training Epoch: 4 [19952/45000]\tLoss: 3.7172\tLR: 0.000010\n",
      "Training Epoch: 4 [19968/45000]\tLoss: 3.6597\tLR: 0.000010\n",
      "Training Epoch: 4 [19984/45000]\tLoss: 3.5471\tLR: 0.000010\n",
      "Training Epoch: 4 [20000/45000]\tLoss: 3.6045\tLR: 0.000010\n",
      "Training Epoch: 4 [20016/45000]\tLoss: 3.5823\tLR: 0.000010\n",
      "Training Epoch: 4 [20032/45000]\tLoss: 3.7371\tLR: 0.000010\n",
      "Training Epoch: 4 [20048/45000]\tLoss: 3.6046\tLR: 0.000010\n",
      "Training Epoch: 4 [20064/45000]\tLoss: 3.6672\tLR: 0.000010\n",
      "Training Epoch: 4 [20080/45000]\tLoss: 3.6600\tLR: 0.000010\n",
      "Training Epoch: 4 [20096/45000]\tLoss: 3.6092\tLR: 0.000010\n",
      "Training Epoch: 4 [20112/45000]\tLoss: 3.5627\tLR: 0.000010\n",
      "Training Epoch: 4 [20128/45000]\tLoss: 3.5394\tLR: 0.000010\n",
      "Training Epoch: 4 [20144/45000]\tLoss: 3.5602\tLR: 0.000010\n",
      "Training Epoch: 4 [20160/45000]\tLoss: 3.4919\tLR: 0.000010\n",
      "Training Epoch: 4 [20176/45000]\tLoss: 3.6268\tLR: 0.000010\n",
      "Training Epoch: 4 [20192/45000]\tLoss: 3.6543\tLR: 0.000010\n",
      "Training Epoch: 4 [20208/45000]\tLoss: 3.6151\tLR: 0.000010\n",
      "Training Epoch: 4 [20224/45000]\tLoss: 3.6980\tLR: 0.000010\n",
      "Training Epoch: 4 [20240/45000]\tLoss: 3.5797\tLR: 0.000010\n",
      "Training Epoch: 4 [20256/45000]\tLoss: 3.5175\tLR: 0.000010\n",
      "Training Epoch: 4 [20272/45000]\tLoss: 3.6724\tLR: 0.000010\n",
      "Training Epoch: 4 [20288/45000]\tLoss: 3.4768\tLR: 0.000010\n",
      "Training Epoch: 4 [20304/45000]\tLoss: 3.5607\tLR: 0.000010\n",
      "Training Epoch: 4 [20320/45000]\tLoss: 3.5874\tLR: 0.000010\n",
      "Training Epoch: 4 [20336/45000]\tLoss: 3.6695\tLR: 0.000010\n",
      "Training Epoch: 4 [20352/45000]\tLoss: 3.6099\tLR: 0.000010\n",
      "Training Epoch: 4 [20368/45000]\tLoss: 3.5188\tLR: 0.000010\n",
      "Training Epoch: 4 [20384/45000]\tLoss: 3.5953\tLR: 0.000010\n",
      "Training Epoch: 4 [20400/45000]\tLoss: 3.5988\tLR: 0.000010\n",
      "Training Epoch: 4 [20416/45000]\tLoss: 3.5880\tLR: 0.000010\n",
      "Training Epoch: 4 [20432/45000]\tLoss: 3.5405\tLR: 0.000010\n",
      "Training Epoch: 4 [20448/45000]\tLoss: 3.5751\tLR: 0.000010\n",
      "Training Epoch: 4 [20464/45000]\tLoss: 3.6727\tLR: 0.000010\n",
      "Training Epoch: 4 [20480/45000]\tLoss: 3.5963\tLR: 0.000010\n",
      "Training Epoch: 4 [20496/45000]\tLoss: 3.6069\tLR: 0.000010\n",
      "Training Epoch: 4 [20512/45000]\tLoss: 3.6784\tLR: 0.000010\n",
      "Training Epoch: 4 [20528/45000]\tLoss: 3.6116\tLR: 0.000010\n",
      "Training Epoch: 4 [20544/45000]\tLoss: 3.5974\tLR: 0.000010\n",
      "Training Epoch: 4 [20560/45000]\tLoss: 3.6104\tLR: 0.000010\n",
      "Training Epoch: 4 [20576/45000]\tLoss: 3.6578\tLR: 0.000010\n",
      "Training Epoch: 4 [20592/45000]\tLoss: 3.5970\tLR: 0.000010\n",
      "Training Epoch: 4 [20608/45000]\tLoss: 3.5554\tLR: 0.000010\n",
      "Training Epoch: 4 [20624/45000]\tLoss: 3.6779\tLR: 0.000010\n",
      "Training Epoch: 4 [20640/45000]\tLoss: 3.6163\tLR: 0.000010\n",
      "Training Epoch: 4 [20656/45000]\tLoss: 3.6618\tLR: 0.000010\n",
      "Training Epoch: 4 [20672/45000]\tLoss: 3.6068\tLR: 0.000010\n",
      "Training Epoch: 4 [20688/45000]\tLoss: 3.6837\tLR: 0.000010\n",
      "Training Epoch: 4 [20704/45000]\tLoss: 3.7118\tLR: 0.000010\n",
      "Training Epoch: 4 [20720/45000]\tLoss: 3.6077\tLR: 0.000010\n",
      "Training Epoch: 4 [20736/45000]\tLoss: 3.5272\tLR: 0.000010\n",
      "Training Epoch: 4 [20752/45000]\tLoss: 3.5787\tLR: 0.000010\n",
      "Training Epoch: 4 [20768/45000]\tLoss: 3.6061\tLR: 0.000010\n",
      "Training Epoch: 4 [20784/45000]\tLoss: 3.7415\tLR: 0.000010\n",
      "Training Epoch: 4 [20800/45000]\tLoss: 3.6462\tLR: 0.000010\n",
      "Training Epoch: 4 [20816/45000]\tLoss: 3.5228\tLR: 0.000010\n",
      "Training Epoch: 4 [20832/45000]\tLoss: 3.6080\tLR: 0.000010\n",
      "Training Epoch: 4 [20848/45000]\tLoss: 3.6184\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [20864/45000]\tLoss: 3.5890\tLR: 0.000010\n",
      "Training Epoch: 4 [20880/45000]\tLoss: 3.6296\tLR: 0.000010\n",
      "Training Epoch: 4 [20896/45000]\tLoss: 3.5714\tLR: 0.000010\n",
      "Training Epoch: 4 [20912/45000]\tLoss: 3.5860\tLR: 0.000010\n",
      "Training Epoch: 4 [20928/45000]\tLoss: 3.6695\tLR: 0.000010\n",
      "Training Epoch: 4 [20944/45000]\tLoss: 3.6241\tLR: 0.000010\n",
      "Training Epoch: 4 [20960/45000]\tLoss: 3.6265\tLR: 0.000010\n",
      "Training Epoch: 4 [20976/45000]\tLoss: 3.6021\tLR: 0.000010\n",
      "Training Epoch: 4 [20992/45000]\tLoss: 3.6070\tLR: 0.000010\n",
      "Training Epoch: 4 [21008/45000]\tLoss: 3.6044\tLR: 0.000010\n",
      "Training Epoch: 4 [21024/45000]\tLoss: 3.5646\tLR: 0.000010\n",
      "Training Epoch: 4 [21040/45000]\tLoss: 3.5872\tLR: 0.000010\n",
      "Training Epoch: 4 [21056/45000]\tLoss: 3.5318\tLR: 0.000010\n",
      "Training Epoch: 4 [21072/45000]\tLoss: 3.5713\tLR: 0.000010\n",
      "Training Epoch: 4 [21088/45000]\tLoss: 3.5816\tLR: 0.000010\n",
      "Training Epoch: 4 [21104/45000]\tLoss: 3.6326\tLR: 0.000010\n",
      "Training Epoch: 4 [21120/45000]\tLoss: 3.6588\tLR: 0.000010\n",
      "Training Epoch: 4 [21136/45000]\tLoss: 3.4559\tLR: 0.000010\n",
      "Training Epoch: 4 [21152/45000]\tLoss: 3.6005\tLR: 0.000010\n",
      "Training Epoch: 4 [21168/45000]\tLoss: 3.6327\tLR: 0.000010\n",
      "Training Epoch: 4 [21184/45000]\tLoss: 3.5479\tLR: 0.000010\n",
      "Training Epoch: 4 [21200/45000]\tLoss: 3.5446\tLR: 0.000010\n",
      "Training Epoch: 4 [21216/45000]\tLoss: 3.6398\tLR: 0.000010\n",
      "Training Epoch: 4 [21232/45000]\tLoss: 3.6254\tLR: 0.000010\n",
      "Training Epoch: 4 [21248/45000]\tLoss: 3.5965\tLR: 0.000010\n",
      "Training Epoch: 4 [21264/45000]\tLoss: 3.5788\tLR: 0.000010\n",
      "Training Epoch: 4 [21280/45000]\tLoss: 3.6560\tLR: 0.000010\n",
      "Training Epoch: 4 [21296/45000]\tLoss: 3.5985\tLR: 0.000010\n",
      "Training Epoch: 4 [21312/45000]\tLoss: 3.6716\tLR: 0.000010\n",
      "Training Epoch: 4 [21328/45000]\tLoss: 3.6372\tLR: 0.000010\n",
      "Training Epoch: 4 [21344/45000]\tLoss: 3.5338\tLR: 0.000010\n",
      "Training Epoch: 4 [21360/45000]\tLoss: 3.5811\tLR: 0.000010\n",
      "Training Epoch: 4 [21376/45000]\tLoss: 3.5724\tLR: 0.000010\n",
      "Training Epoch: 4 [21392/45000]\tLoss: 3.5515\tLR: 0.000010\n",
      "Training Epoch: 4 [21408/45000]\tLoss: 3.6140\tLR: 0.000010\n",
      "Training Epoch: 4 [21424/45000]\tLoss: 3.6915\tLR: 0.000010\n",
      "Training Epoch: 4 [21440/45000]\tLoss: 3.5551\tLR: 0.000010\n",
      "Training Epoch: 4 [21456/45000]\tLoss: 3.5754\tLR: 0.000010\n",
      "Training Epoch: 4 [21472/45000]\tLoss: 3.6070\tLR: 0.000010\n",
      "Training Epoch: 4 [21488/45000]\tLoss: 3.6080\tLR: 0.000010\n",
      "Training Epoch: 4 [21504/45000]\tLoss: 3.4628\tLR: 0.000010\n",
      "Training Epoch: 4 [21520/45000]\tLoss: 3.6509\tLR: 0.000010\n",
      "Training Epoch: 4 [21536/45000]\tLoss: 3.6186\tLR: 0.000010\n",
      "Training Epoch: 4 [21552/45000]\tLoss: 3.5874\tLR: 0.000010\n",
      "Training Epoch: 4 [21568/45000]\tLoss: 3.6378\tLR: 0.000010\n",
      "Training Epoch: 4 [21584/45000]\tLoss: 3.6483\tLR: 0.000010\n",
      "Training Epoch: 4 [21600/45000]\tLoss: 3.6002\tLR: 0.000010\n",
      "Training Epoch: 4 [21616/45000]\tLoss: 3.6106\tLR: 0.000010\n",
      "Training Epoch: 4 [21632/45000]\tLoss: 3.5942\tLR: 0.000010\n",
      "Training Epoch: 4 [21648/45000]\tLoss: 3.6303\tLR: 0.000010\n",
      "Training Epoch: 4 [21664/45000]\tLoss: 3.5101\tLR: 0.000010\n",
      "Training Epoch: 4 [21680/45000]\tLoss: 3.5823\tLR: 0.000010\n",
      "Training Epoch: 4 [21696/45000]\tLoss: 3.7012\tLR: 0.000010\n",
      "Training Epoch: 4 [21712/45000]\tLoss: 3.4315\tLR: 0.000010\n",
      "Training Epoch: 4 [21728/45000]\tLoss: 3.5223\tLR: 0.000010\n",
      "Training Epoch: 4 [21744/45000]\tLoss: 3.6535\tLR: 0.000010\n",
      "Training Epoch: 4 [21760/45000]\tLoss: 3.6623\tLR: 0.000010\n",
      "Training Epoch: 4 [21776/45000]\tLoss: 3.5929\tLR: 0.000010\n",
      "Training Epoch: 4 [21792/45000]\tLoss: 3.6243\tLR: 0.000010\n",
      "Training Epoch: 4 [21808/45000]\tLoss: 3.4862\tLR: 0.000010\n",
      "Training Epoch: 4 [21824/45000]\tLoss: 3.5956\tLR: 0.000010\n",
      "Training Epoch: 4 [21840/45000]\tLoss: 3.5271\tLR: 0.000010\n",
      "Training Epoch: 4 [21856/45000]\tLoss: 3.6165\tLR: 0.000010\n",
      "Training Epoch: 4 [21872/45000]\tLoss: 3.5383\tLR: 0.000010\n",
      "Training Epoch: 4 [21888/45000]\tLoss: 3.5727\tLR: 0.000010\n",
      "Training Epoch: 4 [21904/45000]\tLoss: 3.5760\tLR: 0.000010\n",
      "Training Epoch: 4 [21920/45000]\tLoss: 3.6304\tLR: 0.000010\n",
      "Training Epoch: 4 [21936/45000]\tLoss: 3.6090\tLR: 0.000010\n",
      "Training Epoch: 4 [21952/45000]\tLoss: 3.5966\tLR: 0.000010\n",
      "Training Epoch: 4 [21968/45000]\tLoss: 3.6467\tLR: 0.000010\n",
      "Training Epoch: 4 [21984/45000]\tLoss: 3.6824\tLR: 0.000010\n",
      "Training Epoch: 4 [22000/45000]\tLoss: 3.5496\tLR: 0.000010\n",
      "Training Epoch: 4 [22016/45000]\tLoss: 3.5399\tLR: 0.000010\n",
      "Training Epoch: 4 [22032/45000]\tLoss: 3.6506\tLR: 0.000010\n",
      "Training Epoch: 4 [22048/45000]\tLoss: 3.6406\tLR: 0.000010\n",
      "Training Epoch: 4 [22064/45000]\tLoss: 3.6907\tLR: 0.000010\n",
      "Training Epoch: 4 [22080/45000]\tLoss: 3.5629\tLR: 0.000010\n",
      "Training Epoch: 4 [22096/45000]\tLoss: 3.7889\tLR: 0.000010\n",
      "Training Epoch: 4 [22112/45000]\tLoss: 3.8074\tLR: 0.000010\n",
      "Training Epoch: 4 [22128/45000]\tLoss: 3.6099\tLR: 0.000010\n",
      "Training Epoch: 4 [22144/45000]\tLoss: 3.7172\tLR: 0.000010\n",
      "Training Epoch: 4 [22160/45000]\tLoss: 3.5395\tLR: 0.000010\n",
      "Training Epoch: 4 [22176/45000]\tLoss: 3.6499\tLR: 0.000010\n",
      "Training Epoch: 4 [22192/45000]\tLoss: 3.5159\tLR: 0.000010\n",
      "Training Epoch: 4 [22208/45000]\tLoss: 3.5410\tLR: 0.000010\n",
      "Training Epoch: 4 [22224/45000]\tLoss: 3.6813\tLR: 0.000010\n",
      "Training Epoch: 4 [22240/45000]\tLoss: 3.5787\tLR: 0.000010\n",
      "Training Epoch: 4 [22256/45000]\tLoss: 3.6071\tLR: 0.000010\n",
      "Training Epoch: 4 [22272/45000]\tLoss: 3.6249\tLR: 0.000010\n",
      "Training Epoch: 4 [22288/45000]\tLoss: 3.5758\tLR: 0.000010\n",
      "Training Epoch: 4 [22304/45000]\tLoss: 3.5819\tLR: 0.000010\n",
      "Training Epoch: 4 [22320/45000]\tLoss: 3.6447\tLR: 0.000010\n",
      "Training Epoch: 4 [22336/45000]\tLoss: 3.7094\tLR: 0.000010\n",
      "Training Epoch: 4 [22352/45000]\tLoss: 3.5285\tLR: 0.000010\n",
      "Training Epoch: 4 [22368/45000]\tLoss: 3.5795\tLR: 0.000010\n",
      "Training Epoch: 4 [22384/45000]\tLoss: 3.6757\tLR: 0.000010\n",
      "Training Epoch: 4 [22400/45000]\tLoss: 3.6584\tLR: 0.000010\n",
      "Training Epoch: 4 [22416/45000]\tLoss: 3.4722\tLR: 0.000010\n",
      "Training Epoch: 4 [22432/45000]\tLoss: 3.6146\tLR: 0.000010\n",
      "Training Epoch: 4 [22448/45000]\tLoss: 3.6577\tLR: 0.000010\n",
      "Training Epoch: 4 [22464/45000]\tLoss: 3.4822\tLR: 0.000010\n",
      "Training Epoch: 4 [22480/45000]\tLoss: 3.6826\tLR: 0.000010\n",
      "Training Epoch: 4 [22496/45000]\tLoss: 3.6661\tLR: 0.000010\n",
      "Training Epoch: 4 [22512/45000]\tLoss: 3.5976\tLR: 0.000010\n",
      "Training Epoch: 4 [22528/45000]\tLoss: 3.5767\tLR: 0.000010\n",
      "Training Epoch: 4 [22544/45000]\tLoss: 3.4967\tLR: 0.000010\n",
      "Training Epoch: 4 [22560/45000]\tLoss: 3.6166\tLR: 0.000010\n",
      "Training Epoch: 4 [22576/45000]\tLoss: 3.5156\tLR: 0.000010\n",
      "Training Epoch: 4 [22592/45000]\tLoss: 3.6138\tLR: 0.000010\n",
      "Training Epoch: 4 [22608/45000]\tLoss: 3.6556\tLR: 0.000010\n",
      "Training Epoch: 4 [22624/45000]\tLoss: 3.6213\tLR: 0.000010\n",
      "Training Epoch: 4 [22640/45000]\tLoss: 3.6955\tLR: 0.000010\n",
      "Training Epoch: 4 [22656/45000]\tLoss: 3.5812\tLR: 0.000010\n",
      "Training Epoch: 4 [22672/45000]\tLoss: 3.5772\tLR: 0.000010\n",
      "Training Epoch: 4 [22688/45000]\tLoss: 3.5456\tLR: 0.000010\n",
      "Training Epoch: 4 [22704/45000]\tLoss: 3.6549\tLR: 0.000010\n",
      "Training Epoch: 4 [22720/45000]\tLoss: 3.5503\tLR: 0.000010\n",
      "Training Epoch: 4 [22736/45000]\tLoss: 3.6573\tLR: 0.000010\n",
      "Training Epoch: 4 [22752/45000]\tLoss: 3.6316\tLR: 0.000010\n",
      "Training Epoch: 4 [22768/45000]\tLoss: 3.5983\tLR: 0.000010\n",
      "Training Epoch: 4 [22784/45000]\tLoss: 3.5949\tLR: 0.000010\n",
      "Training Epoch: 4 [22800/45000]\tLoss: 3.4639\tLR: 0.000010\n",
      "Training Epoch: 4 [22816/45000]\tLoss: 3.4738\tLR: 0.000010\n",
      "Training Epoch: 4 [22832/45000]\tLoss: 3.5252\tLR: 0.000010\n",
      "Training Epoch: 4 [22848/45000]\tLoss: 3.6587\tLR: 0.000010\n",
      "Training Epoch: 4 [22864/45000]\tLoss: 3.6002\tLR: 0.000010\n",
      "Training Epoch: 4 [22880/45000]\tLoss: 3.5392\tLR: 0.000010\n",
      "Training Epoch: 4 [22896/45000]\tLoss: 3.5687\tLR: 0.000010\n",
      "Training Epoch: 4 [22912/45000]\tLoss: 3.5969\tLR: 0.000010\n",
      "Training Epoch: 4 [22928/45000]\tLoss: 3.5137\tLR: 0.000010\n",
      "Training Epoch: 4 [22944/45000]\tLoss: 3.7096\tLR: 0.000010\n",
      "Training Epoch: 4 [22960/45000]\tLoss: 3.6014\tLR: 0.000010\n",
      "Training Epoch: 4 [22976/45000]\tLoss: 3.4721\tLR: 0.000010\n",
      "Training Epoch: 4 [22992/45000]\tLoss: 3.6018\tLR: 0.000010\n",
      "Training Epoch: 4 [23008/45000]\tLoss: 3.6582\tLR: 0.000010\n",
      "Training Epoch: 4 [23024/45000]\tLoss: 3.6629\tLR: 0.000010\n",
      "Training Epoch: 4 [23040/45000]\tLoss: 3.6110\tLR: 0.000010\n",
      "Training Epoch: 4 [23056/45000]\tLoss: 3.6426\tLR: 0.000010\n",
      "Training Epoch: 4 [23072/45000]\tLoss: 3.5393\tLR: 0.000010\n",
      "Training Epoch: 4 [23088/45000]\tLoss: 3.5179\tLR: 0.000010\n",
      "Training Epoch: 4 [23104/45000]\tLoss: 3.5939\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [23120/45000]\tLoss: 3.4354\tLR: 0.000010\n",
      "Training Epoch: 4 [23136/45000]\tLoss: 3.6717\tLR: 0.000010\n",
      "Training Epoch: 4 [23152/45000]\tLoss: 3.5474\tLR: 0.000010\n",
      "Training Epoch: 4 [23168/45000]\tLoss: 3.6576\tLR: 0.000010\n",
      "Training Epoch: 4 [23184/45000]\tLoss: 3.5991\tLR: 0.000010\n",
      "Training Epoch: 4 [23200/45000]\tLoss: 3.6948\tLR: 0.000010\n",
      "Training Epoch: 4 [23216/45000]\tLoss: 3.6303\tLR: 0.000010\n",
      "Training Epoch: 4 [23232/45000]\tLoss: 3.5500\tLR: 0.000010\n",
      "Training Epoch: 4 [23248/45000]\tLoss: 3.6761\tLR: 0.000010\n",
      "Training Epoch: 4 [23264/45000]\tLoss: 3.5799\tLR: 0.000010\n",
      "Training Epoch: 4 [23280/45000]\tLoss: 3.5785\tLR: 0.000010\n",
      "Training Epoch: 4 [23296/45000]\tLoss: 3.6830\tLR: 0.000010\n",
      "Training Epoch: 4 [23312/45000]\tLoss: 3.4520\tLR: 0.000010\n",
      "Training Epoch: 4 [23328/45000]\tLoss: 3.5376\tLR: 0.000010\n",
      "Training Epoch: 4 [23344/45000]\tLoss: 3.5329\tLR: 0.000010\n",
      "Training Epoch: 4 [23360/45000]\tLoss: 3.6844\tLR: 0.000010\n",
      "Training Epoch: 4 [23376/45000]\tLoss: 3.4779\tLR: 0.000010\n",
      "Training Epoch: 4 [23392/45000]\tLoss: 3.5430\tLR: 0.000010\n",
      "Training Epoch: 4 [23408/45000]\tLoss: 3.6018\tLR: 0.000010\n",
      "Training Epoch: 4 [23424/45000]\tLoss: 3.6504\tLR: 0.000010\n",
      "Training Epoch: 4 [23440/45000]\tLoss: 3.5833\tLR: 0.000010\n",
      "Training Epoch: 4 [23456/45000]\tLoss: 3.5472\tLR: 0.000010\n",
      "Training Epoch: 4 [23472/45000]\tLoss: 3.5958\tLR: 0.000010\n",
      "Training Epoch: 4 [23488/45000]\tLoss: 3.6459\tLR: 0.000010\n",
      "Training Epoch: 4 [23504/45000]\tLoss: 3.5653\tLR: 0.000010\n",
      "Training Epoch: 4 [23520/45000]\tLoss: 3.6660\tLR: 0.000010\n",
      "Training Epoch: 4 [23536/45000]\tLoss: 3.6612\tLR: 0.000010\n",
      "Training Epoch: 4 [23552/45000]\tLoss: 3.5897\tLR: 0.000010\n",
      "Training Epoch: 4 [23568/45000]\tLoss: 3.6173\tLR: 0.000010\n",
      "Training Epoch: 4 [23584/45000]\tLoss: 3.6579\tLR: 0.000010\n",
      "Training Epoch: 4 [23600/45000]\tLoss: 3.5936\tLR: 0.000010\n",
      "Training Epoch: 4 [23616/45000]\tLoss: 3.6770\tLR: 0.000010\n",
      "Training Epoch: 4 [23632/45000]\tLoss: 3.4584\tLR: 0.000010\n",
      "Training Epoch: 4 [23648/45000]\tLoss: 3.7035\tLR: 0.000010\n",
      "Training Epoch: 4 [23664/45000]\tLoss: 3.6054\tLR: 0.000010\n",
      "Training Epoch: 4 [23680/45000]\tLoss: 3.4572\tLR: 0.000010\n",
      "Training Epoch: 4 [23696/45000]\tLoss: 3.6305\tLR: 0.000010\n",
      "Training Epoch: 4 [23712/45000]\tLoss: 3.6295\tLR: 0.000010\n",
      "Training Epoch: 4 [23728/45000]\tLoss: 3.5560\tLR: 0.000010\n",
      "Training Epoch: 4 [23744/45000]\tLoss: 3.4526\tLR: 0.000010\n",
      "Training Epoch: 4 [23760/45000]\tLoss: 3.6403\tLR: 0.000010\n",
      "Training Epoch: 4 [23776/45000]\tLoss: 3.7168\tLR: 0.000010\n",
      "Training Epoch: 4 [23792/45000]\tLoss: 3.6642\tLR: 0.000010\n",
      "Training Epoch: 4 [23808/45000]\tLoss: 3.5890\tLR: 0.000010\n",
      "Training Epoch: 4 [23824/45000]\tLoss: 3.6454\tLR: 0.000010\n",
      "Training Epoch: 4 [23840/45000]\tLoss: 3.6711\tLR: 0.000010\n",
      "Training Epoch: 4 [23856/45000]\tLoss: 3.7014\tLR: 0.000010\n",
      "Training Epoch: 4 [23872/45000]\tLoss: 3.6310\tLR: 0.000010\n",
      "Training Epoch: 4 [23888/45000]\tLoss: 3.5612\tLR: 0.000010\n",
      "Training Epoch: 4 [23904/45000]\tLoss: 3.5286\tLR: 0.000010\n",
      "Training Epoch: 4 [23920/45000]\tLoss: 3.6091\tLR: 0.000010\n",
      "Training Epoch: 4 [23936/45000]\tLoss: 3.4671\tLR: 0.000010\n",
      "Training Epoch: 4 [23952/45000]\tLoss: 3.6251\tLR: 0.000010\n",
      "Training Epoch: 4 [23968/45000]\tLoss: 3.6390\tLR: 0.000010\n",
      "Training Epoch: 4 [23984/45000]\tLoss: 3.5813\tLR: 0.000010\n",
      "Training Epoch: 4 [24000/45000]\tLoss: 3.7862\tLR: 0.000010\n",
      "Training Epoch: 4 [24016/45000]\tLoss: 3.6395\tLR: 0.000010\n",
      "Training Epoch: 4 [24032/45000]\tLoss: 3.6175\tLR: 0.000010\n",
      "Training Epoch: 4 [24048/45000]\tLoss: 3.4989\tLR: 0.000010\n",
      "Training Epoch: 4 [24064/45000]\tLoss: 3.5451\tLR: 0.000010\n",
      "Training Epoch: 4 [24080/45000]\tLoss: 3.6491\tLR: 0.000010\n",
      "Training Epoch: 4 [24096/45000]\tLoss: 3.6551\tLR: 0.000010\n",
      "Training Epoch: 4 [24112/45000]\tLoss: 3.5088\tLR: 0.000010\n",
      "Training Epoch: 4 [24128/45000]\tLoss: 3.6398\tLR: 0.000010\n",
      "Training Epoch: 4 [24144/45000]\tLoss: 3.3661\tLR: 0.000010\n",
      "Training Epoch: 4 [24160/45000]\tLoss: 3.5603\tLR: 0.000010\n",
      "Training Epoch: 4 [24176/45000]\tLoss: 3.5502\tLR: 0.000010\n",
      "Training Epoch: 4 [24192/45000]\tLoss: 3.5954\tLR: 0.000010\n",
      "Training Epoch: 4 [24208/45000]\tLoss: 3.6316\tLR: 0.000010\n",
      "Training Epoch: 4 [24224/45000]\tLoss: 3.6466\tLR: 0.000010\n",
      "Training Epoch: 4 [24240/45000]\tLoss: 3.4868\tLR: 0.000010\n",
      "Training Epoch: 4 [24256/45000]\tLoss: 3.6105\tLR: 0.000010\n",
      "Training Epoch: 4 [24272/45000]\tLoss: 3.6258\tLR: 0.000010\n",
      "Training Epoch: 4 [24288/45000]\tLoss: 3.6955\tLR: 0.000010\n",
      "Training Epoch: 4 [24304/45000]\tLoss: 3.6214\tLR: 0.000010\n",
      "Training Epoch: 4 [24320/45000]\tLoss: 3.5587\tLR: 0.000010\n",
      "Training Epoch: 4 [24336/45000]\tLoss: 3.6973\tLR: 0.000010\n",
      "Training Epoch: 4 [24352/45000]\tLoss: 3.5656\tLR: 0.000010\n",
      "Training Epoch: 4 [24368/45000]\tLoss: 3.5459\tLR: 0.000010\n",
      "Training Epoch: 4 [24384/45000]\tLoss: 3.6881\tLR: 0.000010\n",
      "Training Epoch: 4 [24400/45000]\tLoss: 3.5503\tLR: 0.000010\n",
      "Training Epoch: 4 [24416/45000]\tLoss: 3.5020\tLR: 0.000010\n",
      "Training Epoch: 4 [24432/45000]\tLoss: 3.6621\tLR: 0.000010\n",
      "Training Epoch: 4 [24448/45000]\tLoss: 3.6307\tLR: 0.000010\n",
      "Training Epoch: 4 [24464/45000]\tLoss: 3.5718\tLR: 0.000010\n",
      "Training Epoch: 4 [24480/45000]\tLoss: 3.5777\tLR: 0.000010\n",
      "Training Epoch: 4 [24496/45000]\tLoss: 3.5863\tLR: 0.000010\n",
      "Training Epoch: 4 [24512/45000]\tLoss: 3.6403\tLR: 0.000010\n",
      "Training Epoch: 4 [24528/45000]\tLoss: 3.5264\tLR: 0.000010\n",
      "Training Epoch: 4 [24544/45000]\tLoss: 3.6138\tLR: 0.000010\n",
      "Training Epoch: 4 [24560/45000]\tLoss: 3.5162\tLR: 0.000010\n",
      "Training Epoch: 4 [24576/45000]\tLoss: 3.5819\tLR: 0.000010\n",
      "Training Epoch: 4 [24592/45000]\tLoss: 3.6854\tLR: 0.000010\n",
      "Training Epoch: 4 [24608/45000]\tLoss: 3.5376\tLR: 0.000010\n",
      "Training Epoch: 4 [24624/45000]\tLoss: 3.4443\tLR: 0.000010\n",
      "Training Epoch: 4 [24640/45000]\tLoss: 3.6085\tLR: 0.000010\n",
      "Training Epoch: 4 [24656/45000]\tLoss: 3.5478\tLR: 0.000010\n",
      "Training Epoch: 4 [24672/45000]\tLoss: 3.4923\tLR: 0.000010\n",
      "Training Epoch: 4 [24688/45000]\tLoss: 3.6084\tLR: 0.000010\n",
      "Training Epoch: 4 [24704/45000]\tLoss: 3.6348\tLR: 0.000010\n",
      "Training Epoch: 4 [24720/45000]\tLoss: 3.4923\tLR: 0.000010\n",
      "Training Epoch: 4 [24736/45000]\tLoss: 3.5835\tLR: 0.000010\n",
      "Training Epoch: 4 [24752/45000]\tLoss: 3.5761\tLR: 0.000010\n",
      "Training Epoch: 4 [24768/45000]\tLoss: 3.6100\tLR: 0.000010\n",
      "Training Epoch: 4 [24784/45000]\tLoss: 3.5867\tLR: 0.000010\n",
      "Training Epoch: 4 [24800/45000]\tLoss: 3.5919\tLR: 0.000010\n",
      "Training Epoch: 4 [24816/45000]\tLoss: 3.6224\tLR: 0.000010\n",
      "Training Epoch: 4 [24832/45000]\tLoss: 3.6437\tLR: 0.000010\n",
      "Training Epoch: 4 [24848/45000]\tLoss: 3.7360\tLR: 0.000010\n",
      "Training Epoch: 4 [24864/45000]\tLoss: 3.5553\tLR: 0.000010\n",
      "Training Epoch: 4 [24880/45000]\tLoss: 3.6984\tLR: 0.000010\n",
      "Training Epoch: 4 [24896/45000]\tLoss: 3.6209\tLR: 0.000010\n",
      "Training Epoch: 4 [24912/45000]\tLoss: 3.5093\tLR: 0.000010\n",
      "Training Epoch: 4 [24928/45000]\tLoss: 3.6689\tLR: 0.000010\n",
      "Training Epoch: 4 [24944/45000]\tLoss: 3.5023\tLR: 0.000010\n",
      "Training Epoch: 4 [24960/45000]\tLoss: 3.5807\tLR: 0.000010\n",
      "Training Epoch: 4 [24976/45000]\tLoss: 3.7366\tLR: 0.000010\n",
      "Training Epoch: 4 [24992/45000]\tLoss: 3.6895\tLR: 0.000010\n",
      "Training Epoch: 4 [25008/45000]\tLoss: 3.6432\tLR: 0.000010\n",
      "Training Epoch: 4 [25024/45000]\tLoss: 3.6853\tLR: 0.000010\n",
      "Training Epoch: 4 [25040/45000]\tLoss: 3.6248\tLR: 0.000010\n",
      "Training Epoch: 4 [25056/45000]\tLoss: 3.5074\tLR: 0.000010\n",
      "Training Epoch: 4 [25072/45000]\tLoss: 3.6056\tLR: 0.000010\n",
      "Training Epoch: 4 [25088/45000]\tLoss: 3.5796\tLR: 0.000010\n",
      "Training Epoch: 4 [25104/45000]\tLoss: 3.6273\tLR: 0.000010\n",
      "Training Epoch: 4 [25120/45000]\tLoss: 3.6566\tLR: 0.000010\n",
      "Training Epoch: 4 [25136/45000]\tLoss: 3.6310\tLR: 0.000010\n",
      "Training Epoch: 4 [25152/45000]\tLoss: 3.7324\tLR: 0.000010\n",
      "Training Epoch: 4 [25168/45000]\tLoss: 3.5400\tLR: 0.000010\n",
      "Training Epoch: 4 [25184/45000]\tLoss: 3.5501\tLR: 0.000010\n",
      "Training Epoch: 4 [25200/45000]\tLoss: 3.5557\tLR: 0.000010\n",
      "Training Epoch: 4 [25216/45000]\tLoss: 3.6168\tLR: 0.000010\n",
      "Training Epoch: 4 [25232/45000]\tLoss: 3.6772\tLR: 0.000010\n",
      "Training Epoch: 4 [25248/45000]\tLoss: 3.6827\tLR: 0.000010\n",
      "Training Epoch: 4 [25264/45000]\tLoss: 3.5840\tLR: 0.000010\n",
      "Training Epoch: 4 [25280/45000]\tLoss: 3.5783\tLR: 0.000010\n",
      "Training Epoch: 4 [25296/45000]\tLoss: 3.6218\tLR: 0.000010\n",
      "Training Epoch: 4 [25312/45000]\tLoss: 3.5470\tLR: 0.000010\n",
      "Training Epoch: 4 [25328/45000]\tLoss: 3.6358\tLR: 0.000010\n",
      "Training Epoch: 4 [25344/45000]\tLoss: 3.6248\tLR: 0.000010\n",
      "Training Epoch: 4 [25360/45000]\tLoss: 3.5662\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [25376/45000]\tLoss: 3.5193\tLR: 0.000010\n",
      "Training Epoch: 4 [25392/45000]\tLoss: 3.5384\tLR: 0.000010\n",
      "Training Epoch: 4 [25408/45000]\tLoss: 3.6858\tLR: 0.000010\n",
      "Training Epoch: 4 [25424/45000]\tLoss: 3.5539\tLR: 0.000010\n",
      "Training Epoch: 4 [25440/45000]\tLoss: 3.6270\tLR: 0.000010\n",
      "Training Epoch: 4 [25456/45000]\tLoss: 3.5561\tLR: 0.000010\n",
      "Training Epoch: 4 [25472/45000]\tLoss: 3.6875\tLR: 0.000010\n",
      "Training Epoch: 4 [25488/45000]\tLoss: 3.6968\tLR: 0.000010\n",
      "Training Epoch: 4 [25504/45000]\tLoss: 3.5853\tLR: 0.000010\n",
      "Training Epoch: 4 [25520/45000]\tLoss: 3.5647\tLR: 0.000010\n",
      "Training Epoch: 4 [25536/45000]\tLoss: 3.6462\tLR: 0.000010\n",
      "Training Epoch: 4 [25552/45000]\tLoss: 3.5837\tLR: 0.000010\n",
      "Training Epoch: 4 [25568/45000]\tLoss: 3.5776\tLR: 0.000010\n",
      "Training Epoch: 4 [25584/45000]\tLoss: 3.6084\tLR: 0.000010\n",
      "Training Epoch: 4 [25600/45000]\tLoss: 3.6071\tLR: 0.000010\n",
      "Training Epoch: 4 [25616/45000]\tLoss: 3.5840\tLR: 0.000010\n",
      "Training Epoch: 4 [25632/45000]\tLoss: 3.5330\tLR: 0.000010\n",
      "Training Epoch: 4 [25648/45000]\tLoss: 3.6356\tLR: 0.000010\n",
      "Training Epoch: 4 [25664/45000]\tLoss: 3.5246\tLR: 0.000010\n",
      "Training Epoch: 4 [25680/45000]\tLoss: 3.6082\tLR: 0.000010\n",
      "Training Epoch: 4 [25696/45000]\tLoss: 3.5903\tLR: 0.000010\n",
      "Training Epoch: 4 [25712/45000]\tLoss: 3.5595\tLR: 0.000010\n",
      "Training Epoch: 4 [25728/45000]\tLoss: 3.5246\tLR: 0.000010\n",
      "Training Epoch: 4 [25744/45000]\tLoss: 3.6569\tLR: 0.000010\n",
      "Training Epoch: 4 [25760/45000]\tLoss: 3.5877\tLR: 0.000010\n",
      "Training Epoch: 4 [25776/45000]\tLoss: 3.6725\tLR: 0.000010\n",
      "Training Epoch: 4 [25792/45000]\tLoss: 3.5722\tLR: 0.000010\n",
      "Training Epoch: 4 [25808/45000]\tLoss: 3.5690\tLR: 0.000010\n",
      "Training Epoch: 4 [25824/45000]\tLoss: 3.5859\tLR: 0.000010\n",
      "Training Epoch: 4 [25840/45000]\tLoss: 3.5525\tLR: 0.000010\n",
      "Training Epoch: 4 [25856/45000]\tLoss: 3.6684\tLR: 0.000010\n",
      "Training Epoch: 4 [25872/45000]\tLoss: 3.5967\tLR: 0.000010\n",
      "Training Epoch: 4 [25888/45000]\tLoss: 3.5314\tLR: 0.000010\n",
      "Training Epoch: 4 [25904/45000]\tLoss: 3.5373\tLR: 0.000010\n",
      "Training Epoch: 4 [25920/45000]\tLoss: 3.5760\tLR: 0.000010\n",
      "Training Epoch: 4 [25936/45000]\tLoss: 3.5710\tLR: 0.000010\n",
      "Training Epoch: 4 [25952/45000]\tLoss: 3.6173\tLR: 0.000010\n",
      "Training Epoch: 4 [25968/45000]\tLoss: 3.7078\tLR: 0.000010\n",
      "Training Epoch: 4 [25984/45000]\tLoss: 3.4914\tLR: 0.000010\n",
      "Training Epoch: 4 [26000/45000]\tLoss: 3.5437\tLR: 0.000010\n",
      "Training Epoch: 4 [26016/45000]\tLoss: 3.6788\tLR: 0.000010\n",
      "Training Epoch: 4 [26032/45000]\tLoss: 3.5847\tLR: 0.000010\n",
      "Training Epoch: 4 [26048/45000]\tLoss: 3.6403\tLR: 0.000010\n",
      "Training Epoch: 4 [26064/45000]\tLoss: 3.6487\tLR: 0.000010\n",
      "Training Epoch: 4 [26080/45000]\tLoss: 3.5900\tLR: 0.000010\n",
      "Training Epoch: 4 [26096/45000]\tLoss: 3.5525\tLR: 0.000010\n",
      "Training Epoch: 4 [26112/45000]\tLoss: 3.5667\tLR: 0.000010\n",
      "Training Epoch: 4 [26128/45000]\tLoss: 3.6510\tLR: 0.000010\n",
      "Training Epoch: 4 [26144/45000]\tLoss: 3.5897\tLR: 0.000010\n",
      "Training Epoch: 4 [26160/45000]\tLoss: 3.5535\tLR: 0.000010\n",
      "Training Epoch: 4 [26176/45000]\tLoss: 3.7216\tLR: 0.000010\n",
      "Training Epoch: 4 [26192/45000]\tLoss: 3.4964\tLR: 0.000010\n",
      "Training Epoch: 4 [26208/45000]\tLoss: 3.7411\tLR: 0.000010\n",
      "Training Epoch: 4 [26224/45000]\tLoss: 3.5952\tLR: 0.000010\n",
      "Training Epoch: 4 [26240/45000]\tLoss: 3.5841\tLR: 0.000010\n",
      "Training Epoch: 4 [26256/45000]\tLoss: 3.5312\tLR: 0.000010\n",
      "Training Epoch: 4 [26272/45000]\tLoss: 3.5740\tLR: 0.000010\n",
      "Training Epoch: 4 [26288/45000]\tLoss: 3.6849\tLR: 0.000010\n",
      "Training Epoch: 4 [26304/45000]\tLoss: 3.6222\tLR: 0.000010\n",
      "Training Epoch: 4 [26320/45000]\tLoss: 3.5305\tLR: 0.000010\n",
      "Training Epoch: 4 [26336/45000]\tLoss: 3.6800\tLR: 0.000010\n",
      "Training Epoch: 4 [26352/45000]\tLoss: 3.5727\tLR: 0.000010\n",
      "Training Epoch: 4 [26368/45000]\tLoss: 3.6541\tLR: 0.000010\n",
      "Training Epoch: 4 [26384/45000]\tLoss: 3.5112\tLR: 0.000010\n",
      "Training Epoch: 4 [26400/45000]\tLoss: 3.6377\tLR: 0.000010\n",
      "Training Epoch: 4 [26416/45000]\tLoss: 3.5700\tLR: 0.000010\n",
      "Training Epoch: 4 [26432/45000]\tLoss: 3.6019\tLR: 0.000010\n",
      "Training Epoch: 4 [26448/45000]\tLoss: 3.5553\tLR: 0.000010\n",
      "Training Epoch: 4 [26464/45000]\tLoss: 3.6406\tLR: 0.000010\n",
      "Training Epoch: 4 [26480/45000]\tLoss: 3.6350\tLR: 0.000010\n",
      "Training Epoch: 4 [26496/45000]\tLoss: 3.4642\tLR: 0.000010\n",
      "Training Epoch: 4 [26512/45000]\tLoss: 3.6200\tLR: 0.000010\n",
      "Training Epoch: 4 [26528/45000]\tLoss: 3.6558\tLR: 0.000010\n",
      "Training Epoch: 4 [26544/45000]\tLoss: 3.4865\tLR: 0.000010\n",
      "Training Epoch: 4 [26560/45000]\tLoss: 3.5731\tLR: 0.000010\n",
      "Training Epoch: 4 [26576/45000]\tLoss: 3.5606\tLR: 0.000010\n",
      "Training Epoch: 4 [26592/45000]\tLoss: 3.5653\tLR: 0.000010\n",
      "Training Epoch: 4 [26608/45000]\tLoss: 3.5185\tLR: 0.000010\n",
      "Training Epoch: 4 [26624/45000]\tLoss: 3.5284\tLR: 0.000010\n",
      "Training Epoch: 4 [26640/45000]\tLoss: 3.5798\tLR: 0.000010\n",
      "Training Epoch: 4 [26656/45000]\tLoss: 3.5944\tLR: 0.000010\n",
      "Training Epoch: 4 [26672/45000]\tLoss: 3.6646\tLR: 0.000010\n",
      "Training Epoch: 4 [26688/45000]\tLoss: 3.6067\tLR: 0.000010\n",
      "Training Epoch: 4 [26704/45000]\tLoss: 3.6401\tLR: 0.000010\n",
      "Training Epoch: 4 [26720/45000]\tLoss: 3.6357\tLR: 0.000010\n",
      "Training Epoch: 4 [26736/45000]\tLoss: 3.4934\tLR: 0.000010\n",
      "Training Epoch: 4 [26752/45000]\tLoss: 3.6330\tLR: 0.000010\n",
      "Training Epoch: 4 [26768/45000]\tLoss: 3.5602\tLR: 0.000010\n",
      "Training Epoch: 4 [26784/45000]\tLoss: 3.5826\tLR: 0.000010\n",
      "Training Epoch: 4 [26800/45000]\tLoss: 3.5770\tLR: 0.000010\n",
      "Training Epoch: 4 [26816/45000]\tLoss: 3.5803\tLR: 0.000010\n",
      "Training Epoch: 4 [26832/45000]\tLoss: 3.5523\tLR: 0.000010\n",
      "Training Epoch: 4 [26848/45000]\tLoss: 3.6638\tLR: 0.000010\n",
      "Training Epoch: 4 [26864/45000]\tLoss: 3.6534\tLR: 0.000010\n",
      "Training Epoch: 4 [26880/45000]\tLoss: 3.5557\tLR: 0.000010\n",
      "Training Epoch: 4 [26896/45000]\tLoss: 3.5524\tLR: 0.000010\n",
      "Training Epoch: 4 [26912/45000]\tLoss: 3.6565\tLR: 0.000010\n",
      "Training Epoch: 4 [26928/45000]\tLoss: 3.5778\tLR: 0.000010\n",
      "Training Epoch: 4 [26944/45000]\tLoss: 3.6379\tLR: 0.000010\n",
      "Training Epoch: 4 [26960/45000]\tLoss: 3.6504\tLR: 0.000010\n",
      "Training Epoch: 4 [26976/45000]\tLoss: 3.5272\tLR: 0.000010\n",
      "Training Epoch: 4 [26992/45000]\tLoss: 3.7299\tLR: 0.000010\n",
      "Training Epoch: 4 [27008/45000]\tLoss: 3.6520\tLR: 0.000010\n",
      "Training Epoch: 4 [27024/45000]\tLoss: 3.6056\tLR: 0.000010\n",
      "Training Epoch: 4 [27040/45000]\tLoss: 3.5909\tLR: 0.000010\n",
      "Training Epoch: 4 [27056/45000]\tLoss: 3.7483\tLR: 0.000010\n",
      "Training Epoch: 4 [27072/45000]\tLoss: 3.6335\tLR: 0.000010\n",
      "Training Epoch: 4 [27088/45000]\tLoss: 3.6820\tLR: 0.000010\n",
      "Training Epoch: 4 [27104/45000]\tLoss: 3.5951\tLR: 0.000010\n",
      "Training Epoch: 4 [27120/45000]\tLoss: 3.6444\tLR: 0.000010\n",
      "Training Epoch: 4 [27136/45000]\tLoss: 3.6247\tLR: 0.000010\n",
      "Training Epoch: 4 [27152/45000]\tLoss: 3.7070\tLR: 0.000010\n",
      "Training Epoch: 4 [27168/45000]\tLoss: 3.6168\tLR: 0.000010\n",
      "Training Epoch: 4 [27184/45000]\tLoss: 3.5310\tLR: 0.000010\n",
      "Training Epoch: 4 [27200/45000]\tLoss: 3.5775\tLR: 0.000010\n",
      "Training Epoch: 4 [27216/45000]\tLoss: 3.7127\tLR: 0.000010\n",
      "Training Epoch: 4 [27232/45000]\tLoss: 3.6226\tLR: 0.000010\n",
      "Training Epoch: 4 [27248/45000]\tLoss: 3.5550\tLR: 0.000010\n",
      "Training Epoch: 4 [27264/45000]\tLoss: 3.6124\tLR: 0.000010\n",
      "Training Epoch: 4 [27280/45000]\tLoss: 3.5276\tLR: 0.000010\n",
      "Training Epoch: 4 [27296/45000]\tLoss: 3.5569\tLR: 0.000010\n",
      "Training Epoch: 4 [27312/45000]\tLoss: 3.5229\tLR: 0.000010\n",
      "Training Epoch: 4 [27328/45000]\tLoss: 3.4802\tLR: 0.000010\n",
      "Training Epoch: 4 [27344/45000]\tLoss: 3.5841\tLR: 0.000010\n",
      "Training Epoch: 4 [27360/45000]\tLoss: 3.5468\tLR: 0.000010\n",
      "Training Epoch: 4 [27376/45000]\tLoss: 3.4847\tLR: 0.000010\n",
      "Training Epoch: 4 [27392/45000]\tLoss: 3.4736\tLR: 0.000010\n",
      "Training Epoch: 4 [27408/45000]\tLoss: 3.5710\tLR: 0.000010\n",
      "Training Epoch: 4 [27424/45000]\tLoss: 3.5118\tLR: 0.000010\n",
      "Training Epoch: 4 [27440/45000]\tLoss: 3.5754\tLR: 0.000010\n",
      "Training Epoch: 4 [27456/45000]\tLoss: 3.5256\tLR: 0.000010\n",
      "Training Epoch: 4 [27472/45000]\tLoss: 3.5747\tLR: 0.000010\n",
      "Training Epoch: 4 [27488/45000]\tLoss: 3.5254\tLR: 0.000010\n",
      "Training Epoch: 4 [27504/45000]\tLoss: 3.5766\tLR: 0.000010\n",
      "Training Epoch: 4 [27520/45000]\tLoss: 3.5863\tLR: 0.000010\n",
      "Training Epoch: 4 [27536/45000]\tLoss: 3.6948\tLR: 0.000010\n",
      "Training Epoch: 4 [27552/45000]\tLoss: 3.6348\tLR: 0.000010\n",
      "Training Epoch: 4 [27568/45000]\tLoss: 3.5999\tLR: 0.000010\n",
      "Training Epoch: 4 [27584/45000]\tLoss: 3.5841\tLR: 0.000010\n",
      "Training Epoch: 4 [27600/45000]\tLoss: 3.7012\tLR: 0.000010\n",
      "Training Epoch: 4 [27616/45000]\tLoss: 3.5370\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [27632/45000]\tLoss: 3.5701\tLR: 0.000010\n",
      "Training Epoch: 4 [27648/45000]\tLoss: 3.5966\tLR: 0.000010\n",
      "Training Epoch: 4 [27664/45000]\tLoss: 3.5398\tLR: 0.000010\n",
      "Training Epoch: 4 [27680/45000]\tLoss: 3.6096\tLR: 0.000010\n",
      "Training Epoch: 4 [27696/45000]\tLoss: 3.6175\tLR: 0.000010\n",
      "Training Epoch: 4 [27712/45000]\tLoss: 3.5736\tLR: 0.000010\n",
      "Training Epoch: 4 [27728/45000]\tLoss: 3.5519\tLR: 0.000010\n",
      "Training Epoch: 4 [27744/45000]\tLoss: 3.6087\tLR: 0.000010\n",
      "Training Epoch: 4 [27760/45000]\tLoss: 3.5109\tLR: 0.000010\n",
      "Training Epoch: 4 [27776/45000]\tLoss: 3.5512\tLR: 0.000010\n",
      "Training Epoch: 4 [27792/45000]\tLoss: 3.6035\tLR: 0.000010\n",
      "Training Epoch: 4 [27808/45000]\tLoss: 3.7460\tLR: 0.000010\n",
      "Training Epoch: 4 [27824/45000]\tLoss: 3.5948\tLR: 0.000010\n",
      "Training Epoch: 4 [27840/45000]\tLoss: 3.6020\tLR: 0.000010\n",
      "Training Epoch: 4 [27856/45000]\tLoss: 3.5504\tLR: 0.000010\n",
      "Training Epoch: 4 [27872/45000]\tLoss: 3.5982\tLR: 0.000010\n",
      "Training Epoch: 4 [27888/45000]\tLoss: 3.6001\tLR: 0.000010\n",
      "Training Epoch: 4 [27904/45000]\tLoss: 3.6300\tLR: 0.000010\n",
      "Training Epoch: 4 [27920/45000]\tLoss: 3.6504\tLR: 0.000010\n",
      "Training Epoch: 4 [27936/45000]\tLoss: 3.6016\tLR: 0.000010\n",
      "Training Epoch: 4 [27952/45000]\tLoss: 3.5191\tLR: 0.000010\n",
      "Training Epoch: 4 [27968/45000]\tLoss: 3.6991\tLR: 0.000010\n",
      "Training Epoch: 4 [27984/45000]\tLoss: 3.7012\tLR: 0.000010\n",
      "Training Epoch: 4 [28000/45000]\tLoss: 3.6409\tLR: 0.000010\n",
      "Training Epoch: 4 [28016/45000]\tLoss: 3.6434\tLR: 0.000010\n",
      "Training Epoch: 4 [28032/45000]\tLoss: 3.6699\tLR: 0.000010\n",
      "Training Epoch: 4 [28048/45000]\tLoss: 3.5567\tLR: 0.000010\n",
      "Training Epoch: 4 [28064/45000]\tLoss: 3.4670\tLR: 0.000010\n",
      "Training Epoch: 4 [28080/45000]\tLoss: 3.6687\tLR: 0.000010\n",
      "Training Epoch: 4 [28096/45000]\tLoss: 3.6181\tLR: 0.000010\n",
      "Training Epoch: 4 [28112/45000]\tLoss: 3.5894\tLR: 0.000010\n",
      "Training Epoch: 4 [28128/45000]\tLoss: 3.6428\tLR: 0.000010\n",
      "Training Epoch: 4 [28144/45000]\tLoss: 3.5227\tLR: 0.000010\n",
      "Training Epoch: 4 [28160/45000]\tLoss: 3.5475\tLR: 0.000010\n",
      "Training Epoch: 4 [28176/45000]\tLoss: 3.7244\tLR: 0.000010\n",
      "Training Epoch: 4 [28192/45000]\tLoss: 3.4762\tLR: 0.000010\n",
      "Training Epoch: 4 [28208/45000]\tLoss: 3.5882\tLR: 0.000010\n",
      "Training Epoch: 4 [28224/45000]\tLoss: 3.5541\tLR: 0.000010\n",
      "Training Epoch: 4 [28240/45000]\tLoss: 3.5100\tLR: 0.000010\n",
      "Training Epoch: 4 [28256/45000]\tLoss: 3.5472\tLR: 0.000010\n",
      "Training Epoch: 4 [28272/45000]\tLoss: 3.6213\tLR: 0.000010\n",
      "Training Epoch: 4 [28288/45000]\tLoss: 3.5388\tLR: 0.000010\n",
      "Training Epoch: 4 [28304/45000]\tLoss: 3.5173\tLR: 0.000010\n",
      "Training Epoch: 4 [28320/45000]\tLoss: 3.5738\tLR: 0.000010\n",
      "Training Epoch: 4 [28336/45000]\tLoss: 3.6277\tLR: 0.000010\n",
      "Training Epoch: 4 [28352/45000]\tLoss: 3.6994\tLR: 0.000010\n",
      "Training Epoch: 4 [28368/45000]\tLoss: 3.5031\tLR: 0.000010\n",
      "Training Epoch: 4 [28384/45000]\tLoss: 3.6083\tLR: 0.000010\n",
      "Training Epoch: 4 [28400/45000]\tLoss: 3.6755\tLR: 0.000010\n",
      "Training Epoch: 4 [28416/45000]\tLoss: 3.5851\tLR: 0.000010\n",
      "Training Epoch: 4 [28432/45000]\tLoss: 3.5826\tLR: 0.000010\n",
      "Training Epoch: 4 [28448/45000]\tLoss: 3.5424\tLR: 0.000010\n",
      "Training Epoch: 4 [28464/45000]\tLoss: 3.5314\tLR: 0.000010\n",
      "Training Epoch: 4 [28480/45000]\tLoss: 3.6184\tLR: 0.000010\n",
      "Training Epoch: 4 [28496/45000]\tLoss: 3.6251\tLR: 0.000010\n",
      "Training Epoch: 4 [28512/45000]\tLoss: 3.5302\tLR: 0.000010\n",
      "Training Epoch: 4 [28528/45000]\tLoss: 3.6162\tLR: 0.000010\n",
      "Training Epoch: 4 [28544/45000]\tLoss: 3.5726\tLR: 0.000010\n",
      "Training Epoch: 4 [28560/45000]\tLoss: 3.7896\tLR: 0.000010\n",
      "Training Epoch: 4 [28576/45000]\tLoss: 3.5418\tLR: 0.000010\n",
      "Training Epoch: 4 [28592/45000]\tLoss: 3.5230\tLR: 0.000010\n",
      "Training Epoch: 4 [28608/45000]\tLoss: 3.5254\tLR: 0.000010\n",
      "Training Epoch: 4 [28624/45000]\tLoss: 3.5768\tLR: 0.000010\n",
      "Training Epoch: 4 [28640/45000]\tLoss: 3.5835\tLR: 0.000010\n",
      "Training Epoch: 4 [28656/45000]\tLoss: 3.5718\tLR: 0.000010\n",
      "Training Epoch: 4 [28672/45000]\tLoss: 3.5937\tLR: 0.000010\n",
      "Training Epoch: 4 [28688/45000]\tLoss: 3.6001\tLR: 0.000010\n",
      "Training Epoch: 4 [28704/45000]\tLoss: 3.5080\tLR: 0.000010\n",
      "Training Epoch: 4 [28720/45000]\tLoss: 3.5863\tLR: 0.000010\n",
      "Training Epoch: 4 [28736/45000]\tLoss: 3.5602\tLR: 0.000010\n",
      "Training Epoch: 4 [28752/45000]\tLoss: 3.5111\tLR: 0.000010\n",
      "Training Epoch: 4 [28768/45000]\tLoss: 3.5646\tLR: 0.000010\n",
      "Training Epoch: 4 [28784/45000]\tLoss: 3.6113\tLR: 0.000010\n",
      "Training Epoch: 4 [28800/45000]\tLoss: 3.7301\tLR: 0.000010\n",
      "Training Epoch: 4 [28816/45000]\tLoss: 3.6485\tLR: 0.000010\n",
      "Training Epoch: 4 [28832/45000]\tLoss: 3.5043\tLR: 0.000010\n",
      "Training Epoch: 4 [28848/45000]\tLoss: 3.6279\tLR: 0.000010\n",
      "Training Epoch: 4 [28864/45000]\tLoss: 3.5652\tLR: 0.000010\n",
      "Training Epoch: 4 [28880/45000]\tLoss: 3.4991\tLR: 0.000010\n",
      "Training Epoch: 4 [28896/45000]\tLoss: 3.7071\tLR: 0.000010\n",
      "Training Epoch: 4 [28912/45000]\tLoss: 3.6851\tLR: 0.000010\n",
      "Training Epoch: 4 [28928/45000]\tLoss: 3.6070\tLR: 0.000010\n",
      "Training Epoch: 4 [28944/45000]\tLoss: 3.8002\tLR: 0.000010\n",
      "Training Epoch: 4 [28960/45000]\tLoss: 3.5590\tLR: 0.000010\n",
      "Training Epoch: 4 [28976/45000]\tLoss: 3.6189\tLR: 0.000010\n",
      "Training Epoch: 4 [28992/45000]\tLoss: 3.6802\tLR: 0.000010\n",
      "Training Epoch: 4 [29008/45000]\tLoss: 3.5315\tLR: 0.000010\n",
      "Training Epoch: 4 [29024/45000]\tLoss: 3.5859\tLR: 0.000010\n",
      "Training Epoch: 4 [29040/45000]\tLoss: 3.6083\tLR: 0.000010\n",
      "Training Epoch: 4 [29056/45000]\tLoss: 3.5492\tLR: 0.000010\n",
      "Training Epoch: 4 [29072/45000]\tLoss: 3.5159\tLR: 0.000010\n",
      "Training Epoch: 4 [29088/45000]\tLoss: 3.5360\tLR: 0.000010\n",
      "Training Epoch: 4 [29104/45000]\tLoss: 3.6797\tLR: 0.000010\n",
      "Training Epoch: 4 [29120/45000]\tLoss: 3.5475\tLR: 0.000010\n",
      "Training Epoch: 4 [29136/45000]\tLoss: 3.6829\tLR: 0.000010\n",
      "Training Epoch: 4 [29152/45000]\tLoss: 3.5849\tLR: 0.000010\n",
      "Training Epoch: 4 [29168/45000]\tLoss: 3.5116\tLR: 0.000010\n",
      "Training Epoch: 4 [29184/45000]\tLoss: 3.5923\tLR: 0.000010\n",
      "Training Epoch: 4 [29200/45000]\tLoss: 3.6642\tLR: 0.000010\n",
      "Training Epoch: 4 [29216/45000]\tLoss: 3.5235\tLR: 0.000010\n",
      "Training Epoch: 4 [29232/45000]\tLoss: 3.5008\tLR: 0.000010\n",
      "Training Epoch: 4 [29248/45000]\tLoss: 3.5169\tLR: 0.000010\n",
      "Training Epoch: 4 [29264/45000]\tLoss: 3.5574\tLR: 0.000010\n",
      "Training Epoch: 4 [29280/45000]\tLoss: 3.6095\tLR: 0.000010\n",
      "Training Epoch: 4 [29296/45000]\tLoss: 3.5474\tLR: 0.000010\n",
      "Training Epoch: 4 [29312/45000]\tLoss: 3.6677\tLR: 0.000010\n",
      "Training Epoch: 4 [29328/45000]\tLoss: 3.6378\tLR: 0.000010\n",
      "Training Epoch: 4 [29344/45000]\tLoss: 3.5891\tLR: 0.000010\n",
      "Training Epoch: 4 [29360/45000]\tLoss: 3.6887\tLR: 0.000010\n",
      "Training Epoch: 4 [29376/45000]\tLoss: 3.5745\tLR: 0.000010\n",
      "Training Epoch: 4 [29392/45000]\tLoss: 3.6797\tLR: 0.000010\n",
      "Training Epoch: 4 [29408/45000]\tLoss: 3.6213\tLR: 0.000010\n",
      "Training Epoch: 4 [29424/45000]\tLoss: 3.6585\tLR: 0.000010\n",
      "Training Epoch: 4 [29440/45000]\tLoss: 3.6108\tLR: 0.000010\n",
      "Training Epoch: 4 [29456/45000]\tLoss: 3.5104\tLR: 0.000010\n",
      "Training Epoch: 4 [29472/45000]\tLoss: 3.5645\tLR: 0.000010\n",
      "Training Epoch: 4 [29488/45000]\tLoss: 3.6095\tLR: 0.000010\n",
      "Training Epoch: 4 [29504/45000]\tLoss: 3.6490\tLR: 0.000010\n",
      "Training Epoch: 4 [29520/45000]\tLoss: 3.5983\tLR: 0.000010\n",
      "Training Epoch: 4 [29536/45000]\tLoss: 3.4804\tLR: 0.000010\n",
      "Training Epoch: 4 [29552/45000]\tLoss: 3.6816\tLR: 0.000010\n",
      "Training Epoch: 4 [29568/45000]\tLoss: 3.6678\tLR: 0.000010\n",
      "Training Epoch: 4 [29584/45000]\tLoss: 3.5633\tLR: 0.000010\n",
      "Training Epoch: 4 [29600/45000]\tLoss: 3.5865\tLR: 0.000010\n",
      "Training Epoch: 4 [29616/45000]\tLoss: 3.5949\tLR: 0.000010\n",
      "Training Epoch: 4 [29632/45000]\tLoss: 3.6512\tLR: 0.000010\n",
      "Training Epoch: 4 [29648/45000]\tLoss: 3.6216\tLR: 0.000010\n",
      "Training Epoch: 4 [29664/45000]\tLoss: 3.5771\tLR: 0.000010\n",
      "Training Epoch: 4 [29680/45000]\tLoss: 3.5874\tLR: 0.000010\n",
      "Training Epoch: 4 [29696/45000]\tLoss: 3.6086\tLR: 0.000010\n",
      "Training Epoch: 4 [29712/45000]\tLoss: 3.6473\tLR: 0.000010\n",
      "Training Epoch: 4 [29728/45000]\tLoss: 3.5533\tLR: 0.000010\n",
      "Training Epoch: 4 [29744/45000]\tLoss: 3.6462\tLR: 0.000010\n",
      "Training Epoch: 4 [29760/45000]\tLoss: 3.5474\tLR: 0.000010\n",
      "Training Epoch: 4 [29776/45000]\tLoss: 3.5709\tLR: 0.000010\n",
      "Training Epoch: 4 [29792/45000]\tLoss: 3.6479\tLR: 0.000010\n",
      "Training Epoch: 4 [29808/45000]\tLoss: 3.6242\tLR: 0.000010\n",
      "Training Epoch: 4 [29824/45000]\tLoss: 3.5905\tLR: 0.000010\n",
      "Training Epoch: 4 [29840/45000]\tLoss: 3.5711\tLR: 0.000010\n",
      "Training Epoch: 4 [29856/45000]\tLoss: 3.5558\tLR: 0.000010\n",
      "Training Epoch: 4 [29872/45000]\tLoss: 3.5089\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [29888/45000]\tLoss: 3.6091\tLR: 0.000010\n",
      "Training Epoch: 4 [29904/45000]\tLoss: 3.5870\tLR: 0.000010\n",
      "Training Epoch: 4 [29920/45000]\tLoss: 3.5543\tLR: 0.000010\n",
      "Training Epoch: 4 [29936/45000]\tLoss: 3.6280\tLR: 0.000010\n",
      "Training Epoch: 4 [29952/45000]\tLoss: 3.6087\tLR: 0.000010\n",
      "Training Epoch: 4 [29968/45000]\tLoss: 3.6346\tLR: 0.000010\n",
      "Training Epoch: 4 [29984/45000]\tLoss: 3.5174\tLR: 0.000010\n",
      "Training Epoch: 4 [30000/45000]\tLoss: 3.6330\tLR: 0.000010\n",
      "Training Epoch: 4 [30016/45000]\tLoss: 3.6235\tLR: 0.000010\n",
      "Training Epoch: 4 [30032/45000]\tLoss: 3.6104\tLR: 0.000010\n",
      "Training Epoch: 4 [30048/45000]\tLoss: 3.5514\tLR: 0.000010\n",
      "Training Epoch: 4 [30064/45000]\tLoss: 3.6249\tLR: 0.000010\n",
      "Training Epoch: 4 [30080/45000]\tLoss: 3.6006\tLR: 0.000010\n",
      "Training Epoch: 4 [30096/45000]\tLoss: 3.6276\tLR: 0.000010\n",
      "Training Epoch: 4 [30112/45000]\tLoss: 3.5822\tLR: 0.000010\n",
      "Training Epoch: 4 [30128/45000]\tLoss: 3.5286\tLR: 0.000010\n",
      "Training Epoch: 4 [30144/45000]\tLoss: 3.5546\tLR: 0.000010\n",
      "Training Epoch: 4 [30160/45000]\tLoss: 3.6015\tLR: 0.000010\n",
      "Training Epoch: 4 [30176/45000]\tLoss: 3.6976\tLR: 0.000010\n",
      "Training Epoch: 4 [30192/45000]\tLoss: 3.6519\tLR: 0.000010\n",
      "Training Epoch: 4 [30208/45000]\tLoss: 3.6722\tLR: 0.000010\n",
      "Training Epoch: 4 [30224/45000]\tLoss: 3.5127\tLR: 0.000010\n",
      "Training Epoch: 4 [30240/45000]\tLoss: 3.4915\tLR: 0.000010\n",
      "Training Epoch: 4 [30256/45000]\tLoss: 3.5336\tLR: 0.000010\n",
      "Training Epoch: 4 [30272/45000]\tLoss: 3.5977\tLR: 0.000010\n",
      "Training Epoch: 4 [30288/45000]\tLoss: 3.6170\tLR: 0.000010\n",
      "Training Epoch: 4 [30304/45000]\tLoss: 3.5737\tLR: 0.000010\n",
      "Training Epoch: 4 [30320/45000]\tLoss: 3.6119\tLR: 0.000010\n",
      "Training Epoch: 4 [30336/45000]\tLoss: 3.6184\tLR: 0.000010\n",
      "Training Epoch: 4 [30352/45000]\tLoss: 3.6690\tLR: 0.000010\n",
      "Training Epoch: 4 [30368/45000]\tLoss: 3.5272\tLR: 0.000010\n",
      "Training Epoch: 4 [30384/45000]\tLoss: 3.4780\tLR: 0.000010\n",
      "Training Epoch: 4 [30400/45000]\tLoss: 3.5406\tLR: 0.000010\n",
      "Training Epoch: 4 [30416/45000]\tLoss: 3.4767\tLR: 0.000010\n",
      "Training Epoch: 4 [30432/45000]\tLoss: 3.4545\tLR: 0.000010\n",
      "Training Epoch: 4 [30448/45000]\tLoss: 3.6015\tLR: 0.000010\n",
      "Training Epoch: 4 [30464/45000]\tLoss: 3.7737\tLR: 0.000010\n",
      "Training Epoch: 4 [30480/45000]\tLoss: 3.4977\tLR: 0.000010\n",
      "Training Epoch: 4 [30496/45000]\tLoss: 3.6771\tLR: 0.000010\n",
      "Training Epoch: 4 [30512/45000]\tLoss: 3.4727\tLR: 0.000010\n",
      "Training Epoch: 4 [30528/45000]\tLoss: 3.5865\tLR: 0.000010\n",
      "Training Epoch: 4 [30544/45000]\tLoss: 3.5856\tLR: 0.000010\n",
      "Training Epoch: 4 [30560/45000]\tLoss: 3.6340\tLR: 0.000010\n",
      "Training Epoch: 4 [30576/45000]\tLoss: 3.5798\tLR: 0.000010\n",
      "Training Epoch: 4 [30592/45000]\tLoss: 3.5960\tLR: 0.000010\n",
      "Training Epoch: 4 [30608/45000]\tLoss: 3.7374\tLR: 0.000010\n",
      "Training Epoch: 4 [30624/45000]\tLoss: 3.5407\tLR: 0.000010\n",
      "Training Epoch: 4 [30640/45000]\tLoss: 3.6478\tLR: 0.000010\n",
      "Training Epoch: 4 [30656/45000]\tLoss: 3.7200\tLR: 0.000010\n",
      "Training Epoch: 4 [30672/45000]\tLoss: 3.5513\tLR: 0.000010\n",
      "Training Epoch: 4 [30688/45000]\tLoss: 3.5401\tLR: 0.000010\n",
      "Training Epoch: 4 [30704/45000]\tLoss: 3.4231\tLR: 0.000010\n",
      "Training Epoch: 4 [30720/45000]\tLoss: 3.6431\tLR: 0.000010\n",
      "Training Epoch: 4 [30736/45000]\tLoss: 3.5589\tLR: 0.000010\n",
      "Training Epoch: 4 [30752/45000]\tLoss: 3.6126\tLR: 0.000010\n",
      "Training Epoch: 4 [30768/45000]\tLoss: 3.6414\tLR: 0.000010\n",
      "Training Epoch: 4 [30784/45000]\tLoss: 3.6481\tLR: 0.000010\n",
      "Training Epoch: 4 [30800/45000]\tLoss: 3.5067\tLR: 0.000010\n",
      "Training Epoch: 4 [30816/45000]\tLoss: 3.5648\tLR: 0.000010\n",
      "Training Epoch: 4 [30832/45000]\tLoss: 3.6144\tLR: 0.000010\n",
      "Training Epoch: 4 [30848/45000]\tLoss: 3.5465\tLR: 0.000010\n",
      "Training Epoch: 4 [30864/45000]\tLoss: 3.5744\tLR: 0.000010\n",
      "Training Epoch: 4 [30880/45000]\tLoss: 3.5558\tLR: 0.000010\n",
      "Training Epoch: 4 [30896/45000]\tLoss: 3.5819\tLR: 0.000010\n",
      "Training Epoch: 4 [30912/45000]\tLoss: 3.6198\tLR: 0.000010\n",
      "Training Epoch: 4 [30928/45000]\tLoss: 3.4544\tLR: 0.000010\n",
      "Training Epoch: 4 [30944/45000]\tLoss: 3.5937\tLR: 0.000010\n",
      "Training Epoch: 4 [30960/45000]\tLoss: 3.7240\tLR: 0.000010\n",
      "Training Epoch: 4 [30976/45000]\tLoss: 3.6269\tLR: 0.000010\n",
      "Training Epoch: 4 [30992/45000]\tLoss: 3.6316\tLR: 0.000010\n",
      "Training Epoch: 4 [31008/45000]\tLoss: 3.5878\tLR: 0.000010\n",
      "Training Epoch: 4 [31024/45000]\tLoss: 3.6203\tLR: 0.000010\n",
      "Training Epoch: 4 [31040/45000]\tLoss: 3.5997\tLR: 0.000010\n",
      "Training Epoch: 4 [31056/45000]\tLoss: 3.5287\tLR: 0.000010\n",
      "Training Epoch: 4 [31072/45000]\tLoss: 3.6415\tLR: 0.000010\n",
      "Training Epoch: 4 [31088/45000]\tLoss: 3.6038\tLR: 0.000010\n",
      "Training Epoch: 4 [31104/45000]\tLoss: 3.5795\tLR: 0.000010\n",
      "Training Epoch: 4 [31120/45000]\tLoss: 3.6140\tLR: 0.000010\n",
      "Training Epoch: 4 [31136/45000]\tLoss: 3.5269\tLR: 0.000010\n",
      "Training Epoch: 4 [31152/45000]\tLoss: 3.6071\tLR: 0.000010\n",
      "Training Epoch: 4 [31168/45000]\tLoss: 3.5394\tLR: 0.000010\n",
      "Training Epoch: 4 [31184/45000]\tLoss: 3.4925\tLR: 0.000010\n",
      "Training Epoch: 4 [31200/45000]\tLoss: 3.5609\tLR: 0.000010\n",
      "Training Epoch: 4 [31216/45000]\tLoss: 3.6838\tLR: 0.000010\n",
      "Training Epoch: 4 [31232/45000]\tLoss: 3.6237\tLR: 0.000010\n",
      "Training Epoch: 4 [31248/45000]\tLoss: 3.6987\tLR: 0.000010\n",
      "Training Epoch: 4 [31264/45000]\tLoss: 3.6800\tLR: 0.000010\n",
      "Training Epoch: 4 [31280/45000]\tLoss: 3.6190\tLR: 0.000010\n",
      "Training Epoch: 4 [31296/45000]\tLoss: 3.6975\tLR: 0.000010\n",
      "Training Epoch: 4 [31312/45000]\tLoss: 3.5395\tLR: 0.000010\n",
      "Training Epoch: 4 [31328/45000]\tLoss: 3.6751\tLR: 0.000010\n",
      "Training Epoch: 4 [31344/45000]\tLoss: 3.5701\tLR: 0.000010\n",
      "Training Epoch: 4 [31360/45000]\tLoss: 3.6713\tLR: 0.000010\n",
      "Training Epoch: 4 [31376/45000]\tLoss: 3.5905\tLR: 0.000010\n",
      "Training Epoch: 4 [31392/45000]\tLoss: 3.5075\tLR: 0.000010\n",
      "Training Epoch: 4 [31408/45000]\tLoss: 3.6735\tLR: 0.000010\n",
      "Training Epoch: 4 [31424/45000]\tLoss: 3.6891\tLR: 0.000010\n",
      "Training Epoch: 4 [31440/45000]\tLoss: 3.5041\tLR: 0.000010\n",
      "Training Epoch: 4 [31456/45000]\tLoss: 3.6207\tLR: 0.000010\n",
      "Training Epoch: 4 [31472/45000]\tLoss: 3.6203\tLR: 0.000010\n",
      "Training Epoch: 4 [31488/45000]\tLoss: 3.6949\tLR: 0.000010\n",
      "Training Epoch: 4 [31504/45000]\tLoss: 3.7070\tLR: 0.000010\n",
      "Training Epoch: 4 [31520/45000]\tLoss: 3.5968\tLR: 0.000010\n",
      "Training Epoch: 4 [31536/45000]\tLoss: 3.6115\tLR: 0.000010\n",
      "Training Epoch: 4 [31552/45000]\tLoss: 3.6425\tLR: 0.000010\n",
      "Training Epoch: 4 [31568/45000]\tLoss: 3.5621\tLR: 0.000010\n",
      "Training Epoch: 4 [31584/45000]\tLoss: 3.5285\tLR: 0.000010\n",
      "Training Epoch: 4 [31600/45000]\tLoss: 3.5887\tLR: 0.000010\n",
      "Training Epoch: 4 [31616/45000]\tLoss: 3.5006\tLR: 0.000010\n",
      "Training Epoch: 4 [31632/45000]\tLoss: 3.5461\tLR: 0.000010\n",
      "Training Epoch: 4 [31648/45000]\tLoss: 3.6448\tLR: 0.000010\n",
      "Training Epoch: 4 [31664/45000]\tLoss: 3.5346\tLR: 0.000010\n",
      "Training Epoch: 4 [31680/45000]\tLoss: 3.5739\tLR: 0.000010\n",
      "Training Epoch: 4 [31696/45000]\tLoss: 3.6287\tLR: 0.000010\n",
      "Training Epoch: 4 [31712/45000]\tLoss: 3.5373\tLR: 0.000010\n",
      "Training Epoch: 4 [31728/45000]\tLoss: 3.5507\tLR: 0.000010\n",
      "Training Epoch: 4 [31744/45000]\tLoss: 3.5392\tLR: 0.000010\n",
      "Training Epoch: 4 [31760/45000]\tLoss: 3.6001\tLR: 0.000010\n",
      "Training Epoch: 4 [31776/45000]\tLoss: 3.5120\tLR: 0.000010\n",
      "Training Epoch: 4 [31792/45000]\tLoss: 3.5990\tLR: 0.000010\n",
      "Training Epoch: 4 [31808/45000]\tLoss: 3.5607\tLR: 0.000010\n",
      "Training Epoch: 4 [31824/45000]\tLoss: 3.6986\tLR: 0.000010\n",
      "Training Epoch: 4 [31840/45000]\tLoss: 3.5332\tLR: 0.000010\n",
      "Training Epoch: 4 [31856/45000]\tLoss: 3.6278\tLR: 0.000010\n",
      "Training Epoch: 4 [31872/45000]\tLoss: 3.6488\tLR: 0.000010\n",
      "Training Epoch: 4 [31888/45000]\tLoss: 3.5948\tLR: 0.000010\n",
      "Training Epoch: 4 [31904/45000]\tLoss: 3.7756\tLR: 0.000010\n",
      "Training Epoch: 4 [31920/45000]\tLoss: 3.4939\tLR: 0.000010\n",
      "Training Epoch: 4 [31936/45000]\tLoss: 3.5677\tLR: 0.000010\n",
      "Training Epoch: 4 [31952/45000]\tLoss: 3.6066\tLR: 0.000010\n",
      "Training Epoch: 4 [31968/45000]\tLoss: 3.6461\tLR: 0.000010\n",
      "Training Epoch: 4 [31984/45000]\tLoss: 3.7757\tLR: 0.000010\n",
      "Training Epoch: 4 [32000/45000]\tLoss: 3.5141\tLR: 0.000010\n",
      "Training Epoch: 4 [32016/45000]\tLoss: 3.6117\tLR: 0.000010\n",
      "Training Epoch: 4 [32032/45000]\tLoss: 3.5229\tLR: 0.000010\n",
      "Training Epoch: 4 [32048/45000]\tLoss: 3.6653\tLR: 0.000010\n",
      "Training Epoch: 4 [32064/45000]\tLoss: 3.7207\tLR: 0.000010\n",
      "Training Epoch: 4 [32080/45000]\tLoss: 3.7134\tLR: 0.000010\n",
      "Training Epoch: 4 [32096/45000]\tLoss: 3.5891\tLR: 0.000010\n",
      "Training Epoch: 4 [32112/45000]\tLoss: 3.6908\tLR: 0.000010\n",
      "Training Epoch: 4 [32128/45000]\tLoss: 3.5718\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [32144/45000]\tLoss: 3.5222\tLR: 0.000010\n",
      "Training Epoch: 4 [32160/45000]\tLoss: 3.6729\tLR: 0.000010\n",
      "Training Epoch: 4 [32176/45000]\tLoss: 3.5059\tLR: 0.000010\n",
      "Training Epoch: 4 [32192/45000]\tLoss: 3.6670\tLR: 0.000010\n",
      "Training Epoch: 4 [32208/45000]\tLoss: 3.5947\tLR: 0.000010\n",
      "Training Epoch: 4 [32224/45000]\tLoss: 3.5670\tLR: 0.000010\n",
      "Training Epoch: 4 [32240/45000]\tLoss: 3.6302\tLR: 0.000010\n",
      "Training Epoch: 4 [32256/45000]\tLoss: 3.6782\tLR: 0.000010\n",
      "Training Epoch: 4 [32272/45000]\tLoss: 3.6239\tLR: 0.000010\n",
      "Training Epoch: 4 [32288/45000]\tLoss: 3.6073\tLR: 0.000010\n",
      "Training Epoch: 4 [32304/45000]\tLoss: 3.7081\tLR: 0.000010\n",
      "Training Epoch: 4 [32320/45000]\tLoss: 3.5236\tLR: 0.000010\n",
      "Training Epoch: 4 [32336/45000]\tLoss: 3.5122\tLR: 0.000010\n",
      "Training Epoch: 4 [32352/45000]\tLoss: 3.6816\tLR: 0.000010\n",
      "Training Epoch: 4 [32368/45000]\tLoss: 3.6543\tLR: 0.000010\n",
      "Training Epoch: 4 [32384/45000]\tLoss: 3.4460\tLR: 0.000010\n",
      "Training Epoch: 4 [32400/45000]\tLoss: 3.6720\tLR: 0.000010\n",
      "Training Epoch: 4 [32416/45000]\tLoss: 3.5319\tLR: 0.000010\n",
      "Training Epoch: 4 [32432/45000]\tLoss: 3.5648\tLR: 0.000010\n",
      "Training Epoch: 4 [32448/45000]\tLoss: 3.7384\tLR: 0.000010\n",
      "Training Epoch: 4 [32464/45000]\tLoss: 3.6066\tLR: 0.000010\n",
      "Training Epoch: 4 [32480/45000]\tLoss: 3.5961\tLR: 0.000010\n",
      "Training Epoch: 4 [32496/45000]\tLoss: 3.5607\tLR: 0.000010\n",
      "Training Epoch: 4 [32512/45000]\tLoss: 3.5143\tLR: 0.000010\n",
      "Training Epoch: 4 [32528/45000]\tLoss: 3.5664\tLR: 0.000010\n",
      "Training Epoch: 4 [32544/45000]\tLoss: 3.5013\tLR: 0.000010\n",
      "Training Epoch: 4 [32560/45000]\tLoss: 3.6516\tLR: 0.000010\n",
      "Training Epoch: 4 [32576/45000]\tLoss: 3.6046\tLR: 0.000010\n",
      "Training Epoch: 4 [32592/45000]\tLoss: 3.6936\tLR: 0.000010\n",
      "Training Epoch: 4 [32608/45000]\tLoss: 3.5736\tLR: 0.000010\n",
      "Training Epoch: 4 [32624/45000]\tLoss: 3.6383\tLR: 0.000010\n",
      "Training Epoch: 4 [32640/45000]\tLoss: 3.7552\tLR: 0.000010\n",
      "Training Epoch: 4 [32656/45000]\tLoss: 3.6663\tLR: 0.000010\n",
      "Training Epoch: 4 [32672/45000]\tLoss: 3.5587\tLR: 0.000010\n",
      "Training Epoch: 4 [32688/45000]\tLoss: 3.6088\tLR: 0.000010\n",
      "Training Epoch: 4 [32704/45000]\tLoss: 3.5315\tLR: 0.000010\n",
      "Training Epoch: 4 [32720/45000]\tLoss: 3.5858\tLR: 0.000010\n",
      "Training Epoch: 4 [32736/45000]\tLoss: 3.6091\tLR: 0.000010\n",
      "Training Epoch: 4 [32752/45000]\tLoss: 3.5440\tLR: 0.000010\n",
      "Training Epoch: 4 [32768/45000]\tLoss: 3.6271\tLR: 0.000010\n",
      "Training Epoch: 4 [32784/45000]\tLoss: 3.5846\tLR: 0.000010\n",
      "Training Epoch: 4 [32800/45000]\tLoss: 3.6137\tLR: 0.000010\n",
      "Training Epoch: 4 [32816/45000]\tLoss: 3.6253\tLR: 0.000010\n",
      "Training Epoch: 4 [32832/45000]\tLoss: 3.6497\tLR: 0.000010\n",
      "Training Epoch: 4 [32848/45000]\tLoss: 3.6903\tLR: 0.000010\n",
      "Training Epoch: 4 [32864/45000]\tLoss: 3.6284\tLR: 0.000010\n",
      "Training Epoch: 4 [32880/45000]\tLoss: 3.6087\tLR: 0.000010\n",
      "Training Epoch: 4 [32896/45000]\tLoss: 3.6645\tLR: 0.000010\n",
      "Training Epoch: 4 [32912/45000]\tLoss: 3.6036\tLR: 0.000010\n",
      "Training Epoch: 4 [32928/45000]\tLoss: 3.5190\tLR: 0.000010\n",
      "Training Epoch: 4 [32944/45000]\tLoss: 3.5747\tLR: 0.000010\n",
      "Training Epoch: 4 [32960/45000]\tLoss: 3.6187\tLR: 0.000010\n",
      "Training Epoch: 4 [32976/45000]\tLoss: 3.7028\tLR: 0.000010\n",
      "Training Epoch: 4 [32992/45000]\tLoss: 3.4839\tLR: 0.000010\n",
      "Training Epoch: 4 [33008/45000]\tLoss: 3.5732\tLR: 0.000010\n",
      "Training Epoch: 4 [33024/45000]\tLoss: 3.5517\tLR: 0.000010\n",
      "Training Epoch: 4 [33040/45000]\tLoss: 3.6904\tLR: 0.000010\n",
      "Training Epoch: 4 [33056/45000]\tLoss: 3.5600\tLR: 0.000010\n",
      "Training Epoch: 4 [33072/45000]\tLoss: 3.5948\tLR: 0.000010\n",
      "Training Epoch: 4 [33088/45000]\tLoss: 3.6883\tLR: 0.000010\n",
      "Training Epoch: 4 [33104/45000]\tLoss: 3.4947\tLR: 0.000010\n",
      "Training Epoch: 4 [33120/45000]\tLoss: 3.5014\tLR: 0.000010\n",
      "Training Epoch: 4 [33136/45000]\tLoss: 3.5483\tLR: 0.000010\n",
      "Training Epoch: 4 [33152/45000]\tLoss: 3.4489\tLR: 0.000010\n",
      "Training Epoch: 4 [33168/45000]\tLoss: 3.6382\tLR: 0.000010\n",
      "Training Epoch: 4 [33184/45000]\tLoss: 3.5116\tLR: 0.000010\n",
      "Training Epoch: 4 [33200/45000]\tLoss: 3.6376\tLR: 0.000010\n",
      "Training Epoch: 4 [33216/45000]\tLoss: 3.5675\tLR: 0.000010\n",
      "Training Epoch: 4 [33232/45000]\tLoss: 3.5419\tLR: 0.000010\n",
      "Training Epoch: 4 [33248/45000]\tLoss: 3.5280\tLR: 0.000010\n",
      "Training Epoch: 4 [33264/45000]\tLoss: 3.5089\tLR: 0.000010\n",
      "Training Epoch: 4 [33280/45000]\tLoss: 3.7429\tLR: 0.000010\n",
      "Training Epoch: 4 [33296/45000]\tLoss: 3.6303\tLR: 0.000010\n",
      "Training Epoch: 4 [33312/45000]\tLoss: 3.5916\tLR: 0.000010\n",
      "Training Epoch: 4 [33328/45000]\tLoss: 3.6142\tLR: 0.000010\n",
      "Training Epoch: 4 [33344/45000]\tLoss: 3.5222\tLR: 0.000010\n",
      "Training Epoch: 4 [33360/45000]\tLoss: 3.6192\tLR: 0.000010\n",
      "Training Epoch: 4 [33376/45000]\tLoss: 3.6037\tLR: 0.000010\n",
      "Training Epoch: 4 [33392/45000]\tLoss: 3.6544\tLR: 0.000010\n",
      "Training Epoch: 4 [33408/45000]\tLoss: 3.4707\tLR: 0.000010\n",
      "Training Epoch: 4 [33424/45000]\tLoss: 3.7596\tLR: 0.000010\n",
      "Training Epoch: 4 [33440/45000]\tLoss: 3.5065\tLR: 0.000010\n",
      "Training Epoch: 4 [33456/45000]\tLoss: 3.5807\tLR: 0.000010\n",
      "Training Epoch: 4 [33472/45000]\tLoss: 3.5657\tLR: 0.000010\n",
      "Training Epoch: 4 [33488/45000]\tLoss: 3.5168\tLR: 0.000010\n",
      "Training Epoch: 4 [33504/45000]\tLoss: 3.6797\tLR: 0.000010\n",
      "Training Epoch: 4 [33520/45000]\tLoss: 3.5141\tLR: 0.000010\n",
      "Training Epoch: 4 [33536/45000]\tLoss: 3.6279\tLR: 0.000010\n",
      "Training Epoch: 4 [33552/45000]\tLoss: 3.6217\tLR: 0.000010\n",
      "Training Epoch: 4 [33568/45000]\tLoss: 3.5191\tLR: 0.000010\n",
      "Training Epoch: 4 [33584/45000]\tLoss: 3.5916\tLR: 0.000010\n",
      "Training Epoch: 4 [33600/45000]\tLoss: 3.5198\tLR: 0.000010\n",
      "Training Epoch: 4 [33616/45000]\tLoss: 3.5438\tLR: 0.000010\n",
      "Training Epoch: 4 [33632/45000]\tLoss: 3.6166\tLR: 0.000010\n",
      "Training Epoch: 4 [33648/45000]\tLoss: 3.6197\tLR: 0.000010\n",
      "Training Epoch: 4 [33664/45000]\tLoss: 3.6985\tLR: 0.000010\n",
      "Training Epoch: 4 [33680/45000]\tLoss: 3.6711\tLR: 0.000010\n",
      "Training Epoch: 4 [33696/45000]\tLoss: 3.5388\tLR: 0.000010\n",
      "Training Epoch: 4 [33712/45000]\tLoss: 3.5429\tLR: 0.000010\n",
      "Training Epoch: 4 [33728/45000]\tLoss: 3.4975\tLR: 0.000010\n",
      "Training Epoch: 4 [33744/45000]\tLoss: 3.5328\tLR: 0.000010\n",
      "Training Epoch: 4 [33760/45000]\tLoss: 3.5829\tLR: 0.000010\n",
      "Training Epoch: 4 [33776/45000]\tLoss: 3.5925\tLR: 0.000010\n",
      "Training Epoch: 4 [33792/45000]\tLoss: 3.4909\tLR: 0.000010\n",
      "Training Epoch: 4 [33808/45000]\tLoss: 3.4866\tLR: 0.000010\n",
      "Training Epoch: 4 [33824/45000]\tLoss: 3.5226\tLR: 0.000010\n",
      "Training Epoch: 4 [33840/45000]\tLoss: 3.6261\tLR: 0.000010\n",
      "Training Epoch: 4 [33856/45000]\tLoss: 3.5384\tLR: 0.000010\n",
      "Training Epoch: 4 [33872/45000]\tLoss: 3.6349\tLR: 0.000010\n",
      "Training Epoch: 4 [33888/45000]\tLoss: 3.5590\tLR: 0.000010\n",
      "Training Epoch: 4 [33904/45000]\tLoss: 3.5981\tLR: 0.000010\n",
      "Training Epoch: 4 [33920/45000]\tLoss: 3.5697\tLR: 0.000010\n",
      "Training Epoch: 4 [33936/45000]\tLoss: 3.6750\tLR: 0.000010\n",
      "Training Epoch: 4 [33952/45000]\tLoss: 3.5954\tLR: 0.000010\n",
      "Training Epoch: 4 [33968/45000]\tLoss: 3.7220\tLR: 0.000010\n",
      "Training Epoch: 4 [33984/45000]\tLoss: 3.5728\tLR: 0.000010\n",
      "Training Epoch: 4 [34000/45000]\tLoss: 3.5864\tLR: 0.000010\n",
      "Training Epoch: 4 [34016/45000]\tLoss: 3.5651\tLR: 0.000010\n",
      "Training Epoch: 4 [34032/45000]\tLoss: 3.5609\tLR: 0.000010\n",
      "Training Epoch: 4 [34048/45000]\tLoss: 3.4708\tLR: 0.000010\n",
      "Training Epoch: 4 [34064/45000]\tLoss: 3.4698\tLR: 0.000010\n",
      "Training Epoch: 4 [34080/45000]\tLoss: 3.6196\tLR: 0.000010\n",
      "Training Epoch: 4 [34096/45000]\tLoss: 3.5569\tLR: 0.000010\n",
      "Training Epoch: 4 [34112/45000]\tLoss: 3.5775\tLR: 0.000010\n",
      "Training Epoch: 4 [34128/45000]\tLoss: 3.6476\tLR: 0.000010\n",
      "Training Epoch: 4 [34144/45000]\tLoss: 3.5324\tLR: 0.000010\n",
      "Training Epoch: 4 [34160/45000]\tLoss: 3.5107\tLR: 0.000010\n",
      "Training Epoch: 4 [34176/45000]\tLoss: 3.6056\tLR: 0.000010\n",
      "Training Epoch: 4 [34192/45000]\tLoss: 3.5328\tLR: 0.000010\n",
      "Training Epoch: 4 [34208/45000]\tLoss: 3.5634\tLR: 0.000010\n",
      "Training Epoch: 4 [34224/45000]\tLoss: 3.6412\tLR: 0.000010\n",
      "Training Epoch: 4 [34240/45000]\tLoss: 3.7480\tLR: 0.000010\n",
      "Training Epoch: 4 [34256/45000]\tLoss: 3.5630\tLR: 0.000010\n",
      "Training Epoch: 4 [34272/45000]\tLoss: 3.5896\tLR: 0.000010\n",
      "Training Epoch: 4 [34288/45000]\tLoss: 3.5504\tLR: 0.000010\n",
      "Training Epoch: 4 [34304/45000]\tLoss: 3.6484\tLR: 0.000010\n",
      "Training Epoch: 4 [34320/45000]\tLoss: 3.5912\tLR: 0.000010\n",
      "Training Epoch: 4 [34336/45000]\tLoss: 3.5874\tLR: 0.000010\n",
      "Training Epoch: 4 [34352/45000]\tLoss: 3.5739\tLR: 0.000010\n",
      "Training Epoch: 4 [34368/45000]\tLoss: 3.6576\tLR: 0.000010\n",
      "Training Epoch: 4 [34384/45000]\tLoss: 3.6201\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [34400/45000]\tLoss: 3.5459\tLR: 0.000010\n",
      "Training Epoch: 4 [34416/45000]\tLoss: 3.5484\tLR: 0.000010\n",
      "Training Epoch: 4 [34432/45000]\tLoss: 3.6376\tLR: 0.000010\n",
      "Training Epoch: 4 [34448/45000]\tLoss: 3.5899\tLR: 0.000010\n",
      "Training Epoch: 4 [34464/45000]\tLoss: 3.6140\tLR: 0.000010\n",
      "Training Epoch: 4 [34480/45000]\tLoss: 3.5030\tLR: 0.000010\n",
      "Training Epoch: 4 [34496/45000]\tLoss: 3.6444\tLR: 0.000010\n",
      "Training Epoch: 4 [34512/45000]\tLoss: 3.6526\tLR: 0.000010\n",
      "Training Epoch: 4 [34528/45000]\tLoss: 3.5222\tLR: 0.000010\n",
      "Training Epoch: 4 [34544/45000]\tLoss: 3.5230\tLR: 0.000010\n",
      "Training Epoch: 4 [34560/45000]\tLoss: 3.5228\tLR: 0.000010\n",
      "Training Epoch: 4 [34576/45000]\tLoss: 3.5262\tLR: 0.000010\n",
      "Training Epoch: 4 [34592/45000]\tLoss: 3.6215\tLR: 0.000010\n",
      "Training Epoch: 4 [34608/45000]\tLoss: 3.5060\tLR: 0.000010\n",
      "Training Epoch: 4 [34624/45000]\tLoss: 3.6647\tLR: 0.000010\n",
      "Training Epoch: 4 [34640/45000]\tLoss: 3.7206\tLR: 0.000010\n",
      "Training Epoch: 4 [34656/45000]\tLoss: 3.4892\tLR: 0.000010\n",
      "Training Epoch: 4 [34672/45000]\tLoss: 3.5335\tLR: 0.000010\n",
      "Training Epoch: 4 [34688/45000]\tLoss: 3.5648\tLR: 0.000010\n",
      "Training Epoch: 4 [34704/45000]\tLoss: 3.5520\tLR: 0.000010\n",
      "Training Epoch: 4 [34720/45000]\tLoss: 3.5914\tLR: 0.000010\n",
      "Training Epoch: 4 [34736/45000]\tLoss: 3.6625\tLR: 0.000010\n",
      "Training Epoch: 4 [34752/45000]\tLoss: 3.6217\tLR: 0.000010\n",
      "Training Epoch: 4 [34768/45000]\tLoss: 3.6458\tLR: 0.000010\n",
      "Training Epoch: 4 [34784/45000]\tLoss: 3.6183\tLR: 0.000010\n",
      "Training Epoch: 4 [34800/45000]\tLoss: 3.5345\tLR: 0.000010\n",
      "Training Epoch: 4 [34816/45000]\tLoss: 3.6562\tLR: 0.000010\n",
      "Training Epoch: 4 [34832/45000]\tLoss: 3.5047\tLR: 0.000010\n",
      "Training Epoch: 4 [34848/45000]\tLoss: 3.5870\tLR: 0.000010\n",
      "Training Epoch: 4 [34864/45000]\tLoss: 3.6907\tLR: 0.000010\n",
      "Training Epoch: 4 [34880/45000]\tLoss: 3.6045\tLR: 0.000010\n",
      "Training Epoch: 4 [34896/45000]\tLoss: 3.5794\tLR: 0.000010\n",
      "Training Epoch: 4 [34912/45000]\tLoss: 3.5380\tLR: 0.000010\n",
      "Training Epoch: 4 [34928/45000]\tLoss: 3.5001\tLR: 0.000010\n",
      "Training Epoch: 4 [34944/45000]\tLoss: 3.7303\tLR: 0.000010\n",
      "Training Epoch: 4 [34960/45000]\tLoss: 3.6027\tLR: 0.000010\n",
      "Training Epoch: 4 [34976/45000]\tLoss: 3.6854\tLR: 0.000010\n",
      "Training Epoch: 4 [34992/45000]\tLoss: 3.5707\tLR: 0.000010\n",
      "Training Epoch: 4 [35008/45000]\tLoss: 3.5965\tLR: 0.000010\n",
      "Training Epoch: 4 [35024/45000]\tLoss: 3.5615\tLR: 0.000010\n",
      "Training Epoch: 4 [35040/45000]\tLoss: 3.5189\tLR: 0.000010\n",
      "Training Epoch: 4 [35056/45000]\tLoss: 3.5614\tLR: 0.000010\n",
      "Training Epoch: 4 [35072/45000]\tLoss: 3.4877\tLR: 0.000010\n",
      "Training Epoch: 4 [35088/45000]\tLoss: 3.7093\tLR: 0.000010\n",
      "Training Epoch: 4 [35104/45000]\tLoss: 3.6139\tLR: 0.000010\n",
      "Training Epoch: 4 [35120/45000]\tLoss: 3.5304\tLR: 0.000010\n",
      "Training Epoch: 4 [35136/45000]\tLoss: 3.6552\tLR: 0.000010\n",
      "Training Epoch: 4 [35152/45000]\tLoss: 3.5400\tLR: 0.000010\n",
      "Training Epoch: 4 [35168/45000]\tLoss: 3.6270\tLR: 0.000010\n",
      "Training Epoch: 4 [35184/45000]\tLoss: 3.7783\tLR: 0.000010\n",
      "Training Epoch: 4 [35200/45000]\tLoss: 3.7449\tLR: 0.000010\n",
      "Training Epoch: 4 [35216/45000]\tLoss: 3.6154\tLR: 0.000010\n",
      "Training Epoch: 4 [35232/45000]\tLoss: 3.6012\tLR: 0.000010\n",
      "Training Epoch: 4 [35248/45000]\tLoss: 3.6485\tLR: 0.000010\n",
      "Training Epoch: 4 [35264/45000]\tLoss: 3.6671\tLR: 0.000010\n",
      "Training Epoch: 4 [35280/45000]\tLoss: 3.5443\tLR: 0.000010\n",
      "Training Epoch: 4 [35296/45000]\tLoss: 3.5189\tLR: 0.000010\n",
      "Training Epoch: 4 [35312/45000]\tLoss: 3.4476\tLR: 0.000010\n",
      "Training Epoch: 4 [35328/45000]\tLoss: 3.5933\tLR: 0.000010\n",
      "Training Epoch: 4 [35344/45000]\tLoss: 3.6192\tLR: 0.000010\n",
      "Training Epoch: 4 [35360/45000]\tLoss: 3.5296\tLR: 0.000010\n",
      "Training Epoch: 4 [35376/45000]\tLoss: 3.5778\tLR: 0.000010\n",
      "Training Epoch: 4 [35392/45000]\tLoss: 3.5714\tLR: 0.000010\n",
      "Training Epoch: 4 [35408/45000]\tLoss: 3.5852\tLR: 0.000010\n",
      "Training Epoch: 4 [35424/45000]\tLoss: 3.5837\tLR: 0.000010\n",
      "Training Epoch: 4 [35440/45000]\tLoss: 3.6246\tLR: 0.000010\n",
      "Training Epoch: 4 [35456/45000]\tLoss: 3.5392\tLR: 0.000010\n",
      "Training Epoch: 4 [35472/45000]\tLoss: 3.6603\tLR: 0.000010\n",
      "Training Epoch: 4 [35488/45000]\tLoss: 3.4972\tLR: 0.000010\n",
      "Training Epoch: 4 [35504/45000]\tLoss: 3.5274\tLR: 0.000010\n",
      "Training Epoch: 4 [35520/45000]\tLoss: 3.5418\tLR: 0.000010\n",
      "Training Epoch: 4 [35536/45000]\tLoss: 3.5829\tLR: 0.000010\n",
      "Training Epoch: 4 [35552/45000]\tLoss: 3.3691\tLR: 0.000010\n",
      "Training Epoch: 4 [35568/45000]\tLoss: 3.5320\tLR: 0.000010\n",
      "Training Epoch: 4 [35584/45000]\tLoss: 3.6044\tLR: 0.000010\n",
      "Training Epoch: 4 [35600/45000]\tLoss: 3.6025\tLR: 0.000010\n",
      "Training Epoch: 4 [35616/45000]\tLoss: 3.5786\tLR: 0.000010\n",
      "Training Epoch: 4 [35632/45000]\tLoss: 3.5925\tLR: 0.000010\n",
      "Training Epoch: 4 [35648/45000]\tLoss: 3.6526\tLR: 0.000010\n",
      "Training Epoch: 4 [35664/45000]\tLoss: 3.5302\tLR: 0.000010\n",
      "Training Epoch: 4 [35680/45000]\tLoss: 3.5676\tLR: 0.000010\n",
      "Training Epoch: 4 [35696/45000]\tLoss: 3.5727\tLR: 0.000010\n",
      "Training Epoch: 4 [35712/45000]\tLoss: 3.5821\tLR: 0.000010\n",
      "Training Epoch: 4 [35728/45000]\tLoss: 3.6187\tLR: 0.000010\n",
      "Training Epoch: 4 [35744/45000]\tLoss: 3.5532\tLR: 0.000010\n",
      "Training Epoch: 4 [35760/45000]\tLoss: 3.7366\tLR: 0.000010\n",
      "Training Epoch: 4 [35776/45000]\tLoss: 3.6043\tLR: 0.000010\n",
      "Training Epoch: 4 [35792/45000]\tLoss: 3.5640\tLR: 0.000010\n",
      "Training Epoch: 4 [35808/45000]\tLoss: 3.6918\tLR: 0.000010\n",
      "Training Epoch: 4 [35824/45000]\tLoss: 3.5505\tLR: 0.000010\n",
      "Training Epoch: 4 [35840/45000]\tLoss: 3.5384\tLR: 0.000010\n",
      "Training Epoch: 4 [35856/45000]\tLoss: 3.5755\tLR: 0.000010\n",
      "Training Epoch: 4 [35872/45000]\tLoss: 3.5692\tLR: 0.000010\n",
      "Training Epoch: 4 [35888/45000]\tLoss: 3.6023\tLR: 0.000010\n",
      "Training Epoch: 4 [35904/45000]\tLoss: 3.4849\tLR: 0.000010\n",
      "Training Epoch: 4 [35920/45000]\tLoss: 3.5721\tLR: 0.000010\n",
      "Training Epoch: 4 [35936/45000]\tLoss: 3.6431\tLR: 0.000010\n",
      "Training Epoch: 4 [35952/45000]\tLoss: 3.5758\tLR: 0.000010\n",
      "Training Epoch: 4 [35968/45000]\tLoss: 3.5348\tLR: 0.000010\n",
      "Training Epoch: 4 [35984/45000]\tLoss: 3.5314\tLR: 0.000010\n",
      "Training Epoch: 4 [36000/45000]\tLoss: 3.5680\tLR: 0.000010\n",
      "Training Epoch: 4 [36016/45000]\tLoss: 3.6128\tLR: 0.000010\n",
      "Training Epoch: 4 [36032/45000]\tLoss: 3.5244\tLR: 0.000010\n",
      "Training Epoch: 4 [36048/45000]\tLoss: 3.5386\tLR: 0.000010\n",
      "Training Epoch: 4 [36064/45000]\tLoss: 3.4001\tLR: 0.000010\n",
      "Training Epoch: 4 [36080/45000]\tLoss: 3.7055\tLR: 0.000010\n",
      "Training Epoch: 4 [36096/45000]\tLoss: 3.6261\tLR: 0.000010\n",
      "Training Epoch: 4 [36112/45000]\tLoss: 3.6338\tLR: 0.000010\n",
      "Training Epoch: 4 [36128/45000]\tLoss: 3.5916\tLR: 0.000010\n",
      "Training Epoch: 4 [36144/45000]\tLoss: 3.5484\tLR: 0.000010\n",
      "Training Epoch: 4 [36160/45000]\tLoss: 3.5730\tLR: 0.000010\n",
      "Training Epoch: 4 [36176/45000]\tLoss: 3.6573\tLR: 0.000010\n",
      "Training Epoch: 4 [36192/45000]\tLoss: 3.6225\tLR: 0.000010\n",
      "Training Epoch: 4 [36208/45000]\tLoss: 3.5734\tLR: 0.000010\n",
      "Training Epoch: 4 [36224/45000]\tLoss: 3.5867\tLR: 0.000010\n",
      "Training Epoch: 4 [36240/45000]\tLoss: 3.7393\tLR: 0.000010\n",
      "Training Epoch: 4 [36256/45000]\tLoss: 3.5833\tLR: 0.000010\n",
      "Training Epoch: 4 [36272/45000]\tLoss: 3.5462\tLR: 0.000010\n",
      "Training Epoch: 4 [36288/45000]\tLoss: 3.5817\tLR: 0.000010\n",
      "Training Epoch: 4 [36304/45000]\tLoss: 3.5740\tLR: 0.000010\n",
      "Training Epoch: 4 [36320/45000]\tLoss: 3.5491\tLR: 0.000010\n",
      "Training Epoch: 4 [36336/45000]\tLoss: 3.6330\tLR: 0.000010\n",
      "Training Epoch: 4 [36352/45000]\tLoss: 3.4248\tLR: 0.000010\n",
      "Training Epoch: 4 [36368/45000]\tLoss: 3.6258\tLR: 0.000010\n",
      "Training Epoch: 4 [36384/45000]\tLoss: 3.6092\tLR: 0.000010\n",
      "Training Epoch: 4 [36400/45000]\tLoss: 3.5868\tLR: 0.000010\n",
      "Training Epoch: 4 [36416/45000]\tLoss: 3.5436\tLR: 0.000010\n",
      "Training Epoch: 4 [36432/45000]\tLoss: 3.5056\tLR: 0.000010\n",
      "Training Epoch: 4 [36448/45000]\tLoss: 3.6525\tLR: 0.000010\n",
      "Training Epoch: 4 [36464/45000]\tLoss: 3.5611\tLR: 0.000010\n",
      "Training Epoch: 4 [36480/45000]\tLoss: 3.5648\tLR: 0.000010\n",
      "Training Epoch: 4 [36496/45000]\tLoss: 3.5949\tLR: 0.000010\n",
      "Training Epoch: 4 [36512/45000]\tLoss: 3.5780\tLR: 0.000010\n",
      "Training Epoch: 4 [36528/45000]\tLoss: 3.7297\tLR: 0.000010\n",
      "Training Epoch: 4 [36544/45000]\tLoss: 3.6265\tLR: 0.000010\n",
      "Training Epoch: 4 [36560/45000]\tLoss: 3.5167\tLR: 0.000010\n",
      "Training Epoch: 4 [36576/45000]\tLoss: 3.6225\tLR: 0.000010\n",
      "Training Epoch: 4 [36592/45000]\tLoss: 3.6100\tLR: 0.000010\n",
      "Training Epoch: 4 [36608/45000]\tLoss: 3.5493\tLR: 0.000010\n",
      "Training Epoch: 4 [36624/45000]\tLoss: 3.5176\tLR: 0.000010\n",
      "Training Epoch: 4 [36640/45000]\tLoss: 3.5605\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [36656/45000]\tLoss: 3.5415\tLR: 0.000010\n",
      "Training Epoch: 4 [36672/45000]\tLoss: 3.6400\tLR: 0.000010\n",
      "Training Epoch: 4 [36688/45000]\tLoss: 3.5446\tLR: 0.000010\n",
      "Training Epoch: 4 [36704/45000]\tLoss: 3.5552\tLR: 0.000010\n",
      "Training Epoch: 4 [36720/45000]\tLoss: 3.5592\tLR: 0.000010\n",
      "Training Epoch: 4 [36736/45000]\tLoss: 3.5459\tLR: 0.000010\n",
      "Training Epoch: 4 [36752/45000]\tLoss: 3.4974\tLR: 0.000010\n",
      "Training Epoch: 4 [36768/45000]\tLoss: 3.5568\tLR: 0.000010\n",
      "Training Epoch: 4 [36784/45000]\tLoss: 3.5595\tLR: 0.000010\n",
      "Training Epoch: 4 [36800/45000]\tLoss: 3.6150\tLR: 0.000010\n",
      "Training Epoch: 4 [36816/45000]\tLoss: 3.5916\tLR: 0.000010\n",
      "Training Epoch: 4 [36832/45000]\tLoss: 3.4926\tLR: 0.000010\n",
      "Training Epoch: 4 [36848/45000]\tLoss: 3.6165\tLR: 0.000010\n",
      "Training Epoch: 4 [36864/45000]\tLoss: 3.4956\tLR: 0.000010\n",
      "Training Epoch: 4 [36880/45000]\tLoss: 3.5915\tLR: 0.000010\n",
      "Training Epoch: 4 [36896/45000]\tLoss: 3.4808\tLR: 0.000010\n",
      "Training Epoch: 4 [36912/45000]\tLoss: 3.6436\tLR: 0.000010\n",
      "Training Epoch: 4 [36928/45000]\tLoss: 3.5579\tLR: 0.000010\n",
      "Training Epoch: 4 [36944/45000]\tLoss: 3.5344\tLR: 0.000010\n",
      "Training Epoch: 4 [36960/45000]\tLoss: 3.5771\tLR: 0.000010\n",
      "Training Epoch: 4 [36976/45000]\tLoss: 3.5243\tLR: 0.000010\n",
      "Training Epoch: 4 [36992/45000]\tLoss: 3.6712\tLR: 0.000010\n",
      "Training Epoch: 4 [37008/45000]\tLoss: 3.5717\tLR: 0.000010\n",
      "Training Epoch: 4 [37024/45000]\tLoss: 3.6225\tLR: 0.000010\n",
      "Training Epoch: 4 [37040/45000]\tLoss: 3.5592\tLR: 0.000010\n",
      "Training Epoch: 4 [37056/45000]\tLoss: 3.6582\tLR: 0.000010\n",
      "Training Epoch: 4 [37072/45000]\tLoss: 3.6180\tLR: 0.000010\n",
      "Training Epoch: 4 [37088/45000]\tLoss: 3.5819\tLR: 0.000010\n",
      "Training Epoch: 4 [37104/45000]\tLoss: 3.6204\tLR: 0.000010\n",
      "Training Epoch: 4 [37120/45000]\tLoss: 3.5733\tLR: 0.000010\n",
      "Training Epoch: 4 [37136/45000]\tLoss: 3.6195\tLR: 0.000010\n",
      "Training Epoch: 4 [37152/45000]\tLoss: 3.6524\tLR: 0.000010\n",
      "Training Epoch: 4 [37168/45000]\tLoss: 3.6299\tLR: 0.000010\n",
      "Training Epoch: 4 [37184/45000]\tLoss: 3.5862\tLR: 0.000010\n",
      "Training Epoch: 4 [37200/45000]\tLoss: 3.6960\tLR: 0.000010\n",
      "Training Epoch: 4 [37216/45000]\tLoss: 3.5251\tLR: 0.000010\n",
      "Training Epoch: 4 [37232/45000]\tLoss: 3.5505\tLR: 0.000010\n",
      "Training Epoch: 4 [37248/45000]\tLoss: 3.6749\tLR: 0.000010\n",
      "Training Epoch: 4 [37264/45000]\tLoss: 3.5215\tLR: 0.000010\n",
      "Training Epoch: 4 [37280/45000]\tLoss: 3.6212\tLR: 0.000010\n",
      "Training Epoch: 4 [37296/45000]\tLoss: 3.5143\tLR: 0.000010\n",
      "Training Epoch: 4 [37312/45000]\tLoss: 3.5741\tLR: 0.000010\n",
      "Training Epoch: 4 [37328/45000]\tLoss: 3.5549\tLR: 0.000010\n",
      "Training Epoch: 4 [37344/45000]\tLoss: 3.5327\tLR: 0.000010\n",
      "Training Epoch: 4 [37360/45000]\tLoss: 3.3974\tLR: 0.000010\n",
      "Training Epoch: 4 [37376/45000]\tLoss: 3.5198\tLR: 0.000010\n",
      "Training Epoch: 4 [37392/45000]\tLoss: 3.6298\tLR: 0.000010\n",
      "Training Epoch: 4 [37408/45000]\tLoss: 3.6336\tLR: 0.000010\n",
      "Training Epoch: 4 [37424/45000]\tLoss: 3.5467\tLR: 0.000010\n",
      "Training Epoch: 4 [37440/45000]\tLoss: 3.5800\tLR: 0.000010\n",
      "Training Epoch: 4 [37456/45000]\tLoss: 3.5354\tLR: 0.000010\n",
      "Training Epoch: 4 [37472/45000]\tLoss: 3.7466\tLR: 0.000010\n",
      "Training Epoch: 4 [37488/45000]\tLoss: 3.5883\tLR: 0.000010\n",
      "Training Epoch: 4 [37504/45000]\tLoss: 3.5420\tLR: 0.000010\n",
      "Training Epoch: 4 [37520/45000]\tLoss: 3.4707\tLR: 0.000010\n",
      "Training Epoch: 4 [37536/45000]\tLoss: 3.5485\tLR: 0.000010\n",
      "Training Epoch: 4 [37552/45000]\tLoss: 3.6514\tLR: 0.000010\n",
      "Training Epoch: 4 [37568/45000]\tLoss: 3.7034\tLR: 0.000010\n",
      "Training Epoch: 4 [37584/45000]\tLoss: 3.5439\tLR: 0.000010\n",
      "Training Epoch: 4 [37600/45000]\tLoss: 3.5440\tLR: 0.000010\n",
      "Training Epoch: 4 [37616/45000]\tLoss: 3.6249\tLR: 0.000010\n",
      "Training Epoch: 4 [37632/45000]\tLoss: 3.5620\tLR: 0.000010\n",
      "Training Epoch: 4 [37648/45000]\tLoss: 3.5011\tLR: 0.000010\n",
      "Training Epoch: 4 [37664/45000]\tLoss: 3.4976\tLR: 0.000010\n",
      "Training Epoch: 4 [37680/45000]\tLoss: 3.6369\tLR: 0.000010\n",
      "Training Epoch: 4 [37696/45000]\tLoss: 3.6351\tLR: 0.000010\n",
      "Training Epoch: 4 [37712/45000]\tLoss: 3.6567\tLR: 0.000010\n",
      "Training Epoch: 4 [37728/45000]\tLoss: 3.5011\tLR: 0.000010\n",
      "Training Epoch: 4 [37744/45000]\tLoss: 3.5499\tLR: 0.000010\n",
      "Training Epoch: 4 [37760/45000]\tLoss: 3.7642\tLR: 0.000010\n",
      "Training Epoch: 4 [37776/45000]\tLoss: 3.6899\tLR: 0.000010\n",
      "Training Epoch: 4 [37792/45000]\tLoss: 3.5628\tLR: 0.000010\n",
      "Training Epoch: 4 [37808/45000]\tLoss: 3.5560\tLR: 0.000010\n",
      "Training Epoch: 4 [37824/45000]\tLoss: 3.6864\tLR: 0.000010\n",
      "Training Epoch: 4 [37840/45000]\tLoss: 3.6574\tLR: 0.000010\n",
      "Training Epoch: 4 [37856/45000]\tLoss: 3.6874\tLR: 0.000010\n",
      "Training Epoch: 4 [37872/45000]\tLoss: 3.5561\tLR: 0.000010\n",
      "Training Epoch: 4 [37888/45000]\tLoss: 3.4875\tLR: 0.000010\n",
      "Training Epoch: 4 [37904/45000]\tLoss: 3.7029\tLR: 0.000010\n",
      "Training Epoch: 4 [37920/45000]\tLoss: 3.5713\tLR: 0.000010\n",
      "Training Epoch: 4 [37936/45000]\tLoss: 3.4782\tLR: 0.000010\n",
      "Training Epoch: 4 [37952/45000]\tLoss: 3.5513\tLR: 0.000010\n",
      "Training Epoch: 4 [37968/45000]\tLoss: 3.6082\tLR: 0.000010\n",
      "Training Epoch: 4 [37984/45000]\tLoss: 3.5203\tLR: 0.000010\n",
      "Training Epoch: 4 [38000/45000]\tLoss: 3.6063\tLR: 0.000010\n",
      "Training Epoch: 4 [38016/45000]\tLoss: 3.5646\tLR: 0.000010\n",
      "Training Epoch: 4 [38032/45000]\tLoss: 3.5566\tLR: 0.000010\n",
      "Training Epoch: 4 [38048/45000]\tLoss: 3.6070\tLR: 0.000010\n",
      "Training Epoch: 4 [38064/45000]\tLoss: 3.5184\tLR: 0.000010\n",
      "Training Epoch: 4 [38080/45000]\tLoss: 3.7407\tLR: 0.000010\n",
      "Training Epoch: 4 [38096/45000]\tLoss: 3.6187\tLR: 0.000010\n",
      "Training Epoch: 4 [38112/45000]\tLoss: 3.5029\tLR: 0.000010\n",
      "Training Epoch: 4 [38128/45000]\tLoss: 3.5201\tLR: 0.000010\n",
      "Training Epoch: 4 [38144/45000]\tLoss: 3.5714\tLR: 0.000010\n",
      "Training Epoch: 4 [38160/45000]\tLoss: 3.6544\tLR: 0.000010\n",
      "Training Epoch: 4 [38176/45000]\tLoss: 3.7183\tLR: 0.000010\n",
      "Training Epoch: 4 [38192/45000]\tLoss: 3.5977\tLR: 0.000010\n",
      "Training Epoch: 4 [38208/45000]\tLoss: 3.6035\tLR: 0.000010\n",
      "Training Epoch: 4 [38224/45000]\tLoss: 3.6097\tLR: 0.000010\n",
      "Training Epoch: 4 [38240/45000]\tLoss: 3.6380\tLR: 0.000010\n",
      "Training Epoch: 4 [38256/45000]\tLoss: 3.6308\tLR: 0.000010\n",
      "Training Epoch: 4 [38272/45000]\tLoss: 3.5602\tLR: 0.000010\n",
      "Training Epoch: 4 [38288/45000]\tLoss: 3.6213\tLR: 0.000010\n",
      "Training Epoch: 4 [38304/45000]\tLoss: 3.6165\tLR: 0.000010\n",
      "Training Epoch: 4 [38320/45000]\tLoss: 3.5862\tLR: 0.000010\n",
      "Training Epoch: 4 [38336/45000]\tLoss: 3.5591\tLR: 0.000010\n",
      "Training Epoch: 4 [38352/45000]\tLoss: 3.5336\tLR: 0.000010\n",
      "Training Epoch: 4 [38368/45000]\tLoss: 3.5842\tLR: 0.000010\n",
      "Training Epoch: 4 [38384/45000]\tLoss: 3.5386\tLR: 0.000010\n",
      "Training Epoch: 4 [38400/45000]\tLoss: 3.5491\tLR: 0.000010\n",
      "Training Epoch: 4 [38416/45000]\tLoss: 3.4919\tLR: 0.000010\n",
      "Training Epoch: 4 [38432/45000]\tLoss: 3.7076\tLR: 0.000010\n",
      "Training Epoch: 4 [38448/45000]\tLoss: 3.6027\tLR: 0.000010\n",
      "Training Epoch: 4 [38464/45000]\tLoss: 3.6422\tLR: 0.000010\n",
      "Training Epoch: 4 [38480/45000]\tLoss: 3.5560\tLR: 0.000010\n",
      "Training Epoch: 4 [38496/45000]\tLoss: 3.5805\tLR: 0.000010\n",
      "Training Epoch: 4 [38512/45000]\tLoss: 3.4748\tLR: 0.000010\n",
      "Training Epoch: 4 [38528/45000]\tLoss: 3.6547\tLR: 0.000010\n",
      "Training Epoch: 4 [38544/45000]\tLoss: 3.4630\tLR: 0.000010\n",
      "Training Epoch: 4 [38560/45000]\tLoss: 3.5567\tLR: 0.000010\n",
      "Training Epoch: 4 [38576/45000]\tLoss: 3.5967\tLR: 0.000010\n",
      "Training Epoch: 4 [38592/45000]\tLoss: 3.6195\tLR: 0.000010\n",
      "Training Epoch: 4 [38608/45000]\tLoss: 3.5510\tLR: 0.000010\n",
      "Training Epoch: 4 [38624/45000]\tLoss: 3.5230\tLR: 0.000010\n",
      "Training Epoch: 4 [38640/45000]\tLoss: 3.6062\tLR: 0.000010\n",
      "Training Epoch: 4 [38656/45000]\tLoss: 3.4637\tLR: 0.000010\n",
      "Training Epoch: 4 [38672/45000]\tLoss: 3.5449\tLR: 0.000010\n",
      "Training Epoch: 4 [38688/45000]\tLoss: 3.5841\tLR: 0.000010\n",
      "Training Epoch: 4 [38704/45000]\tLoss: 3.5064\tLR: 0.000010\n",
      "Training Epoch: 4 [38720/45000]\tLoss: 3.6264\tLR: 0.000010\n",
      "Training Epoch: 4 [38736/45000]\tLoss: 3.5308\tLR: 0.000010\n",
      "Training Epoch: 4 [38752/45000]\tLoss: 3.5430\tLR: 0.000010\n",
      "Training Epoch: 4 [38768/45000]\tLoss: 3.5106\tLR: 0.000010\n",
      "Training Epoch: 4 [38784/45000]\tLoss: 3.5918\tLR: 0.000010\n",
      "Training Epoch: 4 [38800/45000]\tLoss: 3.3525\tLR: 0.000010\n",
      "Training Epoch: 4 [38816/45000]\tLoss: 3.6081\tLR: 0.000010\n",
      "Training Epoch: 4 [38832/45000]\tLoss: 3.5747\tLR: 0.000010\n",
      "Training Epoch: 4 [38848/45000]\tLoss: 3.6031\tLR: 0.000010\n",
      "Training Epoch: 4 [38864/45000]\tLoss: 3.5515\tLR: 0.000010\n",
      "Training Epoch: 4 [38880/45000]\tLoss: 3.5901\tLR: 0.000010\n",
      "Training Epoch: 4 [38896/45000]\tLoss: 3.4509\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [38912/45000]\tLoss: 3.6490\tLR: 0.000010\n",
      "Training Epoch: 4 [38928/45000]\tLoss: 3.6302\tLR: 0.000010\n",
      "Training Epoch: 4 [38944/45000]\tLoss: 3.6285\tLR: 0.000010\n",
      "Training Epoch: 4 [38960/45000]\tLoss: 3.6876\tLR: 0.000010\n",
      "Training Epoch: 4 [38976/45000]\tLoss: 3.6338\tLR: 0.000010\n",
      "Training Epoch: 4 [38992/45000]\tLoss: 3.6233\tLR: 0.000010\n",
      "Training Epoch: 4 [39008/45000]\tLoss: 3.6359\tLR: 0.000010\n",
      "Training Epoch: 4 [39024/45000]\tLoss: 3.5925\tLR: 0.000010\n",
      "Training Epoch: 4 [39040/45000]\tLoss: 3.5633\tLR: 0.000010\n",
      "Training Epoch: 4 [39056/45000]\tLoss: 3.7182\tLR: 0.000010\n",
      "Training Epoch: 4 [39072/45000]\tLoss: 3.5760\tLR: 0.000010\n",
      "Training Epoch: 4 [39088/45000]\tLoss: 3.6582\tLR: 0.000010\n",
      "Training Epoch: 4 [39104/45000]\tLoss: 3.5935\tLR: 0.000010\n",
      "Training Epoch: 4 [39120/45000]\tLoss: 3.5494\tLR: 0.000010\n",
      "Training Epoch: 4 [39136/45000]\tLoss: 3.6019\tLR: 0.000010\n",
      "Training Epoch: 4 [39152/45000]\tLoss: 3.5707\tLR: 0.000010\n",
      "Training Epoch: 4 [39168/45000]\tLoss: 3.4808\tLR: 0.000010\n",
      "Training Epoch: 4 [39184/45000]\tLoss: 3.6213\tLR: 0.000010\n",
      "Training Epoch: 4 [39200/45000]\tLoss: 3.4668\tLR: 0.000010\n",
      "Training Epoch: 4 [39216/45000]\tLoss: 3.5707\tLR: 0.000010\n",
      "Training Epoch: 4 [39232/45000]\tLoss: 3.5122\tLR: 0.000010\n",
      "Training Epoch: 4 [39248/45000]\tLoss: 3.6332\tLR: 0.000010\n",
      "Training Epoch: 4 [39264/45000]\tLoss: 3.4803\tLR: 0.000010\n",
      "Training Epoch: 4 [39280/45000]\tLoss: 3.5469\tLR: 0.000010\n",
      "Training Epoch: 4 [39296/45000]\tLoss: 3.6653\tLR: 0.000010\n",
      "Training Epoch: 4 [39312/45000]\tLoss: 3.6060\tLR: 0.000010\n",
      "Training Epoch: 4 [39328/45000]\tLoss: 3.6722\tLR: 0.000010\n",
      "Training Epoch: 4 [39344/45000]\tLoss: 3.4803\tLR: 0.000010\n",
      "Training Epoch: 4 [39360/45000]\tLoss: 3.5560\tLR: 0.000010\n",
      "Training Epoch: 4 [39376/45000]\tLoss: 3.5176\tLR: 0.000010\n",
      "Training Epoch: 4 [39392/45000]\tLoss: 3.6103\tLR: 0.000010\n",
      "Training Epoch: 4 [39408/45000]\tLoss: 3.5532\tLR: 0.000010\n",
      "Training Epoch: 4 [39424/45000]\tLoss: 3.5309\tLR: 0.000010\n",
      "Training Epoch: 4 [39440/45000]\tLoss: 3.5353\tLR: 0.000010\n",
      "Training Epoch: 4 [39456/45000]\tLoss: 3.5951\tLR: 0.000010\n",
      "Training Epoch: 4 [39472/45000]\tLoss: 3.5422\tLR: 0.000010\n",
      "Training Epoch: 4 [39488/45000]\tLoss: 3.6703\tLR: 0.000010\n",
      "Training Epoch: 4 [39504/45000]\tLoss: 3.5939\tLR: 0.000010\n",
      "Training Epoch: 4 [39520/45000]\tLoss: 3.5052\tLR: 0.000010\n",
      "Training Epoch: 4 [39536/45000]\tLoss: 3.6007\tLR: 0.000010\n",
      "Training Epoch: 4 [39552/45000]\tLoss: 3.5997\tLR: 0.000010\n",
      "Training Epoch: 4 [39568/45000]\tLoss: 3.5993\tLR: 0.000010\n",
      "Training Epoch: 4 [39584/45000]\tLoss: 3.5927\tLR: 0.000010\n",
      "Training Epoch: 4 [39600/45000]\tLoss: 3.6120\tLR: 0.000010\n",
      "Training Epoch: 4 [39616/45000]\tLoss: 3.7153\tLR: 0.000010\n",
      "Training Epoch: 4 [39632/45000]\tLoss: 3.5488\tLR: 0.000010\n",
      "Training Epoch: 4 [39648/45000]\tLoss: 3.5205\tLR: 0.000010\n",
      "Training Epoch: 4 [39664/45000]\tLoss: 3.5310\tLR: 0.000010\n",
      "Training Epoch: 4 [39680/45000]\tLoss: 3.7240\tLR: 0.000010\n",
      "Training Epoch: 4 [39696/45000]\tLoss: 3.5181\tLR: 0.000010\n",
      "Training Epoch: 4 [39712/45000]\tLoss: 3.5384\tLR: 0.000010\n",
      "Training Epoch: 4 [39728/45000]\tLoss: 3.6468\tLR: 0.000010\n",
      "Training Epoch: 4 [39744/45000]\tLoss: 3.4993\tLR: 0.000010\n",
      "Training Epoch: 4 [39760/45000]\tLoss: 3.6291\tLR: 0.000010\n",
      "Training Epoch: 4 [39776/45000]\tLoss: 3.4588\tLR: 0.000010\n",
      "Training Epoch: 4 [39792/45000]\tLoss: 3.5150\tLR: 0.000010\n",
      "Training Epoch: 4 [39808/45000]\tLoss: 3.6558\tLR: 0.000010\n",
      "Training Epoch: 4 [39824/45000]\tLoss: 3.6393\tLR: 0.000010\n",
      "Training Epoch: 4 [39840/45000]\tLoss: 3.4651\tLR: 0.000010\n",
      "Training Epoch: 4 [39856/45000]\tLoss: 3.5199\tLR: 0.000010\n",
      "Training Epoch: 4 [39872/45000]\tLoss: 3.6324\tLR: 0.000010\n",
      "Training Epoch: 4 [39888/45000]\tLoss: 3.6450\tLR: 0.000010\n",
      "Training Epoch: 4 [39904/45000]\tLoss: 3.5251\tLR: 0.000010\n",
      "Training Epoch: 4 [39920/45000]\tLoss: 3.5680\tLR: 0.000010\n",
      "Training Epoch: 4 [39936/45000]\tLoss: 3.5523\tLR: 0.000010\n",
      "Training Epoch: 4 [39952/45000]\tLoss: 3.6474\tLR: 0.000010\n",
      "Training Epoch: 4 [39968/45000]\tLoss: 3.5387\tLR: 0.000010\n",
      "Training Epoch: 4 [39984/45000]\tLoss: 3.6927\tLR: 0.000010\n",
      "Training Epoch: 4 [40000/45000]\tLoss: 3.5119\tLR: 0.000010\n",
      "Training Epoch: 4 [40016/45000]\tLoss: 3.6062\tLR: 0.000010\n",
      "Training Epoch: 4 [40032/45000]\tLoss: 3.6458\tLR: 0.000010\n",
      "Training Epoch: 4 [40048/45000]\tLoss: 3.5366\tLR: 0.000010\n",
      "Training Epoch: 4 [40064/45000]\tLoss: 3.6906\tLR: 0.000010\n",
      "Training Epoch: 4 [40080/45000]\tLoss: 3.6183\tLR: 0.000010\n",
      "Training Epoch: 4 [40096/45000]\tLoss: 3.6331\tLR: 0.000010\n",
      "Training Epoch: 4 [40112/45000]\tLoss: 3.5228\tLR: 0.000010\n",
      "Training Epoch: 4 [40128/45000]\tLoss: 3.5235\tLR: 0.000010\n",
      "Training Epoch: 4 [40144/45000]\tLoss: 3.5096\tLR: 0.000010\n",
      "Training Epoch: 4 [40160/45000]\tLoss: 3.5366\tLR: 0.000010\n",
      "Training Epoch: 4 [40176/45000]\tLoss: 3.4357\tLR: 0.000010\n",
      "Training Epoch: 4 [40192/45000]\tLoss: 3.4803\tLR: 0.000010\n",
      "Training Epoch: 4 [40208/45000]\tLoss: 3.4718\tLR: 0.000010\n",
      "Training Epoch: 4 [40224/45000]\tLoss: 3.5842\tLR: 0.000010\n",
      "Training Epoch: 4 [40240/45000]\tLoss: 3.4733\tLR: 0.000010\n",
      "Training Epoch: 4 [40256/45000]\tLoss: 3.6632\tLR: 0.000010\n",
      "Training Epoch: 4 [40272/45000]\tLoss: 3.4873\tLR: 0.000010\n",
      "Training Epoch: 4 [40288/45000]\tLoss: 3.6458\tLR: 0.000010\n",
      "Training Epoch: 4 [40304/45000]\tLoss: 3.6064\tLR: 0.000010\n",
      "Training Epoch: 4 [40320/45000]\tLoss: 3.4936\tLR: 0.000010\n",
      "Training Epoch: 4 [40336/45000]\tLoss: 3.6029\tLR: 0.000010\n",
      "Training Epoch: 4 [40352/45000]\tLoss: 3.5599\tLR: 0.000010\n",
      "Training Epoch: 4 [40368/45000]\tLoss: 3.6062\tLR: 0.000010\n",
      "Training Epoch: 4 [40384/45000]\tLoss: 3.6738\tLR: 0.000010\n",
      "Training Epoch: 4 [40400/45000]\tLoss: 3.4455\tLR: 0.000010\n",
      "Training Epoch: 4 [40416/45000]\tLoss: 3.5351\tLR: 0.000010\n",
      "Training Epoch: 4 [40432/45000]\tLoss: 3.6460\tLR: 0.000010\n",
      "Training Epoch: 4 [40448/45000]\tLoss: 3.6363\tLR: 0.000010\n",
      "Training Epoch: 4 [40464/45000]\tLoss: 3.7148\tLR: 0.000010\n",
      "Training Epoch: 4 [40480/45000]\tLoss: 3.6896\tLR: 0.000010\n",
      "Training Epoch: 4 [40496/45000]\tLoss: 3.5860\tLR: 0.000010\n",
      "Training Epoch: 4 [40512/45000]\tLoss: 3.5125\tLR: 0.000010\n",
      "Training Epoch: 4 [40528/45000]\tLoss: 3.4936\tLR: 0.000010\n",
      "Training Epoch: 4 [40544/45000]\tLoss: 3.6120\tLR: 0.000010\n",
      "Training Epoch: 4 [40560/45000]\tLoss: 3.7279\tLR: 0.000010\n",
      "Training Epoch: 4 [40576/45000]\tLoss: 3.5682\tLR: 0.000010\n",
      "Training Epoch: 4 [40592/45000]\tLoss: 3.5903\tLR: 0.000010\n",
      "Training Epoch: 4 [40608/45000]\tLoss: 3.5657\tLR: 0.000010\n",
      "Training Epoch: 4 [40624/45000]\tLoss: 3.4943\tLR: 0.000010\n",
      "Training Epoch: 4 [40640/45000]\tLoss: 3.6055\tLR: 0.000010\n",
      "Training Epoch: 4 [40656/45000]\tLoss: 3.6870\tLR: 0.000010\n",
      "Training Epoch: 4 [40672/45000]\tLoss: 3.6009\tLR: 0.000010\n",
      "Training Epoch: 4 [40688/45000]\tLoss: 3.5397\tLR: 0.000010\n",
      "Training Epoch: 4 [40704/45000]\tLoss: 3.5147\tLR: 0.000010\n",
      "Training Epoch: 4 [40720/45000]\tLoss: 3.5403\tLR: 0.000010\n",
      "Training Epoch: 4 [40736/45000]\tLoss: 3.5001\tLR: 0.000010\n",
      "Training Epoch: 4 [40752/45000]\tLoss: 3.4965\tLR: 0.000010\n",
      "Training Epoch: 4 [40768/45000]\tLoss: 3.5756\tLR: 0.000010\n",
      "Training Epoch: 4 [40784/45000]\tLoss: 3.6183\tLR: 0.000010\n",
      "Training Epoch: 4 [40800/45000]\tLoss: 3.5943\tLR: 0.000010\n",
      "Training Epoch: 4 [40816/45000]\tLoss: 3.5211\tLR: 0.000010\n",
      "Training Epoch: 4 [40832/45000]\tLoss: 3.6652\tLR: 0.000010\n",
      "Training Epoch: 4 [40848/45000]\tLoss: 3.5361\tLR: 0.000010\n",
      "Training Epoch: 4 [40864/45000]\tLoss: 3.5170\tLR: 0.000010\n",
      "Training Epoch: 4 [40880/45000]\tLoss: 3.4026\tLR: 0.000010\n",
      "Training Epoch: 4 [40896/45000]\tLoss: 3.6724\tLR: 0.000010\n",
      "Training Epoch: 4 [40912/45000]\tLoss: 3.5059\tLR: 0.000010\n",
      "Training Epoch: 4 [40928/45000]\tLoss: 3.6433\tLR: 0.000010\n",
      "Training Epoch: 4 [40944/45000]\tLoss: 3.6566\tLR: 0.000010\n",
      "Training Epoch: 4 [40960/45000]\tLoss: 3.6131\tLR: 0.000010\n",
      "Training Epoch: 4 [40976/45000]\tLoss: 3.5458\tLR: 0.000010\n",
      "Training Epoch: 4 [40992/45000]\tLoss: 3.5589\tLR: 0.000010\n",
      "Training Epoch: 4 [41008/45000]\tLoss: 3.5435\tLR: 0.000010\n",
      "Training Epoch: 4 [41024/45000]\tLoss: 3.5307\tLR: 0.000010\n",
      "Training Epoch: 4 [41040/45000]\tLoss: 3.6300\tLR: 0.000010\n",
      "Training Epoch: 4 [41056/45000]\tLoss: 3.5701\tLR: 0.000010\n",
      "Training Epoch: 4 [41072/45000]\tLoss: 3.7185\tLR: 0.000010\n",
      "Training Epoch: 4 [41088/45000]\tLoss: 3.5084\tLR: 0.000010\n",
      "Training Epoch: 4 [41104/45000]\tLoss: 3.6302\tLR: 0.000010\n",
      "Training Epoch: 4 [41120/45000]\tLoss: 3.4645\tLR: 0.000010\n",
      "Training Epoch: 4 [41136/45000]\tLoss: 3.6624\tLR: 0.000010\n",
      "Training Epoch: 4 [41152/45000]\tLoss: 3.5612\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [41168/45000]\tLoss: 3.6761\tLR: 0.000010\n",
      "Training Epoch: 4 [41184/45000]\tLoss: 3.6270\tLR: 0.000010\n",
      "Training Epoch: 4 [41200/45000]\tLoss: 3.4579\tLR: 0.000010\n",
      "Training Epoch: 4 [41216/45000]\tLoss: 3.7717\tLR: 0.000010\n",
      "Training Epoch: 4 [41232/45000]\tLoss: 3.5652\tLR: 0.000010\n",
      "Training Epoch: 4 [41248/45000]\tLoss: 3.5322\tLR: 0.000010\n",
      "Training Epoch: 4 [41264/45000]\tLoss: 3.5483\tLR: 0.000010\n",
      "Training Epoch: 4 [41280/45000]\tLoss: 3.6224\tLR: 0.000010\n",
      "Training Epoch: 4 [41296/45000]\tLoss: 3.6330\tLR: 0.000010\n",
      "Training Epoch: 4 [41312/45000]\tLoss: 3.6143\tLR: 0.000010\n",
      "Training Epoch: 4 [41328/45000]\tLoss: 3.5317\tLR: 0.000010\n",
      "Training Epoch: 4 [41344/45000]\tLoss: 3.6651\tLR: 0.000010\n",
      "Training Epoch: 4 [41360/45000]\tLoss: 3.5645\tLR: 0.000010\n",
      "Training Epoch: 4 [41376/45000]\tLoss: 3.6364\tLR: 0.000010\n",
      "Training Epoch: 4 [41392/45000]\tLoss: 3.6590\tLR: 0.000010\n",
      "Training Epoch: 4 [41408/45000]\tLoss: 3.5860\tLR: 0.000010\n",
      "Training Epoch: 4 [41424/45000]\tLoss: 3.6267\tLR: 0.000010\n",
      "Training Epoch: 4 [41440/45000]\tLoss: 3.5185\tLR: 0.000010\n",
      "Training Epoch: 4 [41456/45000]\tLoss: 3.5414\tLR: 0.000010\n",
      "Training Epoch: 4 [41472/45000]\tLoss: 3.5215\tLR: 0.000010\n",
      "Training Epoch: 4 [41488/45000]\tLoss: 3.5882\tLR: 0.000010\n",
      "Training Epoch: 4 [41504/45000]\tLoss: 3.5818\tLR: 0.000010\n",
      "Training Epoch: 4 [41520/45000]\tLoss: 3.6358\tLR: 0.000010\n",
      "Training Epoch: 4 [41536/45000]\tLoss: 3.5673\tLR: 0.000010\n",
      "Training Epoch: 4 [41552/45000]\tLoss: 3.5286\tLR: 0.000010\n",
      "Training Epoch: 4 [41568/45000]\tLoss: 3.5050\tLR: 0.000010\n",
      "Training Epoch: 4 [41584/45000]\tLoss: 3.5541\tLR: 0.000010\n",
      "Training Epoch: 4 [41600/45000]\tLoss: 3.5041\tLR: 0.000010\n",
      "Training Epoch: 4 [41616/45000]\tLoss: 3.6147\tLR: 0.000010\n",
      "Training Epoch: 4 [41632/45000]\tLoss: 3.6035\tLR: 0.000010\n",
      "Training Epoch: 4 [41648/45000]\tLoss: 3.5271\tLR: 0.000010\n",
      "Training Epoch: 4 [41664/45000]\tLoss: 3.4626\tLR: 0.000010\n",
      "Training Epoch: 4 [41680/45000]\tLoss: 3.5586\tLR: 0.000010\n",
      "Training Epoch: 4 [41696/45000]\tLoss: 3.5351\tLR: 0.000010\n",
      "Training Epoch: 4 [41712/45000]\tLoss: 3.6941\tLR: 0.000010\n",
      "Training Epoch: 4 [41728/45000]\tLoss: 3.5849\tLR: 0.000010\n",
      "Training Epoch: 4 [41744/45000]\tLoss: 3.6516\tLR: 0.000010\n",
      "Training Epoch: 4 [41760/45000]\tLoss: 3.6314\tLR: 0.000010\n",
      "Training Epoch: 4 [41776/45000]\tLoss: 3.5011\tLR: 0.000010\n",
      "Training Epoch: 4 [41792/45000]\tLoss: 3.5806\tLR: 0.000010\n",
      "Training Epoch: 4 [41808/45000]\tLoss: 3.4968\tLR: 0.000010\n",
      "Training Epoch: 4 [41824/45000]\tLoss: 3.5606\tLR: 0.000010\n",
      "Training Epoch: 4 [41840/45000]\tLoss: 3.6856\tLR: 0.000010\n",
      "Training Epoch: 4 [41856/45000]\tLoss: 3.6679\tLR: 0.000010\n",
      "Training Epoch: 4 [41872/45000]\tLoss: 3.5665\tLR: 0.000010\n",
      "Training Epoch: 4 [41888/45000]\tLoss: 3.6822\tLR: 0.000010\n",
      "Training Epoch: 4 [41904/45000]\tLoss: 3.6085\tLR: 0.000010\n",
      "Training Epoch: 4 [41920/45000]\tLoss: 3.5661\tLR: 0.000010\n",
      "Training Epoch: 4 [41936/45000]\tLoss: 3.5719\tLR: 0.000010\n",
      "Training Epoch: 4 [41952/45000]\tLoss: 3.4769\tLR: 0.000010\n",
      "Training Epoch: 4 [41968/45000]\tLoss: 3.6130\tLR: 0.000010\n",
      "Training Epoch: 4 [41984/45000]\tLoss: 3.5948\tLR: 0.000010\n",
      "Training Epoch: 4 [42000/45000]\tLoss: 3.8243\tLR: 0.000010\n",
      "Training Epoch: 4 [42016/45000]\tLoss: 3.5844\tLR: 0.000010\n",
      "Training Epoch: 4 [42032/45000]\tLoss: 3.5248\tLR: 0.000010\n",
      "Training Epoch: 4 [42048/45000]\tLoss: 3.5878\tLR: 0.000010\n",
      "Training Epoch: 4 [42064/45000]\tLoss: 3.6502\tLR: 0.000010\n",
      "Training Epoch: 4 [42080/45000]\tLoss: 3.4839\tLR: 0.000010\n",
      "Training Epoch: 4 [42096/45000]\tLoss: 3.5412\tLR: 0.000010\n",
      "Training Epoch: 4 [42112/45000]\tLoss: 3.6073\tLR: 0.000010\n",
      "Training Epoch: 4 [42128/45000]\tLoss: 3.6229\tLR: 0.000010\n",
      "Training Epoch: 4 [42144/45000]\tLoss: 3.6903\tLR: 0.000010\n",
      "Training Epoch: 4 [42160/45000]\tLoss: 3.6226\tLR: 0.000010\n",
      "Training Epoch: 4 [42176/45000]\tLoss: 3.6387\tLR: 0.000010\n",
      "Training Epoch: 4 [42192/45000]\tLoss: 3.5546\tLR: 0.000010\n",
      "Training Epoch: 4 [42208/45000]\tLoss: 3.4718\tLR: 0.000010\n",
      "Training Epoch: 4 [42224/45000]\tLoss: 3.4785\tLR: 0.000010\n",
      "Training Epoch: 4 [42240/45000]\tLoss: 3.5331\tLR: 0.000010\n",
      "Training Epoch: 4 [42256/45000]\tLoss: 3.5679\tLR: 0.000010\n",
      "Training Epoch: 4 [42272/45000]\tLoss: 3.5900\tLR: 0.000010\n",
      "Training Epoch: 4 [42288/45000]\tLoss: 3.7344\tLR: 0.000010\n",
      "Training Epoch: 4 [42304/45000]\tLoss: 3.5826\tLR: 0.000010\n",
      "Training Epoch: 4 [42320/45000]\tLoss: 3.6549\tLR: 0.000010\n",
      "Training Epoch: 4 [42336/45000]\tLoss: 3.6984\tLR: 0.000010\n",
      "Training Epoch: 4 [42352/45000]\tLoss: 3.6878\tLR: 0.000010\n",
      "Training Epoch: 4 [42368/45000]\tLoss: 3.5757\tLR: 0.000010\n",
      "Training Epoch: 4 [42384/45000]\tLoss: 3.4646\tLR: 0.000010\n",
      "Training Epoch: 4 [42400/45000]\tLoss: 3.5758\tLR: 0.000010\n",
      "Training Epoch: 4 [42416/45000]\tLoss: 3.5393\tLR: 0.000010\n",
      "Training Epoch: 4 [42432/45000]\tLoss: 3.6129\tLR: 0.000010\n",
      "Training Epoch: 4 [42448/45000]\tLoss: 3.5877\tLR: 0.000010\n",
      "Training Epoch: 4 [42464/45000]\tLoss: 3.5667\tLR: 0.000010\n",
      "Training Epoch: 4 [42480/45000]\tLoss: 3.6047\tLR: 0.000010\n",
      "Training Epoch: 4 [42496/45000]\tLoss: 3.5209\tLR: 0.000010\n",
      "Training Epoch: 4 [42512/45000]\tLoss: 3.5973\tLR: 0.000010\n",
      "Training Epoch: 4 [42528/45000]\tLoss: 3.5480\tLR: 0.000010\n",
      "Training Epoch: 4 [42544/45000]\tLoss: 3.6007\tLR: 0.000010\n",
      "Training Epoch: 4 [42560/45000]\tLoss: 3.6069\tLR: 0.000010\n",
      "Training Epoch: 4 [42576/45000]\tLoss: 3.5622\tLR: 0.000010\n",
      "Training Epoch: 4 [42592/45000]\tLoss: 3.5396\tLR: 0.000010\n",
      "Training Epoch: 4 [42608/45000]\tLoss: 3.6444\tLR: 0.000010\n",
      "Training Epoch: 4 [42624/45000]\tLoss: 3.5997\tLR: 0.000010\n",
      "Training Epoch: 4 [42640/45000]\tLoss: 3.6107\tLR: 0.000010\n",
      "Training Epoch: 4 [42656/45000]\tLoss: 3.6315\tLR: 0.000010\n",
      "Training Epoch: 4 [42672/45000]\tLoss: 3.4625\tLR: 0.000010\n",
      "Training Epoch: 4 [42688/45000]\tLoss: 3.5043\tLR: 0.000010\n",
      "Training Epoch: 4 [42704/45000]\tLoss: 3.4923\tLR: 0.000010\n",
      "Training Epoch: 4 [42720/45000]\tLoss: 3.6737\tLR: 0.000010\n",
      "Training Epoch: 4 [42736/45000]\tLoss: 3.5694\tLR: 0.000010\n",
      "Training Epoch: 4 [42752/45000]\tLoss: 3.5507\tLR: 0.000010\n",
      "Training Epoch: 4 [42768/45000]\tLoss: 3.6248\tLR: 0.000010\n",
      "Training Epoch: 4 [42784/45000]\tLoss: 3.6567\tLR: 0.000010\n",
      "Training Epoch: 4 [42800/45000]\tLoss: 3.7222\tLR: 0.000010\n",
      "Training Epoch: 4 [42816/45000]\tLoss: 3.6265\tLR: 0.000010\n",
      "Training Epoch: 4 [42832/45000]\tLoss: 3.5686\tLR: 0.000010\n",
      "Training Epoch: 4 [42848/45000]\tLoss: 3.7157\tLR: 0.000010\n",
      "Training Epoch: 4 [42864/45000]\tLoss: 3.6547\tLR: 0.000010\n",
      "Training Epoch: 4 [42880/45000]\tLoss: 3.4763\tLR: 0.000010\n",
      "Training Epoch: 4 [42896/45000]\tLoss: 3.5215\tLR: 0.000010\n",
      "Training Epoch: 4 [42912/45000]\tLoss: 3.4961\tLR: 0.000010\n",
      "Training Epoch: 4 [42928/45000]\tLoss: 3.4672\tLR: 0.000010\n",
      "Training Epoch: 4 [42944/45000]\tLoss: 3.5871\tLR: 0.000010\n",
      "Training Epoch: 4 [42960/45000]\tLoss: 3.6692\tLR: 0.000010\n",
      "Training Epoch: 4 [42976/45000]\tLoss: 3.5519\tLR: 0.000010\n",
      "Training Epoch: 4 [42992/45000]\tLoss: 3.6151\tLR: 0.000010\n",
      "Training Epoch: 4 [43008/45000]\tLoss: 3.5989\tLR: 0.000010\n",
      "Training Epoch: 4 [43024/45000]\tLoss: 3.6054\tLR: 0.000010\n",
      "Training Epoch: 4 [43040/45000]\tLoss: 3.6366\tLR: 0.000010\n",
      "Training Epoch: 4 [43056/45000]\tLoss: 3.6404\tLR: 0.000010\n",
      "Training Epoch: 4 [43072/45000]\tLoss: 3.5406\tLR: 0.000010\n",
      "Training Epoch: 4 [43088/45000]\tLoss: 3.6628\tLR: 0.000010\n",
      "Training Epoch: 4 [43104/45000]\tLoss: 3.6769\tLR: 0.000010\n",
      "Training Epoch: 4 [43120/45000]\tLoss: 3.6093\tLR: 0.000010\n",
      "Training Epoch: 4 [43136/45000]\tLoss: 3.6332\tLR: 0.000010\n",
      "Training Epoch: 4 [43152/45000]\tLoss: 3.5917\tLR: 0.000010\n",
      "Training Epoch: 4 [43168/45000]\tLoss: 3.5611\tLR: 0.000010\n",
      "Training Epoch: 4 [43184/45000]\tLoss: 3.5499\tLR: 0.000010\n",
      "Training Epoch: 4 [43200/45000]\tLoss: 3.5658\tLR: 0.000010\n",
      "Training Epoch: 4 [43216/45000]\tLoss: 3.4716\tLR: 0.000010\n",
      "Training Epoch: 4 [43232/45000]\tLoss: 3.6546\tLR: 0.000010\n",
      "Training Epoch: 4 [43248/45000]\tLoss: 3.6156\tLR: 0.000010\n",
      "Training Epoch: 4 [43264/45000]\tLoss: 3.4717\tLR: 0.000010\n",
      "Training Epoch: 4 [43280/45000]\tLoss: 3.6029\tLR: 0.000010\n",
      "Training Epoch: 4 [43296/45000]\tLoss: 3.6575\tLR: 0.000010\n",
      "Training Epoch: 4 [43312/45000]\tLoss: 3.6035\tLR: 0.000010\n",
      "Training Epoch: 4 [43328/45000]\tLoss: 3.5601\tLR: 0.000010\n",
      "Training Epoch: 4 [43344/45000]\tLoss: 3.5155\tLR: 0.000010\n",
      "Training Epoch: 4 [43360/45000]\tLoss: 3.6885\tLR: 0.000010\n",
      "Training Epoch: 4 [43376/45000]\tLoss: 3.5159\tLR: 0.000010\n",
      "Training Epoch: 4 [43392/45000]\tLoss: 3.5896\tLR: 0.000010\n",
      "Training Epoch: 4 [43408/45000]\tLoss: 3.4983\tLR: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 [43424/45000]\tLoss: 3.5831\tLR: 0.000010\n",
      "Training Epoch: 4 [43440/45000]\tLoss: 3.5875\tLR: 0.000010\n",
      "Training Epoch: 4 [43456/45000]\tLoss: 3.5891\tLR: 0.000010\n",
      "Training Epoch: 4 [43472/45000]\tLoss: 3.5995\tLR: 0.000010\n",
      "Training Epoch: 4 [43488/45000]\tLoss: 3.5461\tLR: 0.000010\n",
      "Training Epoch: 4 [43504/45000]\tLoss: 3.5010\tLR: 0.000010\n",
      "Training Epoch: 4 [43520/45000]\tLoss: 3.5037\tLR: 0.000010\n",
      "Training Epoch: 4 [43536/45000]\tLoss: 3.5309\tLR: 0.000010\n",
      "Training Epoch: 4 [43552/45000]\tLoss: 3.5640\tLR: 0.000010\n",
      "Training Epoch: 4 [43568/45000]\tLoss: 3.5880\tLR: 0.000010\n",
      "Training Epoch: 4 [43584/45000]\tLoss: 3.6589\tLR: 0.000010\n",
      "Training Epoch: 4 [43600/45000]\tLoss: 3.5128\tLR: 0.000010\n",
      "Training Epoch: 4 [43616/45000]\tLoss: 3.5172\tLR: 0.000010\n",
      "Training Epoch: 4 [43632/45000]\tLoss: 3.5402\tLR: 0.000010\n",
      "Training Epoch: 4 [43648/45000]\tLoss: 3.6924\tLR: 0.000010\n",
      "Training Epoch: 4 [43664/45000]\tLoss: 3.6409\tLR: 0.000010\n",
      "Training Epoch: 4 [43680/45000]\tLoss: 3.6327\tLR: 0.000010\n",
      "Training Epoch: 4 [43696/45000]\tLoss: 3.5526\tLR: 0.000010\n",
      "Training Epoch: 4 [43712/45000]\tLoss: 3.5769\tLR: 0.000010\n",
      "Training Epoch: 4 [43728/45000]\tLoss: 3.5781\tLR: 0.000010\n",
      "Training Epoch: 4 [43744/45000]\tLoss: 3.6173\tLR: 0.000010\n",
      "Training Epoch: 4 [43760/45000]\tLoss: 3.5899\tLR: 0.000010\n",
      "Training Epoch: 4 [43776/45000]\tLoss: 3.4751\tLR: 0.000010\n",
      "Training Epoch: 4 [43792/45000]\tLoss: 3.5671\tLR: 0.000010\n",
      "Training Epoch: 4 [43808/45000]\tLoss: 3.5915\tLR: 0.000010\n",
      "Training Epoch: 4 [43824/45000]\tLoss: 3.5685\tLR: 0.000010\n",
      "Training Epoch: 4 [43840/45000]\tLoss: 3.6591\tLR: 0.000010\n",
      "Training Epoch: 4 [43856/45000]\tLoss: 3.5756\tLR: 0.000010\n",
      "Training Epoch: 4 [43872/45000]\tLoss: 3.5603\tLR: 0.000010\n",
      "Training Epoch: 4 [43888/45000]\tLoss: 3.6858\tLR: 0.000010\n",
      "Training Epoch: 4 [43904/45000]\tLoss: 3.5537\tLR: 0.000010\n",
      "Training Epoch: 4 [43920/45000]\tLoss: 3.5931\tLR: 0.000010\n",
      "Training Epoch: 4 [43936/45000]\tLoss: 3.6217\tLR: 0.000010\n",
      "Training Epoch: 4 [43952/45000]\tLoss: 3.6918\tLR: 0.000010\n",
      "Training Epoch: 4 [43968/45000]\tLoss: 3.6801\tLR: 0.000010\n",
      "Training Epoch: 4 [43984/45000]\tLoss: 3.5707\tLR: 0.000010\n",
      "Training Epoch: 4 [44000/45000]\tLoss: 3.5349\tLR: 0.000010\n",
      "Training Epoch: 4 [44016/45000]\tLoss: 3.6132\tLR: 0.000010\n",
      "Training Epoch: 4 [44032/45000]\tLoss: 3.5752\tLR: 0.000010\n",
      "Training Epoch: 4 [44048/45000]\tLoss: 3.5701\tLR: 0.000010\n",
      "Training Epoch: 4 [44064/45000]\tLoss: 3.6990\tLR: 0.000010\n",
      "Training Epoch: 4 [44080/45000]\tLoss: 3.5846\tLR: 0.000010\n",
      "Training Epoch: 4 [44096/45000]\tLoss: 3.6166\tLR: 0.000010\n",
      "Training Epoch: 4 [44112/45000]\tLoss: 3.6882\tLR: 0.000010\n",
      "Training Epoch: 4 [44128/45000]\tLoss: 3.6718\tLR: 0.000010\n",
      "Training Epoch: 4 [44144/45000]\tLoss: 3.6078\tLR: 0.000010\n",
      "Training Epoch: 4 [44160/45000]\tLoss: 3.6160\tLR: 0.000010\n",
      "Training Epoch: 4 [44176/45000]\tLoss: 3.5315\tLR: 0.000010\n",
      "Training Epoch: 4 [44192/45000]\tLoss: 3.4892\tLR: 0.000010\n",
      "Training Epoch: 4 [44208/45000]\tLoss: 3.5059\tLR: 0.000010\n",
      "Training Epoch: 4 [44224/45000]\tLoss: 3.5739\tLR: 0.000010\n",
      "Training Epoch: 4 [44240/45000]\tLoss: 3.5976\tLR: 0.000010\n",
      "Training Epoch: 4 [44256/45000]\tLoss: 3.6070\tLR: 0.000010\n",
      "Training Epoch: 4 [44272/45000]\tLoss: 3.4986\tLR: 0.000010\n",
      "Training Epoch: 4 [44288/45000]\tLoss: 3.6750\tLR: 0.000010\n",
      "Training Epoch: 4 [44304/45000]\tLoss: 3.5750\tLR: 0.000010\n",
      "Training Epoch: 4 [44320/45000]\tLoss: 3.5398\tLR: 0.000010\n",
      "Training Epoch: 4 [44336/45000]\tLoss: 3.6586\tLR: 0.000010\n",
      "Training Epoch: 4 [44352/45000]\tLoss: 3.5331\tLR: 0.000010\n",
      "Training Epoch: 4 [44368/45000]\tLoss: 3.5810\tLR: 0.000010\n",
      "Training Epoch: 4 [44384/45000]\tLoss: 3.5474\tLR: 0.000010\n",
      "Training Epoch: 4 [44400/45000]\tLoss: 3.6951\tLR: 0.000010\n",
      "Training Epoch: 4 [44416/45000]\tLoss: 3.5449\tLR: 0.000010\n",
      "Training Epoch: 4 [44432/45000]\tLoss: 3.4169\tLR: 0.000010\n",
      "Training Epoch: 4 [44448/45000]\tLoss: 3.5728\tLR: 0.000010\n",
      "Training Epoch: 4 [44464/45000]\tLoss: 3.6015\tLR: 0.000010\n",
      "Training Epoch: 4 [44480/45000]\tLoss: 3.5426\tLR: 0.000010\n",
      "Training Epoch: 4 [44496/45000]\tLoss: 3.6089\tLR: 0.000010\n",
      "Training Epoch: 4 [44512/45000]\tLoss: 3.5740\tLR: 0.000010\n",
      "Training Epoch: 4 [44528/45000]\tLoss: 3.5703\tLR: 0.000010\n",
      "Training Epoch: 4 [44544/45000]\tLoss: 3.5841\tLR: 0.000010\n",
      "Training Epoch: 4 [44560/45000]\tLoss: 3.6710\tLR: 0.000010\n",
      "Training Epoch: 4 [44576/45000]\tLoss: 3.5419\tLR: 0.000010\n",
      "Training Epoch: 4 [44592/45000]\tLoss: 3.4687\tLR: 0.000010\n",
      "Training Epoch: 4 [44608/45000]\tLoss: 3.6184\tLR: 0.000010\n",
      "Training Epoch: 4 [44624/45000]\tLoss: 3.5418\tLR: 0.000010\n",
      "Training Epoch: 4 [44640/45000]\tLoss: 3.5406\tLR: 0.000010\n",
      "Training Epoch: 4 [44656/45000]\tLoss: 3.6083\tLR: 0.000010\n",
      "Training Epoch: 4 [44672/45000]\tLoss: 3.6062\tLR: 0.000010\n",
      "Training Epoch: 4 [44688/45000]\tLoss: 3.5961\tLR: 0.000010\n",
      "Training Epoch: 4 [44704/45000]\tLoss: 3.5980\tLR: 0.000010\n",
      "Training Epoch: 4 [44720/45000]\tLoss: 3.5599\tLR: 0.000010\n",
      "Training Epoch: 4 [44736/45000]\tLoss: 3.6312\tLR: 0.000010\n",
      "Training Epoch: 4 [44752/45000]\tLoss: 3.6277\tLR: 0.000010\n",
      "Training Epoch: 4 [44768/45000]\tLoss: 3.5220\tLR: 0.000010\n",
      "Training Epoch: 4 [44784/45000]\tLoss: 3.6698\tLR: 0.000010\n",
      "Training Epoch: 4 [44800/45000]\tLoss: 3.5366\tLR: 0.000010\n",
      "Training Epoch: 4 [44816/45000]\tLoss: 3.6413\tLR: 0.000010\n",
      "Training Epoch: 4 [44832/45000]\tLoss: 3.6436\tLR: 0.000010\n",
      "Training Epoch: 4 [44848/45000]\tLoss: 3.5125\tLR: 0.000010\n",
      "Training Epoch: 4 [44864/45000]\tLoss: 3.5500\tLR: 0.000010\n",
      "Training Epoch: 4 [44880/45000]\tLoss: 3.5446\tLR: 0.000010\n",
      "Training Epoch: 4 [44896/45000]\tLoss: 3.5181\tLR: 0.000010\n",
      "Training Epoch: 4 [44912/45000]\tLoss: 3.6426\tLR: 0.000010\n",
      "Training Epoch: 4 [44928/45000]\tLoss: 3.6036\tLR: 0.000010\n",
      "Training Epoch: 4 [44944/45000]\tLoss: 3.6431\tLR: 0.000010\n",
      "Training Epoch: 4 [44960/45000]\tLoss: 3.5104\tLR: 0.000010\n",
      "Training Epoch: 4 [44976/45000]\tLoss: 3.6145\tLR: 0.000010\n",
      "Training Epoch: 4 [44992/45000]\tLoss: 3.4280\tLR: 0.000010\n",
      "Training Epoch: 4 [45000/45000]\tLoss: 3.4721\tLR: 0.000010\n",
      "epoch 4 training time consumed: 174.91s\n",
      "Accuracy is 0.97860\n",
      "num_zeros / total_parameters ratio is  0.8848418522012796\n",
      "accuracy is  0.9786\n",
      "overall score is  0.9317209261006398\n",
      "Done pruning.\n"
     ]
    }
   ],
   "source": [
    "finetune_prune(model, 3, 4, cifar100_training_loader, cifar100_validation_loader, lr = 0.00001, threshold = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
